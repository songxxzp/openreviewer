[
    {
        "id": "bkvM5izUx8H",
        "original": null,
        "number": 1,
        "cdate": 1666423387889,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666423387889,
        "tmdate": 1666423387889,
        "tddate": null,
        "forum": "U086TJFWy4p",
        "replyto": "U086TJFWy4p",
        "invitation": "ICLR.cc/2023/Conference/Paper5298/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper claims that existing attention-based GNNs are vulnerable to spurious correlations, thereby hampering the generalizability of the model. To improve the generalization ability of the attention-based GNNs, the authors propose a causal inference approach. Specifically, they use a causally-inspired regularization scheme (CAR).  It can be applied to any attention-based GNN architecture. They conduct experiments on node classification tasks, and find the accuracy improvements and loss reductions.",
            "strength_and_weaknesses": "Strength:\n1.\tThey conduct extensive experiments to demonstrate the effectiveness of their work.\n2.\tThe issue of spurious correlation in GNNs is significant.\n\nWeaknesses:\n1. The authors claim that they can solve the problem of spurious correlations. But where is the spurious correlation in their tasks? The authors do not give any detailed descriptions or examples, nor do they show examples of failures of mainstream approaches.\n2. Does the example in Figure 1 exist? The authors use the example of Figure 1 to introduce confounders, but it is doubtful whether there is a corresponding phenomenon in the real-world dataset.\n3. The authors claim that they can improve ANY attention-based GNNs, but only GAT-like networks are introduced in the experiments. But there exist numerous attention-based methods for GNNs [1-5]. It is questionable then whether it will work on other types of attention mechanisms.\n4. For equation (5), the authors only give the regularization term they propose, but do not explain it from a theoretical and causal point of view. For equation (4), the author does not give a detailed definition of $L^p$.\n5. How the edge intervention process is implemented, the author does not give a detailed algorithm process or model architecture diagram to explain in detail.\n6. For experiments, the author reproduces the statement that they use a public data splitting method. However, compared to the public results, the performance of node classification is questionable, for example, the performance of GAT on Cora is probably around 80-83, based on mainstream packages, such as Pyg or DGL.\n7. The authors claim that their method can improve generalization by overcoming spurious correlations, but lack many baseline methods, such as [6].\n\n[1] Gated Graph Sequence Neural Networks, ICLR 2016\n[2] How to find your friendly neighborhood: Graph attention design with self-supervision, ICLR 2020\n[3] Self-attention graph pooling, ICML 2019\n[4] Understanding Attention and Generalization in Graph Neural Networks, NeurIPS 2019\n[5] Causal Attention for Interpretable and Generalizable Graph Classification, KDD 2022\n[6] Handling Distribution Shifts on Graphs: An Invariance Perspective, ICLR 2022\n",
            "clarity,_quality,_novelty_and_reproducibility": "The description of the method is confusing. It is difficult to understand how to implement the method from the current manuscript. \nTheoretical proofs and methodological explanations are missing.\n",
            "summary_of_the_review": "The authors claim that they can solve the spurious correlation problem, but give no examples of their task or failures of existing methods. The description and theoretical justification of the method in this paper are insufficient. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5298/Reviewer_J9zG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5298/Reviewer_J9zG"
        ]
    },
    {
        "id": "V3eSMLtfQfN",
        "original": null,
        "number": 2,
        "cdate": 1666599223476,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599223476,
        "tmdate": 1666599223476,
        "tddate": null,
        "forum": "U086TJFWy4p",
        "replyto": "U086TJFWy4p",
        "invitation": "ICLR.cc/2023/Conference/Paper5298/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The Paper argues that existing studies to improve the generalizability of attention mechanism in GNN are independent of the actual prediction without regard for the training objective. Thus the paper leverages active interventions on nodes\u2019 neighborhoods by deleting some specific edges to align graph attention training with the causal impact of these interventions on task performance. Experiments on three graph attention architectures across an eight-node classification task show improvements.",
            "strength_and_weaknesses": "Strengths:\n1. The paper conducts abundant experiments on a broad range of datasets, which shows consistent performance to demonstrate the effectiveness of CAR.\n2. Qualitative analyses are provided to suggest that the attention-weight changes produced by CAR are intuitive and interpretable.  \n\nWeaknesses:\n1. The paper shares a lot of common idea with the work \u201cCausal Attention for Interpretable and Generalizable Graph Classification, KDD22\u201d, but lack discussion and comparison with it.\n2. The paper does not provide an analysis and discussion of the causal effect score, which is a very important component of the work. Is it theoretical solid in its current form? And experiments are also required to prove its effectiveness compared to other estimations of the causal effect.\n3. Equation 5, p_ij^{n} can be greater than 1 in practice, since removing some noisy edges can also improve the performance. And d(n) >1 will make the value C greater when d(n) increases. However, the author claims that \u201cper-edge attention weights are expected to be smaller for higher-degree nodes\u201d.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good\n\nQuality: Fair\n\nNovelty: Limited\n\nReproducibility: Good",
            "summary_of_the_review": "The proposed method is effective and easy to follow. However, the novelty needs to justify based on related works. And an analysis and discussion of the causal effect score is also required.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5298/Reviewer_iUpK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5298/Reviewer_iUpK"
        ]
    },
    {
        "id": "zNfTN41i77",
        "original": null,
        "number": 3,
        "cdate": 1666649139887,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649139887,
        "tmdate": 1666649139887,
        "tddate": null,
        "forum": "U086TJFWy4p",
        "replyto": "U086TJFWy4p",
        "invitation": "ICLR.cc/2023/Conference/Paper5298/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a regularization framework for training graph attention networks. The proposed method is based on the idea of performing edge interventions to determine the relative importance of an edge to specific prediction tasks. Extensive experiments show that the new regularization framework helps improve generalization while at the same time makes the attention coefficients more interpretable.",
            "strength_and_weaknesses": "Pros: \n- The paper is well structured, well motivated and nicely written. The presentation is clear, the idea is interesting, and the results are easy to follow.\n\nCons/Questions:\n- The test accuracies reported in Table 11 in Appendix A.6 are much lower than what are typically achieved by GNNs. For example, the test accuracy for Cora is usually higher than 0.8 for most existing GNN methods with 1-2 layers, but in Table 11 the test accuracy for GAT is only 0.58. Could the authors comment on what differences had caused such a large gap between existing results and the results reported in this work?\n- For semi-supervised node classification task, usually only a small fraction (e.g. 5% or less) of nodes are labelled. In this case, does it mean that the regularization loss in Equation 3 is computed only on the training nodes, and consequently only the attention coefficients for the training nodes are regularized? If this was true, then the regularization would have no effect on the test nodes. I think I must have misunderstood something, could the authors help clarify the effect of regularization on attention coefficients for nodes whose labels are unknown?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is good. The presentation is clear and the concepts are easy to follow.\n\nQuality is good. The experiments are extensive and well designed.\n\nThe idea to regularize attention coefficients based on edge interventions is interesting, but not very surprising, given prior work that study similar problems. The proposed regularization framework is incremental.",
            "summary_of_the_review": "The paper proposes an interesting regularization framework to improve the generalizability and interpretability of graph attention networks. The idea is interesting and the paper is well written. However the overall method development is incremental and I still have some questions regarding the empirical results. I would increase the score if the authors properly address those questions.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5298/Reviewer_5nKt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5298/Reviewer_5nKt"
        ]
    },
    {
        "id": "oiQyGxoyVp",
        "original": null,
        "number": 4,
        "cdate": 1666727991078,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666727991078,
        "tmdate": 1666727991078,
        "tddate": null,
        "forum": "U086TJFWy4p",
        "replyto": "U086TJFWy4p",
        "invitation": "ICLR.cc/2023/Conference/Paper5298/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper introduces a framework for learning attention weights on the edges of the graph through a graph attention framework. The learned attention is causally-guided, which means that it aims at aligning the attention mechanism with the causal effects of interventions on the graph connectivity. The causal effect of an edge is measured through the impact it has in the final task, thus it is integrated in a loss function of the training phase. The authors show that the proposed framework improves the performance on node classification tasks in standard datasets. Moreover, the learned attention seems to be more interpretable.",
            "strength_and_weaknesses": "Strength: The proposed idea is relatively intuitive and valid. The paper is generally easy to follow. \n\nWeaknesses: Parts of the paper (e.g., definition of causality, discussion of experimental results) are superficially treated (please refer to the detailed comments below)",
            "clarity,_quality,_novelty_and_reproducibility": "Parts of the paper that are related to the algorithm should be more clearly written. The approach is somehow novel but it should be better and more precisely stated and motivated. The experiments should be easily reproducible is the authors eventually make the code available. ",
            "summary_of_the_review": "Below are a few comments that should be addressed by the authors, and could hopefully improve the quality:\n\n1) The causal attention regularization scheme is not clear. A summary of the algorithm should be provided, or a schematic overview that would help the reader understand how Eq (5) is integrated into (3). For example, $\\sigma$ in Eq 5 is not defined. Please make the algorithm as accessible as possible to readers.\n\n2) Is there a reason why the regularisation is applied only to attention networks? Could it be applied to any other architecture as well by adding a regularisation term that represents the auxiliary supervised prediction task that aim to align the weights of the networks with the causal effect of removing specific edges or nodes on the graph?\n\n3) The definition of causality is vague as it captures more correlation of a specific edge with the outcome than causality. Can you comment/clarify that part?\n\n4) How do you define R? It seems that it is an important parameter of your algorithm, and one of the reasons why it does not scale on real graphs. \n\n5) While the method is tested in different datasets, the results are not sufficiently described. Can you comment on the performance of homophily/heterophily datasets? Is there any specific pattern? Does this improved attention scheme help in one or another direction?\n\n6) The neighbor voting regularization scheme is not clear. Please make it precise and clear. \n\n7) The graph pruning approach needs also more details. Why is that method more interesting than classical pruning approaches? \n\n8) While the intuition of the paper is reasonable, there is no clear conclusion on the usefulness of the method. The authors touch upon different aspects such as 1) generalisation 2) interpretability 3) graph pruning, but the results are not strong enough in any of these aspects. The postdoc analysis of the interpretability weight on the ogbn-arxiv is also relatively vague, as some of the statements could be subjective. \n\n9) The authors should include F1 scores in the experiments.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No specific concerns to report. ",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5298/Reviewer_ZGgA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5298/Reviewer_ZGgA"
        ]
    }
]