[
    {
        "id": "9N4Q40A3G3",
        "original": null,
        "number": 1,
        "cdate": 1666563054037,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666563054037,
        "tmdate": 1666563054037,
        "tddate": null,
        "forum": "pNnXjO3q82",
        "replyto": "pNnXjO3q82",
        "invitation": "ICLR.cc/2023/Conference/Paper4538/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes modeling the predictive confidence of the DNN model using RBF-style output layers (Definition 1). This choice is justified by a theoretical argument on the connection between softmax classifier and the  neares centroid classifier, for which a robustness guanrantee can be derived (Section 3). The paper then conducted vision experiments based on standard benchmark and architecture (ResNet-18/50 on MNIST/CIFAR/ImageNet), ans shows accuracy improvement over DUQ, and adversarial robustness improvement over softmax classifier. ",
            "strength_and_weaknesses": "Strength:\n\n* A interesting work that improves the single-model uncertainty methods based on RBF-style classifier (i.e., DUQ).\n* Author investigated (both theoretically and empirically) the implication of adversarial robustness of the distance-based approach.\n\nWeakness:\n\n* Performance is lacking on large-scale benchmarks. There are several single-model methods developed and tested on, e.g., ImageNet with ResNet50 (e.g., see MIMO or SNGP on Uncertainty Baselines: https://github.com/google/uncertainty-baselines/tree/main/baselines/imagenet), which are generally competitive or outperform standard softmax classifier in Table 1. This may somehow discount the emprirical utility of Gauss classifier, as it still incurs a hard uncertainty v.s. utility tradeoff. This somehow leads me to question the utility of centroid-based classifier in more difficult tasks (CIFAR-100 and ImageNet).\n\n* Missing evaluation metric for uncertainty performance: In Table 1, please consider evaluate model uncertainty using a standard evaluation metric such as ECE.\n\n* Missing treatment of Lipschitz constant control / related literature review. As authors commented, Lipschitz constant is important for guanrantee model's uncertainty and robustness performance. However, there are a stream work in the single-model uncertainty literature (e.g., [SNGP](https://arxiv.org/abs/2205.00403), [DUE](https://arxiv.org/abs/2102.11409), [DDU](http://www.gatsby.ucl.ac.uk/~balaji/udl2021/accepted-papers/UDL2021-paper-022.pdf) etc) that tackles this by combining spectral normalization with distance-based classifier, which generally outperforms DUE and works well for high-dimensional benchmarks. Please consider include them into related work, and optionally absorbing some of these baseline techniques into methodology or include these previous work as baselines.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and easy to follow.",
            "summary_of_the_review": "This is an interesting work that theoretically establishes the connection between softmax classifier and centroid classifier, empirically proposed an improved formulation of RBF-style last-layer classifier than outperforms its similar predecessors (i.e., DUQ), and brings the consideration of adversarial robustness into the picture. \n\nHowever, the work is slightly disconnected from the current uncertainty literature in that it does not sufficiently review or compare with its contemporary methods (e.g., SNGP, DUE) that handles Lipschitz control and uses distance-based classifier, and empirically its accuracy performance is not on par with the other uncertainty methods, and its uncertainty performance is not rigorously evaluated with standard performance metrics (e.g., ECE). Adding literature review and additional baseline comparison should address these issues to some extent.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4538/Reviewer_gCc4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4538/Reviewer_gCc4"
        ]
    },
    {
        "id": "UPY33yXzyqG",
        "original": null,
        "number": 2,
        "cdate": 1666652084174,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666652084174,
        "tmdate": 1669063612049,
        "tddate": null,
        "forum": "pNnXjO3q82",
        "replyto": "pNnXjO3q82",
        "invitation": "ICLR.cc/2023/Conference/Paper4538/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focuses on uncertainty quantification and robustness. The authors find that existing work in uncertainty quantification mostly revolves around the confidence reflected in the input feature space. The authors focus on the learned representation of the network and analyze the confidence in the penultimate layer space. The proposed new confidence measure is centroid-based and hence no longer suffers from the artificial confidence inflation of out-of-distribution samples. \n",
            "strength_and_weaknesses": "Strengths:\n\n1. The authors formally prove that independent of optimization-procedural effects, a set of centroids always exists such that softmax classifiers are the nearest centroid classifiers.\n2. The authors proposed a new confidence measure that is centroid-based and hence no longer suffers from the artificial confidence inflation of out-of-distribution samples. \n3. The proposed centroidal confidence measure provides a robustness certificate against attacks.\n\n\nWeaknesses:\n\n1. What is the motivation of Section 3? What is the connection between uncertainty and robustness?\n2. Lack of important related work of uncertainty quantification, such as [1, 2].\n3. It is better to add more baselines to demonstrate the effectiveness of the proposed method.\n4. Since the paper focuses on uncertainty quantification, it may necessary to show some experiments result about out-of-distribution detection.\n\n\n[1] Malinin, Andrey, and Mark Gales. \"Predictive uncertainty estimation via prior networks.\" Advances in neural information processing systems 31 (2018).\n\n[2] Malinin, Andrey, and Mark Gales. \"Reverse kl-divergence training of prior networks: Improved uncertainty and adversarial robustness.\" Advances in Neural Information Processing Systems 32 (2019).\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-presented and organized. The proposed idea is novel. The authors provide the code for experiment result reproduction.\n",
            "summary_of_the_review": "See Strength And Weaknesses:\n\n------------ after rebuttal ------------\n\nThe authors' response addressed some of my concerns. But I still suggest adding more baselines and out-of-distribution detection experiments in the future version to demonstrate the effectiveness of the proposed method. Therefore, I will keep my score.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4538/Reviewer_D1u1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4538/Reviewer_D1u1"
        ]
    },
    {
        "id": "RhGEewQapz",
        "original": null,
        "number": 3,
        "cdate": 1666967609059,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666967609059,
        "tmdate": 1666967609059,
        "tddate": null,
        "forum": "pNnXjO3q82",
        "replyto": "pNnXjO3q82",
        "invitation": "ICLR.cc/2023/Conference/Paper4538/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a new method for measuring confidence and increasing the robustness of neural networks. The core of the method is replacing the last linear layer and softmax with learnable per-class Gaussians (centroids).   \nTo address convergence problems, the paper proposes simplified Gaussians and adding negative log-likelihood with a margin to a loss.\nThe method is backed by proof that classification with centroids is at least as expressive as linear layer classification.",
            "strength_and_weaknesses": "Strengths\n* The paper is well-written, the explanation is clear and the flow is good.\n* The proposed method appears naturally, backed up by a sound theoretical background.\n* Though it's closely related to another method, the one proposed in the paper feels simpler, requiring fewer resources and being more robust at the same time.\n\nWeakness\nMy main concern is that experiments feel shallow\n* First of all, the authors refer to DUQ and make comparisons mostly with it. But DUQ by itself focuses on out-of-distribution detection, not robustness, so I would expect out-of-distribution experiments. If the robustness is expected to be the strongest point for the method, then I would expect some baseline from this area, e.g. adversarial training or improved Lipschitz constant with methods like spectral normalization.\n* The authors mention restricting of Lipschitz constant and it's a part of a proof condition, but it's not addressed in the implementation and experiments. What's more concerning, local Lipschitz constant restriction with spectral normalization is part of the DUQ method, but I feel that it wasn't used in the paper this way. The provided repository doesn't contain the code for it, so I have some concerns about the validity of the provided results.\n* I'm not sure what conclusion should we make from confidence in table 1. Mean confidence is not a very meaningful metric, as with postprocessing like temperature scaling you can get almost arbitrary values for it. The calibration plot would be much more meaningful in this case. Particularly, one can argue that having mean confidence 0.87 with 0.99 accuracy is strongly under-confident.\n* While the statement in theorem 1 seems valid, there are a few issues in derivation, I believe it could use some polishing. E.g., missed opening bracket in eq.1. The sign for b seems wrong as well there, should be '-' in the third line of the appendix.  It's stated that the second term eq.1 could be made zero, but in fact, it is only shown to be constant.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and focused; the statements in the paper are correct. ",
            "summary_of_the_review": "While I have concerns about the experimental part, the paper is coherent and original overall.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4538/Reviewer_SMCi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4538/Reviewer_SMCi"
        ]
    }
]