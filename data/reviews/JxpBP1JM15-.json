[
    {
        "id": "tDTuXFcRNnD",
        "original": null,
        "number": 1,
        "cdate": 1666582121231,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666582121231,
        "tmdate": 1666762451727,
        "tddate": null,
        "forum": "JxpBP1JM15-",
        "replyto": "JxpBP1JM15-",
        "invitation": "ICLR.cc/2023/Conference/Paper3676/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper shows that an algorithm using only forward-mode differentiation can learn well even on ImageNet-scale problems. The key to achieve this result is to use a carefully crafted neural-network architecture with many local loss functions. ",
            "strength_and_weaknesses": "Strengths:\n---\nThe paper is well-written and was easy to follow, except some small details (see clarity section). \n\nTo best of my knowledge, this is the first paper which gives reasonable results on ImageNet-scale problems using a backprop-free algorithm.\n\nThe main advantage of the activity perturbation seems to be the reduced variance. Another way of variance reduction is to consider multiple perturbations and averaging them. Perhaps on a smaller dataset, an experiment could be added which shows how the results change under an increasing number of perturbations. \n\nWeaknesses:\n---\nThe method is not evaluated on standard neural architectures (or perhaps did not perform well on them?). But this does not seem like a big weakness to me, since innovations in training algorithms may require also new architectures as current DL models may be \"tuned\" to work well with backpropagation. \n\nWhile the proposed backprop-free methods can learn well, it seems still much worse than standard training on standard architectures. I am not too familiar with the proposed architecture, but note that a small MLP trained with back-prop on MNIST reaches ~1.5% test error, which can be further reduced using tricks like drop-out, etc.   I am a bit surprised that the methods have ~2.5% test error on MNIST despite 0% training error. Could this be due to overfitting? Maybe adding a weight-decay regularizer could help. \n\nIn Table 3 and 4, training error is also written in \"bold face\". Ideally, a good training algorithm has similar training and test error indicating that there is no over-fitting to the training set.  This appears to be the case for \"FG-W\" method, which however does not perform very well. \n\nMy suggestion here is simply not bold the training error, as it is not clear to me whether having a small training error is desirable.  If the computational resources are available, it would also be good to re-run the experiments over multiple random seeds and report mean and standard error.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n---\nSection 3.2 was easy to follow, perhaps writing that one looks at the directional derivative along a random direction can improve the connection to the previous Section 3.1 which introduces directional gradients. It was a bit unclear why one uses a Gaussian distribution for the perturbation opposed to other distributions? I was also curious if there are connections to mean-field variational inference method which also use weight-perturbation to train NNs (though in a different way).\n\nSection 3.3 was more difficult to understand. In particular, in Equation 3 it is not clear to me how the perturbation in the activations is mapped back to a gradient in the weights.  How is that equation derived?\n\nThe proof of the variance of the estimators looks like a quite tedious calculation spanning multiple pages and I could not verify its correctness.\n\nReproducibility:\n---\nThe result do not appear easily reproducible from the description alone, so it will be important for the code to be released. ",
            "summary_of_the_review": "While the paper may be lacking in novelty (e.g., activity perturbation has been proposed before), this is one of the first works demonstrating that backprop-free methods can learn well on ImageNet-scale problems. Such results are interesting for the community, and I therefore recommend acceptance.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3676/Reviewer_RQfz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3676/Reviewer_RQfz"
        ]
    },
    {
        "id": "lgFaQbzFAMR",
        "original": null,
        "number": 2,
        "cdate": 1666607852009,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666607852009,
        "tmdate": 1668666653058,
        "tddate": null,
        "forum": "JxpBP1JM15-",
        "replyto": "JxpBP1JM15-",
        "invitation": "ICLR.cc/2023/Conference/Paper3676/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a new method for training neural networks, combining forward mode auto-differentiation with directional gradients (forward gradient), weight permutation, and a novel way of using local losses. When combined with a new, complimentary architecture they propose (Local-Mixer), they show that their method is superior to other backprop-free algorithms, on a variety of classification tasks.",
            "strength_and_weaknesses": "Strengths:\n1. The paper does a good job reviewing past literature and building up to the proposed solution.\n2. The solution itself (both LG-FG-A and the arch, LocalMixer), appears to be non-trivial and interesting.\n3. For a backprop (BP) free algorithm, the results for large tasks presented in the paper are impressive. The comparison also includes BP-like methods, which helps at illustrating where the gaps in performance are coming from. \n4. The paper includes a large variety of ablation tests to showcase the benefit of different components- this is very helpful since the solution includes both a new method and a new neural network architecture, and it would be otherwise difficult to asses the empirical results. \n5. The paper closely monitors the biological plausibility of the algorithm, in line with the motivation of the paper of producing a biologically plausible method for training a neural network.\n\n\nWeaknesses:\n1. Despite its key importance to the paper, I found section 4 (Local Losses), to be too lacking in details. As is, the implementation of the local losses is not clear to me. \n    * I found the extensive use of the StopGrad operator to be confusing, and I wonder if the section would be clearer, had the paper used partial-derivative notations instead (With the StopGrad included in the implementation details). All in all, I am not sure why replicating the features with different gradient masks for different losses is better than just aggregating the losses (It's makes the algorithm more complex, but appears to be quite similar).\n   * The local losses (supervised and contrastive) use a shared linear layer. Is it shared across all local losses in a given layer? How is it trained (for either variation)? Unless I missed something, it is very not intuitive to me that a single shared weight is sufficient to give helpful information for all the different losses in the layer. I would appreciate this point being elaborated upon.\n   * The fused implementation seems to be a key to reducing the memory footprint to be scalable, but only the general concept is explained. The paper empirically compares a naive implementation with the fused implementation, without giving sufficient details as to what either of these implementations means. As such, the results in figure 5 are not reproducible.\n   * The contrastive method uses two different \"views\" for the InfoNCE loss, but I did not understand what these views are. Both views share permutation, and neither MNIST/CIFAR include data augmentation, so how are these views different from each other?\n\n2. The submission did not include code. When combined with the previous points, this raises some reproducibility concerns.\n\n3. The trade-offs for using the algorithm, and different variations of it, are not explained. E.g., Figure 5 illustrates the benefit of the \"fused\" implementation in terms of both memory and runtime, but it is not clear what the cost of adding more groups is when the fused implementation is used. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is technically correct and proposes novel techniques and neural network architecture.\n\nFor the most part, the paper is clearly written. Related work is mentioned and properly cited.\n\nSome concerns regarding clarity and reproducibility were raised in the weaknesses section.",
            "summary_of_the_review": "I found the paper to be of high quality-- it is well-written, and provides novel methods that will improve the applicability of backdrop-free training.\n\nMy main concern is that section 4 was not clear enough, and I am not confident I understood how local losses (a major part of the contribution) were implemented. I intend to increase the score from 6 to 8 once all the details are clarified. (Edit: Updated to 8)",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3676/Reviewer_g2TA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3676/Reviewer_g2TA"
        ]
    },
    {
        "id": "T4bDieWsBU",
        "original": null,
        "number": 3,
        "cdate": 1666740767044,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666740767044,
        "tmdate": 1666740913453,
        "tddate": null,
        "forum": "JxpBP1JM15-",
        "replyto": "JxpBP1JM15-",
        "invitation": "ICLR.cc/2023/Conference/Paper3676/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper address the scalability issue of forward gradient learning by employing  many different local greedy loss functions (blockwise, patch-wise, and group-wise local losses, and a combination of all three). The paper shows good performance on MNIST and CIFAR-10, and also outperforms other backprop free algorithms on ImageNet. ",
            "strength_and_weaknesses": "Strengths:\n\n- The paper is easy to read. \n- The paper tackles a very interesting problem.\n- The way the local losses are instantiated is interesting, as naive application of local losses does not seem to result in improvement of the results. \n\nWeaknesses:\n\n\"Silver et al. (2022) proposed to update the weights based on the directional gradient along a random perturbation direction\"\n\nThis seems a bit mis-leading. Silver et. al (2022) proposed to update the weights based on the directional gradient along a random as well as along different learned directions (as a result of truncated backprop or as a result of learned critic), which further helps to reduce the variance of the gradient. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is easy to read.\nQuality: The paper studies an interesting problem.\nNovelty: The paper builds on Silver et. al 2022, and proposes to augment forward gradient with local losses. The way the local losses are instantiated are very interesting. \nReproducibility: The paper seems easy to reproduce.\n\n",
            "summary_of_the_review": "The paper tackles an interesting problem i.e., thinking about more biologically plausible learning rules as compared to backprop. The reviewer likes the results, as well as clarity of the paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3676/Reviewer_jdBC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3676/Reviewer_jdBC"
        ]
    }
]