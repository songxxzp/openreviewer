[
    {
        "id": "oCX7dz9aB9s",
        "original": null,
        "number": 1,
        "cdate": 1666268131566,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666268131566,
        "tmdate": 1666268131566,
        "tddate": null,
        "forum": "yCtxVkTaXg",
        "replyto": "yCtxVkTaXg",
        "invitation": "ICLR.cc/2023/Conference/Paper2417/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "This paper first proposes a novel deep graph-level anomaly detection model, which learns the graph representation with maximum mutual information between substructure features and global structure features while exploring a hypersphere anomaly decision boundary. The numerical and visualization results on a few graph datasets demonstrate the effectiveness and superiority of the methods.",
            "strength_and_weaknesses": "I am unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "clarity,_quality,_novelty_and_reproducibility": "I am unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_review": "I am unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2417/Reviewer_fADg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2417/Reviewer_fADg"
        ]
    },
    {
        "id": "1au1-dId6O",
        "original": null,
        "number": 2,
        "cdate": 1666538831535,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666538831535,
        "tmdate": 1670595451293,
        "tddate": null,
        "forum": "yCtxVkTaXg",
        "replyto": "yCtxVkTaXg",
        "invitation": "ICLR.cc/2023/Conference/Paper2417/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed a graph anomaly detection method through mutual information maximization. The key contributions are proposing (i) an orthogonal projection layer for the decision boundary correction and (ii) a two co-centered hyperspheres structure for estimating the normal distribution. Experimental results on multiple datasets show the effectiveness of the proposed method.",
            "strength_and_weaknesses": "Strength:\n1.\tThe proposed method is simple yet effective. It seems possible to apply the proposed orthogonal projection layer and the bi-hypersphere compression model to many other graph anomaly detection methods.\n2.\tThe paper is well-written and easy to follow. The main contributions are clearly summarized.\n3.\tExperiments on multiple datasets show the effectiveness of the proposed method.\nWeaknesses:\n1.\tThe motivation for the bi-hypersphere compression is still difficult to understand. The authors claim that anomalous data may appear in the empty inner decision region. But Figure 3 did not show this phenomenon. More importantly, the authors did not explain why bi-hypersphere compression can help. For example, if the normal area becomes more compact, how can we guarantee that anomalous data will not appear in the empty inner decision region? The authors may need to provide some comparisons to show the proposed method can indeed solve this problem.\n2.\tImprovements on some of the datasets seem unreasonable. For example, in Table3, compared with DOHSC, DO2HSC often improves the results by less than 2% on most of the datasets. But on class 1 of ER_MD, DO2HSC has a more than 20% improvement. Analysis needs to be provided. For example, it will be very interesting to show, on ER_MD, more anomalous data will appear in the empty inner decision region so that DO2HSC has an impressive improvement on this dataset.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and very clear. Since source codes are provided in the supp, it seems possible to reproduce the results.",
            "summary_of_the_review": "This paper proposed a simple yet effective method for graph anomaly detection. Authors may consider the weakness shown above and revise the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2417/Reviewer_bgGj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2417/Reviewer_bgGj"
        ]
    },
    {
        "id": "swbgB-Bwcgo",
        "original": null,
        "number": 3,
        "cdate": 1666680807439,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666680807439,
        "tmdate": 1666680807439,
        "tddate": null,
        "forum": "yCtxVkTaXg",
        "replyto": "yCtxVkTaXg",
        "invitation": "ICLR.cc/2023/Conference/Paper2417/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The work presents a new one-class classification method for graph-level anomaly detection. The new components added to the original one-class objective include a local-global graph representation learning, a SVD-based representation projection, and a bi-hypersphere learning. The first two newly added components are directly taken from existing work. The bi-hypersphere learning is new, as far as I know. The method is evaluated on six graph datasets and compared with graph kernel and GNN-based methods.",
            "strength_and_weaknesses": "Strengths of the paper are:\n- The work tackles an important yet under-explored problem -- graph-level anomaly detection. Unlike node anomaly detection, graph-level anomaly detection methods, especially deep neural network-based methods, are relatively limited.\n- The bi-hypersphere learning objective is an improved version of popular deep one-class classifiers, which is new, to the best of my knowledge.\n- The effectiveness of the SVD-based representation projection and the bi-hypersphere learning is justified via the ablation study.\n\nThe negative aspects of the paper include:\n- Although the paper is focused on graph-level anomaly detection, the key design or the newly proposed component (i.e., the bi-hypersphere learning) is generic and does not take into account of the graph-level graph mining tasks. The only component relevant to graph-level detection is the mutual information maximization between local and global representations, which is taken directly from existing work, such as Infograph. The main concern here is that the presented method is not designed specifically for graph-level anomaly detection. \n- The bi-hypersphere learning seems to be generalizable to different types of data. Results on image/tabular data would be important  to justify whether the main argument of the bi-hypersphere learning is effective. \n- There have been many variants of deep one-class classifier for learning more meaningful one-class models, such as [1-4]. They can be easily combined with loss functions like Infograph to adapt to graph-level anomaly detection. It's unclear what are the advantages of the proposed method compared to these more advanced one-class classification methods.\n- The datasets used are very different from the ones in the competing methods like GLocalKD and OCGTL. Their performance seems to be less effective than the ones reported in their original paper. What are the reasons/motivations behind? GLocalKD and OCGTL seem to work well on some commonly used graph datasets, e.g., PROTEINS, AIDS, and REDDIT. How is the performance of the proposed method on those datasets?\n- The argument that \"In contrast, there is little work on graph data despite the fact ...\" is invalid. To my knowledge, there have been many studies on anomalous node detection; less work is on graph-level anomaly detection.\n- The benefit of using the mutual information maximization loss is not examined\n- To my understanding, the method can be sensitive to the setting of the percentile parameter in eq. 14, but no empirical results are given about this sensitivity.\n\n**References**\n- [1] \"DROCC: Deep robust one-class classification.\" In International Conference on Machine Learning, pp. 3711-3721. PMLR, 2020.\n- [2] \"Learning and evaluating representations for deep one-class classification.\" arXiv preprint arXiv:2011.02578 (2020).\n- [3]  \"Explainable deep one-class classification.\" arXiv preprint arXiv:2007.01760 (2020).\n- [4] \"Deep one-class classification via interpolated gaussian descriptor.\" In Proceedings of the AAAI Conference on Artificial Intelligence, vol. 36, no. 1, pp. 383-392. 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "The overall paper clarity is fairly good. One of the components is new, but the advantages of this new one-class learning design compared to recently proposed ones are unclear.",
            "summary_of_the_review": "The paper has some merits, but the cons outweigh the pros, as discussed above.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2417/Reviewer_P4g5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2417/Reviewer_P4g5"
        ]
    },
    {
        "id": "ba49sLtuOb",
        "original": null,
        "number": 4,
        "cdate": 1667476333925,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667476333925,
        "tmdate": 1670134946484,
        "tddate": null,
        "forum": "yCtxVkTaXg",
        "replyto": "yCtxVkTaXg",
        "invitation": "ICLR.cc/2023/Conference/Paper2417/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors deal with outlier detection on graphs.\nThey start with the paper on InfoGraph \"INFOGRAPH: UNSUPERVISED AND SEMI-SUPERVISED\nGRAPH-LEVEL REPRESENTATION LEARNING VIA MUTUAL INFORMATION MAXIMIZATION\" by Sun et al , combined with SVDD, and propose two modifications.\n\n1. DOHSC adds on top of infograph+SVDD a singular vector standardization and a projection on the first dimensions corresponding to the largest k' = 8 directions on the right side of the SVD (equation 9) . (see notes in Strength and weaknesses, that the code does actually something different)\n\n2. DO2HSC replaces the SVDD objective by a two-sided objective which aims to identify outliers by samples which have a too large or too small distances from the center.\n\nThis comes with a 2 sided loss (penalizing too large and too small distances from the center), and calculates a distance measure which is positive if the sample distance from the center is either too large or too small.\n\n",
            "strength_and_weaknesses": "Strengths:\nthe paper does several experiments on graph datasets.\n\nWeaknesses:\n\n1. the down projection does something else than the text states,\n\nwhen applying W = V_{k'} \\Lambda^{-1}_{k'}  \nto H= U \\Lambda V^\\top \nthen the result is:\nU_{k'} (in math) aka U[:,:d]  (in python/pytorch)\n\nIt is NOT U[:,:d] I_d V^\\top[:d,:] as what would be the orthogonal projection onto the first d dimensions of a SVD decomposition.\n\nWhat did the authors want to compute  ? \n If it is U[:,:d], then the approach needs to be renamed, as that is not an orthogonal projection onto the first dimensions of U[:,:d] I_d V^\\top[:d,:] .\n\n2. It is not clear whether the singular vector standardization (by \\Lambda^{-1}_{k'}) or the downprojection onto the first k' helps to improve DOHSC over infograph+SVDD. \nTo understand this, an experiment would be useful where one only projects onto the top k' dimensions in the Orthogonal_Projector module, without the .matmul(torch.linalg.inv(S)[:d,:d]) in the weightConstraint class  (or just .matmul(torch.eye(d))  )\n\n3. the outlier detection is based on class-labels only. Depending on the dataset this might cluster too easily compared to outliers in the wild. \n\n4. an analysis is missing why prohibiting too small distances from the center is a good idea.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper readability is okay. \n\nAs for the quality, there is a certain issue with weakness 1. \nAs for experiments see weakness 3. \nThere is no analysis why the two proposed changes are helpful. \nThese factors reduce the quality somewhat.\n\nRegarding quality and reproducibility: several AUCs in the baseline experiments are substantially below 0.5. This indicates that one would obtain a very good AUC if one inverses the prediction rule for outliers. This can be due to the instability of the baselines or due to suboptimal parameters. One can choose not to hold it against the submission.\n\nThe two propositions over infograph+SVDD are novel. ",
            "summary_of_the_review": "The paper proposes two interesting changes. The orthogonal projection could be a mistaken implementation, see weakness 1, which is a point of lack of clarity and quality which has to be addressed.\n\n*edit* after reading the rebuttal, the reviewer is agreeable to increase his rating to marginally above the accept threshold.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2417/Reviewer_mmsV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2417/Reviewer_mmsV"
        ]
    }
]