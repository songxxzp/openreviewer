[
    {
        "id": "A0HBjAlz13",
        "original": null,
        "number": 1,
        "cdate": 1666592234582,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666592234582,
        "tmdate": 1670116564104,
        "tddate": null,
        "forum": "Y1J29OryQg",
        "replyto": "Y1J29OryQg",
        "invitation": "ICLR.cc/2023/Conference/Paper6408/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The knowledge graph completion is a key to studying the correlations in data. This paper proposes to study the causality of the KGC from a causal graph point of view. The method is evaluated by empirical experiments. However, in total, the novelty of the approach and the profound impact are both limited. \n\n",
            "strength_and_weaknesses": "Strength: The authors evaluate the proposed causal KCG by relatively comprehensive empirical experiments. \n\nWeaknesses: \n\n1. The preliminaries and background introduction for the SCM models should be more comprehensive, as this is the fundamental point for the later KGC model development. \n\n2. The logarithmic function definition for designed confounders is restrictive. Otherwise, the author should refer to the existing literature for such definition and evidence. \n\n3. In the one-layer neural network, is it able to approximate the complex confounder? This seems to disobey the universal approximation theorem in DNN. \n\n4. The score function $f(h,r,t)$ is not clear how affect the conditional probability $P(y|h,r,t,z_h,z_r,z_t)$. In addition, the linear decomposition might require the $g$ function is soothing. However, the authors seem not to address or mention this part in the paper.\n\n5. The balancing of $\\alpha_{h}, \\alpha_{r}$ and $\\alpha_{t}$ is crucial to balance the bias-variance tradeoff, the authors might be better to discuss this. \n\n6. The authors define a novel metric for evaluation purposes. I was wondering if is there any existing metric for better comparison.\n\n7. The causal-distmult-2 outperforms the competing methods in FB15k-237. But other ones, like causal TransE-1, RotatE-1, and ComplEX-1 are best. Could the authors give some analysis of this phenomenon? ",
            "clarity,_quality,_novelty_and_reproducibility": "1. The notation is abusive. For example, it would be better to use a different note for the head entity and tail entity. \n\n2. Figure 1. In the causal graph traditional KGC model, illustration example (a) is just one of the cases. The authors might give a more advanced structure in the existing literature for illustrating purposes. \n\n3. In related work, it would be better to provide closely related literature in explainable and interpretable knowledge graph methods. \n\n",
            "summary_of_the_review": "The paper studies the causality of KGC and uses numerical experiments to justify the proposed method. However, the development of the method is not clear and the paper is not well-presented. This limits the potential impact of the paper. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6408/Reviewer_L8AG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6408/Reviewer_L8AG"
        ]
    },
    {
        "id": "xvxCWG51xQi",
        "original": null,
        "number": 2,
        "cdate": 1666618954098,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666618954098,
        "tmdate": 1666618954098,
        "tddate": null,
        "forum": "Y1J29OryQg",
        "replyto": "Y1J29OryQg",
        "invitation": "ICLR.cc/2023/Conference/Paper6408/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a novel approach to the task of knowledge graph completion, which draws on insights from the field of causal reasoning to obtain an adjustment that should - in principle - help with bias correction in the data underlying the knowledge graph. It considers two types of artificial confounders, one based on the log-popularity and another one, based on a one-layer neural network (aka a perceptron). ",
            "strength_and_weaknesses": "Strengths: The overall presentation is clear, and the method is explained in a logical way that is easy to follow. The abstract sets the stage, the introduction reviews relevant work, and the methods clarify the novelty of the work. The results are presented fairly. The conclusion points out that much future work remains.\n\nWeaknesses: These are easier to list for specific sections, which I have done below.\n\nAbstract: \"our causal KGC models achieve better performance than traditional KGC models\" - on what inputs?\n\nIntro: \"the world is driven by causality rather than correlation\" - over-generalisation, especially as causality is often more difficult to observe\n\nBackground: the embedding isn't motivated or explained; is it externally specified? learned in the graph construction process? In the tensor representation of the causal graph each entity and relation is an element of a set, not a vector, so this needs a clear explanation/illustration.\n\nMethods: \n\n1) While the entire process is motivated by causal inference and the removal of confounders, the simplifying assumptions ultimately amount to a. a frequency penalty and b. a learned entity-specific or relationship-specific penalty. Would it not have been easier to present the entire approach as a penalty-based one, and then provide the motivating causal inference-based derivation in the appendix?\n\n2) The group-theoretic view does not provide any additional value or insight to the paper; I say this despite being a big fan of group theory myself. I recommend removing this section altogether.\n\n3) A clearer differentiation from inverse propensity scoring should be provided by explicitly showing how IPS does something different from the frequency penalty introduced in the method.\n\nResults: \"different evaluation metrics\" - it seems that you only used a single evaluation metric in the end, namely, Metric(-1,-1,-1)?\n\nDiscussion: \"our model is [...] model-agnostic\" is confusing; perhaps \"our approach is [...]\" instead?\n\nAppendix: the standard deviation of frequency is not a great way to quantify bias; perhaps fitting a modified Zipf's law or computing a Gini coefficient could be more useful?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is high, although a few grammar and language errors interfere at certain places (the use of \"Roughly\" is inconsistent with current use, in particular).\n\nQuality is moderate as there are three datasets considered (good), but the results are evaluated with a single metric, and thus no \"sensitivity analysis\" is carried out (poor); there is also a throwaway reference to group theory which does not seem to advance the paper in any way.\n\nNovelty is moderate insofar as similar methods have been previously proposed and some of them (especially IPS) perform comparably well.\n\nReproducibility is low as no source code or link to a repository containing it is provided (although the methods are described fairly clearly, this is insufficient for reproducing the results as the learned parameters are missing, as is the code and the RNG seeds used to generate them).",
            "summary_of_the_review": "Overall, a decent paper with a moderate advance over the current state-of-the-art; it is a \"one-trick pony\" paper, with a single idea being presented and implemented, and evaluated with a single metric.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6408/Reviewer_YGuw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6408/Reviewer_YGuw"
        ]
    },
    {
        "id": "u4PAO4dMwk",
        "original": null,
        "number": 3,
        "cdate": 1667247175193,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667247175193,
        "tmdate": 1667247175193,
        "tddate": null,
        "forum": "Y1J29OryQg",
        "replyto": "Y1J29OryQg",
        "invitation": "ICLR.cc/2023/Conference/Paper6408/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a causal KGC model to alleviate the data bias issues that come from the data collection process, and further proposed an evaluation method to evaluate the causal KGC models on observation datasets. Moreover, the authors also provided a different perspective of viewing KGC from group theory. Numerical experiments showcased that the causal KGC models outperform traditional KGC models in most cases. ",
            "strength_and_weaknesses": "Strength: It's an interesting ideal of trying to incorporate causal inference techniques into traditional KGC models, and the group theory perspective of KGC is quite novel.\n\nWeakness: 1.I agree that in some sense, data bias can be treated as confounders in the causal model, however, I do not think it's appropriate to simply define the confounders as the \"artificially designed confounders\" and \"learnable confounders\" in this paper. Confounders are the type of variables that have causal impact over both treatment and outcome variables, but in the definition of \"artificially designed confounders\" in this paper, they are essentially treated as the variables that are impacted by treatment variables. In other words, the directions of certain arcs in the causal graph changed.    \n2. I appreciate the attempt of explaining KGC from the group theory perspective. However, I cannot see if there's an potential application or new insights from such explanation. \n\nOther comments: 1. Too much identical sentences in Abstract, Introduction and Conclusion.      \n2. In multiple places, you wrote \"In this paper, we propose causal KGC models to alleviate the issues ...\" Here you should be more specific by saying \"data bias issues\".   \n3. You mentioned \"causal graph\" is multiple places of this paper. However, in the causal KGC model, all causal graphs are essentially identical and they have the same topology as the graph (b) in Figure 1. The reason why causal graph in traditional causal inference is important is because, it gives people a direct way of viewing the relationship between variables, which can help people identify what are confounders, what are instrumental variables etc. By introduction causal model into KGC, here different triplets (h,r,t) will still have no connecting arcs between them, except the newly added confounder variables $(Z_h, Z_r, Z_t)$. For that reason, I do not think you should highlight the concept of \"causal graph\" in this paper at all.   \n4. You mentioned a few times that \"the main feature of causal is invariance and symmetry (Arjovsky et al., 2020)\". However, I did not see that from your cited literature. Why is the main feature of causal is symmetry? A causes B means something totally different from B causes A.    \n5. First sentence in Section 2.1, \"let $\\epsilon$ denote(s) and ... denote(s)\".  \n6. Bottom of page 4: \"$P(y \\mid h, \\ldots, z_t)$ evaluates...\" this is an incomplete sentence.   \n7. Bottom of page 4: \"confounders (is)\" should be \"are\".   \n8. When constructing the \"learnable confounders\", how to learn those neural networks?   \n9. On page 5, $z_t'$ should be $z_{t'}$.  \n10. Please add references to those ranking metrics $MRR$ and $H@N$.  \n11. Should not use the word $Metric$ as the name of your evaluation metric.   \n12. In Section 3.3, \"should invariant\" -> \"should be an invariant\".  \n13. In Section 3.3, \"which may (do) not match ...\"  \n14. Last sentence of Section 5.2: I cannot see the reason from the degree of data bias. Please explain more. ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is poorly written, bears with various typos and incomplete sentences, and the technical details are hard to follow. Overall, I suggest the authors to rewrite the Introduction and Background sections completely, and try not to use repeated sentences in Abstract, Introduction and Conclusion. ",
            "summary_of_the_review": "Based on my comments in the previous sections, even though this paper has certain merit of introducing causal model into KGC, but overall I do not think the contribution is significant enough to make this paper be accepted as the ICLR conference proceeding. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6408/Reviewer_v6Kd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6408/Reviewer_v6Kd"
        ]
    }
]