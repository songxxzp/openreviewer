[
    {
        "id": "SJucaKCBBT",
        "original": null,
        "number": 1,
        "cdate": 1665759363500,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665759363500,
        "tmdate": 1665759363500,
        "tddate": null,
        "forum": "OoOIW-3uadi",
        "replyto": "OoOIW-3uadi",
        "invitation": "ICLR.cc/2023/Conference/Paper1727/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes inr2vec, a framework for embedding implicit neural representations (INR) into a latent representation. The latent representations can then be used as data for various downstream tasks including classification, generative modeling and shape completion, effectively leading to a framework for performing deep learning directly on INRs. The authors learn such embeddings by training an autoencoder on the weights of INRs fitted to various 3D data, with the encoder mapping the weights to a latent vector and the decoder mapping the latent to the weights of an INR that is decoded into the data it represents. The authors perform a series of experiments on various 3D shape representations (point clouds, voxels, meshes) and various tasks (point cloud retrieval, classification, part segmentation, generative modeling, point cloud completion and surface reconstruction), with interesting results.",
            "strength_and_weaknesses": "**Strengths**\n- With the growing interest in INRs, the paper tackles an important and timely problem (performing deep learning on INRs) which should be of interest to the ICLR community\n- The paper is well written and clear\n- The proposed method makes sense and is well suited for the tasks in the paper\n- The experiments are well done and thorough. The authors tackle an impressively large number of tasks\n- The appendix is very thorough and includes a lot of helpful extra clarifications as well as experimental results\n\n**Weaknesses**\n- Experimental results do not match SOTA methods on most tasks considered. However, this is explicitly mentioned as a weakness in the conclusion and I don't believe this is crucial. As this paper consists in one of the first attempts to perform deep learning on INRs, it is reasonable to not expect SOTA results\n- As mentioned in the paper, the work is closely related to [1], which also proposes to perform various deep learning tasks on INRs. While it is briefly discussed in the paper, I believe readers would benefit from a more detailed comparison. For example, the authors mention that [1] rely on a shared network whereas the proposed method processes individual INRs. However, the encoder/decoder architecture is effectively shared across INRs too, and the encoding/decoding steps limit the reconstruction quality too. It would be nice to clarify this point in a little more detail in the paper. Further, while there are some experiments comparing the proposed model to [1] in the appendix, there are no comparisons on the tasks of classification and shape generation, both of which are tackled by [1]. For example, it seems like [1] also does classification on ShapeNet10 - why not include a comparison to this in the paper?\n- The evaluation of the generative model is quite weak. There are no quantitative metrics and no qualitative comparisons to other baselines. While quantitative evaluation of generative models of 3D shapes is difficult, it would be nice to at least have qualitative comparisons. For example, [2, 3] follow a very similar setup to the paper (generating task/modality-agnostic INRs) and also have experiments on 3D shapes, which might be worth comparing with\n- In the timing experiments (Figure 6), I think it makes sense to include the same experiments *without* the time required to reconstruct the point cloud from the INR. It is unclear from this experiment if most of the time is spent converting the INR to point clouds or if it's the actual point cloud model that is slow. While I understand the motivation for including the INR to point cloud conversion time, I think this experiment would greatly benefit from showing both the experiment with and without the conversion time\n\n**Questions**\n- As mentioned in Section 3, the encoder takes as input all the *hidden* layers of the INR and does not include the input and output layers. How are these layers treated? For example, given a latent embedding, you would still need to the input and output layer to reconstruct the signal. Are these just stored separately? I could not find any information explaining this in the paper, which I feel is a fairly important point\n\n**Nitpicks**\n- It seems like most citations are missing brackets. Using something like `\\citep{}` should help\n- Some of the wording can be slightly misleading. For example, in Section 4, \"inr2vec is able to match, and in some cases slightly surpass, the considered baselines\" does not really align with the results. It seems like the method underperforms PointNet++ (often by a significant margin) on 8/9 experiments. The wording should be changed to more accurately reflect this\n\n\n[1] From data to functa: Your data point is a function and you can treat it like one\n\n[2] Learning signal agnostic manifolds of neural fields\n\n[3] Generative models as distributions of functions",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nThe paper is clearly written and the figures are very nice and informative.\n\n**Quality**\n\nThe method is well explained, the experiments are thorough and well done and most relevant prior work is discussed. While there are a few weaknesses as listed in the previous sections, overall the paper is of high quality.\n\n**Novelty**\n\nWhile the idea of performing deep learning on INRs has already been considered in [1], the method presented here is quite different and interesting. Further, the authors consider a variety of different tasks not handled in [1] and also show more impressive empirical results on various 3D tasks.\n\n**Reproducibility**\n\nThe appendix is very detailed and the paper seems to contain most details required to reproduce the results in the paper.",
            "summary_of_the_review": "Overall I believe this is a strong paper which should be of interest to the ICLR community. The paper presents a novel method for performing deep learning on INRs with interesting experiments. While the results are not SOTA and there are a few other minor weaknesses, I still believe this paper is strong and as such I recommend acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethical concerns.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1727/Reviewer_rRwy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1727/Reviewer_rRwy"
        ]
    },
    {
        "id": "9VljWvNc0M3",
        "original": null,
        "number": 2,
        "cdate": 1666140058409,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666140058409,
        "tmdate": 1669069244719,
        "tddate": null,
        "forum": "OoOIW-3uadi",
        "replyto": "OoOIW-3uadi",
        "invitation": "ICLR.cc/2023/Conference/Paper1727/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a framework that computes a compact latent vector for an input implicit neural representation for 3D shape (i.e., encoded with MLP weights). It's trained on a dataset of INRs via reconstruction loss, and is able to obtain a compact embedding from an unseen INR (but still from the same data distribution) at inference time. The produced embeddings can be readily used for downstream tasks like classification or segmentation without the need of decoding an actual discrete representation. Through experiments on several different tasks, the authors demonstrate that the proposed framework achieve results on-par with simple baselines using discrete representation.",
            "strength_and_weaknesses": "Strengths:\n\n- This paper tries to address an interesting problem --- how to process INRs directly for downsream tasks without reconstructing the discrete counterparts. Given that nowadays INRs are popular to represent 3D shapes, directly processing them is potential very useful, if can be done properly.\n\n- The experiments are very comprehensive and lots of results are presented. The proposed framework is evaluated on many downstream tasks ranging from classification to generation.\n\nWeaknesses:\n- The proposed framework has some technical drawbacks that limits its application scope. For example, all input INRs need to be initialized with the same random vector (page 4 bottom). This requirement for training data is acceptable but it also applies to input INRs in testing time. This severely limits the generalization ability and such requirement is probably even not possible in real-world where INRs can come from anywhere. In addition, all input INRs need to have the same network structures since the encoder of inr2vec is a MLP of fixed structure.\n\n- Though the experiments are very comprehensive and cover many tasks, the quantitative results are inferior to compared baselines on nearly all tasks. Then the proposed framework is less favourable. Traditional discrete representions are easy to obtain (e.g., point cloud scan) and are ready to be processed by existing models. INRs, on the contrary, are much hard to obtain as it requires network training but better represent the signal. So I would expect the proposed framework to have superior performance, such that it would be worth applying deep learning models directly on INRs. \n\n- Missing one important baseline. Auto-decoder INRs, where a single network fits the whole dataset by condiitoning on different learned embeddings, is an important baseline. As the authors suggested in page 2 (\"Earlier work in .... downstream tasks\"), it is the natural solution to this research problem. Even though it may have clear drawbacks (i.e., insufficint capacity), it is a direct baseline that should be compared to, especially for those discriminative tasks.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and easy to follow. The experiments are comprehensive except missing one important baseline. The technical novelty is limited but the paper tackles an interesting novel research problem.",
            "summary_of_the_review": "This paper tries to address an interesting problem of directly applying deep learning models on INRs. The proposed framework is somewhat novel but has some clear limitations that may prevents its real-world applications. Experiments are comprehensive but the method gets inferior performance on nearly all tasks, casting doubts on whether we really need such framework in the first place. Overall, the paper's weaknesses outweighs its strengths. Therefore, I'm inclined to rejection.\n\nUpdate: given that the authors' rebuttal addressed my major concerns, I have raised my score from 5 to 6.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1727/Reviewer_HTw1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1727/Reviewer_HTw1"
        ]
    },
    {
        "id": "4eqsEkVib0b",
        "original": null,
        "number": 3,
        "cdate": 1666542832946,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666542832946,
        "tmdate": 1669901485146,
        "tddate": null,
        "forum": "OoOIW-3uadi",
        "replyto": "OoOIW-3uadi",
        "invitation": "ICLR.cc/2023/Conference/Paper1727/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper targets a novel {inr2vec} problem setting: to squeeze the weights of a learned implicit neural representation (INR) into compact latent codes for various downstream tasks. By training an encoder-decoder to recover the learned implicit function represented by the INR, the encoded feature can be fed into learning pipelines to solve tasks such as classification, retrieval, part segmentation, unconditioned generation, surface reconstruction, and completion. Detailed experiments verify the efficacy of the proposed method.",
            "strength_and_weaknesses": "Pros:\n+ The paper targets an interesting yet not well-explored problem to directly encode the learned INR into a compact latent vector. The solution is simple yet effective. Thorough experiments are conducted to show empirically that the encoded feature captures the high-level cues inherent in the geometric neural representation.\n+ The writing and organization are clear and straightforward. The figures well demonstrate the key components of the paper. Overall, I enjoy reading the paper.\n+ The design of the encoder-decoder is interesting. Unlike traditional autoencoding that encodes the weight values in the embedding, the supervision for recovering the learned function may be the key to success. Besides, the transfer between different embedding spaces is also interesting and impressive. \n\nCons:\nThough experimentally verified, the paper lacks explanations and theoretic proofs on several critical issues.\n1. As proved in [A], each feature unit in the first layer serves as a single frequency basis, whose spectral support is gradually expanded after the non-linear activations. That is to say, the input layer is the most crucial part for an INR to define the spectral basis. It is hard to understand why the input layer should be discarded and why their use does not change the inr2vec performance (page 4). With slightly different input layers, the INRs define drastically different functions. Though the same initialization leads to linear mode connectivity, I don't think initialization with the same random vector can mitigate this issue.\n2. The property of the embedding space is not clearly demonstrated or analyzed (e.g., through t-sne). The invariance against noise, transformation, or the over-parameterized network (a shape can be represented by multiple network parameters) is unknown. According to the experimental results, the embedding captures both local (part segmentation) and global (classification and retrieval) information. The distance within the embedding space reflects the geometric/categorical similarity (interpolation and retrieval). However, it is unclear how such an ideal embedding space is guaranteed by the proposed supervision manner.\n\n\nMinor issues:\n1. SIREN with 256 units in each layer is able to recover nice geometric details in scene scale. I don't understand why the paper adopts a (512 units with 4 hidden layers) network configuration (page 6) for the coarse ShapeNet geometry.\n2. INRs provide fine-grained and continuous geometric cues. However, the learned embeddings perform worse than the compared point cloud features. Though I think the novelty is sufficient, remarks concerning this issue and insights for future potentials should be added.\n\n[A] A structured dictionary perspective on implicit neural representations. Gizem Y\u00fcce*, Guillermo Ortiz-Jimenez*, Beril Besbinar and Pascal Frossard, CVPR 2022",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and well-written. The targeted problem setting and the proposed solution are novel and interesting. The architecture is simple for implementation. However, the training process may be cumbersome as each shape in the ShapeNet dataset needs to be trained to obtain the implicit neural representation.",
            "summary_of_the_review": "Overall, I think it is an interesting paper and is worth spreading in the community. The main concerns are summarized in the [Cons] section. I am currently positive, and I would like to see how the author responds and the opinions of other reviewers.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1727/Reviewer_VZbJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1727/Reviewer_VZbJ"
        ]
    },
    {
        "id": "zS4i4phXvjf",
        "original": null,
        "number": 4,
        "cdate": 1666618151451,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666618151451,
        "tmdate": 1669911375334,
        "tddate": null,
        "forum": "OoOIW-3uadi",
        "replyto": "OoOIW-3uadi",
        "invitation": "ICLR.cc/2023/Conference/Paper1727/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "As implicit neural representations (INRs) is now becoming a popular 3D representation, especially for reconstruction tasks. This paper presents an interesting question: is it possible to use INR to replace explicit representation (like point cloud and mesh) for downstream tasks, such as classifaction or segmentation? Thus, a trial is presented: a method is designed for encoding INR weights into a vector which can be used for several tasks. ",
            "strength_and_weaknesses": "Strenth:\n* The trial to encode INRs weights to a compact code and try to use it for downstream tasks is interesting. \n* The experiments well-verifies the possibility. \n\nWeaknesses: \n* If this is a right direction, then I have no concerns. My major concern is: it is not clear why we need such a trial.  Point cloud is the raw 3D data format which can be directly captured by 3D sensors. And, mesh is the raw data format created from some 3D modeling tools, such as Maya and 3DMax. Then, if we can do classification on point cloud and mesh, why we need to convert them into INRs and then conduct downstream tasks. If the conversion between different representations become easier, then it is also no need to propose a unified representation. \n* The results do not show better performance. ",
            "clarity,_quality,_novelty_and_reproducibility": "In total, the writing and organization is good. The raised problem is also interesting. Experiments also show very interesting results. ",
            "summary_of_the_review": "In whole, I appreciate the efforts for this trial. It is indeed an interesting attempt. However, I have only one concern is the necessity to do downstream tasks using INRs. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1727/Reviewer_shEg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1727/Reviewer_shEg"
        ]
    }
]