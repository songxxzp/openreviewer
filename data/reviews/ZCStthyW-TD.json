[
    {
        "id": "cNwjtjQmleY",
        "original": null,
        "number": 1,
        "cdate": 1666591155916,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666591155916,
        "tmdate": 1666591155916,
        "tddate": null,
        "forum": "ZCStthyW-TD",
        "replyto": "ZCStthyW-TD",
        "invitation": "ICLR.cc/2023/Conference/Paper4974/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper presents a transformer memory architecture for processing events from an event camera. A block of events are converted into positional embeddings, passed through self attention, and then fused with a memory tensor which is updated with events over time. The memory tensor can then be decoded at any time to produce the desired output. Qualitative examples are provided for the dynamics of the learned memory, and experiments are performed on image classification on the N-Caltech 101 and N-Cars datasets, where the proposed method outperforms previous state of the art, at significantly lower MFLOPs/ev.",
            "strength_and_weaknesses": "The motivation of having a stored memory for event processing is compelling, and the proposed work uses many of the current techniques that have demonstrated efficacy (attention, RNNS). The provided qualitative examples are quite interesting, showing that the memory differentiates between different classes for classification from t-SNE, and can update its state when the input changes to a different class. The results from the classification experiments are also strong, showing strong classification accuracy mostly above prior state of the art, at significantly less compute. \n\nThe method is presented as asynchronous, but does seem to require some level of batching of events at input. The Refine stage requires pairwise interactions between the input events, so it seems like this stage would have no effect if a single event was passed in. The computational latency of this method also seems quite high (4.5ms per event), as a single 30k event block would take over two seconds. This seems to go against the arguments presented in Table 3, where efficiency is reported in terms of MFLOPs/ev. For 'synchronous' methods which batch events into tensor representations, they should be able to process 30k event blocks at > 10Hz. Obviously there are tradeoffs for each, but currently the synchronous methods are only described as being more expensive.\n\nAnother concern is whether this method would scale up for more difficult tasks. It seems like the memory tensor is at most 32 x 32, which makes sense for classification. However, if a dense task was provided (e.g. optical flow), or something like detection, would it be sufficient to scale up the size of the memory? At what point does this become prohibitively expensive? 32 x 32 seems fairly small for a learned representation.\n\nThe outline of the method mostly is clear, but the Read, Write and Erase sections are a little hard to follow. While the other parts are clearly outlined in equations, these three are condensed entirely in text under 'Associative memory augmented recurrent module', and it's not clear what goes where. Some clarifications here could help the reader.\n\nTable 3: AEGNN slightly outperforms the proposed method for N-Cars and should be bolded.",
            "clarity,_quality,_novelty_and_reproducibility": "The method is mostly quite clear, although some improvements in the read/write/erase section would be appreciated. Overall, the method is compelling, and shows improvements over prior state of the art. ",
            "summary_of_the_review": "I believe that this work can serve as a good model for future memory-based event processing architectures. The overall architecture is simple and well motivated, and the experiments show improvements over prior work. Overall, my main concerns are the claims of efficiency given the latency results and the ability to scale up the method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4974/Reviewer_rsty"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4974/Reviewer_rsty"
        ]
    },
    {
        "id": "wnO1F3xrfjv",
        "original": null,
        "number": 2,
        "cdate": 1666750772966,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666750772966,
        "tmdate": 1666750772966,
        "tddate": null,
        "forum": "ZCStthyW-TD",
        "replyto": "ZCStthyW-TD",
        "invitation": "ICLR.cc/2023/Conference/Paper4974/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a high performance asynchronous encoding scheme for event-based camera data, which uses associative memory and preserves the spatio-temporal relationships between events in a compact and efficient manner. The authors evaluate the pipeline on recognition tasks, and achieve high speedups without sacrificing the accuracy of the predictions.\n",
            "strength_and_weaknesses": "The paper presents and efficient way to encode and incrementally update the event stream, which is a pressing issue for any event-based processing pipeline; I believe the method could have a big impact if made publicly available to the community.\n\nThe evaluation is performed on N-Caltech101 and N-Cars for recognition tasks. While valid, the event camera (specifically - spatio-temporal event relations) emphasizes motion over the appearance, and an evaluation on any egomotion dataset or at least a more challenging recognition / segmentation would strengthen the paper.\nWe suggest for the future work (or, a revision of this paper if feasible) authors to add EVIMO (https://better-flow.github.io/evimo/) dataset to evaluation - egomotion, segmentation and depth estimation are all valuable applications for event cameras. MVSEC (https://daniilidis-group.github.io/mvsec/) is another\ngreat source of data, with both egomotion and depth.\n",
            "clarity,_quality,_novelty_and_reproducibility": "I really enjoyed the quality of the illustrations, and the literature review is very detailed and gives the reader a good overview of the existing approaches to event encoding. Maybe the review section could benefit from more diversity, especially among papers that tackle egomotion, motion segmentation and depth - for example\n - Learning visual motion segmentation using event surfaces (3D, graph representation)\n - https://arxiv.org/pdf/1903.07520.pdf (dense image-like representation)\n - https://arxiv.org/pdf/1803.04523.pdf (image-like representation, classic pipeline)\n\nIn regards to novelty, I think the paper presents a relatively new (at least, to the field) problem and addresses it directly, while most of the existing papers to not consider the problem of event encoding as an independent one.",
            "summary_of_the_review": "The asynchronous frame-less nature of the event stream is a big problem for event-based processing, and most modern methods either sacrifice information contained in the events, or the performance. I believe the paper has a potential to improve on the current state of the art, at least in terms of the encoding of the events. The only major weakness I see is the lack of focus / evaluation on depth and motion, with motion estimation (egomotion or segmentation) being the major applications of the event camera. But, the approach is still valuable and I would be willing to accept this paper provided the authors make their method available.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4974/Reviewer_AhYC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4974/Reviewer_AhYC"
        ]
    },
    {
        "id": "U2p1DtB01z",
        "original": null,
        "number": 3,
        "cdate": 1666855323930,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666855323930,
        "tmdate": 1666974504743,
        "tddate": null,
        "forum": "ZCStthyW-TD",
        "replyto": "ZCStthyW-TD",
        "invitation": "ICLR.cc/2023/Conference/Paper4974/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a new event representation framework EventFormer, which can process sparse events asynchronously and efficiently. The author proposes a memory-based mechanism to retrieve the past representation, store the memory with new representation and update the hidden states of associative memory. The paper claims that the method obtains high performance with minimal compute cost on the N-Caltech101 and N-Cars dataset.",
            "strength_and_weaknesses": "Pros: \n1. This paper is well written and clear in general. \n2. The proposed EventFormer seems to perform well on two event-based object recognition datasets. \n3. The hybrid transformer and rnn architecture design seems novel.\n\nCons:\n1. The input of EventFormer is a list of events {(x_i, y_i)}, does it mean that the polarity information of events is lost? Does it have any influence to the performance?\n2. As is mentioned in paper, the MFLOPs/ev on average window of 25000 events are reported. However, 50ms long sequence is used for each sample in supplementary material. What exactly does that mean?\n3. The resolution of N-Caltech101 should be 180\u00d7240, but the paper says 180\u00d7260, is this a typo or is there pre-processing?\n4. How is the efficiency of the proposed method when dealing with high spatial resolution events such as the ones produced by Prophesee Gen4? This is especially important for tasks such as object detection, semantic segmentation and optical flow estimation.\n5. Authors are suggested to provide inference speed other than flops of models.\n6. What about performance of the proposed method on other tasks such as object detection, depth estimation and optical flow estimation?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and the hybrid transformer and rnn design has certain novelty.",
            "summary_of_the_review": "Overall, I think the design is interesting and seems to work to some extent. However, authors are suggest to apply the proposed representation on more advanced tasks such as object detection and optical flow estimation instead of only classification.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4974/Reviewer_rHjG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4974/Reviewer_rHjG"
        ]
    },
    {
        "id": "NgTltiXqn55",
        "original": null,
        "number": 4,
        "cdate": 1666943447647,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666943447647,
        "tmdate": 1666943447647,
        "tddate": null,
        "forum": "ZCStthyW-TD",
        "replyto": "ZCStthyW-TD",
        "invitation": "ICLR.cc/2023/Conference/Paper4974/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "A memory-augmented representation learning model, EventFormer, is proposed for asynchronous event-based perception. To achieve this goal, the EventFormer learns to store, retrieve and update its memory representation in the latent form of higher-order spatiotemporal dynamics of the events. The idea is interesting and also obtains good performance on two classification tasks. As the drawbacks of this paper, many typos can be found in the manuscript. I also wonder how about the performance on the long-term event representation learning and also other challenging tasks, such as event-based object detection, event-based visual tracking, etc. ",
            "strength_and_weaknesses": "Strength \n1. the idea to adopt the Transformer and memory scheme for event-based representation learning is interesting and new for this problem. \n2. the model works well on short-term and simple classification datasets, including n-caltech101, and n-cars. \n\n\nWeaknesses\n1. the writing of this paper still needs further improvements, many typos can be found, even in the figure; \n2. the performance on the long-term event streams, and challenging tasks is not verified. ",
            "clarity,_quality,_novelty_and_reproducibility": "this paper is clearly written, but with some typos. The implementation details are enough for re-implementation. ",
            "summary_of_the_review": "A memory-augmented representation learning model, EventFormer, is proposed for asynchronous event-based perception. To achieve this goal, the EventFormer learns to store, retrieve and update its memory representation in the latent form of higher-order spatiotemporal dynamics of the events. The idea is interesting and also obtains good performance on two classification tasks. \nThe following issues can be addressed in future versions to further improve the quality of this work. \n1. the writing of this paper still needs further improvements, many typos can be found, even in the figure; \n2. the performance on the long-term event streams, and challenging tasks is not verified. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4974/Reviewer_wCjB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4974/Reviewer_wCjB"
        ]
    }
]