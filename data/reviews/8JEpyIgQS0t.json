[
    {
        "id": "rlSPwaxkQ7",
        "original": null,
        "number": 1,
        "cdate": 1666612507021,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666612507021,
        "tmdate": 1666621522802,
        "tddate": null,
        "forum": "8JEpyIgQS0t",
        "replyto": "8JEpyIgQS0t",
        "invitation": "ICLR.cc/2023/Conference/Paper3955/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper compares a RNN with step nonlinearities with randomly initialized parameters to ones in which parameters are trained by simple local updates inspired by biology. Namely, connections are changed to reinforce sequential structure (STDP) while the neuron thresholds change so as to keep activities small (IP). These RNN variants are evaluated in terms of their criticality via numerical perturbations and in terms of the ability of the network representations to carry information about sequential inputs to the network (using a separately trained decoder).",
            "strength_and_weaknesses": "+ Strength: SORNs involve purely local unsupervised updates; that endows them with some computational advantages relative to static reservoirs with randomly initialized parameters by exploiting statistical regularities in the inputs.\n- Weakness: the choice of model seems out of touch with the field, which invariably uses differentiable nonlinearities for the units, and which have lent itself to perhaps more interesting analytical investigation of the RNN dynamics after learning\n- W: the tasks are somewhat contrived to involve toy sequential structure\n- W: performance seems relatively poor overall\n- W: relevance of the work seems restricted to a small niche of computational neuroscience which focuses on criticality and reservoir computing, unclear what implications if any should this have on the wider comp neuro or machine learning field. ",
            "clarity,_quality,_novelty_and_reproducibility": "The text is overall easy to read, although I found a few of the technical descriptions not precise enough and subject to interpretation. In particular, i was unclear on exactly how the readout works for each of the tasks (bayesian decoder is a little too vague). I was unsure in places if results reported were on the training or test set. For the first task, it seemed that nothing except for externally defined semantics differentiated elements from sequence a and b, since the temporal structure in the input space was purely periodic, i did not understand the logic of decoding a vs b at large lags.\nUnclear if the code for the simulations was released with the manuscript, if so that would alleviate some of the clarity/reproducibility concerns.",
            "summary_of_the_review": "Overall, a simple model analyzed with numerical means using methodology similar to past SORN work (Lazar, Triesch, etc), on a few toy tasks. The results show slight benefits from SORN learning over no learning (arguably, the minimal precondition for usefulness); I would not say that the mechanics of the process are much better understood as a result of the accompanying analysis and the relevance for the broader community seems minimal.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3955/Reviewer_vp6e"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3955/Reviewer_vp6e"
        ]
    },
    {
        "id": "UcJM-j88-w",
        "original": null,
        "number": 2,
        "cdate": 1666638514457,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666638514457,
        "tmdate": 1666638514457,
        "tddate": null,
        "forum": "8JEpyIgQS0t",
        "replyto": "8JEpyIgQS0t",
        "invitation": "ICLR.cc/2023/Conference/Paper3955/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors compare the dynamical characteristics of recurrent neural networks before and after training. Specifically, the results presented in the paper suggest that training shifts RNNs toward subcriticality. The authors suggest that this subcriticality is a signature of specialization that can potentially be used to study specialization in biological neural networks.",
            "strength_and_weaknesses": "$\\textbf{Strengths}$:\n\nStudying the connection between dynamical properties and learning in artificial neural networks (ANN) is novel, and can potentially build stronger link between the two common approaches of dynamical systems and deep learning in neuroscience. I found the approach presented in the paper very useful in that sense.\n\n$\\textbf{Weaknesses}$:\n\nI have some reservations about the main claim of the paper: namely \u201cthe shift in criticality is a signature of specialization.\u201d I am not convinced that the data presented in the paper supports this general claim and is not specific to the learning rule and training sequences used in the experiments. I elaborate below:\n\n$\\textbf{Questions}$:\n\n1- All the results in this paper are produced with a learning rule that is a combination of a Hebbian plasticity and a homeostatic plasticity rule. If the main claim of the paper is that gaining specialization (regardless of the learning rule) leads to subcriticality in the dynamics of the RNN, I'd expect to see similar results with other learning rules, e.g. Oja\u2019s rule, BCM rule, gradient descent rules, etc. \n\n2- The change in the Hamming distance after learning is different between different tasks. For example, in Figure 2a after applying the learning rule, the Hamming distance immediately starts going down, but in Figure 3b (the MNIST data), applying the learning rule actually causes a jump in the Hamming distance which gradually goes down but doesn\u2019t get to below one (the subcriticality) until learning is turned off. This seems to suggest that there is an interaction between the effect of learning and the sequence statistics. How do the authors explain this apparent discrepancy between the two experiments? \n\n3- Although the effect of homeostatic plasticity on the dynamics is investigated separately (e.g Figure 1), the effect of STDP isn\u2019t examined separately. Therefore, it is not clear whether the shift from criticality to subcriticality is due to the STDP rule or it is a combined effect of STDP and homeostatic plasticity. I suggest that the authors also include a comparison with STDP alone, or if it is not possible, please explain the reason. \n\n4- Related to comment # 2, the interaction between the statistics of the input sequence and the learning rule on shifting the dynamics of RNNs is not clear. How would the dynamical regime change if the input data was white noise? In a more systematic exploration, you could gradually increase the temporal (and even spatial) correlations (e.g. using an auto-regression process) and evaluate the shift in the dynamics as a function of the temporal/spatial correlation in the input sequence. \n\n5- In the introduction it is mentioned that \u201crandom RNNs with critical dynamics exhibit a strong memory of recent inputs for any arbitrary input sequences.\u201d The results presented in the paper, however, show that learning improves the memory of the RNN for the training sequences. But, it is expected that it should decrease memory performance for other arbitrary sequences. It would be useful to explicitly show the underperformance of the RNN with other sequences compared to an RNN functioning at the edge of chaos. This would give a more balanced picture of the advantages and disadvantages of specialization. For example, in the context of continual learning (which might be beyond the scope of this paper), becoming too specialized might be a disadvantage for the neural network.  \n\n$\\textbf{Minor comments}$:\n\n1- In section 2.1, all inhibitory and excitatory synaptic weights are explained as being sampled from [0,1]. Is this only the magnitude of the synaptic connections, given that the inhibitory connections are expected to be sampled from a range of negative values.\n\n2- How are memory and prediction performance measured separately for the plots in Figure 3e?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The methods and experimental results are clear. The investigated link between learning and dynamics in RNNs is very novel. ",
            "summary_of_the_review": "I believe this paper can make an important contribution to both machine learning and neuroscience by providing a dynamics-based metric for studying specialization in artificial and biological neural networks. However, I believe that the paper could benefit from more thorough examination of different learning rules and a few more control experiments, which I explained in my comments. I am willing to improve my score if the authors address my questions especially ones regarding different learning rules.  ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3955/Reviewer_RfJy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3955/Reviewer_RfJy"
        ]
    },
    {
        "id": "vDD0wyj9mDm",
        "original": null,
        "number": 3,
        "cdate": 1666639180872,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666639180872,
        "tmdate": 1666639180872,
        "tddate": null,
        "forum": "8JEpyIgQS0t",
        "replyto": "8JEpyIgQS0t",
        "invitation": "ICLR.cc/2023/Conference/Paper3955/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors showed that self-organizing recurrent networks which learn the spatio-temporal structure of their inputs, increase their recurrent memory by preferentially propagating the relevant stimulus specific structure signal, while becoming more robust to random pertubation. They also showed that the SORN model with subcritical dynamics outperfrom random RNN counterparts with critical dynamics on a range of tasks. ",
            "strength_and_weaknesses": "Strength:\n\nThe idea is somehow interesting and the written is clear.\n\nWeaknesses:\n\n1, It is better to give an illustration of the network model, especially for those readers without comp. neuro. background. For the pertubabtion analysis, you can also give a illustration at somewhere. \n\n2, Many parts of the paper need to be explained more clearly. For instance, what does the input looks like when producing Figure 1?\n\n3, All the results are only verified with simulations, and theoretical analysis of why the network work is missing, making the paper more like a technical report.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written, but the core idea is not well explained and verified.",
            "summary_of_the_review": "This paper is lack of many details and contributes only in a limited way to the ICLR society. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3955/Reviewer_CT5J"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3955/Reviewer_CT5J"
        ]
    },
    {
        "id": "rLRooDsUwjA",
        "original": null,
        "number": 4,
        "cdate": 1666768123326,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666768123326,
        "tmdate": 1666768123326,
        "tddate": null,
        "forum": "8JEpyIgQS0t",
        "replyto": "8JEpyIgQS0t",
        "invitation": "ICLR.cc/2023/Conference/Paper3955/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, authors study the performance and properties of SORNs that have been exposed to the training dataset in terms of its ability to differentiate between task relevant and noise inputs. They show that these SORNs have sub-critical dynamics and can outperform RNNs at the edge of criticality in a couple of benchmarks.\n",
            "strength_and_weaknesses": "## Strengths:\n\n- The properties of SORNs shown are very interesting in terms of such a sub-critical network performing better than RNNs at EOC.\n- Being able to get better performance than a standard reservoir on these tasks based on SORN training is nice.\n\n## Weaknesses:\n\n- A lot of the experimental setup seems very arbitrary, and there are no ablation studies to determine what's important. e.g. does IP always have to precede SORN?\n- The results of the study are hard to generalize due to very specific choices of plasticity and network setup.\n- Some parts of the experimental details are not clear.\n\n## Other questions\n\n- In Fig. 2, why is the performance above chance for both positive and negative time lags?\n- How's the bayesian readout trained?\n- More explanation needed for what variant and invariant aspects of processing are in Sec. 5.\n- How does SORN compare with self-supervised training using other optimization methods?",
            "clarity,_quality,_novelty_and_reproducibility": "The work is original to my knowledge.\n\nThe clarity of the manuscript can be improved quite significantly, see comments above. Moreover, the motivation and the specific issue being investigated is not made very clear. The experimental setup seems to be used without justification as well.\n\nBased on the details in the paper, reproducing the experiments would be challenging.",
            "summary_of_the_review": "Overall, while the issue investigated and the results are interesting, the paper needs to improve on multiple fronts -- better and clearer writing, clearer statement of question being investigated, better justifications for various experiment details, more experiments to judge generality of results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3955/Reviewer_B89g"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3955/Reviewer_B89g"
        ]
    }
]