[
    {
        "id": "IJrYbWMxKc",
        "original": null,
        "number": 1,
        "cdate": 1666371891686,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666371891686,
        "tmdate": 1666417262254,
        "tddate": null,
        "forum": "qWt3YobXdwe",
        "replyto": "qWt3YobXdwe",
        "invitation": "ICLR.cc/2023/Conference/Paper2777/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper addresses the problem of OOD robustness with respect to pose changes. To this end, a Lie group transformation of latent representations is learned. This groups is parametrized via its Lie algebra in order to properly integrate it into a (vector space-driven) deep learning framework.\n\nTo train the network, pairs of images are used that show the same object at different poses.\nUsing these pairs, an SSL is performed by using a combination of four loss functions:\n1. Standard SSL training loss\n2. InfoNCE to measure the similarity of the latent representation (w.r.t. the algebra estimation)\n3. Euclidean similarity between the latent representation\n4. Task-dependent algebra-regularization\n\nThe proposed method is trained on a dataset of about 500K generated images based on models owned by Trimble Inc.",
            "strength_and_weaknesses": "Strengths:\n+ The used mathematical concept of Lie groups/algebras is nicely explained\n+ The four different loss components are explained in detail and ablation studies are performed to emphasize their usefulness\n+ Newest models (like CLIP) are used to demonstrate the usefulness of this new approach\n\nWeakness:\n- It is not clear why 3D rotations should translate to group operations in the latent space. This two operations seem to be logically disconnected\n- The paper is not clear about the (manifold) dimension of the Lie group. Depending on the latent space, this dimension might be quite high\n- The proposed method uses different hyper-parameters for the four different loss components. Since these are not disclosed, it is difficult to reproduce the results.\n- In Section 2, it is not clear why the scalar `t` is necessary. After all, the Lie algebra is a vector space and is closed under scalar multiplication",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and introduces all relevant concepts in the main paper.\n\nThe concept of Lie groups has been used before in machine learning, but to my knowledge not for OOD robustness.\n\nAccording to the \"General Model License\" of Trimble Inc., it is not allowed to \"[...] use or incorporate such Model in any application, product, service, database or repository\". This raises a reproducibility issue of the paper, since the used 500K images for training cannot be used by other researchers to reproduce the presented results.\n",
            "summary_of_the_review": "Overall, I like the idea presented in this paper. There are minor concerns like the Lie group's dimension.\n\nMy main concern is with respect to the reproducibility with stems from the license of the used data.\nTherefore, I see the paper marginally below the acceptance threshold.\n\nIf the reproducibility issue can be resolved, I am happy to raise my vote. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2777/Reviewer_iZ5V"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2777/Reviewer_iZ5V"
        ]
    },
    {
        "id": "Pg4T1X1bKr",
        "original": null,
        "number": 2,
        "cdate": 1666611667191,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666611667191,
        "tmdate": 1666611667191,
        "tddate": null,
        "forum": "qWt3YobXdwe",
        "replyto": "qWt3YobXdwe",
        "invitation": "ICLR.cc/2023/Conference/Paper2777/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Though deep learning has achieved many advances, many existing methods suffer from poor generalization performance due to the domain-shift impact. To this end, this paper focuses on improving the robustness of self-supervised methods. Specifically, the authors choose matrix Lie groups to model continuous transformations and employ contrastive learning to enhance the generalization. In the experiments, the proposed method is evaluated on multiple datasets.\n\n\n",
            "strength_and_weaknesses": "\nUsing group theories to improve OOD robustness is an interesting idea.\n\n\n1. The motivation of this paper is not clear. In Introduction Section, the authors directly indicate that self-supervised models own limited OOD robustness. However, I am not clear why self-supervised models are with limited OOD robustness. The authors should give more interpretations.\n\n2. Some indications in this paper are not accurate. For example, the authors indicate that for image data, augmentations can only be applied to the pixels themselves. However, to the best of my knowledge, there exist some feature-level augmentation methods. Besides, the authors should further interpret why augmentation fails to generalize to novel objects.\n\n3. The writing of the method section is very chaotic. The proposed method contains multiple operations. However, the authors do not introduce the motivation of these operations clearly. Besides, it is better to give some theory analyses for the proposed method.\n\n4. In Table 1 and 2, this paper only compares MAE and VICReg. The authors should evaluate the effectiveness on more methods and tasks. The proposed method involves multiple operations. The authors should make sufficient ablation experiments. Finally, the authors should give more training details, e.g., the training curves, and feature-level visualization analyses, which is beneficial for further understanding the proposed method.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing of this paper is not clear. The proposed method only uses the idea of Lie group and contrastive learning. The novelty of this paper is limited. Besides, the proposed method contains multiple operations and is complex. It is better to give the code to reproduce the results.\n\n",
            "summary_of_the_review": "The writing of this paper is not clear. The proposed method only uses the idea of Lie group and contrastive learning. The novelty of this paper is limited. Besides, the proposed method contains multiple operations and is complex.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2777/Reviewer_wpyw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2777/Reviewer_wpyw"
        ]
    },
    {
        "id": "lrDGxDjSCy7",
        "original": null,
        "number": 3,
        "cdate": 1666692604746,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666692604746,
        "tmdate": 1666692654431,
        "tddate": null,
        "forum": "qWt3YobXdwe",
        "replyto": "qWt3YobXdwe",
        "invitation": "ICLR.cc/2023/Conference/Paper2777/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to apply the formalism of Lie groups to capture continuous transformationsto improve models robustness to distributional shifts. Specifically, it structures the representation of corresponding vector space of the assumed Lie group by learning some basis metrics and then constructs their Lie operator by using this vector space structure. The general idea is impressive, and the experimental results are promising.",
            "strength_and_weaknesses": "Strength: This paper shows great potantial of learning the transformation in laten space induced by changes in pose to enable self-supervised models to generalize variation across objects. The perspective is novel and ablation study shows promising results.\n\nWeaknesses: In Section 2.1, there is no description about how to decide the dimention d of the Lie algebra. In my understanding, there should be a way to specify the dimention, or it is the degree of freedom of the transformation matrix in Li group. Is my understanding correct?",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and presents a novel perspective to enable self-supervised models to generalize variation across objects.",
            "summary_of_the_review": "In general, the presented method is novel and effective, which is also well-supported by the experimental results.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2777/Reviewer_1hzj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2777/Reviewer_1hzj"
        ]
    }
]