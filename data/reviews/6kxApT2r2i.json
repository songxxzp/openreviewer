[
    {
        "id": "MN4K9RjMkHZ",
        "original": null,
        "number": 1,
        "cdate": 1666430079456,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666430079456,
        "tmdate": 1666613882747,
        "tddate": null,
        "forum": "6kxApT2r2i",
        "replyto": "6kxApT2r2i",
        "invitation": "ICLR.cc/2023/Conference/Paper54/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a distillation framework that makes a network learn with crops and augmentations from a single image. The learning target comes from a pre-trained teacher's outputs. The results obtained is of decent level (69% ImageNet top1). Various design options and internal properties of the resulting network are analyzed.",
            "strength_and_weaknesses": "Strengths:\n1 ) It is interesting to know with a teacher and a single large image, what level of accuracy a student can achieve on certain images.\n\n2 ) It demonstrates (vanilla) knowledge distillation's immense power. It means KD can be done with extremely small amount of data. The paper may consider citing related few-shot KD methods such as [1].\n\n3 ) The paper's ablation study is comprehensive and reveals many interesting points. \n\t\n\nWeaknesses\n\n1 ) The teacher is supervised pre-trained. It contains information from a full dataset. Thus it may not be fair to say this study helps to understand the mechanism of NNs when provided with the minimum data. Moreover, the semantic categories are explicitly  modeled with teacher's final classifier, which is clearly learned from large data instead of the single image. \n\t\nTherefore, I don't think the question in \"we go far beyond these and instead ask what the minimal data requirements are for neural networks to learn semantic categories\" can be answered with \"only one image and augmentations\" without mentioning the teacher.\n\nThe conclusion sentence in the discussion section may add \"together with a supervisory signal provided by a teacher pretrained on large data with many semantic categories, provide sufficient \u2026\"\n\t\nThere is another way to frame the conclusion and finding: KD can be done with one image and augmentations to reach decent accuracy. I think this one represents the finding more accurately and concisely.\n\t\n2 ) As the paper suggested in the intro, the use case of the method is not obvious.\n\t\n3 ) It may be an exaggeration to say that this is learning from a single datum also because the image used is very high resolution. Small crops of CIFAR-size (32x32) with data augmentations easily surpass thousands. The \"image space\" doesn't specify image size so in extreme I could tile all ImageNet images into one and still call it one \"image\". \n\n[1] few sample knowledge distillation for efficient network compression\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. Details are documented in appendix.",
            "summary_of_the_review": "The paper presents some interesting findings but I think there are exaggerations in claims as discussed in weaknesses, so both considered my recommendation is \"marginally above\".",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper54/Reviewer_AYLh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper54/Reviewer_AYLh"
        ]
    },
    {
        "id": "LMjaUgatArH",
        "original": null,
        "number": 2,
        "cdate": 1666660736112,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666660736112,
        "tmdate": 1669507061934,
        "tddate": null,
        "forum": "6kxApT2r2i",
        "replyto": "6kxApT2r2i",
        "invitation": "ICLR.cc/2023/Conference/Paper54/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper uses a single image along with its augmentation and a pretrained classification model (teacher) together to train a student classifier. Through experiments on different datasets including images, audios, and videos, the authors find that the student classifier can achieve reasonably good classification performance.",
            "strength_and_weaknesses": "Strength:\nIn order to verify its effectiveness, the authors have conducted experiments on different datasets and also conducted ablation studies on different components of this proposed method. \n\n\nWeakness:\n\n1) The motivation is not clear. Since this proposed method only uses a single image and its augmentations as its training data (it also uses a \u201cteacher\u201d model which should also be considered as an input information source), thus it might be acceptable that it will sacrifice some performance/accuracy. But the question is do we really want to do that? I do not see any benefits from doing this. If we think there are some domains where obtaining training data is expensive, then we say this model may be helpful. However, the thing is we still need a \u201cgood\u201d teacher which should be trained on a large amount of dataset in this domain.\n\n2) Using a single image to train a classifier and gain reasonable accuracy sounds surprising; however, there are several recent papers finding that even a \u201crandomly initialized neural network with frozen network\u201d can also yield good classification performance (I list several references below). Given this background, the finding may not be as impressive as it sounds since in any way it has updated its network weights and take the advantage of the knowledge from the \u201cgood teacher\u201d.\n\nRef1: K. Jarrett, K. Kavukcuoglu, M. Ranzato, and Y. LeCun, \u201cWhat is the best multi-stage architecture for object recognition?\u201d 2009 IEEE 12th International Conference on Computer Vision, Sep. 2009, pp. 2146\u20132153, ISSN: 2380-7504.\n\nRef2: H. Zhou, J. Lan, R. Liu, and J. Yosinski, \u201cDeconstructing Lottery Tickets: Zeros, Signs, and the Supermask,\u201d in Advances in Neural Information Processing Systems, vol. 32. Curran Associates, Inc.,\n2019.\n\nRef3: K. Sreenivasan, S. Rajput, J.-y. Sohn, and D. Papailiopoulos, \u201cFinding Everything within Random Binary Networks,\u201d 2021.\n\nRef4: S. Baek, M. Song, J. Jang, G. Kim, and S.-B. Paik, \u201cFace detection in untrained deep neural networks,\u201d Nature Communications, vol. 12, no. 1, p. 7328, Dec. 2021.\n\nRef5: G. Kim, J. Jang, S. Baek, M. Song, and S.-B. Paik, \u201cVisual number sense in untrained deep neural networks,\u201d Science Advances, vol. 7, no. 1, p. eabd6127, Jan. 2021.\n\n\n\n\n\n\n/********************************** After Rebuttal******************************/\n\nThanks for your response. After reviewing the responses and the discussions, most of my major concerns have been resolved. I would slightly raise my rating. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The overall presentation and writing sound good to me. The authors also provided the code, so it might be possible to reproduce the results.",
            "summary_of_the_review": "Overall, this paper is easy to follow and understand. It also has a lot of experiments. The big issue is it is not clear what benefits this method can bring to the community; also \u201crandom neural network with frozen weights\u201d can also achieve impressive classification accuracy, then the finding in this paper does not sound as surprising as it is. \n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper54/Reviewer_rxVL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper54/Reviewer_rxVL"
        ]
    },
    {
        "id": "zazAHSXcuXo",
        "original": null,
        "number": 3,
        "cdate": 1666685262901,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666685262901,
        "tmdate": 1668722204487,
        "tddate": null,
        "forum": "6kxApT2r2i",
        "replyto": "6kxApT2r2i",
        "invitation": "ICLR.cc/2023/Conference/Paper54/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper investigates knowledge distillation using a data set consisting of a single or a few images which are heavily augmented. The paper finds that this type of knowledge distillation is as effective as using the training set, at least for small scale data sets such as CIFAR-10/100. Different design choices such as student and teacher architecture, the effect of the teacher training set as well as the image(s) chosen for distillation and the augmentations used are explored in-depth. Furthermore, the method is also shown to be effective for other modalities such as audio and videos, albeit these are less explored than images.",
            "strength_and_weaknesses": "Overall I feel that the paper provides a comprehensive investigation of single/few image based distillation. Nevertheless, I have a few suggestions on how to improve the paper.\n\n*Strengths:*\n- The observation that a single or a few images are enough for distillation is surprising and interesting (at least to me).\n- The paper covers a lot of datasets, architectures, and modalities, and provides many insightful ablations, and as such answers many important questions on the phenomenon.\n\n*Weaknesses/suggestions for improvement:*\n- One important open question: What happens to transfer and robustness properties of the distilled models? The output confidence scores seem to change significantly on the testing set (Figure 3), and the paper also delivers a potential hint why this could be happening: The output probabilities on the samples used for training are very flat for the teacher (Figure 8). Given this observation, the models might be mis-calibrated or have reduced OOD robustness, which would merit more investigation.\n- A related analysis would be to look at examples for which are misclassified by the student but correctly classified by the teacher. Are there some patterns.\n- It would be interesting to see if more sophisticated synthetic data than uniform noise can lead to better transfer, such as the synthetic data sets considered in Baradad et al. 2021.\n- The observation that the method works less well for transformer models could be discussed in the main paper. Given that transformers are harder to train on small data sets than ConvNets this is not very surprising.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow. It provides a comprehensive investigation of the phenomenon and covers most of the important aspects. The experiments are well-documented and the details should suffice to reproduce the results. To my knowledge, distillation based on a few or a single image has not been explored before, so the contributions are novel as far as I can tell.",
            "summary_of_the_review": "The paper provides an interesting and comprehensive investigation of knowledge distillation based on a single or a few images. I think the paper should be published, but I also believe the points I raised above regarding calibration/robustness should be answered before publication, which is why I chose my rating defensively.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper54/Reviewer_rSwz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper54/Reviewer_rSwz"
        ]
    }
]