[
    {
        "id": "yiDOQGTVLY",
        "original": null,
        "number": 1,
        "cdate": 1666604540012,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604540012,
        "tmdate": 1666604540012,
        "tddate": null,
        "forum": "kh3JurmKlux",
        "replyto": "kh3JurmKlux",
        "invitation": "ICLR.cc/2023/Conference/Paper771/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "Main concern. How to accommodate GNNs to deal naturally with heterophily and provide a theoretical analysis (from signal processing perspective). The core idea is to transform/combine low-pass filter into/with high-pass, for instance. There are two learnable parameters: w and \\eta whose values lead to low-pass or high-pass filters (adaptive filters): \n\nThe above conditions are sufficient and in fact, there are many other combinations of w and \u03b7 that can produce low-pass/high-pass filters \nAs stated in the proof of Lemma 1. I found this idea very interesting, in particular the distinction between GLOBAL and LOCAL filtering. In particular, the insight of how GLOBAL filtering degrades the performance in a heterophilic scenario is useful. \n\nRelated work is analyzed and the contribution evolves from FAGCN which explicitly mixes high-frequency and low-frequency signals. ALT generalizes this idea to the \u2018mixture of complementary filters\u2019; thus, even though the backbone GNN\u2019s convolution kernel is unknown \n\nResults are very challenging since for heterophilic graphs, the proposed approach ALT increases the performance and for homophilic case, it preserves it or even improves it. The ablation study is very useful to understand the contribution of the local filter. \n\nNotes. Please, clarify that the frequency profile is basically the function phi applied on the spectrum (e.g phi = exp() when we apply a heat kernel) under the spectral theorem: phi(A) = U*phi(lambda)*U^T.\n\n",
            "strength_and_weaknesses": "* Strengths: results are very challenging and \n* Weaknesses: the underlying theory could be clarified more clearly for the nonexperts in spectral graph theory.",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity in the spectral stuff could be improved but in general it is well written. \n* Novelty. Seems that is not incremental wrt FAGCN but I am open to discuss it. \n* No code released yet but experimental protocol specified. ",
            "summary_of_the_review": "The paper provides nice results regarding how to minimally modify existing GNNs to deal with heterophilic graphs. The theory could be better explained but the paper is in general readable and direct. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Ok.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper771/Reviewer_Jqz9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper771/Reviewer_Jqz9"
        ]
    },
    {
        "id": "h5otkeaFU7",
        "original": null,
        "number": 2,
        "cdate": 1666648782071,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666648782071,
        "tmdate": 1666648782071,
        "tddate": null,
        "forum": "kh3JurmKlux",
        "replyto": "kh3JurmKlux",
        "invitation": "ICLR.cc/2023/Conference/Paper771/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors ALT to handle graphs with either low or high homophily by decomposing a given graph into two components, extracting complementary graph signals from these two components, and adaptively merge the graph signals for node classification. ",
            "strength_and_weaknesses": "## Strength\nThe frequency analysis is somehow interesting.\n\n## Weaknesses\n1. The writing needs to be improved.\n2. The idea is not novel.\n\n\n## Questions and Comments\n\n1. \u201cour core idea is to adaptively combine signals from two filters with the complementary filter characteristics. For example, if a low-pass filter GNN is given, it should be adaptively combined with another high-pass filter.\u201d Combining low-pass filter and high-pass filter adaptively is exactly the same as [3] and as the author mentioned, \u201cequip GNNs with an adaptive filter\u201d is not a new idea.\n\n2. The authors show that \u201cThe filter characteristic of the proposed ALT-global (Eq. 1d) is adaptive\u2026\u201d. How does the learned filter compared with GPRGNN and BernNet?\n\n3. \u201capplies a global filter to every node, which could lead to suboptimal performance.\u201d Any evidence to this claim?\n\n4. The ALT-LOCAL is very similar to FB-GAT, which combines low-pass filter, high-pass filter and learnable edge weights adaptively.\n\n5. It is invalid to use validation label in the training process.\n\n5. Some recent works find some empirical and theoretical  evidence that heterophily is not always harmful and homophily is not always necessary for GNNs [1,2,3]. How.does this work align with the previous works.\n\n6. Some missing comparison, e.g. LINKX [4], BernNet [5], ACM-GCN [3] and GloGNN[6].\n\n[1] Zhu J, Yan Y, Zhao L, et al. Beyond homophily in graph neural networks: Current limitations and effective designs[J]. Advances in Neural Information Processing Systems, 2020, 33: 7793-7804.\n\n[2] Ma Y, Liu X, Shah N, et al. Is homophily a necessity for graph neural networks?[J]. arXiv preprint arXiv:2106.06134, 2021.\n\n[3] Luan S, Hua C, Lu Q, et al. Is Heterophily A Real Nightmare For Graph Neural Networks To Do Node Classification?[J]. arXiv preprint arXiv:2109.05641, 2021.\n\n[4] Lim D, Hohne F, Li X, et al. Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods[J]. Advances in Neural Information Processing Systems, 2021, 34: 20887-20902\n\n[5]  He M, Wei Z, Xu H. Bernnet: Learning arbitrary graph spectral filters via bernstein approximation[J]. Advances in Neural Information Processing Systems, 2021, 34: 14239-14251.\n\n[6] Li X, Zhu R, Cheng Y, et al. Finding Global Homophily in Graph Neural Networks When Meeting Heterophily[J]. arXiv preprint arXiv:2205.07308, 2022.\n\n[7] Eli Chien, Jianhao Peng, Pan Li, and Olgica Milenkovic. Adaptive universal generalized pagerank\ngraph neural network. In International Conference on Learning Representations, 2021.\n\n[8] Luan S, Zhao M, Hua C, et al. Complete the missing half: Augmenting aggregation filtering with diversification for graph convolutional networks[J]. arXiv preprint arXiv:2008.08844, 2020.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: medium\nQuality: medium\nNovelty: low\nReproducibility: NA",
            "summary_of_the_review": "Although some theoretical analysis is interesting, this paper lacks novelty and strong experimental support. Thus, I don't think it is ready to be published.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper771/Reviewer_AcUh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper771/Reviewer_AcUh"
        ]
    },
    {
        "id": "y0WyNAlWfkz",
        "original": null,
        "number": 3,
        "cdate": 1666751734117,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666751734117,
        "tmdate": 1666751734117,
        "tddate": null,
        "forum": "kh3JurmKlux",
        "replyto": "kh3JurmKlux",
        "invitation": "ICLR.cc/2023/Conference/Paper771/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a general framework ALT to deal with the heterophily problem in GNNs. The main idea is to design multiple GNNs or MLP with different graph filters and it finally merges their predictions regardless of the GNN backbones. A local version is also developed for further improvement. ",
            "strength_and_weaknesses": "# Strength:\n\n1. The paper is well-written and easy to follow.\n\n2. The proposed idea can be used as a general framework to potentially improve any GNN models.\n\n3. The motivation of ALT-Global is clear and valid.\n\n# Weakness:\n\n1. The novelty of the proposed idea is limited. The idea of combining graph signals from different graph filters is implicitly encoded in polynomial filters of graph signals, and this is a well-studied problem in the literature. For instance, in the analysis of ALT-Global (Section 3.2), the paper assumes the GA-MLP architecture: $H=C~MLP(X)$ and all three MLPs share the same parameters. Then the proposed ALT essentially reduces to a specific case of GPRGNN [1] whose polynomial filter is even more flexible and adaptive. \n\n2. The proposed framework might be able to improve some classic GNN backbones (such as GCN, SGC, and APPNP) that intrinsically adopt low-pass filters and therefore can not handle heterophilic data. However, it is unclear how the proposed idea improves stronger approaches such as GPRGNN [1] and other approaches with high-frequency filters. \n\n3. In the ablation study (Table 3), even for GCN, the ALT-Glocal variant only improves the performance very marginally. I suspect that ALT-Global can not improve the performance of GPRGNN, APPNP, or GCNII. The paper only presents the ablation study on GCN, but more results are needed to clarify this concern.\n\n4. The local adaptive method proposed in Section 3.4 is heuristic and ad-hoc. The training procedure in Section 3.5 seems to be computationally expensive but there is no discussion on the running time and training cost. \n\n5. There is a lack of comparison with other local adaptive approaches which also adaptively adjust the edge weight as in ALT-Local. For instance, graph attention networks [2] adjust the weight by attention scores; ElasticGNN [3] models the locally adaptive smoothness over the graph by graph trend filtering; DAGNN [4] adjusts the feature combination from different propagation layers by attention scores; More discussion and comparison will be helpful to justify the advantages of the proposed idea. Overall, it will be beneficial to show how the proposed idea improves state-of-art algorithms instead of old algorithms.\n\n[1] Adaptive Universal Generalized PageRank Graph Neural Network, ICLR 2021\n\n[2] Graph Attention Networks, ICLR 2018\n\n[3] Elastic Graph Neural Networks, ICML 2021\n\n[4] Towards Deeper Graph Neural Networks, KDD 2020\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written but the novelty is limited.",
            "summary_of_the_review": "The paper proposes a general framework ALT to deal with the heterophily problem in GNNs. The main idea is to design multiple GNNs or MLP with different graph filters and it finally merges their predictions regardless of the GNN backbones. The novelty is limited compared with existing approaches, and it is unclear how it advances the state-of-art algorithms. Moreover, a local version is developed for further improvement but the proposed method is quite heuristic without clear justification and running time analysis.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper771/Reviewer_j7Qg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper771/Reviewer_j7Qg"
        ]
    },
    {
        "id": "ll5SN9bhzA2",
        "original": null,
        "number": 4,
        "cdate": 1666846134240,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666846134240,
        "tmdate": 1666846134240,
        "tddate": null,
        "forum": "kh3JurmKlux",
        "replyto": "kh3JurmKlux",
        "invitation": "ICLR.cc/2023/Conference/Paper771/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "**Summary**\nThe paper proposed a method ALT to convert any graph neural network to be effective for non-homophily graphs. The key idea is to use two backbone GNNs and an additional MLP to shift (or adapt) the frequency response function of the diffusion filter. The authors also propose a more complicated version of ALT which compute a weight of edges with an additional GNN. The resulting model is optimized with a bi-level optimization method on both the train and valid vertices. ALT shows good empirical performance, especially on non-homophily graphs and on top of the classical GNNs.",
            "strength_and_weaknesses": "**Good Empirical Results**\nThe authors performed a very comprehensive study on a wide range of datasets. The authors also compared against a wide range of baselines. Overall the improvement is quite significant. Also, the authors conducted a detailed ablation study of ALT-local. That highlight the importance of frequency modulator.\n\n**Well Motivated/Explained Architecture Design**\nThe ALT design is well motivated by the combination of two filters with complementary characteristics. The edge reweighting is well motivated by the need to switch from global filter to local filter. The augmentation GNN is also well motivated by the discriminative argument to use a high pass filter.\n\n**Issue with Experiments**\nOne complain I have is that the bi-level optimization explicitly use the validation vertices to train the augmentation. This makes the empirical comparison unfair for the baselines. My suggestion would be to split part of the training nodes for training the backbone and augmentation separately.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\nWriting is very easy to follow.\n\n**Quality**\nGood.\n\n**Novelty**\nGood.\n\n**Reproducibility**\nShould be reproducible.",
            "summary_of_the_review": "Borderline accept, would be stronger if issue with experiments fixed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper771/Reviewer_qBZ9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper771/Reviewer_qBZ9"
        ]
    }
]