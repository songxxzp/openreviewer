[
    {
        "id": "VvBTpTr1_S",
        "original": null,
        "number": 1,
        "cdate": 1666495363771,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666495363771,
        "tmdate": 1666495363771,
        "tddate": null,
        "forum": "2xQVAXKjLdH",
        "replyto": "2xQVAXKjLdH",
        "invitation": "ICLR.cc/2023/Conference/Paper672/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "1, Present a new method to evaluate the cross-modal consistency by inspecting the decomposed semantic concepts.\n2, Introduce a new metric, called MIS-Score, which is designed to measure the fine-grained semantic alignment between a prompt and its generation quantitatively.\n3, Developed an automated robustness testing technique with referential transforms to test and measure the robustness of multi-modal synthesis models.",
            "strength_and_weaknesses": "Strength:\n1, The first time to propose a new approach for measuring the fine-grained semantic consistency for the multi-modal image synthesis tasks.\n2, A robustness testing technique is designed and implemented to evaluate the robustness of text-to-image generation models.\n3, Comparisions between different methods are interesting.\nWeaknesses:\n1, How to calculate weight wi in eq3?\n2, Can you calculate your metric directly on the benchmark dataset to check the annotation quality of the caption?\n3, Why Stable Diffusion is not the best model here?  It seems that they use more data.\n4, Do you still need a pretrained CLIP to calculate your score?\n5, How can you locate the object region?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity, Quality, Novelty, and Reproducibility are OK.",
            "summary_of_the_review": "A new metric is designed for measuring the fine-grained semantic consistency for the multi-modal image synthesis tasks. The measurement for multi-modal image synthesis tasks are important.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper672/Reviewer_1VeC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper672/Reviewer_1VeC"
        ]
    },
    {
        "id": "YPV_JSYwEt",
        "original": null,
        "number": 2,
        "cdate": 1666686536527,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666686536527,
        "tmdate": 1666686557792,
        "tddate": null,
        "forum": "2xQVAXKjLdH",
        "replyto": "2xQVAXKjLdH",
        "invitation": "ICLR.cc/2023/Conference/Paper672/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new metric to evaluate the image quality for multi-modal image synthesis task,  which relies on a parser to find different semantic concepts and a detector to find the corresponding objects and attributes in the image. Besides, a robustness testing technique is proposed to evaluate the robustness of a generative model.",
            "strength_and_weaknesses": "Strength:\n\n1. The paper is well written and easy to follow.\n\n2. Authors further consider the fine-grained semantic consistency between the given text and synthetic image to completely evaluate the correlation between them.\n\nWeaknesses:\n1. Basically, the proposed metric mainly focuses on measuring the semantic consistency between the given text and the generated image, which is different from IS and FID. So some statements shown in introduction, e.g., \"These metrics work well for the generation from simple prompts, e.g., description of a single object. However, for prompts with multiple objects and additional context information, simply adopting these metrics is insufficient and may lead to inaccurate or inconsistent results. \" might not be completely accurate. Also, the R-precision and CLIP score can also be adopted to measure the correlation between multiple object by adopting a similar detector used in the propose method.\n\n2. Although the proposed MIS-Score further considers the fine-grained correlation between the text and image, it mainly depends on a parser to find semantic concepts and a detector, so its performance might be affected by both components. \n\n3. For equation 2, could authors give more details to explain why it can be used to measure the correlation?",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty of proposed metric might be limited, but authors provide sufficient information to reproduce the proposed method.",
            "summary_of_the_review": "Please see above weaknesses, and I am happy to change my rating based on authors' responses.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper672/Reviewer_jHfC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper672/Reviewer_jHfC"
        ]
    },
    {
        "id": "Xx3aOGDZdq",
        "original": null,
        "number": 3,
        "cdate": 1666927146757,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666927146757,
        "tmdate": 1666927146757,
        "tddate": null,
        "forum": "2xQVAXKjLdH",
        "replyto": "2xQVAXKjLdH",
        "invitation": "ICLR.cc/2023/Conference/Paper672/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The author proposes a new metric for evaluating the multi-mode image synthesis method, and has tested new metrics. However, method details are limited. In addition, the author's contribution point 1,3 is difficult to capture in the introduction. Besides, the papers investigated are old.",
            "strength_and_weaknesses": "+The author proposes a new metric for evaluating multi-mode image synthesis methods\n+The author used a large number of experiments to verify\n\n-Recently, there are many meaningful works for multi-mode image synthesis. I don't know why the author has not conducted more detailed research in the Introduction section. Instead, follow the work of 2020 and 2021.\n\nDalmaz O, Yurt M, \u00c7ukur T. ResViT: residual vision transformers for multimodal medical image synthesis[J]. IEEE Transactions on Medical Imaging, 2022, 41(10): 2598-2614.\nIsaac-Medina B K S, Bhowmik N, Willcocks C G, et al. Cross-Modal Image Synthesis Within Dual-Energy X-Ray Security Imagery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 333-341.\nWu G, Chen X, Shi Z, et al. Convolutional neural network with coarse-to-fine resolution fusion and residual learning structures for cross-modality image synthesis[J]. Biomedical Signal Processing and Control, 2022, 71: 103199.\nLv Z, Li X, Niu Z, et al. Semantic-shape Adaptive Feature Modulation for Semantic Image Synthesis[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 11214-11223.\nTan Z, Chu Q, Chai M, et al. Semantic Probability Distribution Modeling for Diverse Semantic Image Synthesis[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022.\n\n-In denying that Measure is an important metric, as Section 7 of [1], I hope that the author can further compare the advantages of the metric and have more proof of the metrics.\n\n[1] Zhou R, Jiang C, Xu Q. A survey on generative adversarial network-based text-to-image synthesis[J]. Neurocomputing, 2021, 451: 316-336.\n\n-In the introduce section, the author introduces MIS-Score, but it is difficult capture the first contribution point and the third contribution point by reading this section.\n\n-The introduction of the method is limited, and it is difficult to capture the details of the method. The author's description of the implementation framework is incomplete and it is difficult to understand the proposed framework.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The introduction of the method is limited, and it is difficult to capture the details of the method.",
            "summary_of_the_review": "The research topic is worth recommending, but the author's description of the method needs to be strengthened.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper672/Reviewer_nMLm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper672/Reviewer_nMLm"
        ]
    }
]