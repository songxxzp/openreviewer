[
    {
        "id": "q-PVSwrsQe",
        "original": null,
        "number": 1,
        "cdate": 1666506958156,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666506958156,
        "tmdate": 1666507095361,
        "tddate": null,
        "forum": "coLtCLTHFbW",
        "replyto": "coLtCLTHFbW",
        "invitation": "ICLR.cc/2023/Conference/Paper4791/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the effect of freezing parameters after certain iterations of differentially private training, both theoretically and empirically. Theory shows the convergence could be improved under certain situations and experiments show freezing layers closer to input (bottom layers) after training for a while could improve performance after DP training.\n\n",
            "strength_and_weaknesses": "Strengths:\n1. Freezing bottom layers during training is proven to be useful in DP training in a few other works, this paper provides some theory support of the approach.\n\n2. The decomposition of bias caused by clipping from an angular perspective is new in the community, to the best of my knowledge.\n\nWeaknesses:\n1. It is unclear whether the bias caused by clipping in Lemma 3.1 is a tight characterization or not, if the authors could provide a case when the bias is achieved, it will make the theory more convincing.\n\n2. The experiments are only for relatively simple architectures and datasets, if the authors could verify that freezing lower layers will benefit more variety of tasks, it would strengthen the contribution.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to follow and in good quality, the novelty is moderate significant and the experiment should be reproducible with details provided in the paper.",
            "summary_of_the_review": "Overall I feel the paper studied an interesting problem/approach, with both theory and experiment support, but there is plenty room for improvements.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4791/Reviewer_z6fv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4791/Reviewer_z6fv"
        ]
    },
    {
        "id": "Isi-U4Wpk-",
        "original": null,
        "number": 2,
        "cdate": 1666659955898,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659955898,
        "tmdate": 1666659955898,
        "tddate": null,
        "forum": "coLtCLTHFbW",
        "replyto": "coLtCLTHFbW",
        "invitation": "ICLR.cc/2023/Conference/Paper4791/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper studies the DP-SGD with a set of fine-tuning methods, which freeze some hidden layers in a neural network. The authors claim that their method can (under some strong assumptions) improve the utility under the same privacy budget, which is verified on small image datasets.",
            "strength_and_weaknesses": "Strength: The paper is clearly written and the algorithm is carefully verified, from both theoretical and empirical perspectives.\n\nWeakness: The major flaw is in the novelty which is explained in detail in the following section. Another major flaw is the scope of this work: notice that DP is a systematic effort, covering different clipping function (e.g. recent DP-NSGD or automatic clipping still work with layer freezing, but not mentioned; also per-layer clipping will likely violate Assumption 3.2; but this work only considers the common gradient clipping in the flat clipping style), fine-tuning methods, tasks (this work only experiment on tiny images and not consider language tasks), optimzers (only experiment with SGD, not adaptive optimizers which have been used to achieve SOTA on CIFAR10), etc. Therefore, this work really studies a very narrow perspective of DP deep learning.\n\nBecause of the narrow scope of this work, I would expect to see better analysis or empirical improvement. However, the improvement is insignificant (about 1% within the incomplete Table 1), and the analysis relies on too strong assumptions that are not empirically verified. In fact, it shouldn't be hard to print out the percentage of per-sample gradients that are clipped/not-clipped before and after freezing.",
            "clarity,_quality,_novelty_and_reproducibility": "The overall quality is okay, especially the clarity. However, I doubt the originality of the work is significant given that last-layer training (also known as linear probing) and training only the last few layers is commonly used already (see Sec 5.2 in https://aclanthology.org/2020.blackboxnlp-1.4.pdf and \"top2\" method in https://arxiv.org/pdf/2110.05679.pdf)",
            "summary_of_the_review": "I recommend heavy revision of this work before publishing.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4791/Reviewer_PEmL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4791/Reviewer_PEmL"
        ]
    },
    {
        "id": "5xCAew4g3AF",
        "original": null,
        "number": 3,
        "cdate": 1666902627181,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666902627181,
        "tmdate": 1666902627181,
        "tddate": null,
        "forum": "coLtCLTHFbW",
        "replyto": "coLtCLTHFbW",
        "invitation": "ICLR.cc/2023/Conference/Paper4791/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to do layer freezing for DPSGD training. It analyzes the properties of different layers in the training process, provides some theoretical analysis on the affect of freezing, and shows the effectiveness of the algorithm in some real datasets.",
            "strength_and_weaknesses": "Strength:\nThe paper looks at an important problem, and provides some interesting empirical and theoretical analyses. I like the part about PWCCA specifically.\n\nWeakness:\n- Given the amount of work on layer freezing in private training (though in the pre-training / fine-tuning case, as has been mentioned in the paper), I'm not so sure about the novelty of the work.\n- The empirical improvement doesn't seem very significant.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\nIn general it's clear, but the theoretical analysis seems a bit confusing to me. (See point below.)\n\nQuality:\n- The analysis in Section 3.4 sounds quite straightforward to me. Because I think when we freeze some parameters, the norm \"quota\" of the rest of the parameters are for sure increased and that would give us reduced bias. Could you elaborate more on the difficulty of the analysis?\n- The empirical results don't seem very significant.\n\nNovelty:\nI'm a bit concerned about this, as it seems like the idea of layer freezing is quite common in DPSGD training (though in the pre-training / fine-tuning case, as has been mentioned in the paper). Also, I feel like the works about per-layer clipping or adaptive clipping might be related, as they also look at properties of different layers. I guess per-layer clipping can be viewed as a general case of freezing, i.e. some layer has clip norm 0.\n\nReproducibility:\nI didn't see the specification of batch size and number of steps in the experiments. Those parameters are quite essential as they affects the privacy-utility tradeoff.\n\n\nOther comments:\n\"... adding noise does not bias the estimation...A higher variance means a larger noise is more likely added to s_t^B , therefore we would expect \u03b3_t to be large.\": It seems a bit contradictive to me. Also, I feel like if the noise is increased by increasing C, then \u03b3_t^B might even be smaller, right?\n\n- Assumption 3.2 \"... does not change the gradients that are clipped and unclipped gradients\": I don't understand the sentence. Could you elaborate more?",
            "summary_of_the_review": "Some analyses seem interesting, while I'm a bit concerned about the novelty of the work.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4791/Reviewer_Hfmj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4791/Reviewer_Hfmj"
        ]
    }
]