[
    {
        "id": "3LV6TgoSYu",
        "original": null,
        "number": 1,
        "cdate": 1665691878851,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665691878851,
        "tmdate": 1665691878851,
        "tddate": null,
        "forum": "3v2DIO9oVl",
        "replyto": "3v2DIO9oVl",
        "invitation": "ICLR.cc/2023/Conference/Paper4001/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies generalization bounds for neural networks based on the algorithmic stability. To this aim, the paper first introduces a new stability called almost sure support stability, which relaxes the uniform stability by allowing the stability to be violated with some probability. The first result is an exponential bound on generalization gaps for algorithmic satisfying almost (sure) support stability. Then, the paper develops a.e. support stability bounds for SGD with locally Lipschitz/smooth functions. Finally, the authors develop bounds on the global Lipschitz/smoothness constants for neural networks with ReLU activation functions. Experimental results are also provided to verify the effectiveness of the theoretical results.",
            "strength_and_weaknesses": "Strength:\n\nThe almost sure support stability is a relaxation of the uniform stability, and therefore can be applied to more general problems. The authors apply this stability to derive generalization bounds for neural networks with ReLU activations, which have not been studied by uniform stability.\n\nWeakness:\n\nThe generalization bounds depend on the global Lipschitz and global smoothness constants. While the authors give estimates for these constants, the upper bounds grow as a linear function of the number of parameters, and an exponential function on the depth. This implies these results can only apply to neural networks with small complexity. An advantage of stability analysis is that it can imply dimension-independent bounds. However, the results of this paper does not inherit this property. \n\n",
            "clarity,_quality,_novelty_and_reproducibility": "In Thm 3, the authors develop high-probability generalization bounds for algorithms with support stability. The bounds are of the order $O(\\sqrt{m}\\beta)+1/\\sqrt{m}$. This bound is a bit crude. For example, in the recent analysis generalization bounds for the order $O(\\beta\\log m+1/\\sqrt{m})$ have been developed for $\\beta$-uniformly stable algorithms, which is much better than the bounds in Thm 3. While Thm 3 considers a relaxation of uniform stability, the results do not recover the existing bounds if $\\eta=0$.\n\nThe upper bounds of Thm 7 also seem to be suboptimal. For example, if $\\alpha_0=0$ we expect the generalization error to be 0. However, in this case, the upper bounds there become $O(L_g^22^{T/m}/(K_gm))$. Furthermore, the step size is of the order $O(1/t)$. The step size decays very fast for which the training errors by SGD decay very slowly. Therefore, it is hard to find a good model with this step size scheme.\n\nIf we combine Proposition 12 and Thm 7 together, the generalization bounds would involve $O(nK^{2H})$, where $n$ is the number of parameters and $H$ is the depth. It seems that this approach does not show advantage over complexity-based approach. For example, size-independent generalization bounds have been derived based on Rademacher complexity analysis, see, e.g., Ref [1,2]. Therefore, it is not quite clear to me the usefulness of the support stability since there are no convincing applications. I would suggest the authors to make a detailed comparison between these bounds.\n\n[1]: Golowich, Noah, Alexander Rakhlin, and Ohad Shamir. \"Size-independent sample complexity of neural networks.\" Conference On Learning Theory, 2018.\n[2]: Bartlett, Peter L., Dylan J. Foster, and Matus J. Telgarsky. \"Spectrally-normalized margin bounds for neural networks.\" Advances in neural information processing systems 30 (2017).\n\nMinor comments:\n\nSection 4: In 3.1 should be in Section 3.1\n\nSection 4: and and\n\nThm 9: what is the meaning of ab(x)\n\nSection 5.3: it is possible look\n\nProof of Thm 7: you define $\\delta_t=\\|E_r[w_t-w_t']\\|$. According to the proof, it seems that $\\delta_t=w_t-w_t'$\n\nProof of Thm 3: \"the concavity of the absolute value function\" should be \"the convexity of absolute value function\"",
            "summary_of_the_review": "The paper provides a new stability and apply it to problems with local Lipschitz/smooth problems, e.g., neural networks with activation functions. However, the upper bound is a linear function of the number of parameters and an exponential function of the depth. Therefore, it is not clear to me the advantage of this approach over the complexity-based approach.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4001/Reviewer_omdi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4001/Reviewer_omdi"
        ]
    },
    {
        "id": "cOs5emV6Dvp",
        "original": null,
        "number": 2,
        "cdate": 1666536936877,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666536936877,
        "tmdate": 1666536936877,
        "tddate": null,
        "forum": "3v2DIO9oVl",
        "replyto": "3v2DIO9oVl",
        "invitation": "ICLR.cc/2023/Conference/Paper4001/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper designs a new notion \u201calmost sure support stability (a.s. support stability)\u201d to measure the learned model\u2019s stability to the disturbance in the training data. The authors then give a generalization bound based on this stability measure. The authors also show that ReLU network is a.s. locally smooth and a.s. locally Lipschitz continuous, which then imply that that the network is a.s. support stability.",
            "strength_and_weaknesses": "This paper presents a relatively new notion on the stability. The generalization bound based on the stability is also novel but not seems not difficult. The authors are required to clarify why the \u201ca.s.\u201d is helpful. Is it designed to match the zero-measure nonlinear points in the activation functions? Also, the authors are required to give a more detailed discussion on the differences and advantages of the a.s. support stability with the many existing stability measures.\n\nThe paper gives detailed proofs in appendices. However, the paper needs a proof sketch in the main text. Based on the sketch, the authors need to clarify the significance and difficulty of the proofs. To me, the proofs are quite straightforward: the relationship between the stability and the generalization bound needs merely an additive decomposition on the probability compared with the existing results; the a.s. locally smooth and a.s. locally Lipschitz continuous are straightforward given the nonlinear points in ReLU are of zero measure; and the a.s. support stability of the whole ReLU network comes from (1) the stability of a single layer (linear mapping of the weight matrix + a.s. linear mapping of the ReLU) and (2) composition of the multiple layers. These undermines the quality of this paper. Please correct me in the responses if I was wrong.\n\nOverall, the authors are encouraged to address the issues above in the responses and the revised draft.",
            "clarity,_quality,_novelty_and_reproducibility": "For clarity and novelty, please refer to point 1 above. This paper is of fair quality in its current form.",
            "summary_of_the_review": "Overall, I recommend \"5: marginally below the acceptance threshold.\" I need the authors to give more details in their responses, and if this paper is accepted, the draft needs a revision.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4001/Reviewer_gUyv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4001/Reviewer_gUyv"
        ]
    },
    {
        "id": "wkQTNUPRnz5",
        "original": null,
        "number": 3,
        "cdate": 1666708204507,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666708204507,
        "tmdate": 1669564929889,
        "tddate": null,
        "forum": "3v2DIO9oVl",
        "replyto": "3v2DIO9oVl",
        "invitation": "ICLR.cc/2023/Conference/Paper4001/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper attempts to prove algorithmic stability-based generalization error bounds for neural nets with ReLU activation functions. To do this, the modified definition of \"Almost (Sure) Support Stability\" is proposed, which weakens the standard uniform stability definition and requires it to hold with a certain probability over the support set of real data. Theorem 3 shows that a previously-known stability-based generalization bound can be modified using the new definition. Next, the paper defines almost locally Lipschitz and smooth functions, and Theorem 7 shows that assuming a bounded almost locally Lipschitz and smooth coefficients, a generalization guarantee will hold for the SGD optimizer where the number of epochs can be as large as $O(\\log(m))$ with $m$ being the number of training samples. Finally, Theorem 9 uses the notions of almost locally Lipschitz and smooth functions to prove an asymptotic convergence guarantee for ReLU-based neural nets.",
            "strength_and_weaknesses": "Strengths:\n\n1) The paper is well written, and the presentation is clear and satisfactory.\n\n2) The proposed theoretical framework seems useful for proving generalization error bounds for neural nets with non-smooth activation functions such as ReLU.\n\nWeaknesses:\n\n1) I do not find the paper's results adequate to answer the introduction question: \"Is there a reasonable definition of stability that incorporates distribution properties and leads to small generalization error?\" This is because the paper's results are mostly based on the assumptions on the local Lipschitzness and smoothness of the loss function, and there are very few assumptions on the data distribution which is the key to the good generalization performance of deep convolutional nets on image data. In addition, the smoothness coefficient of standard deep neural networks could be extremely large in practice, which makes the generalization bound overly large for actual deep learning experiments.\n\n2) Theorem 9 is an asymptotic convergence result and does not provide a non-asymptotic generalization error bound that holds for finite training data.\n\n3) The paper's experiments use a one-layer neural network with ReLU activation (the width of the network is not specified in the text). This setting seems too simple for experimenting the generalization framework, and that would be better to include numerical results for more realistic deep learning problems, e.g. a deep CNN or ResNet applied to a more challenging image dataset.  ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and the theoretical analysis has sufficient novelty.",
            "summary_of_the_review": "This paper aims to extend the algorithmic stability generalization analysis to ReLU-based neural networks by defining and analyzing the notion of almost (sure) support stability. While the paper is well written and the analysis takes some steps toward the goal of understanding the generalization of ReLU-based networks, I still think the paper's results are not sufficient to properly bound the generalization error of standard deep neural networks in practice.  ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4001/Reviewer_8Tfr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4001/Reviewer_8Tfr"
        ]
    },
    {
        "id": "fllvYM3lwX",
        "original": null,
        "number": 4,
        "cdate": 1666715058001,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666715058001,
        "tmdate": 1666715058001,
        "tddate": null,
        "forum": "3v2DIO9oVl",
        "replyto": "3v2DIO9oVl",
        "invitation": "ICLR.cc/2023/Conference/Paper4001/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper aims to establish a sharp generalization error bound for NN with ReLU activation when the network size doesn\u2019t grow with the training set size. This paper provides a weakened version of uniform stability and proves the generalization guarantees of SGD for training over locally Lipschitz and smooth objectives. Moreover, the authors apply the developed generalization analysis to prove the generalization bound of SGD for training NN with ReLU activations, which yields a vanishing generalization bound when the NN size doesn\u2019t grow with the training sample size.",
            "strength_and_weaknesses": "Strength:\n* This paper provides a new notion of algorithmic stability, which is weaker than prior works and can lead to a meaningful generalization error bound.\n* This paper proves the generalization of SGD under a new set of assumptions on the training objectives including \u201calmost locally Lipschitz\u201d and \u201calmost locally smooth\u201d.\n* This paper further establishes the generalization of SGD for training NN with ReLU activations by showing that the objective function satisfies the almost locally Lipschitz/smooth conditions with certain parameters.\n\nWeakness:\n* I can understand that involving the almost sure definition and considering the support of $D$ can certainly weaken the original definition of uniform stability. However, the authors may need to provide some examples to quantify how weak it is and how much improvement we can get by using this weaker version of stability.\n* What\u2019s the difference between Theorem 7 and the generalization results in [Hardt et al., 2016], if ignoring the difference in terms of the assumptions?\n* The neural network terminology in Section 5.1 is confusing. It seems that the major goal of Section 5 is to (1) verify that Assumptions (Definitions 4 & 5) are satisfied. Then why Section 5.1.1 and Section 5.1.2 are necessary, at least in the main part of this paper?\n* As claimed in the beginning of this paper, one potential advantage of the developed theoretical framework is to leverage the information of data distribution, or simply, the support of data distribution. However, I do not see this in the theorem or discussion after the theorems. I believe this should be a key point of the new theory, so the authors may need to thoroughly discuss whether or how considering this point can give better generalization results.\n* The definition of $\\phi_{i,j}(w,x)$ needs more explanation, why this definition is useful and how to leverage it should be particularly discussed.\n* In Observation 10, why the results do not rely on the negativeness or positiveness of $in_{i,j}(w\u2019,x)$?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity needs to be improved. Many notations are confusing and the authors do not clearly illustrate why they are needed and how they are used in proving the main results.\n\nNovelty seems good, but it still lacks a thorough comparison with prior works.\n",
            "summary_of_the_review": "Overall this paper gives some new notions and analyses for studying the generalization of SGD. However, I am not fully convinced by the novelty and contribution of this paper as some discussions and comparisons to prior works are missing.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4001/Reviewer_UXnu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4001/Reviewer_UXnu"
        ]
    }
]