[
    {
        "id": "E7QRXrgH_V",
        "original": null,
        "number": 1,
        "cdate": 1666465615838,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666465615838,
        "tmdate": 1666465615838,
        "tddate": null,
        "forum": "QUK1ExlbbA",
        "replyto": "QUK1ExlbbA",
        "invitation": "ICLR.cc/2023/Conference/Paper1678/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the author proposes a RGB SLAM model with neural implicit map representation. In contrast to previous competitors, e.g., iMap and NICE-SLAM requiring depth maps as input, the proposed approach takes only RGB image sequences as input and leverages the hierarchical feature volumes with more levels to boost the performance. Experiments show that the proposed method achieves more accurate poses than NICE-SLAM and better depth maps than DROID-SLAM, but at the cost of higher memory and running time.",
            "strength_and_weaknesses": "strength:  \n\n(1)\tThe main contribution of the paper is the proposed dense SLAM system with implicit map representation, which allows SLAM system with implicit map representation to take only RGB images as input. \n\n(2)\tExperiments demonstrate that the proposed method gives competitive pose and depth accuracy to previous both classic and learning-based methods.  \n\nWeakness:\n\n(1)\tHigher memory and computational cost. The proposed method adopts hierarchical feature volumes with more levels to make the system work, which inevitably brings additional memory and time cost.\n\n(2)\tMissing explanations of some details.\n\na.\tOne thread for joint pose and map optimization. In many classic VO/SLAM systems (e.g., ORB-SLAM) and learning-based models (e.g., NICE-SLAM), two or more threads are used for tracking and mapping respectively to speed up. Is it possible to use a thread for tracking by taking only important pixels into consideration and another slower thread for mapping in this system? \n\nb.\tIn Eq (4), the paper uses randomly sampled M pixels for photometric rendering loss computation. In fact, because of the noise or the dynamic objects, not all pixels can provide the equal contribution to the constraint, so it might be better to use more stable pixels as in Eq (7).\n\n(3)\tDiscussion of related works of NeRFs without pose as input. \nThis work is also related to works of NeRFs which do not require poses as input, such as R1. \n\nR1: Barf: Bundle-adjusting neural radiance fields, Lin et al., ICCV 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "The calrity, quality, novelty and reproducibility are all good.",
            "summary_of_the_review": "As this paper is the first dense RGB SLAM with neural implicit map representation, I tend to accept this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1678/Reviewer_K6me"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1678/Reviewer_K6me"
        ]
    },
    {
        "id": "6lB4U5G57B",
        "original": null,
        "number": 2,
        "cdate": 1666560615987,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666560615987,
        "tmdate": 1672494814866,
        "tddate": null,
        "forum": "QUK1ExlbbA",
        "replyto": "QUK1ExlbbA",
        "invitation": "ICLR.cc/2023/Conference/Paper1678/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a SLAM system based on neural implicit representation as the underlying 3D map representation. Inspired by NICE-SLAM, the proposed approach uses a multi-resolution feature grid to represent the scene and jointly updates the camera poses and the map. The main difference to prior work is that the proposed approach operates on RGB instead of RGB-D images. This is achieved by integrating a multi-view stereo loss to enforce consistent depth and color predictions between close-by images. The proposed approach is evaluated on both synthetic and real data and the paper provides an ablation study.",
            "strength_and_weaknesses": "**Strength**:\n\nS1) The proposed approach is technically sound and its description in the paper is easy to follow.\n\nS2) Each part of the proposed approach is well-motivated.\n\nS3) The experimental results show that the proposed approach performs well on multiple datasets and is competitive with RGB-D-based methods.\n\n**Weaknesses**:\n\nW1) There are multiple statements that need to be clarified and / or revised (see below).\n\nW2) Eq. 5 is wrong. It should be $q_{k \\rightarrow l} = K_l \\tilde{R}_l^T \\left(\\tilde{R}_k K_k^{-1} q_k^\\text{homo} \\tilde{D}_q + \\tilde{t}_k - \\tilde{t}_l \\right)$.\n\nW3) Some design choices are not fully motivated: For the photometric warping loss, why not use the fact that the neural implicit representation also provides normal information to do a perspective warp of the patch instead of using a fronto-parallel warp? Why use SSIM and not any other robust loss (e.g., see [Park et al., Illumination change robustness in direct visual SLAM, ICRA 2017])?\n\nW4) Many components described in Sec. 3.1 are based on or inspired by prior work but are missing references. E.g., there is prior work on using multi-resolution volumes in combination with a MLP, e.g., NICE-SLAM, and work on explicitly storing the required information in the voxel volume (thus foregoing the use of a MLP), e.g., [Fridovich-Keil et al., Plenoxels Radiance Fields without Neural Networks, CVPR 2022] It would be good to acknowledge this prior work here. Similarly, using a photometric warping loss is common when training neural networks for monocular depth prediction, defining the photometric warping loss over patches is standard in the multi-view stereo literature, and depth map regulation is a standard loss term in networks that predict monocular depth. I don't think it is an issue that the paper builds upon existing work, but existing ideas should be clearly acknowledged.\n\nW5) It is unclear to me how the weights for Eq. 9 are chosen and how sensitive the proposed approach is to their choice.\n\nW6) Given that [Schoeps et al., CVPR 2019] showed that RGB-D-based methods perform worse on TUM than RGB-based methods, attributed due to the rolling shutter sensors used to capture the datasets, why not chose a dataset that enables a better comparison, e.g., the one from [Schoeps et al., CVPR 2019]? Why not compare against ORB-SLAM2 (or better ORB-SLAM3) in RGB- instead of RGB-D-mode to compare against a state-of-the-art feature-based approach?\n\nW7) The paper states that \"Our method is implemented with PyTorch (Paszke et al., 2017) and runs on a server with two NVIDIA 2080Ti GPUs.\" and that \"Our running time is reported with an RTX 2080TI GPU\". It is unclear to me whether one or two GPUs are used when reporting the running times in Tab. 4. This is important information required to understand the results.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity of presentation**\n\nThere are multiple statements that need clarification and / or revision:\n* The statements \"However, RGB-D cameras are limited to indoor scenes and are much less energy efficient for mobile devices.\" and \"However, they both require RGB-D sequences as input, which limits their application in outdoor scenes or mobile devices with a tight power budget.\" are used to motivate using a RGB-only approach. Yet, these statements ignore that depth sensors can operate outdoors, e.g., when based on time-of-flight measurements such as the depth sensor used by HoloLens 2, and that such sensors are available on mobile devices with tight power budgets, e.g., HoloLens 2. While it is true that RGB cameras are more energy efficient, I don't think this implies that RGB-SLAM approaches are more energy efficient than RGB-D-SLAM methods as the former often require compute to obtain depth measurements. Case in point, the proposed approach is clearly too powerhungry to be applicable on mobile devices. Furthermore, the proposed approach is only evaluated in indoor scenes.\n* I don't see how the proposed feature volume is \"fundamentally different\": 1) The statement \"Firstly, the decoders in NICE-SLAM (Zhu et al., 2022) are pretrained, which might cause problems when generalizing to different scenes, while our method learns the scene features and decoders together on the fly.\" seems self-contradictory: if the proposed approach learns the features and decoders on the fly per scene, then it does not attempt to generalize, so criticizing another method for attempting to generalize seems strange to me. It is furthermore not a difference in the feature volume. 2) The difference between aggregating features and computing occupancy from the aggregated feature instead of computing occupancies first and then aggregating them seems more like a design / implementation choice than a fundamental difference of the underlying feature volume.  \n* The paper states that \"In this way, we save many unnecessary occupancy evaluations and thus can afford to have much more layers of feature hierarchy.\" While true, the overall run-time and memory requirements of the proposed approach are still higher than NICE-SLAM.\n* The paper states that \"While NICE-SLAM (Zhu et al., 2022) only optimizes two feature volumes with voxel sizes of 32cm and 16cm, our method solves six feature volumes from 8cm to 64cm. Our fusion of features across many different scales leads to more robust and accurate tracking and mapping as demonstrated in experiments.\" I don't think the last claim holds as the paper compares a RGB- and a RGB-D-based approach, from which I don't clearly see that the fusion of the features is the main reason that the proposed approach is more accurate and robust (setting aside that this statement is not always true as shown in the experiments).\n\n**Originality of the work**\n\nPlease see W4 above for details. Overall, while the individual components might not be novel themselves, I think their combination into a RGB-based system is interesting and the proposed approach and its results will be valuable for the community.",
            "summary_of_the_review": "Overall, this is a solid paper that I think is of interest to the community. Most of the concerns raised above can be addressed quite easily. I am happy to increase my ranking if they are addressed. I did not give a higher ranking as I feel that the concerns have to be addressed first.\n\n------- After discussion -----------\n\nDuring the discussion phase, the authors successfully addressed my concerns. I thus increase my score and recommend to accept the paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1678/Reviewer_pLyh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1678/Reviewer_pLyh"
        ]
    },
    {
        "id": "lEWG0_3a7_",
        "original": null,
        "number": 3,
        "cdate": 1666766214100,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666766214100,
        "tmdate": 1672026154505,
        "tddate": null,
        "forum": "QUK1ExlbbA",
        "replyto": "QUK1ExlbbA",
        "invitation": "ICLR.cc/2023/Conference/Paper1678/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper attempts to tackle an important topic of monocular dense mapping using neural implicit maps. Inspired by iMAP and NICE-SLAM, differential neural rendering and multi-scale feature volumes are adopted to serve as the driving force of optimisation. On important contribution claimed is the multi-scale patch-based photometric loss applied to the reference view and its overlapping views. Experiment results on three public available datasets shows the effectiveness of the proposed method in terms of tracking and mapping.",
            "strength_and_weaknesses": "Strengths:\n\nMonocular dense mapping of indoor scenes is an interesting and important research direction. This paper builds upon previous work on RGB-D neural mapping and extends them to monocular setup with proposed multiscale scene encoding together with warping loss as well as window optimisation. Though the idea of each component is not novel and has been adopted in related works, there is good system contribution by extending neural dense mapping to monocular cases.\nAdequate quantitative results on three public datasets show the performance gain compared to other baselines.\n\n\nWeaknesses:\n\n\n- As mentioned in the strength part, the unique technical novelty of this paper is a bit limited and is not as large as its system contribution.\n\n- To my own understanding, incorporating depths not only provide direct supervision of geometry, more importantly, these geometric cues would able to largely accelerate the learning process. I am still not fully clear whether the proposed system would able to convergence in real-time as a SLAM system. More explanation from authors are appreciated. If it is real-time, I would not call it a SLAM system but a SfM/reconstruction system.\n\n- Related to last point, in the main text, though the run time is provided, it is more desirable to show the practical tracking and mapping time efficiency (including necessary ). For example, iMAP works at 10Hz tracking and 2Hz mapping. What about the proposed system? I\n\n\n- One interesting question to analysis or discuss is whether batch optimization of MLP and poses from scratch are ale to converge using proposed patch-based photometric losses. Works like BARF and NeRF-- struggles in indoor scenes. If not, could you provide more insights why incremental manner would work?\n\n- Reconstruction results on real-world TUM, Euroc datasets or self-captured scenes are expected as only reconstructed meshes on Replica are shown. It would be interesting to see these real-world scenes captured in an less idea conditions. Some video demos would be great to see.\n\n- The MLP decoder is fixed after intialisation stage. What is the main point of dosing so. Will there be clear performance drop enabling optimisation of MLP decoder? I am wonder whether fixing it would somehow affect the system performance to regions which are largely different to these during initialsation.\n\n\n- Like iMAP, the reconstruction are mainly shown on bouded single room scenes (like Replica). Would the monocular tracking perform well on ScanNet datasets where the image capturing conditions are more challenging and the scene volume is also larger.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity, Quality, Novelty:\nThe overall paper is well written with adequate experiments. Details could be found in last section.\n\nReproducibility: The codes are promised to be released so there should be possible to reproduce the work.\n",
            "summary_of_the_review": "I think this is a good paper which tries to taclke an interesting and important topic. \n\nHowever, I am not fully convincing about its real timeness (i.e., a SLAM) and would like to hear more from authors.\nI would like to adjust my rating after my concerns are properly addressed and more information could be provided.\n\n\n--------------------------------------------------------------------------------------------------------------------------------------------------------\nPost Rebuttal\n\nI have carefull read all the reviews and authors' feedbacks.\nMost of my concerns have been properly addressed by the authors, and I think a monocular dense neural filed SLAM like this would be beneficial to the area. There have also been some other NeRF-SLAM system recently available, it would be good if authors could add some discussion towards these recent works.\n\nOverall, I keep my positive rating towards this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1678/Reviewer_W3wZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1678/Reviewer_W3wZ"
        ]
    },
    {
        "id": "3w4LSiED-6",
        "original": null,
        "number": 4,
        "cdate": 1666828737793,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666828737793,
        "tmdate": 1671925138220,
        "tddate": null,
        "forum": "QUK1ExlbbA",
        "replyto": "QUK1ExlbbA",
        "invitation": "ICLR.cc/2023/Conference/Paper1678/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a dense SLAM method using neural implicit model as map representation. Compared to previous methods, the proposed method does not need depth maps as input. A hierarchical feature volume is used to facilitate map decoding. A photometric warping loss is proposed to be combined with the photometric rendering loss for optimizing the scene geoemtry and camera poses. Evaluation on both synthetic and real datasets show comparable or better results compared to previous methods. ",
            "strength_and_weaknesses": "Streangth\n- The photometric warping loss is novel and seems to be the main source of the boosted performance compared to NICE-SLAM.\n- The evaluations are thorough and consider both map and camera pose accuracies and cover both synthetic and real datasets.\n\n\nWeakness\n- Compared to NICE-SLAM, the main differences are (1) using different number of levels for hierarchical feature volume (2) adding the photometric warping loss. However, the camera pose accuracies in Table 1 are ~10 times better than NICE-SLAM. This is quite surprising, especially considering that the proposed method does not consume depth maps. It might be helpful to add more discussions accordingly.\n- In Eq (6), why are the warped images comapred to the rendered images instead of to the real images? This looks a bit strange and more explaination should be added.\n- The way of getting the visibility mask on page 5 is a bit strange. The used method does not handle occlusion at all.\n- In 3.3, the naive way of finding the global keyframes are not scalable as it needs to traverse all the previous keyframes for each new frame. This will never work in a real SLAM system.\n- Please add units to Table 2 and Table 3.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well presented and is easy to follow. ",
            "summary_of_the_review": "Despite only moderate modifications and enhancement to NICE-SLAM, the presented work delivers surprisingly good results in some of the evaluations. I feel those parts need to be better supported by further experiments such as more dedicated ablation studies. Compared to the existing works, the overall novelty of this work is marginal. I therefore tend to reject the paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1678/Reviewer_bVvS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1678/Reviewer_bVvS"
        ]
    }
]