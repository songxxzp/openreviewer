[
    {
        "id": "WQo_p10bjW5",
        "original": null,
        "number": 1,
        "cdate": 1666081817140,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666081817140,
        "tmdate": 1666082469195,
        "tddate": null,
        "forum": "N9Pk5iSCzAn",
        "replyto": "N9Pk5iSCzAn",
        "invitation": "ICLR.cc/2023/Conference/Paper2701/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes OTGNet to tackle the problem of continual learning/class-incremental learning on graphs. OTGNet consists of two components. The first component is an open/close triad selection and replay method to avoid catastrophic forgetting of existing knowledge. The second component is an information bottleneck module to decouple class-related knowledge from class-agnostic knowledge, and use the class-agnostic knowledge for propagation between nodes from new classes and existing classes. It is designed to avoid over-smoothing between existing classes and new classes. The authors perform experiments on real-world class-incremental settings. The proposed OTGNet outperforms various baselines of continual learning on graphs. ",
            "strength_and_weaknesses": "Strengths: \n- The problem of class-incremental GNN learning is valid and interesting. Dynamics and new classes are indeed problems in real-world graph learning. \n- The observation that nodes from existing classes influence nodes from new classes due to homophily is a unique and interesting perspective. It is also shown in the experiments that this indeed poses challenges and affects the results. \n- The designed methods seem novel and sound. Selecting important triads for replay to alleviate forgetting makes sense. Using influence functions to approximate the importance of triads is interesting. \n- The experimental results seem very good. The improvements over existing works are significant. The ablation studies are extensive enough to demonstrate the effects of individual components. \n\nWeaknesses and Questions: \n- Some notations and words can be revised to better describe the methods. For example, $log$ should be $\\log$, $exp$ should be $\\exp$, $sup$ should be $\\sup$, 'representative' should be 'representativeness'. \n- Some details of the proposed method are not very clearly described. I list several unclear points. \n    - On measuring the representativeness. We know that nodes in a graph influences the learned model in two ways, both in forward propagation (i.e. neighborhood aggregation) and backward propagation (i.e. model optimization via the loss). As far as I can see, the influence function in Eqn. 1 can only capture the latter one, i.e. whether a node appears in the loss, but not the former one, i.e. whether the node propagates its features to neighboring nodes. \n    - Intuitively, the scores $\\mathcal{R}(g_k^c)$ should influence each other. For example, suppose $i, j, k$ and $i, j, m$ are both close triads of class $k$, $i, j$ are both important nodes (e.g. hubs with high degrees) while $j, m$ are not. It is likely that both triads will get high scores. However, it is often sufficient to select only one of them (as only $i, j$ are important), i.e. with the presence of $i, j, k$, the score of $i, j, m$ will decrease. Is my understanding correct? If yes, how can OTGNet address for the case? \n    - In the triad structure replay, it is said that 'we will replay these triads from old classes when learning new classes'. However, it is not clear how will nodes that are not in selected triads be dealt with. Specifically, will they still participate in the forward propagation? If they are dropped, there will be missing auxiliary information (e.g. nodes in the selected triads will have missing neighbors). If they are not, the training cost is still high (since a whole graph participates in forward computation). Please clarify that. \n    - In Eqn. 10, 11, 12, it seems that $x_i(t), z_i(t)$ are not related to the layer. Does it imply that OTGNet only supports one layer of TGAT? \n- I appreciate the extensiveness of experiments with the following minor questions. \n    - I suggest some visualization or case study on the class agnostic embeddings $z$ and $x$ to better illustrate the necessity of learning $Z$. \n    - In Table 6, changing $K$ from 1000 to 100 leads to a significant performance drop. However, in Figure 7, it shows that the performance stabilizes with only $M=20$, which means that only 20 triads per class is enough for OTGNet to work. This seems counter-intuitive. From my understanding, it indicates that the triads with high $\\mathcal{R}$ (top $K$) do not necessarily lead to a good selection. Is that correct? ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is largely clear with some minor ambiguity in the methods description. See weaknesses and questions. \n\nNovelty: Overall, I think the paper presents a novel solution on an interesting problem (class-incremental GNN learning). The insights of the proposed solution are also novel. I specifically appreciate the use of class-agnostic information. \n\nQuality: The experimental evaluations of the proposed method are extensive. OTGNet outperforms existing baselines. Ablation experiments are also extensive. \n\nReproducibility: This paper is not submitted with code. Also, as the methods described in this paper are rather complex and not sufficiently clearly described, I do not think that this paper is easy to reproduce. ",
            "summary_of_the_review": "Overall, I think this paper proposes a novel and insightful solution to an important problem, with solid experimental evaluations. I recommend accepting the paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2701/Reviewer_FhGE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2701/Reviewer_FhGE"
        ]
    },
    {
        "id": "62GjKmX7k_a",
        "original": null,
        "number": 2,
        "cdate": 1666504790806,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666504790806,
        "tmdate": 1668727316351,
        "tddate": null,
        "forum": "N9Pk5iSCzAn",
        "replyto": "N9Pk5iSCzAn",
        "invitation": "ICLR.cc/2023/Conference/Paper2701/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a new task in temporal networks and with new methods. The proposed problem is related to the new class appearing at different times. \n\nThe authors claimed there are two challenges for the current temporal network: 1) How to dynamically propagate appropriate information in an open temporal graph, where new class nodes are often linked to old class nodes. This indicates that temporal graphs are usually homophily. 2) How to avoid catastrophic knowledge forgetting over old classes when learning new classes occurred in temporal graphs. No previous temporal network model includes a class-incremental learning setting.\n\nTo handle these two challenges, the authors proposed an information bottleneck-based message-passing framework, assuming that the information of a node can be disentangled into a class-relevant and class-agnostic one.",
            "strength_and_weaknesses": "Strength:\n\nThis paper proposed a framework to handle the class-incremental task in the temporal graph. The Triad Structure Selection is interesting. By using the influence function, it can select the important triangles. The task is novel and interesting. To accelerate the algorithm, the authors also apply a greedy result by showing that the value function F is monotone and submodular. This is intuitive. The experiments also shows that the model compared with TGN and TGAT have a better result, the ablation result shows that all the module works well. The experiments in the appendix show that the model can learn the class-agnostic knowledge and is able to mitigate the catastrophic forgetting problems. The ablation study is solid.\n\nWeaknesses: I have the following questions:\n\nFirst, the paper mentioned the heterophily setting in the temporal graph, which can be one main issue. However, in previous research, people found that the heterophily indicates that usually, GNN(such as vanilla GCN) can't work, but the traditional pagerank-based algorithms(APPNP) or other models which have a more powerful aggregator method(such as GCNII, GGCN, or other attention-based models, which implicitly handle the heterophily by a learning-based aggregator) perform well in these heterophily tasks. I think this kind of model should also be a baseline (although I understand the setting is a temporal graph and new coming tasks, so maybe the authors can first ignore the temporal information. ). Moreover, the baselines are not enough, both TGN and TGAT are baselines 2 years ago. Plenty of temporal network models are proposed and should be compared. \n\nSecondly, the time complexity of choosing triads is unscalable. If the testing set is large, or the graph itself is large, the algorithm can't work in a limited time. However, for temporal graphs, we usually have more edges due to the time domain. Some possible work like Causal Anonymous Walk may somehow solve this issue by random walk. And these methods also have the potential to represent more complex motives instead of triangles.\n\n[1] Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph Convolutional Neural Networks\n[2] Inductive Representation Learning in Temporal Networks via Causal Anonymous Walks",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, I think it's a good paper. The paper proposed a new setting for temporal graphs and proposed a new algorithm based on the task. The task is interesting and novel in the temporal graph domain. The ablation study also shows that the model can work as expectation. The paper also provides some experiments to show that their model can achieve state-of-the-art performance. The paper is technically sound. The paper needs some background to have a better understanding.",
            "summary_of_the_review": "Overall, I think this paper is borderline paper. This paper proposed a novel task. It focused more on the class-incremental learning problem. The tasks and proposed methods all focused on this topic. The temporal network setting is more like a specific task. The paper also proposed some new techniques to solve this problem but these techniques are mostly from papers from other domains. The performance is not solid enough, with only 2 baselines that are only focused on the temporal network (can't solve either class incremental problems or heterophilic graph problems). ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2701/Reviewer_Riiz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2701/Reviewer_Riiz"
        ]
    },
    {
        "id": "oaLONpHbakd",
        "original": null,
        "number": 3,
        "cdate": 1666585927526,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666585927526,
        "tmdate": 1666585927526,
        "tddate": null,
        "forum": "N9Pk5iSCzAn",
        "replyto": "N9Pk5iSCzAn",
        "invitation": "ICLR.cc/2023/Conference/Paper2701/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focusing on continuous open temporal graph where new nodes and new target node labels will join with time going on. This field is lack of study, and this paper proposes OTGNet which is far better than similar works.",
            "strength_and_weaknesses": "## Strength\n\n- This paper focues on continuous open temporal graph which is lack of formal study in previous works.\n- This paper proposes OTGNet which is empirically far better than similar works.\n\n## Weakness\n\nSome statements need to be improved for better understanding.\n\n- The definition of $I_{loss}$ need to be improved. For example, upweight by $\\epsilon$ need to be formally expanded. I understand that $\\epsilon$ is the extra weighted classification loss only for traidic nodes only after reading the appendix.\n- Will it be possible that Algorithm 1 select triadics that are not connected with any node in current batch or task? I think those triadics are meaningless. If Algorithm 1 can avoid this, how it is guaranteed? I do not see any step in Algorithm 1 to avoid this.\n- Class-agnostic representation $Z(t)$ need to be clarified. How to really compute $L_{IB}$? I think it is infeasible to compute any expection value in the formula.\n- Is neural network method the only way to get $Z(t)$? I think this optimization is quite classic, and may have non-parametric approximation. Can you confirm that there is no other approximation?\n\nBesides, I have a minor concern of Algorithm 2:\n\n- For every task, you will select new important triadics $S_k$ for each class and update them in the memory. Thus the triadic buckect $S$ will indeed grow without restriction. Is there any way that you can limit the maximum size of $S$? If so, how will this restriction hurts the performance?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity need to be improved.\nQuality and novelty are fine.",
            "summary_of_the_review": "This paper focues on continuous open temporal graph task which is lack of study, and make a concrete contribution to the field with OTGNet which is empirically far better than similar baselines.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2701/Reviewer_KnTc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2701/Reviewer_KnTc"
        ]
    },
    {
        "id": "ZokVEz971_",
        "original": null,
        "number": 4,
        "cdate": 1666612242186,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666612242186,
        "tmdate": 1666612242186,
        "tddate": null,
        "forum": "N9Pk5iSCzAn",
        "replyto": "N9Pk5iSCzAn",
        "invitation": "ICLR.cc/2023/Conference/Paper2701/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper focuses on learning GNNs on open temporal graph where new nodes with novel classes are also added to the graph. The proposed method solves two major issues that existing temporal GNN methods have under this setting: learning with added heterophily and catastrophic forgetting. To solve the catastrophic forgetting, a data selection process motivated by the fluence function is considered which is defined to maximize the representativeness of the selections. The author proposes an information bottleneck based loss function to encourage the model to learn the class agnostic representations. Experimentations on real-world benchmark suggests this algorithm works with state of art temporal GNN and performs favorably.",
            "strength_and_weaknesses": "Strength:\n1. The problem of learning open temporal graph is of great practical value as in many applications where graphs are updated consistently with both new and old node types. The algorithm proposed in the paper clearly improves the state of art temporal GNN algorithms under this setting. \n2. The proposed methods are well motivated, and are supported with both theoretical and empirical results. \n3. The proposed algorithm is very generalizable. It works with basically any temporal GNN model with no or little modifications.\n\nWeakness:\n1. The experimentation process needs further elaboration, especially on how the baseline models are trained and tuned. For example, there might be trade-off between AP and AF depending on how many epochs the model trains on the new task.\n2. While the loss function encourage class-agnostic representation, to what extend the learned representation is class-agnostic can be better depicted besides the ablation study measured by model performances. For example, suppose we cluster the embeddings, will the clusters correlate with classes?",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well structured and in general easy to follow. The evaluation is thorough and extensive but the experimentation setting needs further elaborations. The proposed solution is novel and original.",
            "summary_of_the_review": "This paper provides a neat and novel solution to the open temporal graph, a setting is of great practical value but not actively researched. The algorithm's correctness is proved both theoretically and empirically. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2701/Reviewer_WeDg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2701/Reviewer_WeDg"
        ]
    }
]