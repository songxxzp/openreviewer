[
    {
        "id": "fK9i-_Kn8vV",
        "original": null,
        "number": 1,
        "cdate": 1666503998667,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666503998667,
        "tmdate": 1670314063551,
        "tddate": null,
        "forum": "AZFvpnnewr",
        "replyto": "AZFvpnnewr",
        "invitation": "ICLR.cc/2023/Conference/Paper204/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper propose a regularization method to maintain the trainability of the model during the filter pruning process. The regularization is applied on both the weight and the BN parameters. Experiment results on multiple dataset and model architectures show promising performance comparing to other SOTA pruning methods.",
            "strength_and_weaknesses": "## Strength\n1. The paper makes novel and significant contribution by introducing the concept of trainability preservation into the neural network pruning process.\n2. The proposed method is well motivated and theortically sound\n3. Thorough emperical evaluation is provided to prove the effectiveness of the proposed method\n\n## Weakness\n1. The paper only demonstrates the model performance during the finetuning process. As a regualrization paper, it would be interesting to show how the regularization perform during the regularized training process. Things like how does the regularization affect model accuracy before pruning, and how it changes the mean JSV. I would encourage the author to repeat Figure 3 with the regualrized training epochs before the pruning.\n2. To my understanding the regularizer requires additional training epochs before pruning to take effect, however there's no discussion on how many epochs is needed, and how it's decided. This may also cause unfair comparison for the results in Table 1 and 2, as some baselines may be trained with less epochs in total (both before and after pruning), and may benefit from more training epochs\n3. The paper limits the exploration on L1 megnitude-based pruning with fixed pruning precentage on each layer. However there are more advanced filter pruning techniques like Taylor importance-based global pruning[1], or dynamically determining the filters to be pruned during regularized training process[2,3]. It would be interesting to see if the proposed method works under these pruning schemes.\n\n[1] https://arxiv.org/abs/1906.10771\n\n[2] https://proceedings.neurips.cc/paper/2016/file/41bfd20a38bb1b0bec75acf0845530a7-Paper.pdf\n\n[3] https://arxiv.org/pdf/1908.09979.pdf",
            "clarity,_quality,_novelty_and_reproducibility": "The paper makes novel and significant contribution by introducing the concept of trainability preservation into the neural network pruning process. The paper is overall clearity written and easy to follow. The quality of the paper is generally good, but can be improved by further showing the model behavior during the regularized training phase with the proposed method, and consider the additional training steps needed by the proposed method in discussing the experiment results.",
            "summary_of_the_review": "Generally the paper proposes an interesting and strong method for improving the finetuning trainability of the pruned model. The method is novel and solid. Meanwhile there are some concern on the behavior of the model during the regularized training phase and the fairness of the experiment. I would recommend a weak acceptance for now, expecting the author to clear my doubt in the rebuttal.\n\n## Post rebuttal\n\nI have read other reviews and all responses from the author. Most of my concerns are resolved. The paper provides a novel prespective for improving DNN pruning, where is shows small but consistent improvement in accuracy under practical sparsity, and larger accuracy improvement under high sparsity. I would keep my score as weak accept.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper204/Reviewer_LVfu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper204/Reviewer_LVfu"
        ]
    },
    {
        "id": "RK-j3t29I7k",
        "original": null,
        "number": 2,
        "cdate": 1666589894121,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666589894121,
        "tmdate": 1670528090742,
        "tddate": null,
        "forum": "AZFvpnnewr",
        "replyto": "AZFvpnnewr",
        "invitation": "ICLR.cc/2023/Conference/Paper204/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a neural network pruning method which perserves trainability after pruning. The authors argue that the proposed approach will make the network easier to train after pruning therefore lead to a better finetuned model. First, the proposed method use L1 norm to select important and unimportant filters. Then,  a trainability regularization term is induced during the finetuning step which enforces the important filters to be orthogonal to unimportant ones. In addition, parameters in BN layers are regularized by L2 norm for those unimportant filters. The authors validate the proposed method on CIFAR-10/100 and ImageNet-1k.",
            "strength_and_weaknesses": "[Strength]\n\n* The paper is overall well-written and easy to follow.\n* The authors compared their method to multiple strong baseline methods, such as OrthConv and KernOrth.\n* In the finetuning, the authors compared two different learning rates. All methods are trained under the same settings for fairness.\n* Experiment results on ImageNet are reported, in addition to the CIFAR-10/100, including a dozen baseline methods.\n* The accuracy improvement is significant on CIFAR-10/100\n\n[Weakness]\n* The novelty is incremental. Orthogonal regularization is not new in training deep network. Dating back to years ago, there were lots of discussions of weight regularization to make network more trainable, such as dynamic isometry constraint or nuclear norm regularizer. This work extends these ideas to network pruning, with some heuristic adaptations. For example, the correlation between selected important filters is not penalized in the proposed regularizer. BN norms of unimportant filters are considered. However, all these adaptations lack strong theoretical motivations. The authors did not provide any theoretical insight of why the proposed decorrelation plays a critical role in deep neural network pruning. From the numerical results, it seems that the improvement of the proposed method is also marginal on large-scale datasets.\n\n* Marginal improvement on large-scale datasets such as ImageNet. The difference sof the proposed method v.s. previous SOTA methods are around or less than 0.5% in most cases. This is not significant, especailly when the training setting in this work is not SOTA. For example, using a better training recipe in \"Resnet strikes back: An improved training procedure in timm\u201c, it is possible to improve ResNet-50 from 76% to 80% on ImageNet-1k. The 0.5% improvement is hardly to say a significant number.\n\n* No trained long enough. In SOTA training setting, ResNet-50 on ImageNet requires 360 epochs of training. Training even longer can still improve accuracy a bit. In this paper, most training experiments are early-stopped. So it is hard to tell the final accuracies when all models are trained by 360 epoches.\n\n* Training curves not reported. As the key argument of this work is trainability, the convergence curve should be plotted. Again, please consider to train long enough such that all models achive their stable convergent points. Then please compare the convergence speed.\n",
            "clarity,_quality,_novelty_and_reproducibility": "* The paper is presented clearly, with sufficient related works and related discussions. \n* Experiments come with sufficient details. Training parameters are provided in appendix. It should not be difficult to reproduce results in this work.\n* This work lacks novelty in both theory and methodology. The practical impact may be very limited.",
            "summary_of_the_review": "The majority concern is lacking novelty. Some improvments in the experiments would make this work more stronger and more convincing.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper204/Reviewer_Qf3U"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper204/Reviewer_Qf3U"
        ]
    },
    {
        "id": "QvsKhcYVFW",
        "original": null,
        "number": 3,
        "cdate": 1666701998840,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666701998840,
        "tmdate": 1670384260583,
        "tddate": null,
        "forum": "AZFvpnnewr",
        "replyto": "AZFvpnnewr",
        "invitation": "ICLR.cc/2023/Conference/Paper204/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors present trainability prerseving pruning (TPP), considering to maintain trainability for the pruned networks. The authors construct two regularization terms to achieve this goal. TTP decorrelates the pruned weights from the kept weights, thus achieves non-trivial improvement in pruning process. ",
            "strength_and_weaknesses": "Strength:\n1. The trainability of pruned models is interesting, and may provide a new perspective to pruning, and even to the whole deep learning field.\n2. The proposed pruning method is easy to implement, and produces good experimental results.\n\nWeakness:\n1. The relationship between trainability and dynamical isometry is not clear. I find no evidence to indicate this point, i.e. how can trainability be expressed by the orthogonal property of channels?\n2. The necessity of contraining BN parameters is not shown. The reason in the paper is that \"Although unimportant weights are enforced with regularization for sparsity, their magnitude can barely be exact zero, making the subsequent removal of filters biased\". However, if the pruned weights are not zeros, how to achieve the speedup of models during  the inference phase?",
            "clarity,_quality,_novelty_and_reproducibility": "The logic of the paper is easy to follow, but some motivations are not clear.\nThe method proposed in the paper is novel.\nThe work is original.",
            "summary_of_the_review": "The paper focuses on an interesting topic, and proposes a working solution. However, the motivation of the methods and some specific techniques are not very clear. Therefore, I think this paper should be weakly rejected.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper204/Reviewer_aS72"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper204/Reviewer_aS72"
        ]
    },
    {
        "id": "_mqpb-Bv2y0",
        "original": null,
        "number": 4,
        "cdate": 1666765250334,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666765250334,
        "tmdate": 1666765250334,
        "tddate": null,
        "forum": "AZFvpnnewr",
        "replyto": "AZFvpnnewr",
        "invitation": "ICLR.cc/2023/Conference/Paper204/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on preserving the trainability of network after pruning. As proposed by the authors, the trainability of pruned networks can be affected with the phenomenon of being less robust to finetuning learning rate. To alleviate this issue, the authors proposes the trainability preserving pruning (TPP) that can maintain the trainability during pruning. The authors suggest that the dependency between weights may cause the issue. So in this paper, the authors propose to decorrelate the pruned weights and the kept weights. In detail, the authors propose to regularize the gram matrix of weights in the way that the correlation of between the kept and pruned weights approaches 0. In addition, the authors suggest that the parameters of BatchNormalization should be explicitly considered for pruning by regularizing the parameters. Experiments on MNIST, Cifar and ImageNet verifies the efficacy of the proposed methods. On ImageNet classification task  with ResNet50, the proposed TPP  illustrates significant improvement compared with other SOTA methods.",
            "strength_and_weaknesses": "Pros\nThis paper proposes a post process for pertained network to get  more trainable sparse weights for finetuning. Experiments verifies the trainability of the sparse weight via comparisons with different finetuning  learning rate.  Extensive experiments on several datasets illustrates the efficacy of the proposed method. In addition, the authors also consider the effect of batch normalization parameters and adds to the regularization term.\n\nCons\nThe authors illustrate the ablation with regularizing  BN weight and without regularizing BN weight. However, I do not find the results of using the regularization term of BN parameters alone. Could the authors show this result?\n\n\nQuestion\nAs shown in the paper, the proposed TPP method is a post-process algorithm for a pertained model. After the TPP process, the sparse weight is finetuned to get a sparse model with decent performance. I am wondering whether the TPP algorithm can be combined with the pretraining? In addition,  the TPP post process also takes the classification loss into consideration, so it can be considered as the part of finetuning. It would be better to have the experiments with similar finetuning cost to compare TPP with other methods in a more fair way. Whether the proposed TPP can be useful for finding lottery ticket subnetwork in a filter level?",
            "clarity,_quality,_novelty_and_reproducibility": "this paper is well written and of good novelty.",
            "summary_of_the_review": "please refer the comments listed above.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper204/Reviewer_p5ry"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper204/Reviewer_p5ry"
        ]
    }
]