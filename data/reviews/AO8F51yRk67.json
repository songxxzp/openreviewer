[
    {
        "id": "2PRxmVun2mF",
        "original": null,
        "number": 1,
        "cdate": 1666391348002,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666391348002,
        "tmdate": 1666391348002,
        "tddate": null,
        "forum": "AO8F51yRk67",
        "replyto": "AO8F51yRk67",
        "invitation": "ICLR.cc/2023/Conference/Paper2179/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the problem of providing algorithmic recourses -- that is, providing users who were rejected by a model (e.g. denied a loan) a way to change themselves so that they will not be rejected in the future. The paper is specifically concerned with the setting where the model may change over time (e.g. by getting updated training data); in this setting, we would want old recourses to be valid for the new model. The authors propose to locally fit a linear surrogate model around the given model's decision boundaries. They specifically use \"minimax probability machines\" (MPMs) to make these linear surrogate models more robust to changing models. The authors propose a few modifications to existing MPMs; in particular, they propose different objective functions in fitting the MPMs and study the asymptotic behaviors of the resulting surrogate models. With a linear surrogate in hand, existing algorithmic recourse methods are applied to the surrogate model.",
            "strength_and_weaknesses": "The provided experiments are interesting, and provide good evidence that their proposed method can outperform existing methods. I overall feel that the proposed method needs some more investigation and explanation before publication. I've tried to break issues down into categories below:\n\n\n**Theoretical development.** A number of theorems and propositions are stated about fitting various MPMs and the properties of MPMs. I found three proofs that were explicitly omitted and a couple more that I had a hard time following. First, I do not think it is OK to publish a paper with omitted proofs. Omitting proofs makes the paper extremely difficult to validate, reproduce, and build on in future work; I definitely cannot tell if the stated results are correct or not. I read through the proof of Proposition 3.4, and got stuck in a few places:\n1. \"note that the worst-case probability admits a two-layer decomposition\" I don't immediately see why this is true. I don't think the notation of taking a max over $P_y \\sim (\\hat\\mu_y, \\Sigma_y)$ was ever defined.\n2. The proof ends without reducing to something that looks like the objective $\\min_{w \\in W} \\sum_y \\tau_y^\\varphi (w)$. Is there some kind of extra dual argument needed? All of the steps should be made clear in the proof.\n\nI couldn't follow the proof of Proposition 3.5 for the same reasons as Proposition 3.5; I didn't check the rest of the proofs.\n\n**Motivation.** Some of the results didn't feel well-motivated.\n1. It seems that one major addition over Lanckriet et al. (2003) is the use of new metrics over covariance matrices in the MPM. But it's not clear why this is desirable. The authors note \"the [previously used] quadratic divergence ... does not coincide with any distance between probability distributions\". Why is this something we should want given the goal of producing algorithmic recourses that are stable to model shift? Why study both the Bures and Fisher-Rao MPM?\n2. What is the purpose of the asymptotics in the paper? It seems like the asymptotic regime studied requires at least one of the radii of the ambiguity sets to grow to infinity. Why should we be concerned about the model's performance when we are infinitely uncertain about things? What do the derived limits tell us about the suitability of these MPMs for algorithmic recourses? \n3. I'm not exactly sure what the experiments tell us about the proposed method. In Section 6.2, in some cases, it looks like one of the proposed methods is outperforming competing methods according to some metrics. Why is this happening? What about the datasets is causing FR-MPM-PROJ to succeed? Additionally, the experiments in Figure 4 only show the use of the Fisher-Rao distance; what about using Bures or quadratic distances?",
            "clarity,_quality,_novelty_and_reproducibility": "I found a few things unclear:\n- \"By definition $\\mathbb{Q}$ ... equals zero if and only if $\\Sigma = \\hat \\Sigma$. I don't think this is by definition; this follows by its relation to the Frobenius norm.\n- In the definition of $\\mathbb{Q}$, is the square meant to indicate entrywise squaring or a matrix product?\n- I can't tell what the $\\sim$ notation means. It looks like a distribution always goes on the left hand side, but sometimes a set of parameters go on the right, and sometimes a distribution goes on the right.\n- In Section 6.1, a max is taken over $x' \\sim N(x, 0.001I)$. Is this a max over the support over the normal distribution (so a max over all real numbers)?\n- In the definition of LocalFid, I don't think $s_x$ was ever defined; this should be explicitly defined.\n",
            "summary_of_the_review": "I mainly think the paper needs to contain proofs for all of its claimed results and explain what the takeaways are from all of its claimed results. I think both of these things need to be included in a paper, so I've voted for reject.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2179/Reviewer_14wF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2179/Reviewer_14wF"
        ]
    },
    {
        "id": "6fM5n8YajrN",
        "original": null,
        "number": 2,
        "cdate": 1666576057785,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666576057785,
        "tmdate": 1666576057785,
        "tddate": null,
        "forum": "AO8F51yRk67",
        "replyto": "AO8F51yRk67",
        "invitation": "ICLR.cc/2023/Conference/Paper2179/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper targets the problem of algorithmic recourse, which is to suggest how an input instance should be modified to alter the outcome of a predictive model. In particular, the paper proposes a pipeline to generate a model-agnostic recourse that is robust to model shifts. The main idea is to estimate a linear surrogate of the black-box model using covariance-robust minimax probability machines (MPM), then generate the recourse using this surrogate. The paper derives several theoretical analyses to show that the covariance-robust MPM correspond to the l2-regularization and class-reweighting schemes. Finally, experiments are conducted on various real-world datasets to confirm the effectiveness of the proposed approach.",
            "strength_and_weaknesses": "Strengths:\n+ The paper targets an important and interesting problem. The related work and existing literature are described in detailed and thorough.\n+ The paper's writing is very clear and easy to understand. Even though the paper has many complicated theoretical analyses, but thanks to the clear writing, these analyses could be followed easily.\n+ A lot of theoretical analyses are derived to understand the property of the MPM-based proposed approach. They seem to be sound to me, although note that I can't dig into detail of the proof, so I can't guarantee if these theoretical analyses are completely correct or not.\n+ The discussion around the experimental evaluation is thorough and detailed. The paper also compared their proposed approach with various existing and new baselines. Different metrics are used to evaluate different aspects of the proposed approach.\n+ The code is published in order to aid reproducibility. \n\nWeaknesses:\n+ The datasets used in the experimental evaluation seem to be simple and easy datasets. Although I completely understand that the research field of algorithmic recourse is new, and thus the evaluation can be done on some simple datasets.\n\nQuestions:\n+ Based on the experimental evaluation, it seems to me that the approach of using a robust surrogate then derive a recourse from this robust surrogate is much better compared to the approach of using a non-robust surrogate and then derive a robust recourse. Is there any explanation for this particular property? Does this mean the choice of surrogate model affects robustness property the most?\n+ There are several settings in the experiments that I feel unclear on why they are set that way. For example, in Section 6.1 - Stability, 10 neighbours data points are sampled in the distribution N(x, 0.001I). In Section 6.1 \u2013 Fidelity, r_fid is set to 10% of the maximum distance between instances in the training data. Or the radius r_p is set to 5% of the maximum distance between instances in the training data. Why are these values (10, 0.001, 10%, 5%) chosen? Will these values be sensitive to the performance of the proposed approach?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper's writing is clear and easy to understand - please see my comments above.\n\nThe paper's quality is good, and I think the proposed approach is novel and can be of benefit to the community. Theoretical analyses are also conducted to understand the performance of the proposed approach (although note I can't dig into detail to confirm the correctness of these analyses).\n\nThe code is made available so I believe in the reproducibilty of the paper.",
            "summary_of_the_review": "Overal, I think the paper targets an important problem. The key idea seems to be sound and novel to me. The experiments are also detailed and thorough. The paper's writing is very clear, and easy to understand.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2179/Reviewer_33C8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2179/Reviewer_33C8"
        ]
    },
    {
        "id": "6YDtsLnVoL",
        "original": null,
        "number": 3,
        "cdate": 1666580895820,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666580895820,
        "tmdate": 1666647120196,
        "tddate": null,
        "forum": "AO8F51yRk67",
        "replyto": "AO8F51yRk67",
        "invitation": "ICLR.cc/2023/Conference/Paper2179/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces two variants of covariance-robust minimax probability machines (MPM) which the authors term as Bures MPM and Cramer-Rao MPM based on different statistical divergences between Gaussian distributions. The authors discuss how to estimate the parameter for these new variants of MPM and discuss the potential applications for algorithmic recourse.",
            "strength_and_weaknesses": "### Strength:\n* The MPM part is easy to follow.\n\n### Weaknesses:\n* From my point of view, I don\u2019t think the derivation of the covariance-robust MPMs with these two statistical divergences is hard. And I think an extension to general f-divergence is also possible.\n* The authors spend most of the space on presenting the variants of covariance-robust MPMs, without discussing the necessity of studying these variants for algorithmic recourse.\n* The empirical results do not have significant improvement over the quadratic MPM.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall well-written, however, not so novel. The authors provide the code, but I haven\u2019t checked it.",
            "summary_of_the_review": "The authors do not provide strong motivation for proposing the two new MPM variants. The theoretical results are not technically hard and the empirical results are not strong.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2179/Reviewer_NHFj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2179/Reviewer_NHFj"
        ]
    },
    {
        "id": "5pwNyROcgNI",
        "original": null,
        "number": 4,
        "cdate": 1667075972327,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667075972327,
        "tmdate": 1667075972327,
        "tddate": null,
        "forum": "AO8F51yRk67",
        "replyto": "AO8F51yRk67",
        "invitation": "ICLR.cc/2023/Conference/Paper2179/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors consider the application of a distributionally robust minimax probability machine, relying on statistical distances defined on the space of Gaussian measures. The authors motivate this as a tool for finding algorithmic recourses that are robust to changes in parameters of a classifier, that might be induced by underlying changes in the distribution of covariates. Several experiments are considered to compare the method in terms of a cost-validity trade-off and actionability of the recourses.",
            "strength_and_weaknesses": "## Strengths\n- The experiments appear to be quite thorough, especially considering the detail provided in the supplement.\n- The method seems to be a reasonable minor adaptation of existing methods in MPM, and yet some benefit is still achieved in experiments. This suggests it might be quite practical.\n- The presentation is generally good.\n\n## Weaknesses\n\n- The authors claim that a major contribution of the work is an \"intuitive and interpretable approach to generate robust recourse\". However, not much of the paper is dedicated to the interpretation of what it means for robustness to be defined with respect to a MPM that is distributionally robust with respect to a particular distance between Gaussians. For example, how different are the Bures and Quadratic distances in practice; would figure 2 change much had you used quadratic distance? Intuitively when would I want to use a Bures MPM versus a Fisher-Rao MPM? In the fidelity/stability experiments, it seems the Fisher-Rao MPM often is more stable/higher fidelity. Can you convey intuition as to why this is the case? I think the geometric intuition in figure 2 and remark 4.6 is helpful, but you should go further in relating the distances chosen to robustness of the resulting recourse if a major claim of the paper is that the method is both intuitive and interpretable.\n",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\n- A schematic of the sampling done in step 1 of the algorithm would improve the readability of the algorithm description. Figure 2 partially, but not fully, addresses this.\n- It feels to me there is a big jump from the introduction related to algorithmic recourse to the development of the method. I think a sentence or two better motivating the choices made in the method would improve the exposition, e.g. how robustness of the MPM translates back to robustness of a recourse, would be helpful.\n\n## Quality and novelty\n- I am not familiar enough with related work to comment on the novelty of the ideas in relation to existing literature. The quality of the experiments and derivations seems to be reasonably high.\n\n## Reproducibility\n- Experimental details are provided, and existing code relied on for experiments is documented, so it seems likely the findings are reproducible. Code is provided, as well as details to run the code.",
            "summary_of_the_review": "I am in favor of accepting the paper on balance. I think the presentation was reasonably good, the method seems practical and experiments seem thorough. However, I am not an expert in this area and have not read large portions of the related literature. I therefore have a low degree of confidence in my review and it is very possible I will change my score in light of future feedback and discussion with the other reviewers and authors.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2179/Reviewer_CMDf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2179/Reviewer_CMDf"
        ]
    }
]