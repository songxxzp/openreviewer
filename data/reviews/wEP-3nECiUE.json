[
    {
        "id": "lM5ayJa93oi",
        "original": null,
        "number": 1,
        "cdate": 1666097717449,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666097717449,
        "tmdate": 1666097717449,
        "tddate": null,
        "forum": "wEP-3nECiUE",
        "replyto": "wEP-3nECiUE",
        "invitation": "ICLR.cc/2023/Conference/Paper5023/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper is an extension of RELIC self supervised learning method.\n\nIn this extension, two main augmentation method is added. (1) Saliency map (2) Views of varying sizes.\nThe loss function has also been modified.\n\nExtensive experiments had been perform to study the effects of these extensions.",
            "strength_and_weaknesses": "(1) Strength: a lot of experiments are being carried out with a lot of analysis\n(2) Strength: Results seems to be better than previous methods.\n(3) Weakness: However there is no error bars to convince readers about the robustness of the reported results. for example, multiple duplicated experiments should be perform and p-value calculated when comparing the results of various methods.\n(4) Weakness: it is not clear if the reported results are due to more careful tuning of hyper-parameters. A good way to silence this criticism is to show evidence of robustness of results with respect to hyper-parameter values.\n(5) Weakness: Seems that the major contributions are two more augmentation methods. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: paper was carefully written with good clarity\nQuality: extensive experimental results, though without uncertainties reporting\nNovelty: The main contribution is additional augmentation method\nReproducibility: details are given, not sure if models are easy to tune",
            "summary_of_the_review": "Well written paper, however paper can be strengthen with error bars and with experiments showing how results differs with different hyper-parameters.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5023/Reviewer_hHxH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5023/Reviewer_hHxH"
        ]
    },
    {
        "id": "_WyY21_O9QJ",
        "original": null,
        "number": 2,
        "cdate": 1666563538057,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666563538057,
        "tmdate": 1666680346901,
        "tddate": null,
        "forum": "wEP-3nECiUE",
        "replyto": "wEP-3nECiUE",
        "invitation": "ICLR.cc/2023/Conference/Paper5023/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a novel self-supervised learning framework called ReLIC v2. This framework builds upon ReLIC's loss and combines multicrops and background mask. The method achieves the state-of-the-art and better linear probe accuracy than supervised ResNet50.\nExtensive transfer experiments and ablation study verifies the effectiveness of the proposed method.   ",
            "strength_and_weaknesses": "Strengths:\n1. This method achieves state-of-the-art ImageNet linear probe accuracy. It combines a few existing effective building components including ReLIC loss function, multicrops and background mask. Even though these components are already existing in the literature, I find that some special settings including 4x big + 2x small multicrops are novel.\n2. The authors conducted a scaling study on a larger dataset such as JFT300M. Even though they derived relatively poor scaling performance, I find such study helpful and insightful, i.e. how augmentation-based joint-embedding method can benefit from scaling. \n\nWeaknesses:\n1. Overall the paper has very limited novelty.\n2. From ablation study, the background mask only shows 0.3% improvements. The main advantage seems to come from the multicrops. Using 4x big views + 2x small views means effectively much higher computation cost. This method still uses 4096 batch size. As far as I can tell, the previous works limiting to 2x big views + many small views with this batch size are mainly caused by GPU memory. It is not discussed how their method can afford this. \n3. The background mask here is very hand-crafted. Figure 8 seems too good to be true for arbitrary input. Is there any failure case for the background removing?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written.\nAll experimental details are provided.",
            "summary_of_the_review": "State-of-the-art self-supervised learning framework using ReLIC loss plus multicrops and background mask. Overall limited novelty but a lot of novel engineering design that's useful for the community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5023/Reviewer_Z39N"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5023/Reviewer_Z39N"
        ]
    },
    {
        "id": "CfLuj8yhnRk",
        "original": null,
        "number": 3,
        "cdate": 1666689868528,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666689868528,
        "tmdate": 1670693303892,
        "tddate": null,
        "forum": "wEP-3nECiUE",
        "replyto": "wEP-3nECiUE",
        "invitation": "ICLR.cc/2023/Conference/Paper5023/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a few tricks that can be added on top of ReLIC for self-supervised learning. First, saliency masking is used to explicitly reduce spurious correlations in the model. Second, augmentations of small sizes are used. This has the effect of occluding some regions of the image. Using these two tricks, the authors were able to improve the performance of ReLIC by a good margin. Moreover, the authors also achieve SOTA results on Resnet based self-supervised learning methods. Several ablation studies are also performed.\n\n",
            "strength_and_weaknesses": "Strengths:\n\nThis is a well written paper. The authors clearly state what their main contribution is. The two tricks that are proposed is intuitive and looks promising. The paper is also explained well and I was able to understand the main contributions.\n\nThe experiments are very extensively performed. Comparisons with existing Resnet based models are included. Experiments are performed with different model sizes. Results are also shown on OOD, transfer, semi-supervised leanrning and for other tasks such as segmentation. Experimental section is quite strong and I don't have any concerns.\n\nI also apprecitate the authors for providing detailed experimental settings in appendix.\n\nWeaknesses:\n\nThe main tricks proposed in this work seem to be general purpose. Do you think this would work on ViTs?\nIn this regard, the self-attentions in ViTs might alrealy be doing some sort of saliency detection. For instance, they have been shown to do semantic segmentation. So, I am curious if thesr tricks can be used with ViTs?\n\nWhy did you stick only with Resnet based architectures? Do you think ReLICv2 would work with architectures like Swin? If so, would you set SOTA results there?\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: This is a well written paper. It is very clear.\n\nQuality and Novelty: The tricks proposed in this paper is very effective as shown in the results. These tricks seem to be general purpose and would benefit other papers too.\n\nReproducibility: The authors have provided extensive experiment details in the appendix which is a good sign for reproducibility.",
            "summary_of_the_review": "Overall, I think this is a very good paper in terms of ideas proposed and rigorous experimental study. I advocate for acceptance.\n\n\n======================================\n\nPost rebuttal:\n\nAfter looking at other reviews and having discussion with some reviewers, I feel like the paper has the following issues:\nSimilarity with prior work: As pointed out by reviewer Z39N, background augmentation only has marginal improvements. So, this makes me a bit worried about the main message the paper gives. Its probably that improvements mainly comes because of multi-crop at scale. If this is the case, the authors need to make this very clear (if the paper gets accepted). I also agree with other reviewers that claiming that they beat supervised learning is bit of a overclaim and I would appreciate if the authjors address this.\n\nBut, I also feel that even if the paper proposes a few tricks, I am fine with accepting the paper as the computer vision field has made progress through a series of tricks. But the authors should make that message very clear.\n\nSince I was not aware of these concerns at the time of giving my review, I downvote my rating to 6. \n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5023/Reviewer_jUzd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5023/Reviewer_jUzd"
        ]
    },
    {
        "id": "XQhHsciQxm",
        "original": null,
        "number": 4,
        "cdate": 1667433244782,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667433244782,
        "tmdate": 1667437385587,
        "tddate": null,
        "forum": "wEP-3nECiUE",
        "replyto": "wEP-3nECiUE",
        "invitation": "ICLR.cc/2023/Conference/Paper5023/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "================================================================= \n\n[Summary] \n\nThis paper proposes an improved version of ReLIC, dubbed ReLICv2, by including views of varying sizes and saliency masking into the ReLIC's training loss, and presents benchmarking results using ResNet encoders in several experiments.\n\n================================================================= \n\n",
            "strength_and_weaknesses": "================================================================= \n\n[Main Strengths] \n\nThe key merit of this paper is that the authors' approaches for improving the ReLIC indeed produce better benchmark results than previous ResNet-based methods at a different model and dataset sizes.\n\n================================================================= \n\n[Main Weaknesses] \n\nThe fundamental shortcoming of this study is that, while the basic idea is interesting, it does not appear to have the intended impact, as the title implies, much like the various flavors of contrastive methods. Given the richness of learned visual representation, focusing primarily on linear evaluations in the classification tasks is a too narrowed contribution.  I encourage authors to explore further into specific image domains and/or paired with Vision transformers to see whether ReLICv2 is still effective. Furthermore, I don\u2019t see the implementation GitHub repo is intended to be provided.\n\n================================================================= \n",
            "clarity,_quality,_novelty_and_reproducibility": "================================================================= \n\n[Technical Comments] \n\n1) Does the linear evaluation setup in fact disclose learning less spurious/correlated features? Background and style features may not be useful for dominant/foreground object classifications, but they would be valuable for dense prediction, which often needs consistency of multiple objects. \n2) Furthermore, I believe the linear evaluations employ all the labels in the fine-tuning stage, thus the performances shown in the paper are not label-free as the title implies. On the other hand, studying the labeled sample complexity will have more practical implications and will be a more engaging story.\n3) In Tables 4 and 5, how does the ReLICv1 perform?\n\n================================================================= \n\n",
            "summary_of_the_review": "Using views of varying sizes and saliency masking to improve the original ReLIC's training loss is intriguing, but, it does not appear to make a significant impact, as do the many flavors of contrastive self-supervised approaches. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5023/Reviewer_aWZZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5023/Reviewer_aWZZ"
        ]
    }
]