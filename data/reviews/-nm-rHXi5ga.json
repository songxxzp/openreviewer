[
    {
        "id": "3WSHPvyfzy8",
        "original": null,
        "number": 1,
        "cdate": 1666105122370,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666105122370,
        "tmdate": 1666105122370,
        "tddate": null,
        "forum": "-nm-rHXi5ga",
        "replyto": "-nm-rHXi5ga",
        "invitation": "ICLR.cc/2023/Conference/Paper2932/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new framework to improve the sample efficiency of model-free RL algorithms through combining them with a learnable data augmentation approach. The paper provides a theoretical analysis of how their method works to improve the representation learning and reports results on DMControl and Atari100K.",
            "strength_and_weaknesses": "Strength:\n1. The idea proposed in this paper is novel.\n2. The proposed idea is presented clearly and the paper is globally well-written.\n3. The theoretical analysis is provided.\n4. The proposed framework is easy to implement.\n\nWeakness:\n1. Although the idea seems to be new, the contribution of this paper seems to be limited. According to Table 1, the improvement resulted from the proposed framwork is quite limited. Second, it is not discussed whether the proposed method can also contribute to improved performance in addition to sample efficiency. Besides, the improvement on stability is not very obvious, more explainations should be provided.\n2. The paper lacks comparison with more recent methods, such as soda, svea and so on.\n3. The paper lacks parameter analysis. For instance, how are hyperparameters \u03b1 and \u03bb determined?\n\nMinor:\n1. The details of how to adjust to the optimal Gt(\u00b5t, \u03c3t) can be mentioned in Algorithm 1.\n2. Lf and Lg should also be mentioned in the paper.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The proposed idea is presented clearly.\n\nQuality and Novelty: The idea is novel and the theoretical analysis is also provided. However, the contribution and improvement seem to be limited.\n\nReproducibility: The code is provided.",
            "summary_of_the_review": "This paper proposes a new solution for the problem, and experiments on two benchmarks demonstrates its effectiveness. The major concerns are limited contributions and the lack of comparison with more recent approaches.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2932/Reviewer_RdJD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2932/Reviewer_RdJD"
        ]
    },
    {
        "id": "h5OvIHgp13P",
        "original": null,
        "number": 2,
        "cdate": 1666578208982,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666578208982,
        "tmdate": 1670453974780,
        "tddate": null,
        "forum": "-nm-rHXi5ga",
        "replyto": "-nm-rHXi5ga",
        "invitation": "ICLR.cc/2023/Conference/Paper2932/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a learnable data augmentation framework for visual RL, which learn the parameterized image augmentation together with model-free RL. Some theoretical interpretations are provided to show the rationale of learned augmentation. Experiments on DMC and Atari100 benchmarks demonstrate that the proposed method CoIT achieves better performance than SOTA augmentation methods for model-free RL.",
            "strength_and_weaknesses": "### Strengths\n\n- The idea of learnable augmentation is relatively novel.\n- The authors provide some theoretical interpretation for why learnable augmentation is desired.\n- The proposed method achieves relatively promising results on several benchmark environments. \n\n### Weaknesses\n\n- I think the proposed algorithm seems simple yet effective. I like the idea of learning augmentations. However, the theoretical analysis sections are a little confusing and not very to the point. First, why is the replay buffer fixed? During training of model-free RL, I would expect the replay buffer to be consistantly updated, with imperfect data coverage. It is weird to me that the paper motivates by \"dynamic distribution\" and \"training-friendly\" but does not discuss much on the distribution shift problem during training. Second, I don't think Section 4.1 and 4.2 have provided sufficient evidence for the \"optimality\" of the proposed metric and the algorithm. Some claims are not very convincing. For example, why does Theorem 4.1 suggest that \"incorporating augmentation directly cannot well meet the basic stationary environment\"? \n- There exist a bunch of grammar errors and typos, which may cause confusion. Some notations are not clearly defined in the context. For example, in Theorem 4.1, what does \"Lemma 4.2 holds for functions $f_{\\xi}$ and $f_{\\bar{\\xi}}$ respectively\" mean? Lemma 4.2 is a lemma, not a condition for $f$. Also, $L_g$ and $L_f$ appear in the theorem without definitions. \n- The ablation study also confuses me. Why does the convergence of $\\mu$ and $\\sigma$ mean that TRANSFORM successfully smooths the distribution shifts? Can the authors provide more explanation?\n\nQuestions:\n- Why is Gaussian distribution used to generate augmentations? Would a deconvolutional network work here?\n- How is \"tasks solved\" defined in Figure 1?",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty and quality of the paper are relatively good. But the clarity needs to be improved, as summarized in \"Strength And Weaknesses\".\n\nFor reproducibility, a Github repo is provided, although I have not tried to run it yet.",
            "summary_of_the_review": "This paper presents a relatively novel idea and show good empirical success of the method. But there are several clarity issues of the theory and critical claims, making it hard to justify the quality of the paper. I would like to increase my rating if the authors can address my confusion with convincing evidence.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2932/Reviewer_ao8s"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2932/Reviewer_ao8s"
        ]
    },
    {
        "id": "q02AcZyNxf",
        "original": null,
        "number": 3,
        "cdate": 1667502396718,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667502396718,
        "tmdate": 1671366306294,
        "tddate": null,
        "forum": "-nm-rHXi5ga",
        "replyto": "-nm-rHXi5ga",
        "invitation": "ICLR.cc/2023/Conference/Paper2932/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a simple yet effective learning module upon the framework of contrastive reinforcement learning. The module could automatically learn a optimal transformation for data augmentation. The algorithm is theoretically founded and also demonstrated by expeiments on DMControl and Atari 100k.",
            "strength_and_weaknesses": "Strength:\n\n- The idea is simple but effective, which might be easy to implement and follow.\n\n- The authors make theoretical efforts in justifying the framework.\n- The experiments are extensive, conducted on DMControl and Atari 100k. Also the baselines (DrQ v2 and CURL) are decent.\n\nWeakness:\n\n- The theoretical analysis in this paper uses several inequalities to achieve the final objective, while some reasoning looks not very clear to me. See following comments for more details.\n- In Equation 5,  the authors use the triangular inequality $d(g(x),g'(x'))\\leq d(g(x),g'(x))+d(g'(x),g'(x'))$ so that they could minimize the upper bound. However, the LHS $d(g(x),g'(x'))$ could be optimized directly. So what is the necessarity of using the upper bound? And it is better that the necessarity be illustrated  from both the theoretical perspective and the empirical perspective. I am very willing to take feedbacks from authors.\n- In Equation 6, the authors still try to prove that minimizing the LHS means minimizing the RHS. However, the LHS is the lower bound and thus it seems not meaningful to minimize the lower bound. If I do not misunderstand, the main theorem might not be able to motivate the CoIT algorithm. There is a chance I misundertand and there could be more efforts in detailing the theorem.\n- The writing could be improved. There are many variables not well stated. For example,  in Theorem 4.1, the variables L_g and L_f are not stated in the main paper. \n\n- The authors propose a multi-task objective that combine three loss functions in total. Though it is common that different objectives are used with different weights, the hyperparameters given in appendix seem to show that the weight for objectives must be carefully choosen for each tasks to make it work. More explanations about the hyperparameter selection and the experiment observation about the hyperparameter might be necessary.\n\n\n\nTypos:\n\n- related work: DRQ -> DrQ\n- main results: Table 2 -> Table 1\n- Some theorem links are not correct. One careful check might be great.\n\nnote: this is an emergency review",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity of the main theorem is not clear to me, and I expect more explanations from authors . Other parts are good.\n\nThere are several typos and wrong links in the paper, which might hurt the paper quality. \n\nThe novelty is limited but I appreciate the efforts that make it work.\n\nThe reproducibility is good since the authors provide the source code.",
            "summary_of_the_review": "I like the proposed algorithm for its simplicity and the theoretical analysis is also somewhat interesting. The main concern for me is (a) whether the main theorem is constructive for the algorithm and (b) whether the objectives really help generally for different tasks or it is carefully tuned for each single task to make it work. The detailed questions are mentioned before, which I hope the authors could address.\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2932/Reviewer_yPYT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2932/Reviewer_yPYT"
        ]
    },
    {
        "id": "GwxhK4CCB0l",
        "original": null,
        "number": 4,
        "cdate": 1667521264516,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667521264516,
        "tmdate": 1667521264516,
        "tddate": null,
        "forum": "-nm-rHXi5ga",
        "replyto": "-nm-rHXi5ga",
        "invitation": "ICLR.cc/2023/Conference/Paper2932/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a learnable data augmentation procedure for speeding up reinforcement learning from pixels. In particular in applies a transformation to the input images, which is parameterized by a Gaussain distribution. The proposed method combines three main components:\n\n1. Standard Q-learning approach with data augmentation, similar to DrQ\n2. Contrastive learning loss for the encoder\n3. Smoothing objective for the transformation parameters\n\nThe paper proposes a theoretical justification for this approach and shows state-of-the-art results on DM Control and Atari. ",
            "strength_and_weaknesses": "Strengths:\n\n1. While practical the proposed method is also justified from a theoretical perspective as well.\n2. The approach is intuitive and straightforward.\n3. Produces state-of-the art results on some standard benchmarks. \n\nWeaknesses:\n\nOnly wandering what results are on the Humanoid task, which has now been successfully solved from images. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and easy to follow. The supplementary material has ample implementation details for reproducible. While the core idea of data augmentation for visual RL is not new, the proposed method takes that further and produces state of the art results. ",
            "summary_of_the_review": "Well written, intuitive paper with good justification and results. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2932/Reviewer_7fsn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2932/Reviewer_7fsn"
        ]
    }
]