[
    {
        "id": "TMwnuyhvJX_",
        "original": null,
        "number": 1,
        "cdate": 1666467301544,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666467301544,
        "tmdate": 1666467301544,
        "tddate": null,
        "forum": "S80ioOGLpD9",
        "replyto": "S80ioOGLpD9",
        "invitation": "ICLR.cc/2023/Conference/Paper4793/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a self-supervised learning approach for MARL which builds on multi-agent transformers to improve results in several domains. This approach consists of learning a centralized world model as an auxiliary task for learning better representations.",
            "strength_and_weaknesses": "# Strengths\n* The main idea is straightforward and improves results.\n* The proposed approach is well motivated.\n\n# Weaknesses\n* The writing could be more clear. \n* Improvements over MAT (which MAJOR builds on) are marginal in many environments.\n* Baselines outside of MAT are methods which learn decentralized policies which seems an unfair comparison (unless my interpretation of the proposed approach as being fully centralized is incorrect - see questions).\n\n# Questions\n* From the description of the multi-agent transformer, it seems that observations from *all* agents are passed into a single network which computes actions. Given this description, the approach would be fully centralized, correct?\n* The authors state that the proposed framework could be applied to CTDE methods, though it is not clear to me how that is the case since the representation learning objective requires sharing information across agents.. Can the authors provide an example of how this may be accomplished in practice?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper uses somewhat unnecessarily complex exposition to put across a relatively simple point, hindering clarity at times.\n\nQuality: The work is solid and builds on prior work. Presentation could be improved in places (e.g. it's not clear why the Meetup task is included)\n\nNovelty: The work is a simple combination of ideas from different sub-fields (MAT + SSL).\n\nReproducibility: Source code, hyperparameters, and pseudo code are all provided, so reproducibility should be straightforward.",
            "summary_of_the_review": "I like the fact that the proposed approach is simple, builds on existing work without adding an overly complicated architecture, and is effective. My main hesitation with the paper is that it overcomplicates the exposition of a relatively simple idea and the presentation in the experimental section could use some work. However, these concerns are relatively minor.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4793/Reviewer_hLyZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4793/Reviewer_hLyZ"
        ]
    },
    {
        "id": "GGR9z2ESrCw",
        "original": null,
        "number": 2,
        "cdate": 1666673341412,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666673341412,
        "tmdate": 1666673341412,
        "tddate": null,
        "forum": "S80ioOGLpD9",
        "replyto": "S80ioOGLpD9",
        "invitation": "ICLR.cc/2023/Conference/Paper4793/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes to integrate an SSL auxiliary objective with standard model-free MARL methods (specifically MAT in this paper) to reap the same benefits as CV and single-agent RL has seen with these types of approaches. Because each agent in a typical MARL setup receives a partial observation of the world, in order to apply the SSL auxiliary objective, they treat the individual observations as a sequence of masked views of the global state. Concretely, they use a joint transition model that inputs the individual agent observations and outputs the future observation representation for each agent, which implicitly requires a reconstruction of the global state. The joint-predictive auxiliary objective they introduce on top of MAT is BYOL-like prediction loss. The authors note that a similar objective can be applied to other model-free MARL methods. The new approach, MAJOR, is evaluated on a number of vision- and state-based multi-agent settings. Performance gains in sample efficiency are reported over MAT and other model-free MARL methods across the various settings. ",
            "strength_and_weaknesses": "Strengths: \n\n* The problem is well-motivated; there is a lack of MARL approaches that take advantage of SSL, and there are a number of challenges associated with doing so. \n\n* The proposed objective is a very natural incorporation of a BYOL-like SSL objective into an existing MARL approach. Moreover, the approach appears to be relatively applicable to other model-free MARL methods.\n\n* The writing is generally clear and gets the main ideas and implementation details across. Figure 1 (the illustration of the full MAJOR method) is also a very useful figure for understanding the gist of the method. \n\n* The method shows improvements in sample efficiency (and in some, final convergence in alloted training time) across the board on numerous and diverse multi-agent environments. \n\nWeaknesses: \n\n* Given that other baselines are used apart from MAT in the evaluation section, and that the authors proclaim the approach is \u201ca plug-and-play module\u201d, it would have been really nice to see the loss incorporated into all of the baselines to really drive home this point. Without this, it is less convincing that the module is indeed as simple as \u201cplug-and-play\u201d.\n\n* The methodology section is quite dense, and very few clarifying breathers are given while the stream of details are being revealed. This required me to jump back and forth quite a bit between the more conceptual explanations and the more technical explanations.\n\n* A lot of the intuition/understanding may require familiarity with previous works such as MAT and especially BYOL.\n\n* The results are nice, but the performance improvements (even in terms of sample complexity) are quite modest given the involvement of the approach. Especially for this reason it would have, again, been nice to have seen this module applied to multiple approaches. \n\n* Some grammatical issues / typos (there are others too\u2014I suggest a careful rereading at the sentence-level):\n\n  * First sentence of 3.1 is very hard to parse (run-on sentence and probably grammatically incorrect): \u201cWe start with the intuition that encourages the observations and actions representations integrating other agents\u2019 information and embodying agent-level relationships and interactions should reduce the non-stationary during the learning process, thus improving the data efficiency of MARL\u201d\n\n  * Second paragraph 3.1 \u201csince this way can execute\u201d (not proper grammar)\n\n  * First sentence of 3.2 doesn\u2019t make sense: \u201cMulti-Agent Joint-Predictive Representations(MAJOR) is an auxiliary objective to promote the learned representations from the latent space of the sequential observation and action embeddings\u201d (promote what in the learned representations?)\n\n  * Grammar and spelling at top of experiments: \u201cWe consider wide-rage MARL benchmarks for evaluating MAJOR and compared MARL algorithms\u201d (\u201dwide-rage\u201d and \u201cand compared\u201d; maybe something like \u201ca wide ranging set of\u201d and \u201cin comparison to relevant SOTA\u201d is meant?). \n\n  * Confusing phrase at the end of \u201cMulti-Agent Quadcopter Control\u201d paragraph in 5.2: \u201cour proposed representation learning framework shows its strength if the underlying approaches don\u2019t work at all\u201d (unclear what is meant here).",
            "clarity,_quality,_novelty_and_reproducibility": "* The paper is generally well-written and of good quality, except for the weaknesses listed above. \n\n* The method and empirical analysis is novel. \n\n* There is no reproducibility statement or promise to publish code, and I could imagine it being difficult to reproduce method/results even with provided detailed explanation of components.",
            "summary_of_the_review": "* Overall the paper is well-written and provides a meaningful contribution to the field of MARL. There are some confusing and grammatically incorrect sentences here-and-there that should be corrected, and the claim of the module being plug-and-play is unsubstantiated (and if it were to be substantiated it would make up for the modest improvements in most of the tasks), but it is likely this paper will be useful to the research community in its present state. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4793/Reviewer_wdZd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4793/Reviewer_wdZd"
        ]
    },
    {
        "id": "cr0XSkfRYL",
        "original": null,
        "number": 3,
        "cdate": 1666684215964,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666684215964,
        "tmdate": 1666684249967,
        "tddate": null,
        "forum": "S80ioOGLpD9",
        "replyto": "S80ioOGLpD9",
        "invitation": "ICLR.cc/2023/Conference/Paper4793/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper describes Multi-Agent Joint-Predictive representations (MAJOR), which is a self-supervised learning mechanism that allows the MARL system to learn policies in a data-efficient manner.\nIn MAJOR, observations obtained by individual agents are treated as a masked sequence for representation learning, i.e., masked prediction. \nThe learned representation should be jointly temporally predictive and consistent across different views overall agents.\nThe performance  is evaluated through both visionbased\nand state-based cooperative MARL benchmarks.\nThe empirical results show that MAJOR outperforms pre-existing methods. ",
            "strength_and_weaknesses": "Strength:\n-The empirical result solidly shows the performance of the proposed method.\n-The proposal is based on the recent progress and success in SSL, and is insightful.\n\nWeakness:\n-The qualitative evaluation and discussion are limited.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper describes its background and proposal clearly. The quality is high. The experiments are comprehensive, and the results look sound. In addition, experiment settings are described clearly to a certain extent.",
            "summary_of_the_review": "The proposed method is new and improves the performance of MARL.\nThough further discussion is expected, the paper has sufficient strength.\nThe proposal is insightful and interesting. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4793/Reviewer_yv1U"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4793/Reviewer_yv1U"
        ]
    },
    {
        "id": "z4Mv_4PHee8",
        "original": null,
        "number": 4,
        "cdate": 1666696068568,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666696068568,
        "tmdate": 1670252213266,
        "tddate": null,
        "forum": "S80ioOGLpD9",
        "replyto": "S80ioOGLpD9",
        "invitation": "ICLR.cc/2023/Conference/Paper4793/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes Multi-Agent Joint-Predictive Representations (MAJOR), which applys the self-supervised learning (SSL) technique to MARL, trying to improve the learning efficiency. Specifically, MAJOR builds a transformer-based transition model, which takes all agents observations and actions as inputs and predicts the observations of the next $K$ steps in the latent space. Experimental results on four MARL benchmarks show the SSL auxiliary task could slightly improve the performance of the underlying algorithms.\n\n",
            "strength_and_weaknesses": "**Strengths**:\n   * Studying how to learning efficient state abstraction in MARL is an interesting and open problem.\n   * The paper conducts extensive experiments on wide-range MARL environments.\n\n**Weaknesses**: \n  * The performance improvement of MAJOR is minor compared with the baselines. The training curves of different algorithms are overlapped and thus the improvements are not significant.\n  * The benefit of applying SSL to vision-based single-agent RL algorithms is that the policy is learned in the transition-irrelevance or policy irrelevance low-dimensional latent space rather than the original high-dimensional visual space. The paper simply applies SSL to existing MARL methods and shows the experimental results. But the motivation is not very clear. Why applying SSL to MARL is beneficial especially for state-based inputs? \n  * Predicting future observations simply based on all agent's current observations may also be inaccurate. In POMDP, all agent's observations may not contain all the information in the state due to the partial observation issue. \n  * Minor:\n    * \"And we define the following mean squared error between the normalized predictions and target projections\". 'mean squared error' should be 'cosine similarities'.",
            "clarity,_quality,_novelty_and_reproducibility": " * Most parts of the paper are clear but the writing could be further improved.\n * Although, the code is not attached in the supplementary material, the author provides detailed parameter settings in the Appendix. I think the results could be reproduced according to these detailed settings.",
            "summary_of_the_review": "This paper simply applies SSL to existing MARL methods and shows the experimental results. But the motivation is not very clear. Besides, the experimental results are not significant and the writing of the paper could also be improved. So, in its current form, the reviewer holds the point that the paper is below the acceptance threshold.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4793/Reviewer_patt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4793/Reviewer_patt"
        ]
    }
]