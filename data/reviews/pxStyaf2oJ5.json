[
    {
        "id": "MD0q-L0H27Z",
        "original": null,
        "number": 1,
        "cdate": 1665837766853,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665837766853,
        "tmdate": 1665838214022,
        "tddate": null,
        "forum": "pxStyaf2oJ5",
        "replyto": "pxStyaf2oJ5",
        "invitation": "ICLR.cc/2023/Conference/Paper1287/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a domain adaptation (DA) method that, as an additional outcome, learns continuous domain indexes directly from multi-domain data and annotated domain identities. Experiments show that the learned indexes improve the predictive performance of the model in DA. The method relies on a graphical model to describe the joint distribution of inputs $x$, targets $y$, latent domain indexes $\\beta$ and $u$, and domain-independent latent codes $z$. Learning is performed by the maximization of the usual ELBO for the likelihood $p(x, y)$. In addition, domain-independent latent codes $z$ are enforced by an adversarial domain discriminator.",
            "strength_and_weaknesses": "Strengths:\n- The paper is well-motivated and its contributions are presented clearly.\n- The proposed method is technically sound and elegant, although some relevant details seem to be missing (see 'Weaknesses' below).\n- The methodology is well grounded by the presented theoretical results.\n- The experiments confirm the effectiveness of the method. In particular, the visualizations of the learned global domain indexes in Figures 5 and 6 are quite interesting.\n\nWeaknesses:\n1. As is apparent from section 3.1, the paper considers the unsupervised multi-source, multi-target DA problem. However, it is not entirely clear which terms in the loss (eq. (14)) are active for unlabeled target examples. I suppose it should be all the terms of the ELBO except for eq. (5), plus the domain discriminator loss, but this should be clarified. From a theoretical perspective, I think this would correspond to the maximization of the ELBO for $p(x)$ plus domain discriminator loss.\n2. In the proof of Lemma A.1, the authors claim that \"since $z_1 \\perp \\beta$ and $z_2 \\perp \\beta$, then $(z_1, z_2) \\perp \\beta$\", but this is not true in general. E.g. suppose $z_1$ and $z_2$ are Bernoulli r.v.'s and $\\beta = z_1  \\mathrm{xor}  z_2$. The authors should explain why the implication holds in their case or otherwise review the proof and reformulate the remainder of the theoretical analysis in case the Lemma cannot be proved.\n3. Architecture and implementation details are missing from the experimental section. This should be provided as supplementary material. Releasing the source code would also be beneficial for reproducibility.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and very well written. To the best of my knowledge, this is the first paper proposing to learn continuous domain indexes for DA directly from data. As mentioned before, some details are missing for reproducibility.",
            "summary_of_the_review": "This well-written paper presents solid contributions to the challenging problem of unsupervised multi-source, multi-target DA. Weaknesses 1. and 3. can be solved easily. Weakness 2. might be harder to solve, but I think that, even if Lemma A.1 cannot be proved and has to be removed, this result is not crucial for the paper. Thus, I recommend acceptance on the condition that the authors will address these concerns appropriately in their rebuttal and change the manuscript accordingly.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1287/Reviewer_YbH3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1287/Reviewer_YbH3"
        ]
    },
    {
        "id": "0W9hbx4qp-A",
        "original": null,
        "number": 2,
        "cdate": 1666667686035,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666667686035,
        "tmdate": 1666667686035,
        "tddate": null,
        "forum": "pxStyaf2oJ5",
        "replyto": "pxStyaf2oJ5",
        "invitation": "ICLR.cc/2023/Conference/Paper1287/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "- To alleviate the reliance on the domain index for domain adaptation, this paper proposes an adversarial variational Bayesian framework that infers domain indices from multi-domain data and provides insights on domain relations to improve domain adaptation performance.\n- The main contributions include\n    1. analyze and define what is an effective domain index\n    2. given the domain identities, infer the domain index as a latent variable from data by developing an adversarial variational Bayesian model.\n    3. provide the corresponding theoretical analysis.",
            "strength_and_weaknesses": "- Strength\n    1. The paper is well-written and clearly presented.\n    2. The proposed method is well-motivated and is theoretically guaranteed.\n    3. The idea of automatically inferring the domain index is interesting.\n- Weakness\n    1. Some of the statements should be further justified. For example, why is leveraging the domain index better than domain identity? Though previous work can somewhat support the statement, it would be better to briefly but explicitly justify it again here.\n    2. The domain index is formally defined in section 3.2. However, the definitions and differences between the local index and the global index are not quite clear.  For example, the global index \\beta is required to be independent of z, but this is not required for the local index, and why? In addition, the definition does not show the global index is responsible for indicating different domains. Moreover, why we explicitly need both the global index and local index is also not well justified. \n    3. The global domain index is inferred based on the local index. Is it necessary to introduce the additional local index? Is it possible to infer the global domain index directly? More analysis and experiments are encouraged for supporting this.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and clearly presented. The problem addressed in this paper is novel and reproducible.",
            "summary_of_the_review": "In general, the paper is well written and the idea is novel. However, there are still some issues that are required to be addressed as shown in weakness.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1287/Reviewer_SAsR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1287/Reviewer_SAsR"
        ]
    },
    {
        "id": "KDlLcfcRRaJ",
        "original": null,
        "number": 3,
        "cdate": 1666684309817,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666684309817,
        "tmdate": 1668849163561,
        "tddate": null,
        "forum": "pxStyaf2oJ5",
        "replyto": "pxStyaf2oJ5",
        "invitation": "ICLR.cc/2023/Conference/Paper1287/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper addresses the domain adaptation problem in VAE.\nThe authors proposed a method to explicitly estimate the domain index (latent variable) while the domain identity (ID) is known.\nThe domain index is modeled to be divided into global and local ones and estimated hierarchically. It is proved that the proposed method can optimally obtain them under certain assumptions with the optimization using the proposed loss. The proposed learning procedure imposes that the representation z is learned to be domain invariant.\nExperimental results on both synthetic and real-world datasets demonstrate that the proposed method performs much better than existing methods.",
            "strength_and_weaknesses": "*Strength\n- The authors provide a formal definition of domain index from the probabilistic perspective.\n- Their theoretical analysis justifies the proposed method.\n\n*Weaknesses\n- The assumption of the independence of beta from representation z is not justified well.\n- The introduction of the hierarchical modeling of global and local domains is not well supported and motivated. Is there any problem when we only use the global one?\n- The paragraph \"Inferring Global Domain Indices\" in Section 3.4 is hard to follow, and it is a different formulation from Eq.2, which is confusing. Is it impossible to use ELBO simply?",
            "clarity,_quality,_novelty_and_reproducibility": "*Clarity\n- The order of input variables is inconsistent, such as in Definition 3.1, which is confusing.\n- The formats of Eqs.4-7 have problem.\n- The description for \"(4) Regularization Terms for All Latent Variables\" is hard to follow. What kind of regularization is it?\n- In the description of the data CompCars, there is no description on what part is source or target.\n- It is unclear the proposed method is trained also on the target domain. If so, how do the authors get labels for the target domain?\n- It is better to provide some intuition that why the proposed method performed so well in Table 1 since there is a large margin from baselines.\n- In the experiment on W->E Level 1, why Source-Only performed the best?\n- In figure 6, there is no desctiption for the numbers on points.\n\n*Quality\n- Please see the above comments.\n\n*Novelty\n- The proposed method seems to be novel.\n\n*Reproducibility\n- Code is not available, but the authors provide enough information in the main text.\n",
            "summary_of_the_review": "The theoretical analysis is solid, but the assumptions behind that are not well justified, such as the independence of beta from representation z and the necessity of beta and u (global and local domain indexes). Clarity is low in general.\n\n================ Update: After the revision in the discussion phase, the assumptions are well justified. Clarity is improved. Thus, I upgraded my score to 6. In the final version, I hope that the authors include a brief description of the efficiency of introducing \\u into the main text, which is described in the paragraph \"Necessity of Local Domain Indices.\"",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1287/Reviewer_uSSJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1287/Reviewer_uSSJ"
        ]
    },
    {
        "id": "HE186QPNfMI",
        "original": null,
        "number": 4,
        "cdate": 1666841107554,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666841107554,
        "tmdate": 1666841107554,
        "tddate": null,
        "forum": "pxStyaf2oJ5",
        "replyto": "pxStyaf2oJ5",
        "invitation": "ICLR.cc/2023/Conference/Paper1287/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Domain-Indexing Variational Bayes for Domain Adaptation\n\nThe manuscript proposes a domain adaption which can infer domain indices (continuous values encoding domain semantics) under the assumptions that domain identities are known but domain indices are not available. The authors first define (local and global) domain indices in the probabilistic viewpoint and then propose an adversarial variational Bayesian framework (the evidence lower bound to learn the approximate posterior distribution for the latent variables and the discrimination term to enforce independence between the global domain indices and the data embeddings) to infer the domain indices. They also provide a theorical analysis which shows that the optimal solution of the proposed objective function is guaranteed to satisfy the three conditions of the domain index they propose to define in the manuscript.  \n",
            "strength_and_weaknesses": "Strengths.\n1.\tI think that the problem the authors try to solve is a new (domain adaptation learning with domain indices) and interesting (inference of unknown domain indices) problem.\n2.\tI think that the manuscript is well written and organized. Although I did not check all the detailed derivations, the theoretical analysis well supports the proposed method.   \n\nWeaknesses\n1.\tThe manuscript does not include the analysis of the computational complexities of the proposed method.\n2.\tRegarding the experiments. I think it would be better to include a table summarizing the data sets, e.g., the input dimension, the number of samples. I also think that it would be better if the previous work, Wang et al. (2020) Xu et al. (2022), had been included in the comparison as all the datasets used in the experiments already include the domain indices. With the same reason, I think that the experiments did not really explain well about what advantages of using the proposed method in practice would be. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity & Quality \nI think that the manuscript is well written. I have a minor comment. In Table 2, SENTRY is the best performer for the case \u201cN(24)->S(24): Average of 8 Level-3 domains\u201d.\n\nNovelty & reproducibility \nPlease see \u201cStrengths and Weaknesses \u201c\n\n \n",
            "summary_of_the_review": "I think that the manuscript has overall high quality. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1287/Reviewer_eAJo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1287/Reviewer_eAJo"
        ]
    }
]