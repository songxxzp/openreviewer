[
    {
        "id": "md8yYYrnuF-",
        "original": null,
        "number": 1,
        "cdate": 1666577018229,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666577018229,
        "tmdate": 1666577018229,
        "tddate": null,
        "forum": "4zGai1tFQE",
        "replyto": "4zGai1tFQE",
        "invitation": "ICLR.cc/2023/Conference/Paper3128/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a simple joint training deep dependency network, which can be built upon CNN baseline models to improve the performance in multi-label action classification tasks. The authors conduct experiments on three open datasets (Charades, TACoS, and Wetlab) and show their superiority on four metrics (mAP, LRAP, SA, and JI)",
            "strength_and_weaknesses": "Strength\n+ Well motivated in Introduction\n\nWeaknesses\n- Unclear diagram, it is hard to figure out the joint learning methodology and how the LOSS is designed according to the figure.\n- Hard to understand due to typo/unclaimed terminology (e.g., 'ds outperforms CNN' in Preliminaries). Meanwhile, the advantages claimed in this work are mainly explained on conceptual/abstract induction or assumption instead of convincing analysis (e.g., 'An issue with the loss function just described is that it significantly changes the structure and semantics of the output nodes of the neural network').\n- Experiments lack a detailed description of author-design modules (even with an unclear setting like 'MLPs with 3 or 4 hidden layers), which makes the experimental procedure unconvincing. \n- For some parts of the experiment results, baseline like Slowfast seems to have higher performance in public disclosure compared with the effect provided here, which is confusing.\n- The authors state the work is a method for action classification. However, the majority of the work lies on optimizing the correlation of feature-label and label-label, while the adjustment for the action classification task is not significant; in other words, I prefer to categorize the work as an application of the previous general method other than insightful research in the scope of action recognition. Therefore, the novelty is relatively limited, in my opinion. Also, if the work is mainly effective in solving the 'MLAC problem, the title of the paper is too big for the work done.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: poor; the paper is unclear and hard to understand\nQuality: poor, \nNovelty: poor; the paper proposes a simple dependency network with a joint training method, which does not show significant novelty\nReproducibility: poor; the paper lack details about their design, and it is hard to reproduce if the authors do not release the code\n",
            "summary_of_the_review": "The work lack novelty and convincing experiment detail, also the paper is hard to understand and the illustration is full of assumption and conceptual description.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3128/Reviewer_KzJi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3128/Reviewer_KzJi"
        ]
    },
    {
        "id": "lZA-Eiw2TD",
        "original": null,
        "number": 2,
        "cdate": 1666656602590,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666656602590,
        "tmdate": 1666656602590,
        "tddate": null,
        "forum": "4zGai1tFQE",
        "replyto": "4zGai1tFQE",
        "invitation": "ICLR.cc/2023/Conference/Paper3128/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work experiments with hybrid modeling with CNN and PGM for the task of multi-label action classification.\nThis work considers (1) `CNN` and (2) `CNN + MRF + GS/ILP/IJGP` as two baselines.\nThis work proposes an approach called `Deep Dependency Networks` to yield better posterior probability estimates.\nExperiments show the proposed approach output performs baseline (1) and (2) in terms multi-label action classification metrics.",
            "strength_and_weaknesses": "Strength\n + This work noticed a particularly interesting problem on the simple implementation of `CNN + MRF + GS/ILP/IJGP` for multi-label action classification, i.e., they yield poor posterior probability estimates.\n + The proposed approach surely addresses the discovered problem and outperforms the aforementioned baseline.\n\nWeakness\n + the baselines used in experiments are out of date. On Charades dataset, the CNN baseline is from 2019. On TACoS and Wetlab, the baseline is from 2016. While the experiments w.r.t. these baselines can provide some proof of usefulness of the proposed method. It is unclear if this performance gain can hold against more recent deep learning models.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Strength\n + Overall clear presentation of motivation, design, experiments, and results\n\nWeakness\n  + In the best performing setting (`DDN-MLP-Joint`), is the network architecture the same between `CNN` and `DDN-MLP-Joint`? Basically a CNN for extracting features and a MLP for mapping features to multi-class predictions. What's different between the two is only the losses applied, is this understanding correct?\n  + need to remove a comment at the beginning of Section 2: \"So just a quick question ......\"",
            "summary_of_the_review": "Overall I like the presentation of the problem motivation and the proposed solution. However the baselines used in experiments are not up to date. It's unclear whether the performance gain hold against more recent deep learning models.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3128/Reviewer_apzy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3128/Reviewer_apzy"
        ]
    },
    {
        "id": "MOnpoYjm6l",
        "original": null,
        "number": 3,
        "cdate": 1666694390676,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666694390676,
        "tmdate": 1666694390676,
        "tddate": null,
        "forum": "4zGai1tFQE",
        "replyto": "4zGai1tFQE",
        "invitation": "ICLR.cc/2023/Conference/Paper3128/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a simple approach that combines the strengths of probabilistic graphical models and deep learning architectures for solving the multi-label video classification task. This work proves that jointly learning the proposed model can yield significant improvements in performance over the baseline neural network. They do experiments on three video datasets: Charades, Textually Annotated Cooking Scenes (TACoS), and Wetlab, showing that deep dependency networks are almost always superior to pure neural architectures that do not use dependency networks.\n",
            "strength_and_weaknesses": "Strength:\n- DDNs are simple and easy to use, which is GPU friendly.\n\n- DDNs can model and reason about the relationship between the labels.\n\nWeakness:\n- The transformer model can also be regarded as modeling the graph between tokens. I suggest the author should compare with transformer-based models.",
            "clarity,_quality,_novelty_and_reproducibility": "I am satisfied with the clarity, quality, and novelty of this paper.",
            "summary_of_the_review": "This paper proposes a new hybrid model called DDNs, combining the strengths of dependency networks.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3128/Reviewer_rXD3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3128/Reviewer_rXD3"
        ]
    }
]