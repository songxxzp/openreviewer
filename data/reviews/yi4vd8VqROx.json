[
    {
        "id": "hYRXDGz1U2h",
        "original": null,
        "number": 1,
        "cdate": 1666592731768,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666592731768,
        "tmdate": 1666592731768,
        "tddate": null,
        "forum": "yi4vd8VqROx",
        "replyto": "yi4vd8VqROx",
        "invitation": "ICLR.cc/2023/Conference/Paper404/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new paradigm for reducing representational similarity analysis in CNNs to filter subspace distance assessment. Model representational similarity can be significantly simplified when filter atom coefficients are shared across networks by calculating the cosine distance among respective filter atoms. This study demonstrates that this simplified filter subspace-based similarity preserves a strong linear correlation with other popular stimulus-based metrics while being significantly more efficient and robust. Overall this is an interesting paper. Major concerns and minor comments are presented in the review section.",
            "strength_and_weaknesses": "Please refer to the review section.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Please refer to the review section.\n",
            "summary_of_the_review": "a) The primary concept that is unclear to me is that the paper claims that the proposed method is linear. How stacked layers of ConvNets can be considered linear. I believe that it should be discussed with some mathematical evidence. \n\nb) The performance of the proposed method should be compared with state-of-the-art representational learning approaches, such as Deep CCA (Andrew 2013), Deep GPs (Damianou 2013), Representational Similarity Learning (Oswal 2016), and Energy-Based Processes for Exchangeable Data (Yang 2020).\n\nc) Lemmas 1 and 5 did not follow the same format to denote matrices \u2013 i.e., they should be highlighted in bold.\n\nd) There are some minor linguistic and typo problems in this paper.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper404/Reviewer_Sx1E"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper404/Reviewer_Sx1E"
        ]
    },
    {
        "id": "JGxhpoGtph",
        "original": null,
        "number": 2,
        "cdate": 1666728759084,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666728759084,
        "tmdate": 1669399971671,
        "tddate": null,
        "forum": "yi4vd8VqROx",
        "replyto": "yi4vd8VqROx",
        "invitation": "ICLR.cc/2023/Conference/Paper404/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a new metric to evaluate representational similarity in deep neural networks. They aim to capture the properties of the well-known centered kernel alignment (CKA; Kornblith et al., 2019), but with substantially faster computation times. To do this, they leverage work by Miao et al. (2021) in which a group of neural networks is trained on different tasks but with a shared \"atom coefficients\" that render their weights directly comparable.",
            "strength_and_weaknesses": "This paper has a relatively detailed theory section and a clever idea. I think it is pretty interesting that weight space similarity and representational similarity can be correlated.\n\nHowever, there are several weaknesses which have muted my enthusiasm.\n\n* It is not clear to me that the computational expense of CKA (and related metrics) is a major bottleneck to research. So while the paper presents a potentially useful way to speed up calculations, I am not sure this enables fundamentally new research directions.\n\n* The authors seem to claim that a weakness of CKA is that it is stimulus-dependent. However, I would claim the opposite &mdash; it is potentially very useful to compare CKA values on in-sample vs out-of-distribution inputs to understand how hidden layer representations are sensitve to these shifts. By focusing only on weight space similarity, the authors' approach is less flexible.\n\n* The authors' framework requires the atom coefficients, denoted $\\alpha$, to be shared across different networks. This means that the authors' method is less generally applicable than CKA. For example, it would be useful to compare representational similarity between the DCFNet architecture (which includes the atom coefficients) and more standard architectures. However, while it would be possible to make this comparison with standard CKA, there isn't a way to do this with the authors' method.\n\n* While there is a lot of theoretical analysis in this paper, certain technical portions of the manuscript are not clear (see below).\n\n* Related to above, I think that certain technical assumptions are not made explicitly. For example, it would seem to me that the atom coefficients need to be full-rank in order for the filter subspace similarity to be meaningful. Consider if $\\alpha_{ij} = 1$, then any permutation of the filter atoms, $\\mathbf{D}^1, \\dots, \\mathbf{D}^m$, would produce the same convolutional filter $\\mathbf{W}$. Is my understanding here correct? If so, the conditions under which the filter atoms are directly comparable across networks needs further unpacking.",
            "clarity,_quality,_novelty_and_reproducibility": "I encountered several unclear passages that I hope the authors can clear up for me:\n\n* Why are the filter atoms first indexed by superscripts $\\mathbf{D}^m$ and elsewhere as subscripts $\\mathbf{D}_u$?\n\n* Is the equality in Theorem 2 actually an equality? Or only an equality when $\\mathbf{Z}_u^\\top \\mathbf{Z}_u$ is strictly diagonal?\n\n* In section 2.1 the authors define $\\mathbf{Z}$ to be post-nonlinearity activations, but they seem to define $\\mathbf{Z}$ as pre-nonlinearity activations in section 2.4\n\n* In section 2.4 the authors write $\\mathbf{Z}_u = \\boldsymbol{\\alpha} \\mathbf{X}_p \\mathbf{D}_u$, but I don't know what this means since all three of these symbols are higher-order tensors and not matrices?\n\n* The federated learning experiment (section 3.3) doesn't provide a lot of detail about how shared atom coefficients are achieved in practice. These details are very important to interpret the results and application and shouldn't be left to the Appendix. Similarly the details in the continual learning application (section 3.4) are pretty thin.\n\n* Section 4.2 seems mostly superfluous and unnecessary. I suggest cutting this and adding more details in section 3.3 and 3.4\n\n* One final comment/suggestion. The authors may consider remarking that their similarity measure becomes a proper metric if one takes the arc-cosine of the filter similarity. Several papers have recently argued that having a formal metric space over representations is important (see e.g. https://arxiv.org/abs/2110.14739)",
            "summary_of_the_review": "Overall, I think this work is potentially interesting. I would have liked to have seen it focused on when and why weight space similarity coincides with representational similarity in deep nets. Instead, the authors sold this new method as being a computationally cheaper and stimulus-independent form of CKA. I am less enthusiastic about this conclusion. The notation and clarity of the manuscript could also be improved. For now, I don't think this is quite ready and am categorizing this as a borderline reject, although I might be persuaded to increase my score if others find this interesting and if the text/equations can be clarified as mentioned above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper404/Reviewer_kifh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper404/Reviewer_kifh"
        ]
    },
    {
        "id": "auc5AD74Jrd",
        "original": null,
        "number": 3,
        "cdate": 1667162126340,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667162126340,
        "tmdate": 1667162126340,
        "tddate": null,
        "forum": "yi4vd8VqROx",
        "replyto": "yi4vd8VqROx",
        "invitation": "ICLR.cc/2023/Conference/Paper404/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper explores the use of the filter subspace distance as a measure of similarity between two neural networks. They provide theoretical and empirical justifications for this measure of similarity and validate their atom-based similarity on continual learning and federated learning tasks.\n\nMost measures of representational similarity (like CCA and CKA) require a forward pass through a trained model to compute representations of different inputs at different layers in a model. This paper takes a different approach and aims to decompose the filter weights of the network directly and then compare the underlying subspaces that are spanned by the network weights. By avoiding having to compute the representations directly, they can avoid the computational overhead needed in other existing approaches.\n\nWhile it is likely that the weights in two networks, when tuned or aligned, can help to reveal differences between the two, the claims in the abstract that they can achieve million times reduction in computation appears overstated because the setup for both approaches and goals is very different -- as RSA and the other tested approaches are black-box. There are other approaches that use weight distributions to compute measures of similarity and perhaps would be more appropriate to compare here.\n\nOverall, the assumptions underlying their framework aren\u2019t very well described and it's unclear how and when their metric will provide appropriate measures of similarity for different pre-trained models. \n",
            "strength_and_weaknesses": "Strengths:\n+ Validated their approach in diverse contexts, continual learning and federated learning setting where different distributed learners have access to different batches of data and are learning locally.\n \n+ Major benefits in terms of savings if filter subspaces are analyzed rather than the representations directly.\n\n+ They show that on simple tasks, analyzing filter subspaces is very correlated with the RSA-based approach\n\nWeaknesses:\n\n- There appear to be fundamental differences in what representational similarity is after vs. what this method provides. Thus it\u2019s unclear if the claims of \u201cthe proposed atom-based method can achieve millions of times computation reduction than popular stimulus-based methods\u201d is entirely fair since the methods aren\u2019t trained/tested under the same assumptions (where RSA is a black-box method).  \n\nThe assumptions are unclear:\n\n- The authors start with the assumption that \u201ctwo convolution neural networks Fu, Fv share atom coefficients layer-wise\u201d. \nWhen is this assumption satisfied? Do you need to train networks in a particular way to align them or to ensure that this constraint holds? \n\n- Because similarity is implicit, it seems that for the comparisons in the first propositions to hold, you need assume that the networks are trained on the same data streams. Either way it seems that the bounds linking the filter subspaces and representational similarity would be very loose.\n\n- Does this only work on CNNs? Why make this assumption?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The premise of the model is not well explained and assumptions are stated early on are not clear.",
            "summary_of_the_review": "This paper provides new tools for measuring similarity between networks using their weights rather than representations. While some of their results are promising and show that their approach can be helpful in continual and federated learning settings, none of the baselines are weight-based analysis approaches, the assumptions underlying their framework aren\u2019t very well described, and it's unclear how and when the atom-based metric will provide appropriate measures of similarity for different pre-trained models. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper404/Reviewer_KvFf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper404/Reviewer_KvFf"
        ]
    }
]