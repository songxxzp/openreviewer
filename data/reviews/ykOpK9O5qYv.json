[
    {
        "id": "yCG3ucku9Q2",
        "original": null,
        "number": 1,
        "cdate": 1666612849995,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666612849995,
        "tmdate": 1669018001655,
        "tddate": null,
        "forum": "ykOpK9O5qYv",
        "replyto": "ykOpK9O5qYv",
        "invitation": "ICLR.cc/2023/Conference/Paper4418/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the problem of capturing the interaction heterogeneity in modeling dynamic user preference for recommendation. A new evolving graph contrastive learning paradigm is designed to preserve both multi-behavior diversity and commonality. Extensive experiments are conducted to demonstrate the effectiveness of the new method compared with a large number of alternative solutions from different perspectives.",
            "strength_and_weaknesses": "Pros:\n1.The manuscript is well-organized and easy to follow. \n2. The descriptions of model motivation with technical details are very clear. The authors point out key challenges in learning preference dynamics for multi-behavior recommender systems. In the proposed EGCM method, the multi-behavior dynamic dependency challenges are addressed by integrating the contrastive SSL with cross-relation memory network. \n2.Theoretical discussion of the new contrastive learning is offered to analyze the benefits of the introduced behavior-wise contrastive-based SSL.\n3.Comprehensive experiments are conducted to justify the effectiveness of the new approach by comparing EGCM with 19 alternative solutions. \n4.Component-wise model evaluation as well as the in-depth analysis of EGCM method are provided to show the rationale of the superior performance.\n\nCons:\nIn the model inference phase, the self-supervision loss objectives L_{cl} with both short-term and long-term behavior modeling are incorporated into the original supervision optimized BPR-based loss. Besides the provided pseudo code in the appendix, the details of learning process in EGCM can be elaborated.\n\nFor the experiment of alleviating data sparsity issue, while the variants already achieve the obvious performance gain, the recommendation results of the new method can also be added.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper solves an under-explored recommendation problem with dynamic diverse behavior patterns. A novel contrastive learning paradigm is designed to tackle the corresponding technical challenges. Sufficient and appropriate experiments are conducted to show the new recommender EGCM\u2019s effectiveness. The source code and evaluation data are released for result reproducibility. The parameter settings are described in the paper.",
            "summary_of_the_review": "The proposed new framework would be beneficial for contrastive learning domain in learning the relational dynamics. The idea of dynamic contrastive learning to behavior-aware recommendation is novel and interesting. Good performance with comprehensive experiments on benchmark datasets are given.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4418/Reviewer_HypT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4418/Reviewer_HypT"
        ]
    },
    {
        "id": "OwlaMBhTAq",
        "original": null,
        "number": 2,
        "cdate": 1666628785370,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666628785370,
        "tmdate": 1670377866939,
        "tddate": null,
        "forum": "ykOpK9O5qYv",
        "replyto": "ykOpK9O5qYv",
        "invitation": "ICLR.cc/2023/Conference/Paper4418/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces an Evolving Graph Contrastive Memory (EGCM) framework which effectively models the multiple behaviors in the recommendation. EGCM is comprised of (1) a multi-behavior graph encoder to model the behavior-aware short-term interests of users, (2) a dynamic cross-relational memory network to model cross-behavior relational transitions, (3) a contrastive learning module to enhance the generalizability and robustness. The experimental results show that the proposed method could effectively outperform SOTA methods.",
            "strength_and_weaknesses": "Strengths:\n\n1. The experimental results show that the proposed method could significantly outperform the SOTA baselines.\n2. Code is provided. \n\nWeaknesses:\n1. The novelty of the paper is limited. Many modules are simple applications/extensions of existing methods.\n2. The proposed model is too complex.\n3. The writing is not quite clear, and some parts are difficult to follow. \n\nFor example, Eq. (4) is difficult to understand. Where to use $\\mathbf{m}^b_{u_t\\leftarrow i_t}$? \n\nYou use $f({\\mathbf{e}^b_{i_t}}, {\\mathbf{e}^b_{u_t}})$ in Eq. (4), however, ${\\mathbf{e}^b_{u_t}}$ does not appear on the right hand side.",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity of the paper should be further improved.\n\nThe overall quality looks good. \n\nNovelty is limited since many modules are simple applications/extensions of existing methods.\n\nReproducibility is good. The implementation details are presented and the code is also provided.",
            "summary_of_the_review": "The experimental results demonstrate that the proposed method could significantly outperform SOTA methods. However, the novelty is limited. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4418/Reviewer_1ytF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4418/Reviewer_1ytF"
        ]
    },
    {
        "id": "ybZS7AHFdz",
        "original": null,
        "number": 3,
        "cdate": 1666641030122,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666641030122,
        "tmdate": 1671209103431,
        "tddate": null,
        "forum": "ykOpK9O5qYv",
        "replyto": "ykOpK9O5qYv",
        "invitation": "ICLR.cc/2023/Conference/Paper4418/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a graph neural network (GNN) based recommender system for datasets featuring heterogeneous interactions (click, purchase, etc). This is done by performing message passing within behavior and time slot-specific subgraphs. Information is fused between behavior types and across time slots using various standard neural network components. Additionally, the paper proposes to use contrastive learning to encourage representations for the same user to be similar while pushing apart representations for different users. Experiments demonstrate the proposed model outperforms baselines on two small benchmark datasets and a proprietary (I think) e-commerce dataset.",
            "strength_and_weaknesses": "**Strengths**\n\n- The method performs well in the experiments.\n- Some ablation studies are included to validate choices.\n\n**Weaknesses**\n\n- The constituent pieces of the proposed model are known and there is limited technical novelty. \n- Many of the design choices seem arbitrary and are not adequately justified. Over three pages of the paper are spent describing the architecture and providing fairly loose intuitive motivation without actually justifying why the specific choice is obvious or should be preferred, e.g., \"both short-term and long-term multi-behavior preferences of users can be preserved by the fused representations,\" \"our EGCM can preserve the dedicated time-evolving behavior dependencies across different types of user interactions.\" The desirability of these properties may be intuitive, but how this maps to the specific choices made is not. \n- The ablation studies are extremely limited, and the experiments are not designed to justify the design decisions made. For example, without designing experiments that explicitly test the model's ability to \"capture such evolving cross-type behavior dependencies across time slots\"  how can the reader be sure this is what the proposed mechanism is actually doing? Indeed, in the results section the authors somewhat tautologically explain the observed performance improvements, \"EGCM outperforms various baselines in all cases by achieving significant performance improvements.\" The lack of rigorous experimental design to validate the reason for performance improvements makes me doubtful that the paper provides a solid foundation on which subsequent research can build.\n- The paper cites [1], although it does not seem to take any lessons from the work. For example, the arguments that applying non-linearities and transformation matrices to non-feature-based representations (e.g. a user or item id) seem to apply to this work as well.\n- The authors use sampled evaluation metrics despite previous work [2] showing this methodology can be misleading. Since the datasets seem relatively small (the largest dataset features 35.5K items), I'm curious if there was a particular reason the paper chose this evaluation.\n- The \"In-Depth Analysis of ECGM Model\" section is only a paragraph, and the conclusions drawn from the figures are not adequately described. I didn't find this section particularly interesting, informative, or in-depth.\n\n**References**\n1. [LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation](https://arxiv.org/abs/2002.02126)\n2. [On sampled metrics for item recommendation](https://dl.acm.org/doi/abs/10.1145/3535335)\n3. [A Troubling Analysis of Reproducibility and Progress in Recommender Systems Research](https://dl.acm.org/doi/abs/10.1145/3434185)",
            "clarity,_quality,_novelty_and_reproducibility": "Despite the ideas being relatively straight-forward, I found the paper quite difficult to read. I found the mathematical presentation particularly poor. In particular, almost everything is an E with various subscripts, superscripts, and accents. Many terms are not defined after they are first used, and the dimension of numerous variables is not explicitly.\n\nGiven the large number of architectural components, I also suspect it would be difficult to reproduce the results in the paper, and the authors do not provide anonymized source code. As this has been a persistent issue in the space [3], I would strongly encourage the authors to consider whether their results would be reproducible.",
            "summary_of_the_review": "While the experiments demonstrate performance improvements over baselines, the large number of seemingly arbitrary design decisions are not sufficiently explored. Instead, the paper reads mostly like a description of random components that happen to perform well in the particular benchmarks chosen. As a result, I believe the paper's contribution is quite limited and do not recommend acceptance.\n\n--------\n\n**Edit**\n\nThe authors have addressed several of my concerns in their replies and I have raised my score accordingly. Furthermore, it should be noted that my original statement that the authors do not provide source code was incorrect. I apologize for having overlooked it initially.\n\n--------\n\n**Edit 2**\n\nI have re-reviewed the most recent revision of the paper. I would like to thank the authors for engaging with reviewers and for their updates to the paper. I believe the paper has improved as a result of the process, but will not be further raising my score at this time, and cannot argue strongly for acceptance of the paper. \n\nWhile I believe there are interesting ideas presented in the paper, I continue to find the disconnect between motivation and experiments the most critical outstanding issue. I would encourage the authors to address this issue in future revisions of the work, as I feel if this issue was addressed, the work has the potential to be a significant contribution. \n\nTo clarify my meaning here, I will reiterate and elaborate on an example I used previously. In Section 3.2 the authors motivate the necessity of the cross-relational memory network component through the need to \"reflect a holistic view of diverse preferences of users across different time slots\" and then go on to give the following example \"customers may first view some products in online retail sites, and make their purchase decisions one day after.\" While the ablation experiments show average performance increases when this component is included, they do not validate that this performance increase is due to the stated motivation. A more convincing experiment would identify examples of such behavior (a product view temporally followed by a purchase) and validate that including this component improves performance on these specific instances (and that performance degrades on these instances when the component is not included). Without this sort of analysis, it is impossible to disentangle the given motivation from other potential sources of performance improvement (regularizing effect, increased capacity, etc).",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4418/Reviewer_rXXA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4418/Reviewer_rXXA"
        ]
    },
    {
        "id": "t4uSYIdfoz",
        "original": null,
        "number": 4,
        "cdate": 1666943336499,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666943336499,
        "tmdate": 1666943336499,
        "tddate": null,
        "forum": "ykOpK9O5qYv",
        "replyto": "ykOpK9O5qYv",
        "invitation": "ICLR.cc/2023/Conference/Paper4418/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "Summary:\n\nThis paper proposed to care about the sequential multi-behavior recommender systems where the multiple behaviors include a subset from {view, favorite, cart, purchase, browse, review}. To capture the multiple user behaviors, a multi-relation deep GNN is adopted to propagate behavior-aware messages and the graph Laplacian normalized function is incorporated into the message passing. In this way, both item representations and user\u2019s short-term interests can be captured. As for the relations among multiple behaviors, The paper is to learn cross-type behavior dependency matrix by a Transformer, or called self-attention-based memory network in the paper. In this way, both sequential/time-evolving and multi-type behavior dependencies are learned. In the end, the paper proposes a contrastive learning to pull the type-specific behavior and multi-behavior representation of the same user to be closer as positive pairs while to push the behavior of different users away as negative pairs. Experiments are conducted on three datasets by comparing with various kinds of 19 baselines. Ablation and visualization are further shown to understand the components of the proposed EGCM model.\n",
            "strength_and_weaknesses": "Strong & Weak:\n\nS1: It seems novel to use contrastive learning framework for the sequential & multi-behavior recommender systems. Although both sequential and multi-behavior ResSys methods are proposed in existing works, this paper is the first to adopt contrastive learning technique to construct the two auxiliary tasks to better learn the main task. Furthermore, the ablation study shows that, the proposed model degrades the performance by a large margin if the contrastive learning component is removed, especially on the Tmall and IJCAI datasets, though the impact of contrastive learning is not so big on the E-commerce dataset.\n\nW1: One possible weakness in my own opinion: While the proposed EGCM is a new method for sequential & multi-behavior recommender systems, each of the individual piece of EGCM (multi-relation GNN, Transformer, contrastive learning) is not new in itself and has been widely adopted in existing works as pointed out in the related works. This may be not a big issue in practice, since EGCM demonstrated a strong empirical result on three datasets.\n",
            "clarity,_quality,_novelty_and_reproducibility": "writing is good; technical originality is somewhat weak.",
            "summary_of_the_review": "Comments:\n\nC1: some typos. On page 2, \u201can\u201d in the statement \u201cwe propose a Evolving Graph\u201d. On page 6, the \u201c+\u201d symbol in computing $\\tilde E_{t,u}$; the subscript $e_i$ should be $e_u$ in the statement \u201cby pulling the type-specific behavior embedding\u2026\u201d; the dot product in the statement \u201cmeasured by the doc product\u2026\u201d \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4418/Reviewer_Usaw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4418/Reviewer_Usaw"
        ]
    }
]