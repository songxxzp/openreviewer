[
    {
        "id": "3VYag52LDf",
        "original": null,
        "number": 1,
        "cdate": 1665652526302,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665652526302,
        "tmdate": 1665652526302,
        "tddate": null,
        "forum": "ZS8L3Fbv-L",
        "replyto": "ZS8L3Fbv-L",
        "invitation": "ICLR.cc/2023/Conference/Paper5349/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "I informed the area chair that I cannot review this paper.",
            "strength_and_weaknesses": "I informed the area chair that I cannot review this paper.",
            "clarity,_quality,_novelty_and_reproducibility": "I informed the area chair that I cannot review this paper.",
            "summary_of_the_review": "I informed the area chair that I cannot review this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5349/Reviewer_nSTb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5349/Reviewer_nSTb"
        ]
    },
    {
        "id": "Xg3cQ_sTXPj",
        "original": null,
        "number": 2,
        "cdate": 1666292298443,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666292298443,
        "tmdate": 1666292298443,
        "tddate": null,
        "forum": "ZS8L3Fbv-L",
        "replyto": "ZS8L3Fbv-L",
        "invitation": "ICLR.cc/2023/Conference/Paper5349/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper begins by providing a toy example on how OOD samples could reduce generalization error. Then they show that this phenomena can also occur in some real dataset when the training data is extremely small. Finally, under the assumption of knowing the exact target and OOD distribution, they can come up with an optimal weighting to reduce the effect of OOD samples.",
            "strength_and_weaknesses": "Strength:\n- The writing is clear, the analysis seems rigorous.\n\nWeakness: \n- This phenomenon only seems to appear in extremely low data regime, which makes this phenomenon not really counter-intuitive. In a low data regime when the feature space is large, there are generally not much guarantees, which makes the existence of Theorem 1 not that surprising. Being only able to operate in such low data regime also limits the scope of the paper.\n- The choice of n, m and m/n seems quite arbitrary in each figure.\n  - Also I think it should be more reasonable to keep m+n fixed instead of keeping n fixed and increase m. In many of their figures, m/n > 1, which is not common to have more OOD samples than in-distribution samples.\n- Only generalization error is shown. Without also looking into the training/testing accuracy, it is hard to grasp what exactly is happening. One can have a constant classifier, it would always have a generalization error close to 0. In other words, generalization error itself cannot reflect how well the model is learning.\n- The developed algorithmic procedure for reducing the affect of OOD samples is also not very useful as normally we don't even have access to P_o and P_t.",
            "clarity,_quality,_novelty_and_reproducibility": "There are no code provided, I cannot say for certain of the reproducibility.\n\nThe paper is written well.",
            "summary_of_the_review": "The paper does provide interesting examples on how OOD examples might effect the model. However, none of the experiment setup/assumption operates in a condition that commonly seem tasks operates in, which limits the scope of the paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5349/Reviewer_Z5vh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5349/Reviewer_Z5vh"
        ]
    },
    {
        "id": "ViDt61c5wvL",
        "original": null,
        "number": 3,
        "cdate": 1666582397159,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666582397159,
        "tmdate": 1666582397159,
        "tddate": null,
        "forum": "ZS8L3Fbv-L",
        "replyto": "ZS8L3Fbv-L",
        "invitation": "ICLR.cc/2023/Conference/Paper5349/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies how OOD samples within datasets impact the generalization error on the desired task and observe that the generalization error of the task can be a non-monotonic function of the number of OOD samples. This work also develops an algorithmic procedure to train on the target task that is resilient to OOD data.",
            "strength_and_weaknesses": "Strengths:\n\nS1. The main observation that generalization error on the target task is non-monotonic in the number of OOD samples is counter-intuitive and interesting.\n\nS2. The structure of this paper is well-written and easy to follow. The motivation is clear.\n\nS3. The extensive experimental results on numerous datasets look good.\n\nWeaknesses:\n\nW1: It is unclear how to select the threshold of OOD samples, after which the generation error can deteriorate.\n\nW2: How to quantify the OOD samples that can improve generalization.\n\nW3: It would be interesting if the authors can conduct experiments on large vision benchmarks such as ImageNet-O, and ImageNet-R.\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation of this paper is clear and easy to follow.",
            "summary_of_the_review": "This paper presents interesting observations that are useful for applications. The extensive experiments and ablation studies are good but there are a few weak issues that need to be clarified.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5349/Reviewer_w9jQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5349/Reviewer_w9jQ"
        ]
    },
    {
        "id": "dOMG4-T2npS",
        "original": null,
        "number": 4,
        "cdate": 1666593886040,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666593886040,
        "tmdate": 1666593886040,
        "tddate": null,
        "forum": "ZS8L3Fbv-L",
        "replyto": "ZS8L3Fbv-L",
        "invitation": "ICLR.cc/2023/Conference/Paper5349/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper shows that generalization error on the target task is non-monotonic in the number of OOD samples. The authors empirically evaluate this phenomenon on MNIST, CIFAR-10, PACS, and DomainNet. Finally, the authors show how to ensure that the generalization error does decrease monotonically with the number of OOD samples. ",
            "strength_and_weaknesses": "Strengths:\n- The paper shows and brings insight into the phenomenon that generalization error doesn\u2019t decrease monotonically with the number of OOD samples. \n- The writing is quite clear overall, and the paper is well-structured.\nWeaknesses:\n- Not clear why intuitively generalization error should decrease monotonically with the number of OOD samples. In particular, if the out-of-distribution task is far from the target task, it\u2019s not clear why have those samples would improve generalization on the target task. Additionally, if there are a lot more OOD samples than target task samples, increasing the number of OOD samples intuitively may not improve the generalization on the target task. Can the authors provide a cite for the claim that the monotonicity is intuitive? If not, would suggest changing the framing to deemphasize how intuitive this is. \n- In order to mitigate the non-monotonic nature of the generalization error, the paper requires knowing which samples in the dataset are OOD. In addition, the proposed method is just using a weighed objective, which has been proposed before.\nSmall nits:\n- Not sure if there\u2019s a point to stating Theorem 1.\n- Italicized sentence at the end of page 7 seems important in making a point but doesn\u2019t make sense. Can the authors clarify?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: pretty good.\nQuality: See weaknesses above.\nNovelty: Paper has novel insights although the proposed method is not novel.\nReproducibility: should be easily reproduced.",
            "summary_of_the_review": "Please see weaknesses. I think the paper is interesting but not quite ready for acceptance.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5349/Reviewer_Gur8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5349/Reviewer_Gur8"
        ]
    }
]