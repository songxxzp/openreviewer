[
    {
        "id": "L8XE4BWmMW",
        "original": null,
        "number": 1,
        "cdate": 1666678267544,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666678267544,
        "tmdate": 1666678267544,
        "tddate": null,
        "forum": "SdXv2C2-tnj",
        "replyto": "SdXv2C2-tnj",
        "invitation": "ICLR.cc/2023/Conference/Paper4714/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents density sketches, which is a cheap and practical way to reduce data in a streaming setting., DS can keep a succint representation of data and can sample unseen data on the fly from this succint represesentation. This is done by reducing KDE into a problem related to histograms. The integrated mean squared error is analyzed. Experimental analysis is perofmred on small scale datasets.",
            "strength_and_weaknesses": "Pros: Interesting algorithmic ideas that work for low-dimensional, Euclidean data.\nCons: Most modern ML problems are high-dimensional problems that do not involve Euclidean data. In such cases density estimation is done via powerful parametric models. For problems which have a Euclidean structure, density estimation procedures cannot scale beyond a few dimensions. ",
            "clarity,_quality,_novelty_and_reproducibility": "Mostly well written. Some interesting ideas. Is failry easily reproducible.",
            "summary_of_the_review": "NIce algorithmic contributions to density estimation literature. But, these approaches will not sale to larger dimensionality, Euliean data. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4714/Reviewer_VE18"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4714/Reviewer_VE18"
        ]
    },
    {
        "id": "av4fNQ3KPl",
        "original": null,
        "number": 2,
        "cdate": 1666989694796,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666989694796,
        "tmdate": 1667435300698,
        "tddate": null,
        "forum": "SdXv2C2-tnj",
        "replyto": "SdXv2C2-tnj",
        "invitation": "ICLR.cc/2023/Conference/Paper4714/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes an approach to estimate the data distribution. For high-dimensional spaces, the traditional histogram-based algorithm and KDE methods require #data exponential in the dimension. The paper proposes Density Sketch (DS) which uses particular data structure Count Sketch (CS) to reduce the memory consumption of histogram-based methods. Moreover, the paper proposes to use a min-heap for efficient sampling from the estimated distribution. ",
            "strength_and_weaknesses": "The method is simple and seems effective from the empirical evaluation. The paper is well-organized and easy to follow. ",
            "clarity,_quality,_novelty_and_reproducibility": "While the paper is well-organized, it is very hard to read due to so many notation problems and typos. See my comments in the summary.",
            "summary_of_the_review": "While the paper is well-organized, it is very hard to read due to so many notation problems and typos. Here are my questions:\n\n1. In many places in the paper, what is the dot . in the denominator of $\\hat f_H$? (i.e., the $n.V(B(x))$)\n\n2. What is $\\hat C(x)$ in Section 4.4? What is the difference between Section 4.3 and 4.4? I don't understand why we don't just use $\\hat f^*_C(x)$ for estimating the density. As stated in the paper, $\\hat f_C(x)$ is not normalized ...\n\n3. In Section 5, what is the probability space of the $E$ in MISE? And what is exactly IMSE? Is there a typo in the second equation in page 7? What is the randomness in Theorem 1 (\"with probability ($1-\\delta$)\"). The argument in the analysis is that `if MISE -> 0, then $\\hat f$ converge to $f$ in probability'. Does the randomness affect this result or not?\n\n4. The author should give more background on L1/L2 LSH in the maintext as they are mentioned a lot later. \n\n5. There are many notation problems in the paper. For example, in Section 4.2 when introducing notations, what is $f(x): S \\subset R^d \\rightarrow R$ intend to tell us? My guess is $S$ a Borel set, but not sure .... Also, the author simply writes $p$ for p as well as many other symbols in many places in the paper. The author seems submitted this work in a rush and there are even paragraphs without period. \n\n6. While the author claims that DS has advantages for high-dimensional spaces, it seems that the evaluations are still performed on datasets with dimensions $<100$. \n\nI suggest the author do a thorough proofreading of the paper to improve the paper's readability and clarity. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4714/Reviewer_Kdqf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4714/Reviewer_Kdqf"
        ]
    },
    {
        "id": "nYTb-eEmkD",
        "original": null,
        "number": 3,
        "cdate": 1667433903191,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667433903191,
        "tmdate": 1667433903191,
        "tddate": null,
        "forum": "SdXv2C2-tnj",
        "replyto": "SdXv2C2-tnj",
        "invitation": "ICLR.cc/2023/Conference/Paper4714/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper constructs a data structure, dubbed density sketch, that represents a density on a high-dimensional space. This data structure is constructed online, in a streaming fashion from data samples assumed drawn i.i.d. from a true density. The representation is capable of evaluating the density at specific points as well as of sampling points. The paper also provides analysis of the approximation level of this representation in MISE distance and illustrates its applicability via some experiments.",
            "strength_and_weaknesses": "### Strengths\n\n* Reducing the overhead of data by representing it accurately in compressed form continues to be a timely topic. \n\n* The construction of the density sketch data structure is intuitive and the compression and accuracy levels achieved in experiments seem very promising. \n\n### Weaknesses\n\n* The paper is typographically in a very rough form. Many mathematical expressions are not placed in math style and there are typesetting errors in those in math style (e.g., hat symbols appearing in the wrong places) that make expressions hard to parse. There are also many linguistic issues, some of which are listed under minor comments. The paper needs a serious polish revision to become of publication quality.\n\n* The main theorem (Theorem 1) is not presented cleanly. Here are some issues:\n    * The parentheses are all the same size, making it hard to parse what goes where. This is an easy fix, with the exception that there seems to be an extra right parenthesis in the very end, which could change the meaning of the expression if it is associated with a left parenthesis somewhere.\n    * Perhaps a related issue to the above, but as written the right-hand side does *not* vanish, even if both $1/nB^d$ and $B^2d$ vanish. That\u2019s because the last parenthesis block which starts with $3\\epsilon(1+2\\mathcal{G}(f)+\\cdots)$ is not affected by either of these. This could be an issue of misplaced parentheses. However, as far as I can tell from the proof (which I have only skimmed through), that term is there.\n\n* The reasons the last point necessitates a clarification is because it makes the conclusions from the Theorem a bit more subtle. In particular, it would seem that we can make $\\delta$ a constant, which implies that $\\epsilon$ vanishes, so this term would vanish. However, if I understand it correctly from the proof, the equation is only valid if $\\delta$ is small for a fixed $\\epsilon$. Therefore we cannot change the order of quantifiers, and that reasoning does not work. I welcome engaging with the authors to clarify this point, as going through the proof to reach the conclusion myself is a bit daunting.\n\n* The paper would benefit from a clear characterization of the worst-case space and time complexity of the method, since lower complexity is one of the selling points. \n\n### Questions\n\n* In Figure 1, what is $g_i(a)$?\n* In SRP, are the volumes of all partitions equal? You assume that throughout, but perhaps that only works for LSH?\n* I don\u2019t think you mean multinomial distribution in Algorithm 3, you instead mean a categorical distribution over the bins.\n\n\n\n### Typos and suggestions\n\n(p.1) include edge > including edge\n(p.2) in the section 2 > in this section. ; function f(x) > function $f(x)$\n(p.3) place $\\hat$ symbols correctly; define $\\mathcal{C}$ as the count vector\n(p.4)\n* Your use of $i$ is too overloaded, you use it to index: data points, coordinates, and LSH/SRP weights. It would be more legible if each of theses uses had its own letter.\n* In Table 1:\n   * for LSH and SRP in the bin column, there shouldn\u2019t be a subscript on $x$\n   * typeset the $w_1$ vector and $W$ vector in math mode\n   * remove trailing parenthesis after $U[0,1]$\n* point x > point $x$\n(p.5) a efficient > an efficient; in the figure > in Figure; fix all the $\\hat$ locations (last mention, this has to be fixed everywhere in the paper); remove trailing parenthesis from $\\hat \\mathcal{C}(x)$\n(p.6) in Algorithm 1, fix the partition function line; in Algorithm 3, remove trailing parenthesis from UniformRandomPoint(b); point x > point $x$; close parenthesis after MSE\n(p.7) add = between IMSE and MISE\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper needs a good polish in its mathematical expressions and language. Another weird point is that the paper was uploaded in non-searchable form (I had to OCR It). It would be very useful for reviewing to have at least the text searchable, and ideally all references hyperlinked.\n\nThe combination of a heavy-hitter list along with LSH bins and count sketching is novel to me, but there have been many streaming data reduction techniques and it is difficulty to fully judge the novelty without being directly in this research area. Code was provided, and the experiments appear reproducible.\n\nIf, after discussions, the main result is determined to truly represent an approximation theorem in the limit, then there is enough contribution here to make it worthy to share with the community, conditionally on clarifying the presentation and polishing the typesetting and language.\n",
            "summary_of_the_review": "The paper puts together various data reduction techniques in an intuitive manner to offer a novel density representation that can be constructed in a streaming fashion. This appears to lead to low space and time complexity, but ideally that analysis should also be part of the paper. The main result requires a bit of clarification, to make sure that the approximation ability of this representation is indeed there. What hampers the paper most is unpolished typesetting and language. With some clarification and polish, the paper may be worth sharing with the community.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4714/Reviewer_jjJ4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4714/Reviewer_jjJ4"
        ]
    }
]