[
    {
        "id": "FcQxupAW0y",
        "original": null,
        "number": 1,
        "cdate": 1666402429056,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666402429056,
        "tmdate": 1666402429056,
        "tddate": null,
        "forum": "dcN0CaXQhT",
        "replyto": "dcN0CaXQhT",
        "invitation": "ICLR.cc/2023/Conference/Paper5043/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors generalize the differentiable causal discovery method to the setting in the presence of latent variables. Compared to related work, the method can tackle non-linear data. They provide both theoretical and empirical results.",
            "strength_and_weaknesses": "Strength:\n1. The paper is clearly written. \n2. The authors give a detailed review of the related studies. \n3. There are some new theoretical results in this paper.\n\nWeaknesses:\nI do not find some significant weaknesses except for some typos. ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the quality is good. The authors take a further step towards the differentiable causal discovery when the data generating process is non-linear.\n\n\ntypo or minor aspects\n1. They enable us to answer questions causal in nature on Page 1.\n2. Lemma 1-Lemma 3 \"if *and* only if \"on Page 4.\n\n\nquestions:\n1. I am not clear how the proposed method enforces that the ADMG learning satisfies\nassumptions in Section 4, as said on Page 5. Shouldn't whether the assumptions are fulfilled related to the task only and not relevant to the method?\n\n2. What does it mean by \"Whilst the observed data distribution may still be identifiable\"?",
            "summary_of_the_review": "Overall, the quality is good. The authors propose a differentiable method for learning ADMG under the current causal discovery framework, with theoretical guarantees and rational experiments. Hence, I give a positive score. The main reason for the borderline score is that I do not quite agree with the study regarding learning the ADMG (this discussion is possibly beyond the scope of this paper.). The assumptions necessary for ADMG learning are too strong. I am strongly skeptical whether such a target of learning ADMG can be achieved in practice, and whether this study can help the practical problems. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "-",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5043/Reviewer_dczA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5043/Reviewer_dczA"
        ]
    },
    {
        "id": "L6A6h21Fhi",
        "original": null,
        "number": 2,
        "cdate": 1666445170432,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666445170432,
        "tmdate": 1666445170432,
        "tddate": null,
        "forum": "dcN0CaXQhT",
        "replyto": "dcN0CaXQhT",
        "invitation": "ICLR.cc/2023/Conference/Paper5043/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors modeled the data structure with acyclic directed mixed graphs (ADMGs). Under the condition where latent confounding is present, a new autoregressive  flow-based approach is proposed to learn the causal and functional relations of the given data. In the experiments. the authors validate competitive performance of their approach in comparison to the baselines.",
            "strength_and_weaknesses": "Strengths: \n1 I like the mathematical formulation discussed in Sec. 4. The introduction of ADMG identifiability seems to be quite clear. Though the additive noise assumption and confounding assumption are simplified, the authors achieve a good balance between practicality in real-world application and technicality in mathematical reasoning. The discussions from  lemma 1-3 also make sense to me and fairly easy to understand.\n\n2. The autoregressive approach that is implemented with MLP is well-motivated. The authors have justified the method on both  a toy and real datasets.\n\nWeakness:\n1 I think the major issue is that the authors altered the layout of the ICLR template and significantly decrease the space between sections.\nI am not sure if this is fair for other authors who follow the submission guidelines. ",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and quality of the paper is okay.\nIt is hard for the reviewer to evaluate the reproducibility of the paper. Because of the page limit, many model implementation details are not disclosed in the paper. ",
            "summary_of_the_review": "Considering the violation of ICLR template's layout and the length of the paper, I would kindly suggest submitting this paper to a journal instead. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5043/Reviewer_ZhRx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5043/Reviewer_ZhRx"
        ]
    },
    {
        "id": "Udl7tCdRry",
        "original": null,
        "number": 3,
        "cdate": 1667341516613,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667341516613,
        "tmdate": 1667341516613,
        "tddate": null,
        "forum": "dcN0CaXQhT",
        "replyto": "dcN0CaXQhT",
        "invitation": "ICLR.cc/2023/Conference/Paper5043/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides a gradient based approach to causal discovery in the presence of unobserved confounding. By making assumptions on the structure of the graph along with additive noise assumptions - identification results for non-linear SCMs are provides. Since the conditional independencies involves learning functions, a neural ADMG learning framework is proposed. Finally, empirical evaluation is performed where the method is shown to perform well. ",
            "strength_and_weaknesses": "Strengths: This paper establishes causal discovery results on a more flexible class of ADMGs than what exists in the literature. Proper identification conditions are established, and the inference framework has computational tractability advantages.\n\nWeakness: The statistical framework for neural ADMG learning does require a lot of modelling decisions when it comes to things such as choice of variational approximation - and I do worry how how much flexibility these methods lose when such choices are made. However, I understand the necessity of these assumptions, and I consider this only a minor weakness. ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well written, and a rigorous discussion of existing work and its limitations is provided. Additionally, the explanation of concepts flows well and allows for the reader to understand the points made in this paper very well. The work here is novel as it provides new identification results as well as a new numerical framework for causal discovery. ",
            "summary_of_the_review": "Overall, this paper presents a novel causal discovery algorithm under the assumption of additive noise. Identification results are first established, then the proposed neural ADMG learning framework is used to learn an ADMG. This paper is novel because it allows for learning ADMGs while relaxing assumptions made by previous works since, it allows for non-linear functions in the SCM. Next, instead of relying on traditional conditional independence tests - which can sometimes run into tractability issues in high dimensions, the neural ADMG framework is proposed that is more suitable for dealing with high dimensional data. High quality paper, I recommend for acceptance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5043/Reviewer_DadL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5043/Reviewer_DadL"
        ]
    },
    {
        "id": "RX87FoZDzB",
        "original": null,
        "number": 4,
        "cdate": 1667439884650,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667439884650,
        "tmdate": 1667439884650,
        "tddate": null,
        "forum": "dcN0CaXQhT",
        "replyto": "dcN0CaXQhT",
        "invitation": "ICLR.cc/2023/Conference/Paper5043/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a method of estimating ADMGs from observational data. The authors build on existing work on ADMG identifiability and on graph learning with deep neural networks. First, two assumptions (sufficient conditions) are proposed that guarantee identifiability of the underlying ADMG (inspired by Maeda and Shimizu, 2021). Subsequently, a variational scheme (N-ADMG) for learning the ADMG is introduced (based on Geffner et al., 2022). The paper concludes with a series of experiments showing causal discovery (ADMG recovery) and causal inference (average treatment effect estimation).",
            "strength_and_weaknesses": "STRENGTHS\n\nWhile this paper builds heavily on existing work, both in deriving the sufficient conditions for ADMG identifiability and for specifying the variational model optimized with neural nets, the two parts fit together nicely which leads to a well-defined model for ADMG estimation.\n\nThe research area is also very relevant and has received a lot of attention recently (deep causal models, accounting for unobserved confounding).\n\n\nWEAKNESSES\n\nThe novelty of the proposed approach is somewhat limited by the fact that the vital building blocks (ADMG identification criteria and variational causal graph structure learning) are already present in the literature.\n\nThe experiments appear inconclusive, especially given the fact that both in the causal discovery and causal inference (ATE estimation) experiment, the methods coming close to (or beating) N-ADMG are the ones corresponding to the \"building blocks\", i.e. N-DAG and CAM-UV.\n\nAs a minor issue, Figures 2 and 3 are difficult to read.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow.",
            "summary_of_the_review": "This paper combines two existing ideas which leads to a somewhat novel approach to ADMG estimation from observable data.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5043/Reviewer_fy3p"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5043/Reviewer_fy3p"
        ]
    }
]