[
    {
        "id": "V4xLOibTox9",
        "original": null,
        "number": 1,
        "cdate": 1666594307373,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666594307373,
        "tmdate": 1670513693289,
        "tddate": null,
        "forum": "2r6YMqz4Mml",
        "replyto": "2r6YMqz4Mml",
        "invitation": "ICLR.cc/2023/Conference/Paper3439/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies to measure the robustness of combinatorial solvers. The solver is defined as non-robust if the CO problem has relaxed constraints while the solver obtains a worse solution. This paper proposes to modify the corresponding graph structure for the CO problem to relax its constraints, and measure the performance of the solver on the modified graph compared to that on the original graph.",
            "strength_and_weaknesses": "Strength:\n\n1. The problem, i.e., the robustness of CO solvers, is novel, interesting, and important.\n2. The proposed framework evaluates different solvers and tasks extensively.\n\nWeaknesses:\n\n1. As an *evaluation* paper, the definition of robustness should be made clearer. I understand that the optimal solution is usually infeasible for NP-hard problems; however, a quantitative measure of robustness is still needed. For example, is the solver more robust with a lower (perturbed_solution - original_solution) absolute value or lower relative ratio (perturbed_solution - original_solution)/original_solution? And how to compare the robustness of two solvers if they get largely different original solutions?\n2. Can the evaluation results lead to some insights about the robustness of different solvers, i.e., greedy solvers, heuristic solvers, neural network solvers, etc.?\n3. Though the motivation to study the robustness of CO solvers is clear, more concrete examples/applications are needed to elaborate on why the attack model makes sense.\n4. The novelty mainly comes from the problem definition, while the technical contribution is a little bit limited. \n\nMinor: Page 5, the sentence above 3.2, edgesh -> edges",
            "clarity,_quality,_novelty_and_reproducibility": "This paper presents an evaluation framework to measure the robustness of CO solvers. The problem setting is novel, while the technical novelty is a bit limited. The evaluation is conducted on various solvers and tasks with good quality.",
            "summary_of_the_review": "This paper studies a novel problem, i.e., the robustness of CO solvers, and provides an interesting framework that evaluates the robustness of various solvers on different tasks. More analysis of the evaluation results, elaboration of the applications of the attack model design, and more profound technical contributions are expected.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3439/Reviewer_baVX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3439/Reviewer_baVX"
        ]
    },
    {
        "id": "x7bEGQap0vy",
        "original": null,
        "number": 2,
        "cdate": 1666672734774,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666672734774,
        "tmdate": 1666672734774,
        "tddate": null,
        "forum": "2r6YMqz4Mml",
        "replyto": "2r6YMqz4Mml",
        "invitation": "ICLR.cc/2023/Conference/Paper3439/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work propose a new evaluation metric for evaluating the robustness of solvers on combinatorial optimization (CO) problems. The proposed evaluation metric is agnostic to optimal values, which may be hard to obtain in real world situations. As the proposed metric requires another problem instance with better optimal objective value but \"harder\" to solve, this work also proposed a RL-based approach, to modify the structure of the input graph which represents the underlying CO problem. It then evaluate the robustness of three combinatorial solvers (traditional solvers, learning based solver and specific MILP solver like Gurobi) using the proposed metric with the proposed approach on four combinatorial tasks: Directed Acyclic Graph Scheduling, Asymmetric Traveling Salesman Problem, Maximum Coverage, and Maximum Coverage with Separate Coverage Constraint. \n\nOverall, the proposed evaluation metric has some novelty over other existing metrics, but it needs problem-specific designs of how to modify the graph structure (e.g., add or remove edges, change edge length, etc). Also, the training of the proposed RL strategy requires call of the solver at each step, which may not be practical for real-world scenarios where the graphs may have thousands (or even more) of nodes. More important, I think this work would have more important contributions if it could utilize ROCO to provide more insights on what make one solver more robust than other solvers or what makes one solver more robust on a specific problem than other problems. Such follow-up experiments and analysis are important to tell the usefulness of ROCO and why it is evaluating the real robustness of the model.\n\n\n\n",
            "strength_and_weaknesses": "Strength:\n-\n\n[+] This work tackles an important domain: how to evaluate the robustness of solvers for Combinatorial Optimization problems.\n\n[+] The proposed evaluation metric does not need the optimal value of the underlying CO problem instance and does not require the solver to be differentiable.\n\n---\nWeakness:\n-\n\n[-] I do not see much insight into why and when a solver would be more robust on a problem than other solvers or other problems from the current experimental results. This part is important in order to tell the usefulness of ROCO and why it is evaluating the real robustness of the model.\n\n[-] The proposed evaluation metric needs problem-specific designs of how to modify the graph structure (e.g., add or remove edges, change edge length, etc)in the attack model.\n\n[-] Sometimes it may be easier to degenerate the performance of good solvers than the bad ones especially when the good one is close to the optimal but the bad one is close to some baseline value, in this case, I think the proposed metric would favor the bad one as it could just perform equally bad on the original and modified instance.\n\n---\n\nMinor comments:\n- It would be better to compare the robustness using ratios rather than raw numbers for all tasks in the main paper. \n- The presentation of the work could be better if some terminology could be defined (earlier) such as \"attacker\" and \"no worse optimal\". costs\"",
            "clarity,_quality,_novelty_and_reproducibility": "The originality and quality of work are okay but not good enough for the standards of ICLR. There are many experiments in this paper as it evaluates 3 solvers on 4 problems using 5 variants of the proposed metric. Yet, I would expect to see more in-depth analyses of these results and some follow-up experiments investigating the robustness of why and when a model/solver tends to be more robust, which is also important for telling the usefulness of a proposed metric and why the proposed metric is evaluating the real robustness of the model. Also, the proposed evaluation metric needs problem-specific designs of how to modify the graph structure and may blindly favor a solver that performs averagely on different problem instances.\nThe presentation of the work could be better by providing a). rigorous definitions of the terminology used and b) better visualization of the robustness comparison.",
            "summary_of_the_review": "This paper studied the robustness of a combinatorial solver as a black box regardless of its differentiability. It developed a robustness metric that does not need the optimal solution by using another instance with no-worse optimal cost guarantee. It uses an RL-based approach to find such instances given some hand-designed relaxation rules given a specific problem. In the experimental section, this work conducted extensive experiments on 14 different combinations of solvers and variants of robust metrics. Yet, it lacks in-depth analyses of why and when a solver is more robust under this metric as well as how the proposed metric is evaluating the real robustness of the model. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3439/Reviewer_oJSV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3439/Reviewer_oJSV"
        ]
    },
    {
        "id": "iX9tM3DpNUP",
        "original": null,
        "number": 3,
        "cdate": 1666708218890,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666708218890,
        "tmdate": 1666708218890,
        "tddate": null,
        "forum": "2r6YMqz4Mml",
        "replyto": "2r6YMqz4Mml",
        "invitation": "ICLR.cc/2023/Conference/Paper3439/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This manuscript proposes a new method (called ROCO) to study robustness of algorithms/solvers for combinatorial optimization problems. It does not need the optimal solution, nor does it require a differnetiable solver.\n\nTo avoid the need for knowing the optimal solution, they modify the input instance in such a way that the optimal cannot become worse. For example, you can reduce edge weights or relax certain constraints. Then they re-run the solver on the new instance and expect that the solution will not produce worse objective values. How much worse it gets determines the level of non-robustness.\n\nThen they get to the problem of finding these \"hard\" instances for the solver. Their reinforcement learning-based method outperforms a few baselines (random edge selection, \"optimum guided\" via beam search, and simulated annealing). In their empirical study, they look at a few combinatorial optimization problems like task scheduling and max coverage.",
            "strength_and_weaknesses": "S1: The new metric does not need to know the optimum.\nS2: It treats the solver as black-box, so it also works with non-differentiable combinatorial optimization problems.\nS3: The RL-based approach works well in practice.\n\nW1: Why is this a good notion of robustness? It's not clear what robustness is supposed to achieve.\nW2: A robustness metric should perhaps produce a number between 0 and 1. While one can simply normalize with respect to the original solution, there is no discussion of the advantages or disadvantages.\nW3: There could be more discussion about relative robustness of the different solvers. For example, CBC performs poorly in terms of robustness on max cover instances. It also performs poorly in terms of quality compared to the other solvers. Is there more to read from this? ",
            "clarity,_quality,_novelty_and_reproducibility": "The writeup quality is decent. There are some typos.\nPresentation could be improved if the goal for robustness were mentioned upfront.",
            "summary_of_the_review": "Decent paper with interesting practical results, though the empirical section and the initial motivation sections could be expanded with more insight.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3439/Reviewer_2fgV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3439/Reviewer_2fgV"
        ]
    },
    {
        "id": "5whQN8iHpn",
        "original": null,
        "number": 4,
        "cdate": 1666840317909,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666840317909,
        "tmdate": 1666864080691,
        "tddate": null,
        "forum": "2r6YMqz4Mml",
        "replyto": "2r6YMqz4Mml",
        "invitation": "ICLR.cc/2023/Conference/Paper3439/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a framework and algorithms for verifying the robustness of combinatorial optimization solvers for graph problems. A key idea is to define a new criterion of successful attacks to the solver, defined without using the optimal solutions, whereas the previous work requires them. The paper then proposes some methods to implement the attacks. Among them, one attack is implemented based on reinforcement learning. Experimental results show the advantages of the RL-based attack against other proposed methods and the random naive method.",
            "strength_and_weaknesses": "Strength:\n- A reasonable definition of the success of an attack for combinatorial optimization solvers\n- Several implementations of attacking are proposed and evaluated in experiments\n\n\nWeakness:\n- The problems are restricted to graph problems so far\n\nThe key idea of the paper is to propose a reasonable criterion of the success of an attack. The previous work needs an optimal solution, which is intractable in general. The current work does not have such a disadvantage and becomes more practical. \n\n\n\nMinor technical issue:\n- In Definition 1, there is no definition of \\tilde{x^*}.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written in general. The work seems new and I think the originality is non-trivial. One of the technical contributions is to define a new success criterion of an attack. The problem is well motivated and relevant.",
            "summary_of_the_review": "The paper proposes a reasonable definition of the success of an attack for combinatorial optimization solvers over graphs.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3439/Reviewer_Agfm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3439/Reviewer_Agfm"
        ]
    }
]