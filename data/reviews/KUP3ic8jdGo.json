[
    {
        "id": "lAAhYn36jL",
        "original": null,
        "number": 1,
        "cdate": 1666562473571,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666562473571,
        "tmdate": 1666613846192,
        "tddate": null,
        "forum": "KUP3ic8jdGo",
        "replyto": "KUP3ic8jdGo",
        "invitation": "ICLR.cc/2023/Conference/Paper1452/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors investigate the generalization performance of convolutional neural networks and their associated kernels, i.e. the infinite-width neural tangent kernel, the empirical neural tangent kernel at initialization, as well as the \u201cafter-kernel\u201d, i.e. the empirical tangent kernel arising after training the finite-width neural network for a certain amount of epochs. The authors assess this performance through so-called scaling laws, a metric that has been popular recently, which measures how test accuracy evolves as sample size is increased. The resulting curves traditionally follow a power law with the exponent indicating how well a model class generalizes. The authors identify that finite-width networks exhibit a better scaling compared to infinite-width kernels as well as empirical kernels both at initialization and after training. Contrary to other works, the after-kernel is found to improve even in later stages of training, stopping the empirical kernel from catching up to the finite-width network. ",
            "strength_and_weaknesses": "**Strengths**\n\n1. Studying the difference between finite and infinite width through scaling laws is a very interesting and timely contribution. While prior work has focused on pointwise comparisons, scaling laws indeed provide a better assessment, which is lacking in the literature to the best of my knowledge. The result that neural kernels exhibit weaker scalings is a stronger one than what was previously known and further highlights the limitations of these approaches.\n\n2. The authors have performed a very rigorous analysis by going beyond infinite-width and Empirical NTK at initialization. The results on the after-kernel and the fact that neither \u201cearly-stopped\u201d nor weaker pre-trained ENTKs can catch up in terms of scaling is somewhat surprising and differs from earlier works. \n\n3. The results in Figure 2b), 2c) are very interesting as well as it contradicts the wisdom that overparametrization always helps. There are some prior results on this phenomenon, for instance [1], referred to as triple descent. Do you observe the same phenomenon if the usual NTK assumptions are broken (e.g. large learning rate, standard parametrization etc)?\n\n**Weaknesses**\n\n1. The usage of optimal stopping is a bit unfair here as the infinite width NTK and the empirical NTK cannot profit from it (I assume you always consider kernels evaluated at t=inf?). Figure 3d) addresses this concern to some degree but I still think the results would be more representative if a certain computational budget would have been fixed before hand.\n2. The paper does have a few typos (see clarity section) which makes reading the work a bit less enjoyable. It is also entirely missing a conclusion and discussion section, which is a bit of a shame as a nice summary of the results obtained in this work would really drive the message home.\n\n[1] The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization, Ben Adlam, Jeffrey Pennington",
            "clarity,_quality,_novelty_and_reproducibility": "1. In general the paper is easy to follow and the results are clearly explained. A final discussion and conclusion however would help the reader to place the results of this work into a broader context.\n\n2. It might make sense to spend a bit time on explaining scaling laws and what exactly they capture. For instance the fact that one model might generalize better at certain sample sizes but exhibit a worse scaling is a bit counterintuitive. For instance in Figure 4.c), the kernel pre-trained on 64k examples exhibits worse scaling than the empirical NTK at initialization. However, the 64k kernel generalizes better (i.e. has lower error) at all considered sample sizes compared to the ENTK. \n\n3. The result of Figure 4.c) still confuses me, do you have any intuition why the kernel pretrained on 64k samples exhibits a worse scaling than the empirical NTK at initialization? Especially the model based on 16k samples has really terrible scaling, just because it has seen more data?\n\n4. There are quite a few grammatical errors, I\u2019m just listing a few here:\n  - Caption figure 4, it should say K_{64k}, not K_{32k}\n  - Emperical -> emperical in multiple places\n  - phrase transition -> phase transition, on page 8, bottom\n  - For to computational limitations -> Due to computational limitations,  on page 9, middle\n  - slope of curve -> slope of the curve, on page 9, top",
            "summary_of_the_review": "In summary, I\u2019m leaning towards accepting this paper because studying neural kernels through scaling laws is an important contribution that has been absent in the literature. The results are very interesting and further highlight the limitations of neural kernels on a stronger level. Especially the findings on the after-kernel and its limitations are very novel and unexpected and should be of interest to the ICLR community. The paper should be improved however, the results should be properly discussed in the end and some more background on scaling laws and their role in explaining generalization of a model class should be provided.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1452/Reviewer_8CKY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1452/Reviewer_8CKY"
        ]
    },
    {
        "id": "5jaSEX6Rja",
        "original": null,
        "number": 2,
        "cdate": 1666685790754,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666685790754,
        "tmdate": 1666685790754,
        "tddate": null,
        "forum": "KUP3ic8jdGo",
        "replyto": "KUP3ic8jdGo",
        "invitation": "ICLR.cc/2023/Conference/Paper1452/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper empirically evaluates how well the NTK and empirical NTK approach captures the performance of neural networks. For that, it analyses the scaling behavior of the kernels in comparison to the original network wrt. dataset size and network width. The paper finds that neither NTK nor empirical NTK can capture the scaling behavior of neural networks and shows that this result is robust to changes in learning parameters. Moreover, the paper shows that the after-kernel also does not capture the scaling behavior of neural networks. This indicates that the NTK framework has significant limitations in capturing the performance and learning dynamics of neural networks in practice.",
            "strength_and_weaknesses": "Strength:\n- interesting and relevant analysis\n- solid, sound, and quite comprehensive analysis\n- insightful results\n\nWeakness:\n- only evaluated for binary classification\n- source code of experiments not published",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written, results are novel, and the methodology and analysis is of high quality. The paper does provide a lot of details on the experimental setup. For reproducibility, however, it would have been great if the authors published their code as well.",
            "summary_of_the_review": "The paper presents an interesting empirical study on the abilities of the NTK framework to capture the performance and training dynamics of realistic neural networks. The experiments cover a range of approaches (NTK, empirical NTK, after-kernel) and analyze them from a wide range of perspectives. The results are insightful and relevant to the community. For future work it would be interesting to see whether these results hold for other learning tasks as well.\n\nSince for such an empirical study reproducibility is particularly important, I would ask the authors to publish their code as open source (for the reviewing process this can be done, e.g., via an anonymized github https://anonymous.4open.science/).\n\nDetailed comments:\n- the paper appears to use proper parenthetical citation in the intro, but then only use textual citation afterwards. I suggest using textual citations only when the citation is part of the sentence, as recommended e.g., by the APA style (cf. https://apastyle.apa.org/style-grammar-guidelines/citations/basic-principles/parenthetical-versus-narrative)",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1452/Reviewer_mmPh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1452/Reviewer_mmPh"
        ]
    },
    {
        "id": "6EOIGataTnv",
        "original": null,
        "number": 3,
        "cdate": 1666819569301,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666819569301,
        "tmdate": 1666819569301,
        "tddate": null,
        "forum": "KUP3ic8jdGo",
        "replyto": "KUP3ic8jdGo",
        "invitation": "ICLR.cc/2023/Conference/Paper1452/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper utilizes the scaling laws as the tool to try to show the gap between the infinite and empirical NTKs, and the neural networks. \n\nThe author compares the scaling of real networks to the scaling of NTKs in 4 ways using some experiments.\n- Data scaling of initial kernel\n- Width scaling of initial kernel\n- Data scaling of  after-kernel\n- Time scaling. \n\n",
            "strength_and_weaknesses": "Strength:\n- Compared the NTK method with the neural network in several different ways.\n- Comprehensive experiments to demonstrate the gap between NTK method and NN.\n\nWeaknesses:\n- The methodology is lack of innovation.\n- The author just piled up many experiment results, but made no effort to explain the reason either in intuitive or mathematical way.\n- The only appearance of NTK related formula are its definitions. I think there should be more analysis or discussion about the NTK itself.\n- This paper only provided one metrics, the test error, among different methods with different parameters. Some statistics such as the variance of multiple experiments may be helpful. \n- Only one network architecture was involved in this work.",
            "clarity,_quality,_novelty_and_reproducibility": "The main contribution of this paper is to demonstrate the empirical performance gap between NTK method and the neural network. But there have been many papers[1,2,3] that state the empirical and limiting NTK methods performs worse on empirical datasets than neural networks and have many limitations like poor sample complexity.\n\nBesides, the tool used by the this work is really simple, and there are few comparisons and analysis for the results except listing the experiment results that was somewhat expectable.\n\nHence I think the novelty and originality of this work are not good enough.\n\nThe clarity of the article is clear in general.\n\n[1] On Exact Computation with an Infinitely Wide Neural Net\n[2] On the Power and Limitations of Random Features for Understanding Neural Networks\n[3] What can linearized neural networks actually say about generalization?\n",
            "summary_of_the_review": "The novelty and originality of this work are not good enough both in the sense of methodology and conclusion. I think what we're most interested in is why neural networks perform better than NTK in many ways, instead of investigating and comparing the performance of different methods for some specific network architecture on a specific dataset, which is not that striking.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1452/Reviewer_fuCi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1452/Reviewer_fuCi"
        ]
    },
    {
        "id": "AvDAZNBhVxf",
        "original": null,
        "number": 4,
        "cdate": 1667000680635,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667000680635,
        "tmdate": 1667000680635,
        "tddate": null,
        "forum": "KUP3ic8jdGo",
        "replyto": "KUP3ic8jdGo",
        "invitation": "ICLR.cc/2023/Conference/Paper1452/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work studies the limitations of NTKs compared to finite neural networks properly trained with SGD. Through the lens of scaling laws, this paper shows that neural networks scale better (in terms of data scaling exponents) than both infinite and empirical NTK models. Additionally, it demonstrates some other properties, namely data scaling of after-kernel and time scaling for empirical NTKs.\n",
            "strength_and_weaknesses": "Strengths:\n- This work provides another empirical confirmation that finite neural networks are superior to their corresponding NTK models, from the viewpoint of scaling laws. \n- It demonstrates that even when trained with more samples, the empirical NTK obtained from a trained network still scales worse than the neural network.\n\n\nWeakness:\n- Scaling laws for neural networks and empirical NTKs were studied in the previous work, as cited in this paper. I also believe that infinite NTK models have been widely known to be inferior to finite neural networks.\n- I don\u2019t see much more values and insights in comparing data scaling exponent versus directly comparing test accuracy. \n- Since NTKs are not realistic neural networks, obviously NTK approaches would not help in understanding the neural network generalization.",
            "clarity,_quality,_novelty_and_reproducibility": "Some questions: \n\n1. I don\u2019t think this statement \u201crealistic settings where as the width of the neural network increases to very large values, the test performance of the network gets worse and approaches the performance of the infinite NTK, unlike existing results in literature which suggest that over-parameterization is always good\u201d is correct. Please cite these works.\n\n2. Can the authors elaborate on how this work helps understand \u201cthe extent to which understanding NTKs (empirical and infinite) can teach us about the success of neural networks\u201d?\n\n3. I find the introduction quite difficult to parse. It jumps right into discussing results without many important details about concepts such as \u201cscaling behavior\u201d and \u201cdata scaling component\u201d as well as the experimental setup.\n\n4. In both experiments, the tasks are binary classification. Why is MSE loss used instead of cross-entropy?\n",
            "summary_of_the_review": "See above.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1452/Reviewer_PzLb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1452/Reviewer_PzLb"
        ]
    }
]