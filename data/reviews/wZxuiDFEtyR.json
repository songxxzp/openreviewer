[
    {
        "id": "dGzQcKLrbc",
        "original": null,
        "number": 1,
        "cdate": 1666533256304,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666533256304,
        "tmdate": 1669262454467,
        "tddate": null,
        "forum": "wZxuiDFEtyR",
        "replyto": "wZxuiDFEtyR",
        "invitation": "ICLR.cc/2023/Conference/Paper2954/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims to alleviate the problem of catastrophic forgetting in continual object detection from the perspective of knowledge distillation (KD). Different from other methods that adopt complex KD supervision, such as feature, location and relation, the proposed method only relies on classification supervision and can also achieve promising results with the help of a combination of soft-hard label assignment and class-adaptive loss coefficient.",
            "strength_and_weaknesses": "1. The fusion of soft and hard labels has been explored in [1], what is the difference between the proposed \u201cHKS\u201d and the fusion method of [1]? Can the authors additionally compare the fusion method of [1] in the experiment part?\n\n2. Class-balanced loss is a common practice, such as the balanced CE loss in [2]. The idea behind the loss design of \"TRD\" seems not strong enough to be accepted.\n\n3. Although the authors have repeatedly emphasized that different detection models do not affect some metrics like \u201cRelGap\u201d and \u201cOmega\u201d. I still think that the authors should consider experiments based on the same model as other methods.\n\n4. I would like to know if the training settings of this paper is consistent with the settings of other papers used as comparisons. If consistent, some citations can be added to the part of experimental setup.\n\n5. In Figure 4, the continual learning curves of other methods are expected to be plotted for better comparison.\n\n6. The importance of \u201c$Loss_{diff}$\u201d term in \u201cTRD\u201d is not considered in ablations.\n\n7. Can the observed phenomenon be reproduced when experiments w.r.t. Fig. 6 being carried in a common dataset, such as MS-COCO, rather than the designed small dataset?\n\nThings to improve the paper that do not impact the score:\n\n1. The loss formulation for \u201cTRD\u201d seems to be redundant, for example, only one of \u201c$Loss_{new}^{\\*}$\u201d and \u201c$Loss_{old}^{\\*}$\u201d is required in Eq.10.\n\n2. Illustrations in the paper had better be vector graphs.\n\n3. In the caption of Table 2, an additional \u201c+10\u201d is missing after \u201cFive-Task scenario of 40+10+10+10\u201d.\n\n4. In Page 8, \u201cKnowledge Selection\u201d in \u201cThen we add Hybrid Knowledge Selection module\u2026\u2026\u201d should be \u201cKnowledge Representation\u201d for consistency.\n\n5. Some explanations in A.3, such as the instance-level discussions, seem to be unrelated to the main ideas of this paper and can be simply removed in my view.\n\n[1]: Kim, Kyungyul, et al. \"Self-knowledge distillation with progressive refinement of targets.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.\n\n[2]: Homayounfar, Namdar, et al. \"VideoClick: Video Object Segmentation with a Single Click.\" arXiv preprint arXiv:2101.06545 (2021).\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: 6/10\n\nQuality: 4/10\n\nNovelty: 4/10\n\nReproducibility: Unknown",
            "summary_of_the_review": "This paper should be rejected for the aforementioned reasons.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2954/Reviewer_jG8i"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2954/Reviewer_jG8i"
        ]
    },
    {
        "id": "IkAbiyrkOKQ",
        "original": null,
        "number": 2,
        "cdate": 1666623002397,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666623002397,
        "tmdate": 1666623002397,
        "tddate": null,
        "forum": "wZxuiDFEtyR",
        "replyto": "wZxuiDFEtyR",
        "invitation": "ICLR.cc/2023/Conference/Paper2954/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a knowledge distillation approach for continual object detection. The paper introduces two contributions: an image-level hybrid knowledge representation method, named HKR, that distill knowledge from the teacher by combining soft and hard pseudo-labels. Secondly, it proposes task regularized distilliation (TRD), that is a strategy to balance the knowledge distillation and classification loss, to prevent the student model to overfit the new tasks. \nOverall, the method performance are assessed on MS-COCO using the YOLOX architecture.",
            "strength_and_weaknesses": "Weaknesses:\n1. The TRD is not clear from the paper's description. First, Eq.7 and Eq.8 are not only always equal, but without other explanations, they are exactly the same equation and have the exact same effect on the network gradients, actually being a single loss with value Loss*_old + Loss*_new = 4*Loss_new*Loss_old / (Loss_old + Loss_new). Seen in this perspective, TRD does not bring any contribution but just computes the harmonic mean between the two losses. Furthermore, very few intuitions are provided for Eq. 9. Why should minimizing the quadratic difference between the old and new loss be beneficial for the training? Finally, the paper should experimentally demonstrate the benefits of adding Loss_diff through an ablation study.\n2. Mixing soft and hard pseudo-labeling is an interesting concept, however, to better exploit the model confidence, previous works propose to introduce a temperature value in the softmax operation to better transfer the model confidence. This is similar in spirit to the HKR and should be carefully demonstrated that the paper technique is superior. Furthermore, the paper introduces a threshold to decide whether use one-hot or soft-pseudo labeling. How is the threshold fixed? Is there any ablation study demonstrating the robustness of this choice? \n3. Regarding the experimental section, the paper reports experiments on MS-COCO. However, the standard and mainly used benchmark for continual object detection is the Pascal-VOC dataset but it is not reported. The paper should report results on this benchmark and should compare with all the state-of-the-art methods and not only a subset of them.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper's clarity may be improved. In particular, the presentation of the results is hard to follow and it is not always evident which is the setting for the tables. Moreover, the methodological section should be improved following the suggestions in the previous answer. \n",
            "summary_of_the_review": "The paper proposes a method for Continual Object Detection introducing two slight modifications to the standard knowledge distillation framework. Moreover, the paper lacks important ablation studies and comparisons with state-of-the-art results. \n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2954/Reviewer_rDxx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2954/Reviewer_rDxx"
        ]
    },
    {
        "id": "Z1ln1VPaRi",
        "original": null,
        "number": 3,
        "cdate": 1667116768015,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667116768015,
        "tmdate": 1667116768015,
        "tddate": null,
        "forum": "wZxuiDFEtyR",
        "replyto": "wZxuiDFEtyR",
        "invitation": "ICLR.cc/2023/Conference/Paper2954/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposed a knowledge selection module between soft and hard labels. It also proposed a task-based regularization distillation loss to balance multiple task losses.\n\nAs a new detector, YOLOX, is employed in this paper, the performance of this work is higher than previous ones. Extensive results on multiple datasets have been shown.",
            "strength_and_weaknesses": "++ The paper pays attention to the regularization of various tasks.\n++The experiment results on multiple settings demonstrate the effectiveness of the proposed detectors.\n\n-- The comparison happens between different detectors and training schemes, which is debatable. Although we should not be limited to old benchmarks for algorithm design, in order to make a fair comparison, experiments on the same detectors should first be shown. For example, the author could re-implement other continuous learning algorithms with the same detector, YOLOX. Or, the proposed method can be first applied to original benchmarks to make a fair comparison, and then a new powerful detector could be proposed for future comparison.\n\n--Ablation studies can not fully demonstrate the effectiveness of the proposed TRD method. If there are more task stages in the training set, will the proposed TRD be more powerful? Or it performs the same. It will be better if more weight-balancing algorithms could be compared with TRD.\n\n-- The representation is not that clear, including the terms and the figures. Details could be referred to in the next blank.\n\n-- For the 60+20 setting in Table1 and Table 4. The one-hot performance of the YOLOX already outperforms the previous work ERD. The improvement of the proposed two methods is not that significant.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Some suggestions which may make the paper clear:\n1. Do not use the abbreviation when the term appears the first time, e.g. LWF.\n2. Some terms are not well-aligned. e.g.: ilYOLOX and ILYOLOX\n3. Figure 1 is confusing. If the FPN feature Is not used, there is no need to add the arrows between them. Has location distillation been employed? What is the meaning of 'w/o' and 'wo'.  If they all mean without, there is no need to include them in the feature.",
            "summary_of_the_review": "I tend to reject the paper. The main contribution is to employ a new powerful detector YOLOX for continuous learning. This can not bring too many insights. I might improve my rating if the author could analysis some interesting insights related to their proposed methods.\n\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2954/Reviewer_i3PC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2954/Reviewer_i3PC"
        ]
    },
    {
        "id": "LabjY1UiAw6",
        "original": null,
        "number": 4,
        "cdate": 1667313740385,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667313740385,
        "tmdate": 1667313740385,
        "tddate": null,
        "forum": "wZxuiDFEtyR",
        "replyto": "wZxuiDFEtyR",
        "invitation": "ICLR.cc/2023/Conference/Paper2954/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper address the continual object detection problem, which is a very recent and challenging vision task. It proposes an image-level hybrid knowledge distillation method. The proposed method exhibits a noticeable gain in COCO 2017 dataset.",
            "strength_and_weaknesses": "**Strengths**\n- S1: In under explored COD task, on COCO dataset, the gain by the proposed method is noticeable (Table 1)\n\n**Weaknesses**\n- W1: The hybrid equation (Eq. (1)-(3)) is not well motivated. Why $ConfDiff$ should be defined in this manner? Why should the hybrid loss mix up the onehot and soft in this manner (necessariliy)?\n- W2: The eq (7) and (8) are the same. Explanation is required.\n- W3: No justification of the proposed evaluation metric of $F_b^1$ and $F_b^2$ in Eq. (11).\n- W4: Choice of hyperparameter also seems arbitrary or based on empirical results which may be specific to COCO dataset only. This limits the applicability of the proposed method to other datasets or tasks.",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity and Quality: the paper has multiple places to be fixed and clarified (see my comments in weakness section). \n- Novelty: the paper is technically marginal. Not an innovative idea, but rather an incremental improvement over some prior arts. \n- Reproducibility: cannot tell.",
            "summary_of_the_review": "Given that the paper has only merit in empirical results but poorly motivates the proposed method, the paper should be heavily revised and encouraged to resubmit.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2954/Reviewer_qEVh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2954/Reviewer_qEVh"
        ]
    }
]