[
    {
        "id": "IvrwNLvRolM",
        "original": null,
        "number": 1,
        "cdate": 1666565130975,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666565130975,
        "tmdate": 1666565130975,
        "tddate": null,
        "forum": "20GtJ6hIaPA",
        "replyto": "20GtJ6hIaPA",
        "invitation": "ICLR.cc/2023/Conference/Paper915/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to estimate articulated object pose on the category level in a self-supervised manner, by applying SE(3) equivariance on the part level. SE(3) equivariant features are extracted for each point from the input point cloud. The point cloud segmentation is conducted using slot attention, which divides the point cloud into articulated parts. Then the equivariant features of each segmented part are aggregated to estimate the part-level and object-level canonical space. Meanwhile, the kinematic chain and the joint parameters are regressed. The entire pipeline is trained using a shape reconstruction loss and a joint regularization loss, without manual annotation on object/part-level pose, kinematic structure, or joint parameters. Experiments show that the articulation structure and joint status emerge in such a self-supervised learning process and the estimation results are reported to be close to or better than the supervised counterpart.  ",
            "strength_and_weaknesses": "Strength\n1. It is very exciting to see that articulation emerges through the proposed self-supervised learning pipeline without any supervision. The system is complex, yet the results look very nice. Great work!\n2. The paper proposed to integrate pose and part awareness in the equivariant point convolution, which naturally handles different articulated poses and unifies the point cloud feature in a canonical coordinate frame. \n3. The results show that the proposed method achieves great performance, despite the system complexity and the simple self-supervised reconstruction loss. \n\nWeakness\n1. The paper is not well written, and the description of the proposed method is unclear. Different components are enumerated but a good overview of the method section is missing, for which I think Figure 3 in the appendix would be helpful. Specifically, what does \u201cper-rotation articulated pose hypotheses\u201d mean? What is the intuition behind the joint regularization loss? \n2. It is not clear what role SE(3)-equivariant operations play in the proposed method. A baseline replacing all equivariant operations with non-equivariant operations is missing, or an argument on why equivariant is necessary is needed. \n3. Experiments on real-world datasets are missing. (Figure 4 of ANCSH)\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Overall the writing is good, but I would suggest the authors revise more on the method section. Currently, it enumerates different components of the proposed system but lacks a good overview. \n\nQuality: The paper is of high quality with solid methods and experiments. \n\nNovelty: The proposed method is novel.  \n\nReproducibility: The source code is provided. It should be fully reproducible. \n",
            "summary_of_the_review": "The overall quality of the paper is very high. I\u2019m excited to see decent results given the complex system and simple self-supervised loss. The description of the method still needs some improvement, but I would still argue for acceptance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper915/Reviewer_GUmv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper915/Reviewer_GUmv"
        ]
    },
    {
        "id": "MBFQv22LHk",
        "original": null,
        "number": 2,
        "cdate": 1666689838189,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666689838189,
        "tmdate": 1666689838189,
        "tddate": null,
        "forum": "20GtJ6hIaPA",
        "replyto": "20GtJ6hIaPA",
        "invitation": "ICLR.cc/2023/Conference/Paper915/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors present a novel self-supervised strategy to reduce the heavy annotations needed for supervised learning methods for Category-level articulated object pose estimation. Specifically, they design a pose-aware equivariant point convolution operator to learn part-level SE(3)-equivariant features. Then, they propose a self-supervised framework to achieve the disentanglement of canonical shape, object structure, and articulated object poses. After that, the authors further predict articulated object poses as per-part rigid transformations describing how parts transform from their canonical part spaces to the camera space. Extensive experiments demonstrate the effectiveness of their method.",
            "strength_and_weaknesses": "Strength:\n1. The paper considers a challenging setting, where the human labels of the articulated object pose estimation task is not given. Category-level articulated object pose estimation is a very popular task. Getting more insight about each different method can be valuable to many people.\n2. The proposed method is novel and effective.\n3. The paper is well written and organized.\n4. Comprehensive experiments are conducted to support the effectiveness of the proposed method.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well written and organized with substantial experiments, clear contributions and high quality. The problem definition is clear, and the proposed method has distinct details. Also, the paper proposed approach seems to be novel and useful.",
            "summary_of_the_review": "The authors study a challenging problem and propose a novel approach. This paper is well-organized and easy to follow. In addition, the experimental results are promising.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper915/Reviewer_QLf2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper915/Reviewer_QLf2"
        ]
    },
    {
        "id": "vZdp5ANR9XJ",
        "original": null,
        "number": 3,
        "cdate": 1666690311651,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666690311651,
        "tmdate": 1666690311651,
        "tddate": null,
        "forum": "20GtJ6hIaPA",
        "replyto": "20GtJ6hIaPA",
        "invitation": "ICLR.cc/2023/Conference/Paper915/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper tackles the problem of category-level articulated object pose estimation, which requires articulated pose estimation of an unseen object from a known category. The authors propose a self-supervised method to reduce the need for annotations. This method factorizes the input point clouds into canonical shapes and part-level poses. By designing a network that learns a part-level equivariance property, the object shape could be reconstructed from the canonical parts. Experiments show that the proposed method can perform on par with or even better than existing methods that are supervised.\n",
            "strength_and_weaknesses": "Strengths:\n- The problem being studied is important and general enough to be applied in other scenarios.\n- The proposed method is intuitive in the sense that we as humans would perceive the canonical shapes of the object parts, not just the entire object.\n\nWeakness:\n- The presentation could be slightly improved. For example, some information in Figure 3 could be put into Figure 1 to help readers get a clearer picture.\n- From my understanding of the paper, the canonical shapes Z_i are instance-level concepts. Should we have a loss to make sure the shapes are aligned between different instance objects of the same category?\n- How are the number of parts controlled in the algorithm?\n- What is the stopping criterion for the iterations?",
            "clarity,_quality,_novelty_and_reproducibility": "The overall quality of the work is good. Although the originality is arguable (the overall framework has been proposed on object-level), the progress made by this paper is interesting to the community.",
            "summary_of_the_review": "Overall I am leaning towards accepting the paper, and I look forward to the authors' response to the above questions.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper915/Reviewer_gB2X"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper915/Reviewer_gB2X"
        ]
    },
    {
        "id": "8qb1y7Ml7p",
        "original": null,
        "number": 4,
        "cdate": 1666768560751,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666768560751,
        "tmdate": 1666768560751,
        "tddate": null,
        "forum": "20GtJ6hIaPA",
        "replyto": "20GtJ6hIaPA",
        "invitation": "ICLR.cc/2023/Conference/Paper915/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper is working on self-supervised articulated object pose estimation at a category level. The objective is to estimate the canonical shape, articulated structure, and transformation that assembles all canonical shapes together. The supervision comes from the overall reconstruction. Experiments are carried out on 7 categories from 3 datasets. Result shows that the proposed method outperforms or on par with baselines, some of which have external supervision.",
            "strength_and_weaknesses": "### Strengths\n- Self-supervision is a good idea when it comes to articulated and part-level tasks, where the annotation effort is high.\n- Many biases are carefully engineered to make sure the correct feature (invariant/equivariant) is used.\n- Based on the experimental results, the proposed self-supervision pipeline gets reasonable preformance.\n\n### Weaknesses / Questions\n- Section 3 is wordy and it would be helpful to re-organize.\n- In Part-assembling parameters prediction, only the translation is predicted. Is translation alone sufficient? It seems that this will make the reconstruction of canonical shape harder.\n- 'we first construct an adjacency confidence graph from object parts and then extract its maximum spanning tree consisting of the set of confident adjacency edges' How are the edge weights determined? How do you define the subset that is \u2018the set of confident adjacency edges\u2019?\n- 'The part proposal module groups N points in the input shape X into K parts' How is K determined? Does that affect the final performance?\n- Since the part segmentation learned by the proposed method comes from self-supervision, how can it be directly compared to the ICP and NPCS where there is ground truth part-segmentation? \n",
            "clarity,_quality,_novelty_and_reproducibility": "The overall idea is clear. But the description in Section 3 is a bit cluttered. It may be helpful to re-organize a bit to make it easier to read. For example, introduce the modules doing canonical shape estimation first, followed by the modules that align them to the observed point cloud. For each module. state clearly which point cloud it is trying to be aligned with, the canonical one or the observed one.\nThe work is of good quality. Code is provided so reproducibility looks good.",
            "summary_of_the_review": "The proposed method alleviates the need of data annotation for articulated object pose estimation. The result is fair given that it's self-supervised. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper915/Reviewer_sxak"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper915/Reviewer_sxak"
        ]
    }
]