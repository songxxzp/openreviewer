[
    {
        "id": "7u3Y-g5Tt0k",
        "original": null,
        "number": 1,
        "cdate": 1666556890971,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666556890971,
        "tmdate": 1666556890971,
        "tddate": null,
        "forum": "b8f2YGWebo",
        "replyto": "b8f2YGWebo",
        "invitation": "ICLR.cc/2023/Conference/Paper3176/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a new method for continual learning with convolutional neural networks for image classification which is based on a novelty detection mechanism using gradients (Sun et al. 2022) and a iterative training and adding of binary IDD/OOD classifiers as new classes arrive in the input stream.\nThe accuracy of OOD is further improved by a batch-mode estimation where a pre-filtering step determine the most pure OOD batches from the mixed IDD/OOD batches.\nThe experimental results show that this approach is able to achieve a high performance with a large number of classes.\n",
            "strength_and_weaknesses": "Strengths:\n- Original approach for continual learning\n\nWeaknesses:\n- Paper difficult to read\n- Overloaded presentation and results difficult to interpret\n- Scalability may be an issue",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is quite difficult to read due to the large amount of different mechanisms and concepts and notations (e.g. OOD becoming IID for different indices i etc.). The diagram in Fig. 1 certainly helps but maybe a second diagram (similar to Fig. 3) would be useful.\nMoreover, the presentation is quite overloaded due to reduced spaces and floating/double-column algorithms and figures. Probably some parts could be put in the appendices to improve the readability.\n\nMore specifically:\n- The approach uses a memory of IID samples to help the OOD. The memory budget is relatively high. This clearly helps to improve the OOD accuracy but is somewhat contrary to the continual learning paradigm (although the memory seems not to be used for further training and other methods also use a memory although at a smaller scale).\n- Figure 3 is not clear. Especially the legend denoting the classes and classifiers.\n- What is the impact of the number of classes for the initial classifier M_0 on the performance? Why can't we just start with 1 or 2 classes? Can this still considered continual learning?\n- The paper states that the method learns one class at a time. But in the experiments, for CIFAR-100 and Tiny-ImageNet, one task is composed of 10/20 classes. What is the reason? Is this done in the same way for the state-of-the-art methods?\n- It is not clear what Figure 4 represents. What do you mean by \"Single Head Accuracy\"? What is the overall accuracy after training N classes?\n- The scalability of the approach may be questionable, both in terms of memory and computing requirements. For each new task/class a small CNN for binary classification is added. The authors only state that the CNN produces little overhead compared to other existing CL methods. It is a 3-layer CNN with one FC but The exact architecture or number of parameters is not specified. For example for CIFAR-100, if one task would be one class, we would end up with (almost) 100 CNNs that would need to by executed sequentially for inference.\n",
            "summary_of_the_review": "Overall the paper proposes a novel and interesting approach for continual learning. But the presentation is lacking in some aspects making the paper difficult to read and understand.\nAlso the fact that a large memory buffer and an initial classifier is used for the first N classes may make the approach less suitable for real \"continual learning\" and potentially not comparable to the state of the art in the domain.\n\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3176/Reviewer_t1EJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3176/Reviewer_t1EJ"
        ]
    },
    {
        "id": "Bzc62CVzx0K",
        "original": null,
        "number": 2,
        "cdate": 1666582406021,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666582406021,
        "tmdate": 1666582406021,
        "tddate": null,
        "forum": "b8f2YGWebo",
        "replyto": "b8f2YGWebo",
        "invitation": "ICLR.cc/2023/Conference/Paper3176/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper focuses on unifying novelty detection and continual learning methods by extracting and learning from the OOD data and merging it with the IDD distribution. It uses a sequence of binary classifiers with a batch-mode technique to achieve this goal. The proposed method improves performance compared to prior CL methods on MNIST, CIFAR-10/100, and Tiny-ImageNet datasets. ",
            "strength_and_weaknesses": "## Originality and Quality\n### Strengths\n* The paper attempts to unify novelty detection and continual learning techniques, which are novel and might interest the community.\n* The experiments are conducted in an unsupervised setting, a comparatively more realistic setting for practical applications.\n## Weaknesses\n* The proposed framework resembles the existing task-free continual learning setting [1, 2], where it uses the gradient-based novelty detector to detect the OOD/new task examples. Thus, the novelty of the framework is limited. Further, it does not include a discussion and comparison with this setting. \n* While the paper focuses on the self-supervised CL setting, it does not compare or mention the prior methods [3, 4] that have investigated self-supervised continual learning.\n* The paper also needs a comparison with recent supervised CL methods [5, 6], which makes it challenging to evaluate the utility of the proposed method.\n* Many design choices and hyper-parameters need to be better ablated and justified. For example, the selection of the linear classifier architecture, learning rate, epochs used for training it (ensuring fair comparison here in comparison to without it), the effect of batch size in Figure 5, and its effect on performance.\n\n---\n\n## Clarity\nOverall, the algorithm and method are well-written and easy to follow. These suggestions should improve the paper's readability and overall presentation.\n* The details about the baselines should have been provided. Further, the information on the dataset split should be included when the datasets are described in the experiments section.\n* The notations in the algorithm can be improved significantly. For instance, use \\text when writing text in the algorithms, and use $\\text{argmin}, \\text{argmax}$, and $\\text{softmax}$ for better presentation.\n* The zoom in Figure 4a) highlights the proposed method instead of the comparison. In Figure 4c), the arrow disrupts the interpretation of other methods.\n* Many references do not reflect the conference proceedings bibliography.\n\n---\n\n## Reproducibility\n The code is not provided with the submission. Since the paper is empirical, it is necessary to provide the code to aid the reproducibility of future works.\n\n---\n## References\n[1] Aljundi et al, Task-Free Continual Learning. CVPR 2019.  \n[2] Wang et al. Improving Task-free Continual Learning by Distributionally Robust Memory Evolution. ICML 2022.  \n[3] Madaan et al. Representational Continuity for Unsupervised Continual Learning. ICLR 2022.  \n[4] Fini et al. Self-Supervised Models are Continual Learners. CVPR 2022.  \n[5] Buzzega et al. Dark Experience for General Continual Learning: a Strong, Simple Baseline. NeurIPS 2020.  \n[6] Saha et al. Gradient Projection Memory for Continual Learning. ICLR 2021.  ",
            "clarity,_quality,_novelty_and_reproducibility": "The review above elaborates on all these points in detail.",
            "summary_of_the_review": "The paper proposes an interesting combination of novelty detection and continual learning techniques; however, due to the missing discussion and comparison with prior task-free CL and self-supervised CL methods, it is difficult to position the work. Furthermore, the experimental evaluation is weak and lacks comparison with recent CL methods. Therefore, for these reasons, the paper is not ready for acceptance in its current form.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3176/Reviewer_wx2w"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3176/Reviewer_wx2w"
        ]
    },
    {
        "id": "i71idK94cq",
        "original": null,
        "number": 3,
        "cdate": 1666846943202,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666846943202,
        "tmdate": 1666846943202,
        "tddate": null,
        "forum": "b8f2YGWebo",
        "replyto": "b8f2YGWebo",
        "invitation": "ICLR.cc/2023/Conference/Paper3176/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a novelty detection based continual learning method. The scenario is practical, but the proposed method seems to be largely heuristic and the tested scenario is somewhat contrived. ",
            "strength_and_weaknesses": "Strength\n- The motivation of the paper is rooted in the practical scenario in which OOD data is continuously arriving while learning IDD data. \n- The paper attempted to merge the two method from ND and CL. \n- Gradient based novelty detection is adopted for the continual learning scenario. \n\nWeakness\n- The proposed method applies several heuristics, which is not clear whether it can be really generalized to settings other than the ones considered in the paper. For example, the threshold for novelty detection (Alg. 2) and threshold_OOD (in Alg.4) should play important roles on overall performance, but it is not clear how to choose them. If the thresholds were chosen to maximize the overall test performance, it violates the continual learning assumption. \n- CIFAR-10/100, MNIST seem to be too small/standard benchmarks, and testing on more enlarged / diverse datasets should be necessary, provided that one of the main concern of the paper is OOD novelty detection. The new class in CIFAR could be thought of as a novel data, but they might have still similar distribution. What happens when completely differently distributed data point comes? From this reasoning, I think the current form of the paper is somewhat limited for a publication.  ",
            "clarity,_quality,_novelty_and_reproducibility": "The description of the algorithm is not crystal clear (e.g., threshold choosing rule), and the main methods are also adopted from previous publications. ",
            "summary_of_the_review": "From above reasoning, I think the paper considers an important variation of ND + CL setting, but the overall scheme requires many heuristics and it is not clear how they will generalize to other data settings. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3176/Reviewer_PhMt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3176/Reviewer_PhMt"
        ]
    },
    {
        "id": "mjwd9i7q77",
        "original": null,
        "number": 4,
        "cdate": 1667206715103,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667206715103,
        "tmdate": 1667206715103,
        "tddate": null,
        "forum": "b8f2YGWebo",
        "replyto": "b8f2YGWebo",
        "invitation": "ICLR.cc/2023/Conference/Paper3176/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a new learner which can address novelty detection and continual learning jointly. Specifically, a batch-mode training and inference method is used to maximize the feature separation between OOD and IDD data samples. Experimental results on several continual learning benchmarks show the effectiveness of the proposed method.",
            "strength_and_weaknesses": "The motivation behind this work is convincing and interesting. Novelty detection and continual learning are really two related tasks in an open-world scenario, because most continual learning methods are limited under a closed world setting where all the incremental classes are fully labelled in a supervised learning fashion. However, there are still several concerns on this work:\n\n-- Although novelty detection is a binary classification task in general, one-class continual learning is not so practical in the applications. In contrast, the continual learner should be able to learn more classes during each incremental session. One potential solution is to consider the task of novel class discovery which learns to cluster the unlabeled samples from a set of classes. \n\n-- In this work, the authors discussed that the proposed method helps achieve the high accuracy in OOD detection and prediction in a\nscenario where IDDs and OODs are streaming into the system, such as videos and audios. However, there has no experiments on video and audio datasets. It lacks experiments to support the conclusion above.\n\n-- The proposed method is built based on existing novelty detection and continual learning methods. It needs more insightful clarifications on the new technical contributions in this work. Otherwise, the novelty would be limited.\n\n-- The training procedure might be expensive when reading the Algorithms in the paper. Apart from the accuracy performance, it is encouraged to consider the computational efficiency, especially for a continual learning model.\n \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper presents the implementation details, which may be helpful to reproduce the reported results in the paper.\nThe paper lacks empirical discussion about the new contributions proposed in this work.\nThe novelty is limited as most of the algorithms are built on top of existing ones.",
            "summary_of_the_review": "It is necessary to see the replies from the authors for the questions above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3176/Reviewer_e2pH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3176/Reviewer_e2pH"
        ]
    }
]