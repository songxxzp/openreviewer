[
    {
        "id": "D5-twjVksr",
        "original": null,
        "number": 1,
        "cdate": 1666367268571,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666367268571,
        "tmdate": 1666367268571,
        "tddate": null,
        "forum": "p7hvOJ6Gq0i",
        "replyto": "p7hvOJ6Gq0i",
        "invitation": "ICLR.cc/2023/Conference/Paper5007/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed to increased robustness to adversarial attacks of an off the shelf classifier by using a (of the shelf) diffusion model as a data augmentation preprocessing step.\n\n",
            "strength_and_weaknesses": "Strength:\n- simplicity of the framework\n- use of off the shelves diffusion model and classifiers",
            "clarity,_quality,_novelty_and_reproducibility": "Sections 1 and 2 are well written and could be understand by a reader unfamiliar with adversarial attacks/robustness (which is my case).\nI made the educated guest for section 3 and 4.\nIn section 5, experimentation are well described and reproducible.",
            "summary_of_the_review": "The framework is simple and clever.\nI could not verify the theoretical analysis part as it is out of my skills.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5007/Reviewer_pQBA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5007/Reviewer_pQBA"
        ]
    },
    {
        "id": "vyxTGeFBVVD",
        "original": null,
        "number": 2,
        "cdate": 1666624021892,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666624021892,
        "tmdate": 1669181982876,
        "tddate": null,
        "forum": "p7hvOJ6Gq0i",
        "replyto": "p7hvOJ6Gq0i",
        "invitation": "ICLR.cc/2023/Conference/Paper5007/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the conditions under which diffusion model can work well for purification of adversarially perturbed samples. A simple diffusion-based purification method named DensePure is proposed by using majority vote  and achieves higher certified accuracy in comparison with other method on CIFAR-10 and ImageNet. ",
            "strength_and_weaknesses": "Strengths:\n\nS1) Theoretical strength: This paper theoretically analyzes why and how diffusion-based purification model can enhance the adversarial robustness of a given classifier for the first time. The robust region of a sample (under a deterministic inverse purification process and a base classifier)  is characterized as the union of several convex sub-robust regions (indexed by samples with the same ground truth label). The newly characterized robust region may provide with a larger robust radius than other methods, which indicates better robustness. \n\nS2) Modelling/algorithmic strength:  The proposed DensePure performs consistently better than existing methods on ImageNet, with 7% improvement on average. \n\nWeaknesses:\n\nW1) Time complexity of DensePure: As it requires repeating the reverse process multiple times, DensePure is really time-consuming and this drawback may prevent it from further applications to large datasets.\n\nW2) Claimed but seemingly not well-supported contributions:  The authors claimed their first contributions as \"We prove that under constrained data density property, an adversarial example can be recovered back to the original clean sample with high probability via the reverse process of a diffusion model\". However, it seems not well-supported. The reason is as follows:\n\nLet $x_0$ be the clean sample and $x_a$ be its adversarially perturbed sample. \nTheorem 3.1 characterizes the distribution of inversed variable $\\hat{x}_0$ from a scaled adversary $x\\_{a,t}=\\sqrt{\\alpha}\\_t x\\_a$ as \n$$ \\mathbb{P}(\\hat{x}_0=x|\\hat{x}\\_t=x\\_{a,t}) \\propto p(x)\\cdot\\frac{1}{\\sqrt{(2\\pi\\sigma^2_t)^n}}\\textnormal{exp}\\big(\\frac{-\\|\\|x-x_a\\|\\|_2^2}{2\\sigma^2_t}\\big)$$ Letting $x=x_0$, we obtain\n$$ \\mathbb{P}(\\hat{x}_0=x_0|\\hat{x}\\_t=x\\_{a,t}) \\propto p(x_0)\\cdot\\frac{1}{\\sqrt{(2\\pi\\sigma^2_t)^n}}\\textnormal{exp}\\big(\\frac{-\\|\\|x_0-x_a\\|\\|_2^2}{2\\sigma^2_t}\\big)$$\n\nwhich seems unable to directly imply \"$\\mathbb{P}(\\hat{x}_0=x_0|\\hat{x}\\_t=x\\_{a,t})$ is high\" or \"$\\mathbb{P}(\\|\\|\\hat{x}_0-x_0\\|\\|\\le \\delta |\\hat{x}\\_t=x\\_{a,t})$ is high with a small $\\delta$\". \n\nSo, I failed to understand why \"under constrained data density property, an adversarial example can be recovered back to the original clean sample with high probability\". What is the \"constrained data density property\"? Can the authors provide upper bounds on $\\|\\|\\hat{x}_0-x_0\\|\\|$ to verify \"an adversarial example can be recovered back to the original clean sample with high probability\"? Did I miss something?\n\n----------------After rebuttal------------\nIn the rebuttal, both of my main concerns about \"Weakness 1: Time complexity of DensePure\" and \"Weakness 2: Claimed but seemingly not well-supported contributions\" have been well explained. Therefore, I decided to change my score from 6 to 8.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity score 7/10: In general, this paper is well-written. However, it still has typos. For example, \"the robust region for data region with ground-truth label under $\\mathbb{P} (\\cdot; t)$\" should be \"the robust region for data region with ground-truth label under $\\mathcal{P} (\\cdot; t)$\".\n\nQuality score 6/10: The theoretical results as well as the proposed DensePure are technically sound. However, the first claimed contribution seems not well supported. (See Weakness (W2) for more details. If I misunderstood this paper, the authors please point it out directly.) \n\nNovelty score 7/10: To the best of my knowledge, this paper theoretically analyzes why and how diffusion model performs well in purification by proposing three interesting and novel theorems. \n\nReproductivity score: 6/10: Although the  code is not shared, I think the details in the supplementary materials are sufficient for reproduction. \n",
            "summary_of_the_review": "In general, this paper provides novel theoretical results and an effective algorithm.  I suggest \"marginally above the acceptance threshold\" mainly due to \"Weakness (W2) Claimed but seemingly not well-supported contributions\". See Weakness (W2) for more details. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5007/Reviewer_HvUT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5007/Reviewer_HvUT"
        ]
    },
    {
        "id": "7Jxse1yNeB",
        "original": null,
        "number": 3,
        "cdate": 1666740782874,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666740782874,
        "tmdate": 1671433675519,
        "tddate": null,
        "forum": "p7hvOJ6Gq0i",
        "replyto": "p7hvOJ6Gq0i",
        "invitation": "ICLR.cc/2023/Conference/Paper5007/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new method, DensePure, designed to improve the certified robustness of a pretrained model (i.e. classifier). Specifically, DensePure uses the diffusion model to denoise the adversarial input to get multiple reversed samples, which are then passed through the off-the-shelf classifier, followed by majority voting of inferred labels to make the final prediction. The extensive experiments demonstrate the effectiveness of DensePure by evaluating its certified robustness given a standard model and show it is consistently better than existing methods on ImageNet.",
            "strength_and_weaknesses": "Quality/Clarity: the paper is well written and the techniques presented are easy to follow. Its motivation is clear to use diffusion model to denoise input to improve classification accuracy. On a technical level, I do not see much new contribution, where most equations are from diffusion model. For the BEiT in Table 2, do we use the same BEiT model for evaluation while comparing to Carlini 2022? We do not know its gain from the model itself or from the label voting. Also it is better to add experimental comparision w/o diffusion model.\n\nOriginality/significance: the idea is interesting, which uses diffusion model to improve data quality to improve classification performance. Another contribution is the label voting from multiple samples. However, both diffusion model and pretrained classifier are known, which makes DensePure an incremental approach. In addition, the diffusion model is only for Gaussian noise, which limit the application of this approach. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and easy to follow. The idea to include denoising step with diffusion model to improve classification performance is incremental. And more experiments are needed in Table 2 (see above for details)",
            "summary_of_the_review": "DensePure with the diffusion step can improve the robustness of prediction in the late stage. Overall, it is a good paper, I am ok if it is accepted.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5007/Reviewer_MqVZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5007/Reviewer_MqVZ"
        ]
    },
    {
        "id": "oE-ezvgNm7j",
        "original": null,
        "number": 4,
        "cdate": 1667071286472,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667071286472,
        "tmdate": 1667071286472,
        "tddate": null,
        "forum": "p7hvOJ6Gq0i",
        "replyto": "p7hvOJ6Gq0i",
        "invitation": "ICLR.cc/2023/Conference/Paper5007/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to solve the potential classification problem of the adversarial samples with the help of diffusion models. Specifically, the authors firstly give some analysis of the regions of the conditional generation. They claim that the conditionally generated samples will concentrate on the regions around the original adversarial sample. Then through majority voting, the proposed method can help find the correct labels. Experiments show that the proposed method does help improve the performance.",
            "strength_and_weaknesses": "Strength:\n- The paper gives some theoretical analysis about the conditional generation, which can help clarify the understanding of the problem.\n- The experiments show that the proposed method can improve the robust of the classification of adversarial inputs.\n\nWeakness:\n- In general, it seems that the classification of the adversarial samples is overkilled. To improve the robustness, the authors need to run the time-consuming diffusion models more than 10 times to get the conditional generation and then run the classifiers. It is unreasonable.\n- The theory part just includes some clarifications of common sense, it hard to get some novel ideas through the definitions or theorems. \n    - It is also unclear if it is proper to bound the complex data support  with hyper-balls. For example, in the data manifold, if the data labeled by 1 is supported in a 2-dimensional rectangular like region with large length and width ratio, can we use definition 3.2 or theorem 3.3 to measure the results?\n    - In theorem 3.4, KL divergence may not be a good method to measure the similarity of two distributions since it is not a distance. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is in general clear and easy to follow. And there seems no reproducibility problem. But the novelty is limited, and the theory cannot support the claim very well.\n",
            "summary_of_the_review": "For one thing, the paper help clarify the conditional distribution of the diffusion models, which may help the community; for another, the theoretical contribution seems limited and the proposed method overkills the adversarial classification problem in terms of resource and time.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5007/Reviewer_ChYc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5007/Reviewer_ChYc"
        ]
    }
]