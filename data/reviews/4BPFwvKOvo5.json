[
    {
        "id": "JPHe-2B6h0f",
        "original": null,
        "number": 1,
        "cdate": 1666456233613,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666456233613,
        "tmdate": 1668868863466,
        "tddate": null,
        "forum": "4BPFwvKOvo5",
        "replyto": "4BPFwvKOvo5",
        "invitation": "ICLR.cc/2023/Conference/Paper5015/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors investigate the problem of computing Nash equilibrium in (normal-form) two-team zero-sum games. The authors argue that the problem is CLS-hard, and give an algorithm guaranteeing local convergence. ",
            "strength_and_weaknesses": "The premise of the paper is interesting, but I have nontrivial concerns about the technical results. In particular:\n\n1. The CLS-hardness proof seems problematic. The game used in the reduction has $|S_i|$ actions for each of $n$ players, so the normal form of the game has representation size $n \\cdot \\prod_{i} |S_i|$, which could be exponential in the representation size of the congestion game instance. (Indeed, if we allowed ourselves an algorithm with that runtime, congestion games would become trivial, since one could directly compute the minimizer $\\boldsymbol s \\in \\bigtimes_i S_i$ of the potential!) If the goal is to show that Nash computation is hard for zero-sum team games in some *succinct* game representation, the authors should formally specify exactly what that succinct representation is and why it is interesting. This is my main concern about the paper.\n\n1. I am also unconvinced regarding the solution concept. In particular, in the GAN example (Sec 2.1.1) that seems like a fundamental motivating example in this paper, it seems that the correct solution concept should be TME. The natural goal is to find $G_p$ and $G_\\theta$ maximizing the discriminator loss, which is exactly what TME does. Also recall that the gap in solution between an arbitrary Nash and a TME can be arbitrarily bad in general. Especially given that the game is already highly nonconvex-nonconcave, I do not see the benefit of using Nash instead of TME here.\n\nMinor things not affecting my evaluation:\n\n1. The probability expressions after Eq (1) are wrong, since $\\zeta$ is a normal variable and therefore $\\zeta+p$ may not be in $[0, 1]$.\n\n1. Section 3.2: \"[Theorem 3.1] does not preclude the prospect of attaining algorithms (learning first-order methods) that converge to Nash equilibria.\" I understand that this because you draw the distinction between $\\text{poly}(1/\\epsilon)$ convergence to $\\epsilon$-Nash (which at this point in the paper could still be achieved learning methods) and $\\log(1/\\epsilon)$ convergence (which would be achieved by an exact method), correct? I think this is worth making explicit, and stating in any hardness result that you are showing hardness for the $\\log(1/\\epsilon)$ version of convergence.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and addresses a problem previously unsolved in the literature. ",
            "summary_of_the_review": "The paper presents new and interesting results on a problem of obvious interest. I have one major concern regarding the technical part of the paper. If it is addressed, I will raise my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5015/Reviewer_m964"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5015/Reviewer_m964"
        ]
    },
    {
        "id": "cC2QM3RIDz",
        "original": null,
        "number": 2,
        "cdate": 1666661214432,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666661214432,
        "tmdate": 1666661214432,
        "tddate": null,
        "forum": "4BPFwvKOvo5",
        "replyto": "4BPFwvKOvo5",
        "invitation": "ICLR.cc/2023/Conference/Paper5015/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies two-team zero-sum multiplayer games, where there are two teams of players, and team members in each team share the same payoff function. This paper focuses on computing a Nash equilibrium in these games, and they show that finding a Nash equilibrium in these two-team zero-sum games is CLS-hard based on the result of computing a Nash equilibrium in two-team zero-sum games. The result then will follow since computing Nash equilibria in congestion games is CLS-hard (Babichenko & Rubinstein 2021). They show that, with some specific settings, some gradient-based algorithms fail to converge (even locally) to a Nash equilibrium. They then provide a new version of gradient-based algorithms, which converges locally to Nash equilibria with some assumptions.",
            "strength_and_weaknesses": "This paper shows that finding a Nash equilibrium in these two-team zero-sum games is CLS-hard and theoretically proposes a new version of gradient-based algorithms, which converges locally to Nash equilibria with some assumptions. However, many things about this algorithm are unclear: the performance relative to existing algorithms, the reason (intuition) why it converges, whether the assumption is realistic in the real world, and how it connects to GAN.\nTwo-team zero-sum games (Schulman & Vazirani 2019b) have been studied. This paper aims to compute a Nash in these games. Schulman & Vazirani (2019b) proposed using a multilinear program to compute a maxmin equilibrium, which is a Nash equilibrium as well. In addition, there are other algorithms for computing a Nash equilibrium in general multiplayer games [1,2], which can solve two-team zero-sum games. Particularly, the proposed algorithm in this paper is not the first gradient-based algorithm guaranteeing to converge for Nash equilibrium in two-team zero-sum games because gradient-based algorithms with theoretical guarantee in general games were proposed [2], which can solve two-team zero-sum games. It is well-known that a gradient-based algorithm cannot guarantee convergence for Nash equilibrium. For convergence, some assumptions/operations should be added to the algorithm. Then, this paper needs to show that the proposed algorithm is better than existing algorithms in terms of theoretical results and/or experimental results.\n \n \n \nSection 3 studies the reason why some settings of gradient-based algorithms cannot converge in GMP. Unfortunately, they only show that their proposed algorithm KPV-GDA can converge in GMP but do not show the reason why their algorithm KPV-GDA can converge in GMP. That is, it is unclear why KP-GDA converges in GMP. Understanding the reason why the proposed algorithm KPV-GDA converges in MPG is also important. \n \n \nTheorems 3.4 and 3.5 are the main results of this paper about the convergence of the proposed algorithm. However, both theorems assume that the matrix of Jacobian related to the Nash equilibrium is invertible. It is unclear if this assumption is realistic. Particularly, it is not easy for us to know the property of a Nash equilibrium before we can obtain it. That is, before we obtain a Nash equilibrium by using the proposed algorithm, we usually do not know its property. Then this requirement seems unrealistic.\n \nIn section 2.1 and Section 4, this paper uses GAN to motivate the study of two-team zero-sum games. However, it is unclear how to model that GAN by using the proposed two-team game. For example, it is unclear what a pure strategy in a Team-WGAN is, and it is unclear what the utility function in a Team-WGAN. I believe continuous games of GAN and discrete games of two-team games have different properties.\n \n\n \n\n\n[1] Berg, K. and Sandholm, T., 2017, February. Exclusion method for finding Nash equilibrium in multiplayer games. In AAAI.\n\n[2] Gemp, I., Savani, R., Lanctot, M., Bachrach, Y., Anthony, T., Everett, R., Tacchetti, A., Eccles, T. and Kram\u00e1r, J., 2022. Sample-based Approximation of Nash in Large Many-Player Games via Gradient Descent.  In AAMAS\n\nMinor:\n\n\u2018lFurthermore\u2019 -> Furthermore\n\n\u2018a NE\u2019 -> an NE\n",
            "clarity,_quality,_novelty_and_reproducibility": "The above.",
            "summary_of_the_review": "This paper shows that finding a Nash equilibrium in these two-team zero-sum games is CLS-hard and theoretically proposes a new version of gradient-based algorithms, which converges locally to Nash equilibria with some assumptions. However, many things about this algorithm are unclear: the performance relative to existing algorithms, the reason (intuition) why it converges, whether the assumption is realistic in the real world, and how it connects to GAN.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5015/Reviewer_1M7d"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5015/Reviewer_1M7d"
        ]
    },
    {
        "id": "1XMCDIBTzDG",
        "original": null,
        "number": 3,
        "cdate": 1666776066534,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666776066534,
        "tmdate": 1666776066534,
        "tddate": null,
        "forum": "4BPFwvKOvo5",
        "replyto": "4BPFwvKOvo5",
        "invitation": "ICLR.cc/2023/Conference/Paper5015/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the computation of Nash Equilibrium for two-team zero-sum games, and\n\n1. proves that computing an approximate (possibly mixed) NE in two-team zero-sum games is CLS-hard.\n\n2. gives a simple family of two-team zero-sum games where some common online, first-order min-max optimization methods (GDA, OGDA, OMWU, EG) fail to converge to NE (regardless of convergence time) except for a measure zero set of initial conditions.\n\n3. gives a new first-order method (KPV-GDA) to stabilize the dynamics around unstable Nash Equilibria in certain class of well-behaved games and converge to them.\n\n4. argues that the study of two-team zero-sum games applies to multi-agent GANs, which performs better than a single-agent GAN on learning a mixture of 8 Gaussians in an experiment.",
            "strength_and_weaknesses": "What I like:\n* The reduction to show CLS-hardness is very simple.\n* The counter example (Generalized Matching Pennies) showing non-convergence is very simple and intuitive.\n* The motivation for the new first-order method (KPV_GDA) to stabilize Nash Equilibria in certain general class of well-behaved games is also intuitive.\n\nWhat might be improved:\n* The argument connecting (the results in this paper concerning) two-team zero-sum games with (the real world performance of) multi-agent GANs, while interesting, may need stronger evidence.",
            "clarity,_quality,_novelty_and_reproducibility": "The introduction is well written, covering an extensive literature on game theory (different solution concepts and how they compare, importance of Nash Equilibrium in applications such as security, networks, and evolution). The technical exposition is also well written, if somewhat a bit too brief.\n\nAll theoretical results are new, and some of them require simple, but slightly new perspectives.\n\nThe simple experiments are described in enough details to reproduce.",
            "summary_of_the_review": "The paper contributes to the study of two-team zero-sum games, and this reader recommends acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5015/Reviewer_fCR8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5015/Reviewer_fCR8"
        ]
    }
]