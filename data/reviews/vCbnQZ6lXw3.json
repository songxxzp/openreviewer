[
    {
        "id": "PWgQUn4MUG",
        "original": null,
        "number": 1,
        "cdate": 1666220186875,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666220186875,
        "tmdate": 1666220228489,
        "tddate": null,
        "forum": "vCbnQZ6lXw3",
        "replyto": "vCbnQZ6lXw3",
        "invitation": "ICLR.cc/2023/Conference/Paper1216/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This article considers Bayesian inference with fully connected networks of depth L and width n in the infinite width limit. In order to have non-trivial feature learning at infinite width, the authors propose scaling the MSE negative log-likelihood by a factor proportional to the width, causing it to be appear at the same order in n relative to the prior (written  in terms of the feature-feature covariances $G^\\ell$ of layers ($\\ell = 1,\u2026,L$). The authors explicitly find the MAP solution for deep linear networks and provide some numerical investigation.\n\nWhile the paper is clearly written, the authors don\u2019t seem to realize that the likelihood re-scaling they propose is precisely what is called the mean-field scaling of neural networks in which the variance of final layer weights is rescaled by an extra factor or 1 / n (see below for references). In the language of this article, this precisely corresponds to rescaling the prior $P( Y | G^L )$ by a factor of n since it multiplies the variance of Y given $G^L$ by an additional factor of 1 / n. Given the significant overlap with existing work, I believe it is not ready to be published.",
            "strength_and_weaknesses": "Strengths:\n- The paper is well-written\n- Understanding feature learning in Bayesian inference in mean-field networks is certainly an interesting topic\n- The article points out a nice closed form solution for the MAP value of the feature-feature covariances for deep linear networks in the mean-field regime. I believe this point is novel.\n\nWeaknesses:\n- The main contribution of this article has been considered in many prior articles on mean-field neural networks, though it is phrased somewhat differently (in terms of rescaling the likelihood instead of the weight variance in the final layer). Below are a few representative references. The article would be significantly strengthened by connecting to this literature. \n\nYang, Greg, and Edward J. Hu. \"Tensor programs iv: Feature learning in infinite-width neural networks.\" International Conference on Machine Learning. PMLR, 2021.\n\nSirignano, Justin, and Konstantinos Spiliopoulos. \"Mean field analysis of neural networks: A central limit theorem.\" Stochastic Processes and their Applications 130.3 (2020): 1820-1852.\n\nSirignano, Justin, and Konstantinos Spiliopoulos. \"Mean field analysis of neural networks: A law of large numbers.\" SIAM Journal on Applied Mathematics 80.2 (2020): 725-752.\n\nMei, Song, Andrea Montanari, and Phan-Minh Nguyen. \"A mean field view of the landscape of two-layer neural networks.\" Proceedings of the National Academy of Sciences 115.33 (2018): E7665-E7671.\n\nNguyen, Phan-Minh, and Huy Tuan Pham. \"A rigorous framework for the mean field limit of multilayer neural networks.\" arXiv preprint arXiv:2001.11443 (2020).",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written. However, as explained above, the main contribution of this article is not original.",
            "summary_of_the_review": "This article proposes in a Bayesian framework a well-known modification of neural networks, the so-called mean field regime, that makes them capable of learning features at infinite width and any fixed depth. The article also provides an explicit form of the MAP feature-feature covariances for deep linear networks. While a more detailed understanding of Bayesian interference in the mean-field regime is certainly of interest, the article is not sufficiently novel to be published in its current form. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1216/Reviewer_SEBy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1216/Reviewer_SEBy"
        ]
    },
    {
        "id": "OvCprBc_e5A",
        "original": null,
        "number": 2,
        "cdate": 1666620505678,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666620505678,
        "tmdate": 1666620505678,
        "tddate": null,
        "forum": "vCbnQZ6lXw3",
        "replyto": "vCbnQZ6lXw3",
        "invitation": "ICLR.cc/2023/Conference/Paper1216/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a Bayesian learning algorithm that preserves the representation-learning ability of neural networks in the fixed-depth-infinite-width limit. This result parallels that of the maximal-update parametrization [Yang & Hu (2020)], which attains the similar limit in the gradient-descent setup (in contrast to the Bayesian setup discussed herein). In order to construct such a limit, the paper proposes to amplify the effect of target labels on the posterior representation by replicating labels N times, where N is a typical width of hidden layers. The proposed algorithm is applied to several tasks. ",
            "strength_and_weaknesses": "As stated in the \"Summary Of The Paper\" section, this paper contributes a nontrivial idea (strength) -- the construction of the Bayesian representation learning limit through label replications -- albeit with the overstated claim on the theoretical tractability (weakness).\n\nSpecifically, the paper claims that the proposed Bayesian algorithm is \"extremely theoretically tractable.\" While it is easy to state the optimization objective, its theoretical analysis doesn't seem to be tractable for general deep neural networks (which is not surprising as the maximal-update parametrization is also hard to theoretically analyze after some gradient-descent iterations). In fact, as explained in the paper itself, to solve for the maximum of the objective in Eq.(17)/Eq.(21), in general one must resort to numerical/variational methods.\n\nSimilarly (but in an opposite direction), the large body of work listed in the second paragraph of Section 2 -- which utilizes perturbation theory to analyze large-but-finite-width neural networks -- is dismissed as \"highly complex.\" However, in these perturbative approaches, one can systematically understand the behavior of networks order by order in 1/width, and get layer-by-layer recursive equations -- much like that for the NNGP in the infinite-width limit -- that determine the depth dependences of these perturbative corrections. This is theoretically analyzable -- hence such a large body of work exists -- and dismissing them as \"highly complex\" seems misleading (especially because the paper uses such a claim to further illustrate the simplicity of the proposed representation learning limit).\n\nAll those said, the proposed Bayesian algorithm remains nontrivial and interesting. But these claims on the theoretical (in)tractability should be clarified/softened/dropped, unless there is a substantive counter argument.\n\n\nMinor comments:\n\nA. It is preferable _not_ to use subjective adjectives/adverbs. For instance:\n\n(A-i) \"elegant objective\" in the abstract: it is not clear what makes Eqs.(17)/(21) \"elegant.\"\n\n(A-ii) \"strong regulariser\" in 3.4: it is not clear what makes it \"strong\" (in fact, the relative width ratio, \\nu_{\\ell}=N_{\\ell}/N, in front of each KL-divergence term controls its strength, so the relative strength of the regularizer can be adjusted).\n\n(A-iii) \"extremely theoretically tractable\" in the abstract: \"extremely\" is subjective (even if we temporarily forget the previous major objection to this claim).\n\nB. A missing period for \"which we call the deep kernel machine (DKM) Here\" in 3.7. (Also, the terminology/abbreviation is already introduced long before and used throughout the paper, so this phrasing doesn't make sense here.)\n\nC. In the first paragraph, for \"(NNGP Matthews et al., 2018; Novak et al., 2018)\" it is probably more standard to cite [Lee et al., 2017] as well (or in place of [Novak et al., 2018]). (I am not an author of these papers.)\n\nD. It may be appropriate to also cite [Dyer and Gur-Ari, arXiv:1909.11304] and [Hanin and Nica, arXiv:1909.05989] in the second paragraph of Section 2. (I am not an author of these papers.)\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed modification to the Bayesian algorithm is novel/original. However, the paper was not written in a clear manner. Here are a few suggestions (though far from exhaustive).\n\nI. On the core trick: the core trick of (noticing diminishing effects of target labels on posterior hidden-layer representations and then amplifying them by) replicating labels can be stated simply, yet it is not clear until a reader gets to the paragraph surrounding Eq.(16) buried in Sec.3.3. It would be beneficial/motivating to have it explained up front in Section 1.\n\nII. On large datasets: since the paper makes a claim about scalability of the algorithm to large datasets, it would be beneficial to (i) have a discussion of how the computational time scales with the training dataset size and (ii) to detail how many training samples there are in each training dataset used in the paper.",
            "summary_of_the_review": "Overall, the recommendation for \"marginal acceptance\" is based on the novelty and possible significance of the proposed algorithm on deep learning theory. The weakness should be addressed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1216/Reviewer_gVJs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1216/Reviewer_gVJs"
        ]
    },
    {
        "id": "_JETf7REDgU",
        "original": null,
        "number": 3,
        "cdate": 1667233252979,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667233252979,
        "tmdate": 1669048812286,
        "tddate": null,
        "forum": "vCbnQZ6lXw3",
        "replyto": "vCbnQZ6lXw3",
        "invitation": "ICLR.cc/2023/Conference/Paper1216/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Large-width networks converge to GPs with fixed/ unlearnable kernels, making the networks unable to perform representation learning. In this paper, the authors proposed a simple recipe to allow for representation learning: making the logit layer as wide as the hidden layers and replicating the labels accordingly. The authors argue that this approach allows the kernel to evolve and possible learning a representation. The authors also support their claims using synthetical dataset experiments and UCI datasets. \n",
            "strength_and_weaknesses": "# Strength.\n1. The paper proposed simple and interesting ideas that allow feature learning in the infinite-width network, which is worth further exploration. \n2. Some experiments from the paper show non-Gaussian behavior of the learned representation that differs from the NNGP limit.  \n\n# Weakness\n\n1. The notations and terminologies are confusing, which makes it hard to parse the paper. \n2. Missing key empirical comparison (vs. NNGP/NTK) for representation learning. I would like to see a comparison using CIFAR10. \n3. Several strong claims that require further justifications. ",
            "clarity,_quality,_novelty_and_reproducibility": "1. Many strong claims from the paper are unconvincing. \n\n- Using `**the** representation learning limit` is not proper; there can be many of them, and the proposed approach is just one of many. \n\n - I can't agree with the claim that the approach is `extremely theoretically tractable.` (in the abstract) and it is misleading. Unlike NNGP, the solution can be written analytically as an exact closed-form formula of the input data. The approach in the paper is not analytically tractable (except possibly in the linear network setting) and requires approximation methods. Cited from the paper, \"In practice, the true posteriors required to evaluate Eq. (21) are intractable \".  \n\n- \"We show that DKMs can be scaled to large datasets using inducing point methods from the Gaussian process literature, and we show that DKMs exhibit superior performance to other kernel-based approaches\" (from the abstract.) This is certainly an overclaim. The largest dataset used in UCI, could not justify *superior performance* and scalability to *large datasets*. Again, I expect at least experimental results on CIFAR10 if not more complicated. \n\n- I would like to re-emphasize that the dataset used here (UCI) is too simple to capture *representation learning*. I would expect a comparison using CIFAR-10 against benchmark results for NNGP kernels; see Lee et al. finite vs infinite (https://arxiv.org/abs/2007.15801); neural kernel without tangents (Shankar, https://arxiv.org/abs/2003.02237). I am also interested in the visualization of the learned representation using the image dataset. \n\n\n2. Notations and terminologies. \n\n- The definition of DNNs is confusing in Sec 3. Do you mean a fully-connected network with trainable parameters that are optimized using gradient descent? This is what DNNs mean for most people in ML. In addition, what does that mean to marginalize the weights in each layer in eq (2)? Do you mean sequentially? Can you verbally explain the difference between (3a) and (3b)? \n\n-  DGP \"Deep Gaussian Processes\" (by Andreas C. Damianou, Neil D. Lawrence, not cited in the paper) is a standard framework. Is it the same thing used in the paper? If so, why not cite the above (or related ) paper? \n\n-  Notations in equation (11) are confusing. What are $G_l/G_{l-1}$ here? Don't they depend on $N$ ? Or are they some *infinite/deterministic* objects that don't rely on $N$, and you overload the notations? Same for equations (12), etc. In addition, Eq (13) seems to be a result in \"Wide Bayesian neural networks have a simple weight posterior: theory and accelerated sampling\" by Hron et al. Please clarify. \n\n\n\n3. Others. \n- First citation in the intro. Please cite \"Radford M. Neal. Priors for infinite networks,\" which is the first NNGP (one-hidden layer) paper. \"Lee et al Deep Neural Networks as Gaussian Processes\"  should also be added. \n",
            "summary_of_the_review": "Update: \nI thank the authors for the clarification/updates of several notations/terminologies. I like the idea from the paper, a Bayesian prospective of feature learning. I have increased my score accordingly. However, there are still a lot of room for improvement and several open questions. To name some,  \n\n1. Even though this is a theory paper, authors should not shy away from more empirical work. Even doing a small scale experiments on Cifar10 (baseline against kernel) could really helpful to both practitioners and theorists. \n\n2. Authors should have more detailed discussion/comparison between the meanfield/feature learning limit of neural networks and the current proposed Bayesian framework, both theoretically and empirically. E.g., baselining performance (bayesian feature learning vs NN feature learning), are they learning similar features, etc. \n\n\n---------------------------------\n\nOverall, I think the idea from the paper is interesting and worth further exploration. However, I also find the paper hard to parse due to clarity issues from notations and terminology, and the theoretical and empirical results from the paper do not support the strong claims from the paper.    \n\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1216/Reviewer_JjRZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1216/Reviewer_JjRZ"
        ]
    }
]