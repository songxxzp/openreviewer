[
    {
        "id": "2g4rBtdGxsO",
        "original": null,
        "number": 1,
        "cdate": 1666112029989,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666112029989,
        "tmdate": 1666112029989,
        "tddate": null,
        "forum": "a-bD9-0ycs0",
        "replyto": "a-bD9-0ycs0",
        "invitation": "ICLR.cc/2023/Conference/Paper6522/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors propose a latent ODE model for irregularly sampled timeseries forecasting, where the dynamics in the latent space evolve according to a linear neural ODE. This is enabled by (1) a nonlinear encoder/decoder pair that maps the dynamics between the latent and observed space, and (2) a neural Kalman-like filter operating in the observation space, which updates the states given an observation. By taking the latent space to be higher dimensional than the observation space, the authors justify the use of a linear ODE, reflecting ideas in Koopman theory. The resulting model satisfies a list of desiderata given by the authors and performs well on some benchmark datasets.",
            "strength_and_weaknesses": "__Strengths:__\n- The proposed model seems to preform quite well on the benchmark datasets, outperforming the state-of-the art in the climate example by a large margin. Though this may simply be due to the higher dimensionality of the latent space used here compared to that in the baselines (perhaps the baselines may perform just as well if they used hidden states of similar size?), the experiments at least demonstrate that the linear dynamics assumption in the latent space is not so limiting.\n\n- The use of a Kalman filter-inspired update rule is nice, enabling some level of interpretability (at least in the linear, shallow case) as opposed to the RNN-type updates used in the other works. The theoretical benefits gained through this choice is also an advantage.\n\n__Weaknesses:__\n- Uncertainty quantification does not seem possible within the proposed framework, which may be useful in several applications. Other models such as ODE-VAE and GRU-ODE-Bayes has an advantage in this regard.\n\n- The experiments section feels a little rushed and lacking in quality. For example,\n   - One of the reported benefits of LinODEnet is the computational efficiency due to the use of matrix exponentials. A comparison of compute time between the different models would have been desirable to verify this claim. This claimed efficiency is not so clear since there much be some tradeoff between the efficiency gain by linearity vs the need to lift the dynamics to a higher dimension.\n   - A novelty of this paper is the introduction of a neural Kalman filter, which distinguishes itself from RNN-style updates. An ablation study to show the efficacy of a self-consistent filter would have been desirable, e.g. by using the same latent dynamical model and encoder/decoder but with different filters.\n   - Likewise, some experiments showcasing the performance of the learned filter would have been a great addition, to demonstrate how useful it can be in online settings to perform long-term predictions. For example, including a plot of the filtered trajectory or showing the improvements in e.g. MSE after applying the update step will suffice.\n\n- The writing in some places is not very clear and the presentation can be improved (more details below).\n",
            "clarity,_quality,_novelty_and_reproducibility": "__Clarity + Quality:__\n- There is no mention in the body about the \"global existence\" property highlighted in table 2.\n- Some of the notations used in this paper are non-standard and confusing, at least to me:\n   - What does $\\psi(K)$ mean in Algorithm 2? Is it meant to be $K(\\psi)$? i.e. matrix a $K$ parameterised by $\\psi$.\n   - The star $^*$ notation (for example, $\\mathbb{R}^*$) used in section 3 is confusing. Please explain what this means.\n- Please clarify which function is required to have model stability (definition 1). Is it just required for the filter component?\n- Notation for the filter is inconsistent. For example, in definition 3, a lower case $f$ is used, whereas in Definition 4, an upper case $F$ is used. Note that the vector field of an ODE is also denoted $f$ in this paper, further adding to the confusion.\n- The labels in Figure 3 are too small. Please make it bigger.\n- What is the `kernel matrix' mentioned in \u00a76.2?\n- Some comments on the Appendix:\n   - In the proof of self-consistency (section B), please include a line about why the (stacked) filter is idempotent.\n   - Section B.1 appears to be incomplete.\n   - I am not sure if the argument in section B.2 makes sense. In particular, why do you take $R=\\Sigma$? This is generally not true in Kalman filters. I would say the claim \"the choice $\\alpha=1/2$ corresponds to the Kalman filter\" in Lemma 3 is misleading, as this would imply that the two are equivalent in general, although the proof seems to suggest that the correspondence only holds for a very special case of KF.\n\n__Novelty:__\nI believe that the ideas introduced in this work are original, in particular the use of linear dynamics in the latent and the Kalman-style update cells, although the technical aspects are not new.\n\n__Reproducibility:__\nSufficient information on the experiments is provided in the appendix for reproducibility, along with dataset and code.\n",
            "summary_of_the_review": "The paper presents a model that, while technically not quite advanced, is original and performs well on several benchmark tasks, proving its capability for use in time series modelling. The paper however suffers from several presentation issues and a weak experiments section.\nIn light of this, I recommend a light reject, with the possibility of an acceptance provided some of these issues are addressed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6522/Reviewer_kNhy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6522/Reviewer_kNhy"
        ]
    },
    {
        "id": "g7cHVa9jvp",
        "original": null,
        "number": 2,
        "cdate": 1666544373436,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666544373436,
        "tmdate": 1666544373436,
        "tddate": null,
        "forum": "a-bD9-0ycs0",
        "replyto": "a-bD9-0ycs0",
        "invitation": "ICLR.cc/2023/Conference/Paper6522/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a Neural ODE model that implements a filtering approach for time series. In contrast to previous works, this approach relies on mapping the observations on a linear hidden process. The linearity of the underlying ODE allows fast integration and enforcing several desirable properties such as  consistency and forward stability. The authors show improved forecasting performance on MIMIC and weather forecast datasets. ",
            "strength_and_weaknesses": "## Strengths\n\n- The problem tackled in this paper is very important. Namely, how do we build better latent state space models with irregular and missing data.\n- The idea of using a linear hidden ODE is nice as it theoretically can express any complex dynamical system, with a sufficiently large hidden process and expressive observation / embedding function.\n- The desiderata and objectives for a desireable time series model are clearly stated \n- The figure 1 regarding the abstraction for a latent space model is very clear and effective\n\n## Weaknesses\n### Notation\nAn important improvement consits in improving the notation. \n- In the problem formulation, it's not clear what $P:\\mid t \\mid - F$ actually means. \n- Introducing a mask instead of \"not-missing\" would be appreciated too.\n- More importantly, the authors seem to mix $z$ and $x$ over the whole manuscript which makes it unecessarily hard to read. For instance, in Section 4, it seems clear that $z$ stands for the latent process while $x$ is the observation. Now, in section 5, $x$ is now used for the latent space ! (And in Algorithm 2, $z$ is used again). $\\hat{x}$ is also sometimes used for the latent space (equatiions 9).\n\nThis is a very important point that would greatly benefit the readibility of the paper.\n\n### Lemma 2 \n\nFirst, it seems that Lemma 2 lacks a proof. What is more, you mention backward stability in D3. How does the matrix exponential fares in terms of differentiability ? I would assume it's not super stable either ?\n\nAlso, if your hidden process is forward stable, what does it say about your whole model ? I guess it depends on the output function that you are choosing. So in a sense, you're not ensuring forward stability of your whole state space model.\n\n### Output function\n\nIf I understand correctly, your encoding/update function (from observation space to hidden space) is given by Equation 9. What is missing in your manuscript is a discussion of the output function and how it is linked to the update function. \n\n### Expressivity\n\nOne of the important point of that paper is that the desiderata should be achieved without trading for expressivity. In the introduction, the authors hint at the fact that this model can be as expressive as non-linear latent dynamcis models. However, this statement does not get enough focus in the paper. Specifically, I believe an in-depth discussion of the expressivity of the presenteed model should be present in the paper.\n\n### Experiments\n\n- Regarding the non-linear vs linear Kalman cell. It would be nice to have an experiment comparing both approaches.\n\n- The w/hidden version of your model seems to suggest that your latent space and your observation space are the same  (Remark 1)? This seems contradictory with your intro that says that the \"observations are nonlinearly mapped into a latent space\".\n\n- In general, the experimental section is not very convincing. Indeed, despite the nice layout of the desiderata you need for a good latent state space model, you don't use this blueprint in the experimental section. I believe it would be more impactful to showcase how your model improves upon these metrics. \n\n- It's not clear what \"global existence\" mean in Table 2.\n\n- Section 6.2 comes a bit out of the blue and lacks context. So it's hard to appreciate its value in the current state of the paper.\n\n### Minor\n\n- end of page 7, I think \"git adLinODEnet\" is probably a typo.",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\n\nThe idea is clear but the notations are inconsistent which makes the overall clarity of the paper low. Additional details are also needed regarding the output and update function of the model.\n\n## Quality\n\nThe paper lacks key analysis such as expressivity of the resulting function as well as key experments such as a head to head comparison with GRU-D (for instance on synthetic data).\n\n## Novelty\n\nThe paper builds upon a lot of existing work and positions itself very close to GRU-D but with the ability to allows for complex eigenvalues in the state update matrix. The idea explored in itself is novel and will eventually provide a solid paper.\n\n## Reproducibility\n\nThe paper is currently not reproducible from the manuscript alone. Indeed, some keys components are still required for full reproducibility (such as the output function). The code has been packaged into a python module.",
            "summary_of_the_review": "This paper addresses an important problem but currently fails to provide an in-depth investigation of the proposed approach. The experimental section is not convincing and does not reflect the aims of the paper (the 5 desideratas). The notations are inconsistent, making the overall presentation unclear.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I have not ethical concern.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6522/Reviewer_x2ff"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6522/Reviewer_x2ff"
        ]
    },
    {
        "id": "k6eg5N97ls",
        "original": null,
        "number": 3,
        "cdate": 1666646742860,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666646742860,
        "tmdate": 1670256192434,
        "tddate": null,
        "forum": "a-bD9-0ycs0",
        "replyto": "a-bD9-0ycs0",
        "invitation": "ICLR.cc/2023/Conference/Paper6522/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "In this work, the authors propose to forecast irregular time series using state-space model whose dynamics is specified by a linear ODE. The proposed method meets several desirable properties to time series forecast such as self-consistency, forward stability and allowing for missing values. The experiments show the proposed method achieved competitive performance.",
            "strength_and_weaknesses": "Strength:\nThe continuous-time dynamics, specified by ODE, allows for irregular sampling and missing values.\nThe linear ODE specification eases the integrator and computational cost.\nThe linear specification enables Kalman filter\nThe approach exhibits forward stability and self-consistency.\n\nWeaknesses:\nThe linear model limits the power of expressive and rules out such as line attractors, limit cycles, strange attractors and etc.\nThe manuscript seems finished in a hurry. It lacks information.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\nThe full model specification is not in the main text. At least, the distributions of state noise (if any) and measurement(observation) noise are needed. \nMore elaboration is needed why the nonlinear Kalman cell is needed for a linear model.\nIt might be a little confusing or inconsistent using $x$ as ODE variable and then as the measurement (observation).\n\nQuality:\nThe loss or objective function is not in the main text. It is important as there are trainable parameters.\nIt is unclear how those parameters are trained, in an offline or online fashion.\nThe speed of proposed method was not shown in the main text even though claimed fast.\nIt is unclear why the proposed method performed better than other methods. It's possibly that the dynamics in the datasets happen to be (near) linear, the nonlinear dynamics are harder to train, or by other reasons. It would make the work comprehensive to show the performance with/without model mismatch on synthetic data.\nFor reader's information and formality, more descriptions are needed in the captions of figures.\n",
            "summary_of_the_review": "This work aims to forecast irregular time series using state-space model whose dynamics is specified by a linear ODE. The proposed method meets several desirable properties to time series forecast such as self-consistency, forward stability and allowing for missing values. \nSeveral key information seems missing. The writing can be improved.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6522/Reviewer_M6Ey"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6522/Reviewer_M6Ey"
        ]
    },
    {
        "id": "_7mynAPfCFK",
        "original": null,
        "number": 4,
        "cdate": 1666673674747,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666673674747,
        "tmdate": 1666673674747,
        "tddate": null,
        "forum": "a-bD9-0ycs0",
        "replyto": "a-bD9-0ycs0",
        "invitation": "ICLR.cc/2023/Conference/Paper6522/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a novel Neural ODE model that embeds the observations into a latent space with dynamics governed by a linear ODE. \nThey carefully show that the model satisfies self-consistency, which allows forecasting irregularly sampled time series and have some numerical stability guarantees. They evaluate the performance on medical and climate synthetic datasets, where the model outperforms the similar state of the art models.",
            "strength_and_weaknesses": "The theoretical guarantees of the model are nicely derived and clearly presented, and Table 2 is a nice summary of the theoretical advantages of the proposed model. \n\nThe empirical evaluation is compelling, but is on synthetic benchmark datasets only. Including results on a real dataset would make the paper stronger. Even without ground truth, including some visualization of the learnt dynamics vs true dynamics and other models for real datasets would be a great addition to the paper (for example, modeling ocean dynamics)\n\nFigure 1 should also be updated. I think it is of poor quality and doesn't give much insight into the model.\n\nFinally, the OBSERVATIONS section (6.2.) is interesting as it shows the Eigen-values of the kernel matrix, and the authors speculate that the learnt dynamics are periodic. There is space to include some true and inferred dynamics to visualize the periodic signal (or maybe include it in the appendix) ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clear and of good quality.",
            "summary_of_the_review": "The paper is very clear and shows the the method outperforms previous state of the art models. However, I think the paper would gain in quality with better visualization of the learnt dynamics, in synthetic and real datasets.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6522/Reviewer_gake"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6522/Reviewer_gake"
        ]
    }
]