[
    {
        "id": "tJ_H30PDiD",
        "original": null,
        "number": 1,
        "cdate": 1666042221125,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666042221125,
        "tmdate": 1666514792668,
        "tddate": null,
        "forum": "OnD9zGAGT0k",
        "replyto": "OnD9zGAGT0k",
        "invitation": "ICLR.cc/2023/Conference/Paper1619/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a framework for general Bayesian noisy inverse problems using diffusion probabilistic models. The unknown data distribution is expressed as a posterior distribution. The updated reverse diffusion process now involves a generally intractable likelihood term. The authors propose the use of Laplace approximation of the likelihood term to circumvent the intractability issue. Results are presented that show the usefulness of the proposed framework.",
            "strength_and_weaknesses": "The main selling point of the paper is that it proposes a rather straightforward framework for solving general Bayesian noisy inverse problems using diffusion probabilistic models. The numerical results show that by using the framework one can obtain high quality results for a diverse set of problems. It is worth mentioning that the proposed method works on top of existing diffusion probabilistic models.\n\nIts main weakness is that overall, it brings little to the table in terms of new knowledge. The paper is interesting, however, and with the risk of oversimplifying a bit the contributions, it is a collection of existing models and/or techniques. While the use of the Laplace approximation is clever in allowing a straightforward approximation of the likelihood term in the reverse diffusion, it is arguably a standard technique in a statistician and ML practitioner's toolbox.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. The authors correctly place their work in the with respect to existing bodies of work. Sufficient details are given in my opinion to reproduce the results, not to mention that the authors also provide a link to the code. The novelty is somewhat limited, the authors propose more or less an application of diffusion probabilistic models.",
            "summary_of_the_review": "The paper is overall interesting, the issue is the novelty factor which is low. The paper could still appeal to a sufficiently large audience. I'm not convinced on accepting the paper, but I'm not convinced on rejecting it either. I'm looking forward to reading the rebuttal on the novelty factor.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1619/Reviewer_ooZZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1619/Reviewer_ooZZ"
        ]
    },
    {
        "id": "YaCBoP2AYo",
        "original": null,
        "number": 2,
        "cdate": 1666080647184,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666080647184,
        "tmdate": 1666080647184,
        "tddate": null,
        "forum": "OnD9zGAGT0k",
        "replyto": "OnD9zGAGT0k",
        "invitation": "ICLR.cc/2023/Conference/Paper1619/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a framework based on denoising diffusion model for solving inverse problem in image processing. The main contribution is the characterization of the forward process for non-linear models which include many well known image formation models. The proposed method has the specificity to both be easier to use than previous models (e.g no SVD) and relies on automatic differentiation for complex computation. The results shows great improvement compare to others methods based on diffusion models. ",
            "strength_and_weaknesses": "## Strength\n\nThe proposed methods has several interesting contributions,\n1. The forward process is easy to implement and don't ask for heavy operations like SVD.\n2. All the framework is well motivated and the explanation are clear.\n3. Results are impressive compared to state-of-art.\n4. The full framework seems very extensible and then may interest a large part of image processing community.\n\n## Weaknesses\n\nThere is no clear weakness. My only regrets is there is no comparison against more classical methods (e.g image denoising with sparse prior and ADMM as solver).",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\n\nThe paper is straightforward and so very clear. \n\n## Quality\n\nThis is good work.\n\n## Novelty\n\nWhile the denoising diffusion models are not new, their application to inverse problems is still work in progress. The proposed framework is a clear contribution on this subject and is very novel.\n\n## Reproducibility\n\nAll the work is reproducible. The paper is very clear on the parameters, context and networks. Moreover the code is available.",
            "summary_of_the_review": "This paper proposes a denoising diffusion process for inverse problems. The main contribution is on the forward process that is well described and easy to implement. The experiments show promising results for image processing problems.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1619/Reviewer_dAym"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1619/Reviewer_dAym"
        ]
    },
    {
        "id": "A9BCfVNHdjG",
        "original": null,
        "number": 3,
        "cdate": 1666486182475,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666486182475,
        "tmdate": 1666486182475,
        "tddate": null,
        "forum": "OnD9zGAGT0k",
        "replyto": "OnD9zGAGT0k",
        "invitation": "ICLR.cc/2023/Conference/Paper1619/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "this submission deals with posterior sampling from diffusion models for inverse problems. For general inverse problems with nonlinearity and measurement noise, sampling the conditional posterior needs the conditional score \\log \\nablap(y|x_t), that is very complicated and can be quite far from Gaussian, at a generic time step t. The idea in this submission is to (first-order) approximate it around the optimal MMSE estimate at each time t, namely \\hat{x}_0. Several experiments, provided for linear and nonlinear inverse tasks, show significant quality (FID & LPIPS) improvement over SOTA with this simple approximation.   ",
            "strength_and_weaknesses": "Strength\n- extensive evaluation results and good improvements over SOTA methods\n- addressing an important and timely problem\n- simple approach but seems effective\n- well written for the most parts\n\n\nWeakness\n- The main result in Theorem 1 includes quite strict assumptions that may not hold true for distributions with scores with order beyond linear such as Gaussian. This can really limit the scope of Theorem 1. \n\n- The result in Theorem 1 seems to be a simple first order approximation, but it\u2019s been derived in a complex manner. The Laplace approximation to end up with the result in Theorem 1 seems not necessary.\n\n- The approximation can be very loose for large noise levels at the later steps of the diffusion process because MMSE estimator will be quite far from the ground-truth x_0\n\n\nQuestions and comments\n- The assumptions in Theorem 1 seem to be quite restrictive, which does limit the scope of the results and they don\u2019t even include Gaussian distribution. First of all, what's the intuitive meaning of the assumptions? Second, the authors need to elaborate when these assumptions are satisfied and how limited the scope of the distributions satisfying these assumptions would be.\n\n- in section 3.2. it is not quite clear, how p(y|x_0) is related to p(y|\\hat{x}_0)? This seems to be coming from proposition 1, but it's not clear since x_0 and \\hat{x}_0 could have completely different distributions. Is that exact or is there an additional hidden assumption here? This needs to be clarified in the paper. \n\n- The choice of step size seems to be very specific in this work. Did you try other step sizes such as the constant or diminishing step size rule? it seems that the step size rule adopted here is the key to suppress noise? what if one uses the step size coming from eq. 12, namely 1/sigma^2? an ablation on the choice of step size would be needed to clarify the sensitivity of the algorithm to step size.\n\n- better to move tables/algorithms to the top part of each page\n- page 3, last paragraph, line 6, is there a typo in p(x|y)? shouldn\u2019t it be p(y|x)?\n- page 3, last line, remove \u201cthe\u201d from \u201c.... both lines of the works \u2026\u201d\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written for the most parts. Some steps of derivations need more clarity. ",
            "summary_of_the_review": "This paper deals with an important and timely problem. The idea is original, and the experimental results are solid. However, the main result in Theorem 1 seems to be quite restrictive to a small class of distributions that limits the scope of the theorem. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1619/Reviewer_VKPQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1619/Reviewer_VKPQ"
        ]
    },
    {
        "id": "YcM_5YDJuwc",
        "original": null,
        "number": 4,
        "cdate": 1666566747429,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666566747429,
        "tmdate": 1666588692729,
        "tddate": null,
        "forum": "OnD9zGAGT0k",
        "replyto": "OnD9zGAGT0k",
        "invitation": "ICLR.cc/2023/Conference/Paper1619/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper considers an important problem in denoising diffusion models (DPM), that is, how to accurately conduct posterior sampling given a pre-learned score function and an inverse problem. Previous works address this problem by circumventing the calculation of $p(y|x^t)$ and resorting to projections onto the measurement subspace. However, these works either achieve unsatisfactory performance or are not elegant in terms of theoretical interpretation. Different from prior methods, diffusion posterior sampling (DPS) proposes to approximately compute $p_t(y|x^t)$ for each diffused image $x^t$, and conduct posterior sampling using the discretized version of the following equation\n$$dx=[-\\frac{\\beta(t)}{2}x-\\beta(t)(\\nabla_{x_t}\\text{log} p_t(x_t) + \\nabla_{x_t} \\text{log} p_t(y|x_t))]dt + \\sqrt{\\beta{t}} d\\bar{w}$$\n\nIn summary, the contribution of this work is:\n1. It proposes a feasible approach to compute $p_t(y|x_t)$ by using Tweedie's formula and Laplace's method. In particular, \n$$\\nabla_{x_t} \\text{log} p_t(y|x^t) \\sim \\nabla_{x_t} \\text{log} p_t(y|\\hat{x}_0),\\quad\\text{where}\\quad \\hat{x}_0 = \\text{TweedieFormula}(x_t)$$\n2. It experimentally shows that DPS achieves better results than the state-of-the-art algorithms on multiple inverse problems",
            "strength_and_weaknesses": "*Strength*:\n1) The manuscript is well-written and easy to follow.\n2) The figures are illustrative and useful for readers to understand the problem and the approach.\n3) The proposed DPS is novel and provides a new way to compute $p_t(y|x^t)$ \n4) Clear experiments with sharp results\n\n*Weakness & Questions*:\n1. The connection between Proposition 2 and Theorem 1 is not clear in the text. Please provide more explanation on how Proposition 2 helps derive Theorem 1. I notice the proof in the appendix, what I suggest is to include some high-level explanation.\n2. Fig. 3 is very illustrative. However, it can mislead readers to interpret that DPS sticks to each manifold $\\mathcal{M}_n$ perfectly, which I don't think is true as multiple layers of approximation are applied. I suggest the authors emphasize in the caption that this is just a conceptual illustration of DPS.\n3. In the experiments, performance is only evaluated by using perception loss rather than PSNR/SNR/SSIM. Is it because diffusion models generally have bad performance under these metrics? It will be interesting to the PSNR/SSIM comparison because reconstruction accuracy is much more important than perceptual quality in imaging inverse problems.\n4. What is the denoiser of PnP-ADMM? If it is not a deep denoiser, I suggest comparing DPS with a deep denoiser.\n\n*Minors:\n1. Eq. 11 and Alg. 1 & 2 are not consistent.\n2. Please clarify the definition of $\\simeq$.\n",
            "clarity,_quality,_novelty_and_reproducibility": "*Clarity:* well-written and easy to follow\n*Quality:* the overall quality of the manuscript is high\n*Novelty:* the work is novel\n*Reproducibility:* looks like it could be reproduced\n",
            "summary_of_the_review": "I think this paper makes concrete contributions to the literature on diffusion models with application to inverse problems. The method DPS is novel, and the theoretical interpretation in the work is insightful.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1619/Reviewer_3uLY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1619/Reviewer_3uLY"
        ]
    }
]