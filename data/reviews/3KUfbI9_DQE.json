[
    {
        "id": "QeNX57JI7oS",
        "original": null,
        "number": 1,
        "cdate": 1666563885852,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666563885852,
        "tmdate": 1666563910852,
        "tddate": null,
        "forum": "3KUfbI9_DQE",
        "replyto": "3KUfbI9_DQE",
        "invitation": "ICLR.cc/2023/Conference/Paper1943/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studied the problem of distributional shifts in classification models and proposed a distributional robust formulation to tackle this problem. The authors showed that the Bayes optimal solution is a post-hoc scaling of the conditional class probabilities, where the scales can be learned via solving a saddle-point problem. They showed the convergence of this post-hoc classifier, and experimentally demonstrated the superior performance of the proposed algorithm on several datasets compared to baselines. ",
            "strength_and_weaknesses": "Strength: \n\n1. The paper is well written. Problem is clearly set up and described. The algorithm is well justified both theoretically and empirically. \n\n2. Starting from a complicated distributional robust formulation, the resulting post-hoc classifier is yet in a very simple form, which would facilitate its use in many practical problems. \n\n3. The proposed method does not require knowledge of the class distribution in the test set, which adds to its applicability compared with a class of methods that uses undersampling to match the distribution between train and test.\n\nWeakness: \n\n1. Even though the authors claimed that their formulation is essentially different from the worst-case optimization (as done in DRO, for example), from what I read, their approach is not very different from DRO. It is still trying to minimize the worst-case loss among a set of distributions centered around some nominal distribution (Eq. (2) and (3)). The conservativeness of the formulation is controlled by some parameter \\delta, which is the same with DRO. Could you please clarify what is essentially the difference between your approach and DRO, if any?\n\n2. In Proposition 1, the RHS, should we remove the constraints w.r.t g under max, since we already penalize the constraint violation in the Lagrangian?\n\n3. In Theorem 1, \\eta is the ground truth conditional class probabilities, right? Do we assume there is no shift in \\eta between train and test? Do we require the estimated \\eta to have good properties for your method to work well? I think explanations on the \\eta component needs to be added. \n\n4. In the experiments section under label shifts, can you also compare with the DRO solutions that handle class label shifts? Many DRO models reduce to adding a regularizer to the loss function. I am curious about how your method performs compared with those traditional DRO methods.\n\n5. In practice, how should we pick the parameter \\delta to ensure an appropriate amount of robustness?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written very clearly, and uses easy to understand language to demonstrate complicated mathematical ideas. Even though the formulation itself does not seem to be novel, the resulting post-hoc classifier looks novel to me, and is in a very simple form that can facilitate many practical use cases.",
            "summary_of_the_review": "Overall I think this paper is of good quality, and the resulting post-hoc classifier could be potentially valuable to practitioners who are faced with imbalanced classification problem. I like the succinctness of the results regardless of the fact that it was derived from a complicated min-max formulation. The experimental results also look promising. One thing that confuses me is the authors' claim about how their approach differs from DRO (or worst case optimization), which I expect the authors to further clarify. I'd also like to understand in practice, how should we pick the parameter \\delta to ensure an appropriate amount of robustness?",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1943/Reviewer_P4Hw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1943/Reviewer_P4Hw"
        ]
    },
    {
        "id": "Z-Ydb2ASMN",
        "original": null,
        "number": 2,
        "cdate": 1666661413118,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666661413118,
        "tmdate": 1666661413118,
        "tddate": null,
        "forum": "3KUfbI9_DQE",
        "replyto": "3KUfbI9_DQE",
        "invitation": "ICLR.cc/2023/Conference/Paper1943/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes to apply a post-hoc learning process for correcting label (class-prior) shifts between training and test distribution. It utilizes a labelled validation set that has the same label prior distribution as the test data and optimizes a delta-constrained objective (Eq.(1) or (2)). The delta quantifies how much the prior can change from the test/validation class distribution. Using the Lagrangian method, the algorithm alternates between different components. Convergence analysis is provided and experiments on common benchmarks show the superiority of the proposed method, Distributionally RObust PoSt-hoc method (DROPS).",
            "strength_and_weaknesses": "Strengths\n- Writing is clear\n- A simple method that is easy to implement\n- Theoretical justification\n\nWeaknesses\n- Some experiment details are missing\n\nDetail comments & questions regarding the experiments:\n\n1. What are the sizes of the validation sets? What happens if we fine-tune the model on the validation set?\n\n2. It is mentioned in the tables\u2019 captions that the best performed methods in each setting are highlighted. They are best in terms of what criteria? Did you perform any statistical testing?\n\n3. Figure 1 is concerning. For CIFAR10, why delta_{train}=1 is so good across different eval deltas? If the model is trained based on delta=2, then we should expect it to work best when the evaluation delta is also 2. However, it seems that delta_{train}=1 works best even for evaluation delta = 2. What\u2019s so special about delta_train=1?\n\n4. What\u2019s the performance of DFR for Table 1?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and the method seems novel.",
            "summary_of_the_review": "The paper proposes a simple method with theoretical convergence justification. Experiments on common benchmark datasets show that the proposed method can work better than alternative methods. Despite some missing details in the experiments, the results are mostly convincing.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1943/Reviewer_b7xp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1943/Reviewer_b7xp"
        ]
    },
    {
        "id": "UZP6hheJz2",
        "original": null,
        "number": 3,
        "cdate": 1666718641571,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666718641571,
        "tmdate": 1666718717539,
        "tddate": null,
        "forum": "3KUfbI9_DQE",
        "replyto": "3KUfbI9_DQE",
        "invitation": "ICLR.cc/2023/Conference/Paper1943/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a classifier that performs well under the shift of class proportions. The approach involves a distributionally robust formulation (a min-max problem) where the weight vector is constrained in a $f$-divergence ball of radius $\\delta$. The optimal post-hoc classifier is shown to be a reweighed classifier. The paper contains a gradient descent-ascent type algorithm to find the optimal post-hoc classifier from an initialization.",
            "strength_and_weaknesses": "I experience certain difficulties in assessing the quality of this paper. I believe that the authors did not clarify well the contributions of the paper.\n\nI am relatively familiar with adversarial training and minimax formulation of equation (3). Theorem 1 of this paper is simply an implication of the Nash equilibrium results, which are abundant in the field of adversarial training and robust learning. For $f$-divergence type set $\\mathbb{G}(\\delta)$, the results of Duchi and Namkoong (2018) and BenTal et al. (2013) have provided much information about the reweighing schemes and how to solve the problem. The gradient descent-ascent algorithm is also widely used to solve min-max problems. Finally, Theorem 3 provides the guarantee only for the ergodic average $\\bar f$, but not for the terminal $f^{(T)}(x)$, thus it is of limited usefulness in practice.\n\nFrom the perspective of a researcher with moderate experience in adversarial learning, I do not feel that I have learned something new with this paper. I hope that the authors can provide strong justifications for their contributions.",
            "clarity,_quality,_novelty_and_reproducibility": "Possible typo in the middle of page 4: To my understanding, the Lagrangean function should eliminate the constraint $D(g, u)\\le \\delta$, thus, the maximization over $g$ in Proposition 1 should be over $g \\in \\Delta_m$. ",
            "summary_of_the_review": "There is not enough evidence about the novelty and the significance of the results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1943/Reviewer_xUWa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1943/Reviewer_xUWa"
        ]
    }
]