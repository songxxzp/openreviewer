[
    {
        "id": "-XtTWhj65AV",
        "original": null,
        "number": 1,
        "cdate": 1666604001373,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604001373,
        "tmdate": 1666604001373,
        "tddate": null,
        "forum": "uFWSIObdx5H",
        "replyto": "uFWSIObdx5H",
        "invitation": "ICLR.cc/2023/Conference/Paper2134/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the number of simplices contained in triangulations of all polytopes generated by ReLU networks. From the theoretical viewpoint, the authors prove upper (Theorem 1) and lower (Theorem 2) bounds on the maximal number of simplices. This implies that the average number of faces in a polytope grows only linearly in the input dimension (Theorem 3 and 4, for neural networks with one and multiple hidden layers, respectively). From the experimental viewpoint, the authors demonstrate that, at initialization, most of the polytopes are simple (i.e., have few faces). The authors vary the initialization method, the depth, the dynamic range of the input, the size of the biases and (to the extent allowed by numerical simulations) the input dimensions, showing that their conclusions hold in rather large generality.   ",
            "strength_and_weaknesses": "Strengths\n\n* To the best of my knowledge, the number of simplices has not been investigated before, as a measure of the inherent simplicity of the solution found by a ReLU network.\n\n* The numerical results show that, at initialization, the polytopes of deep ReLU networks consistently have triangulations composed by few simplices.\n\nKey weaknesses\n\n* The experimental results only concern initialization, and there is a single qualitative experiment concerning the training of the neural network (Figure 8). It is hard to draw any conclusions on the training dynamics in absence of more quantitative results about gradient descent training. \n\n* The theoretical results are interesting, but relatively straightforward and, given the lack of a more formal connection with gradient training, the insight they bring on the phenomenon of implicit bias remains questionable.\n\n\n\nMinor weaknesses\n\n\n* Because of the inherent difficulty of the counting problem, only relatively small input dimensions can be investigated. This makes it very difficult to scale the experiments of this work to any setting where the input dimension is closer to practice.\n\n* The authors seem to always consider the regime in which the number of neurons $n$ is large and the input dimension $d$ is constant. What happens when $d$ is allowed to scale with $n$? In this case, it seems that both the upper and the lower bound of Theorem 1-2 are dominated by $\\mathcal O(n^{dL-1})$. Is it be possible to understand the constant hidden in the $\\mathcal O(\\cdot)$? Do the results of Theorem 3-4 still hold if $d$ is allowed to grow with $n$?\n\n* Can the results be generalized to deep networks in which the number of neurons in the various layers differ? Is some interesting behavior happening in the presence of a bottleneck (i.e., a layer with few neurons in the middle of two layers with many more neurons)?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written.\n\nThe originality is questionable. In fact, the paper adds one more observation to the earlier work by Hanin & Rolnick (2019b): Hanin & Rolnick (2019b) showed that deep ReLU networks have few polytopes, and this paper shows that such polytopes have to be simple (namely with small number of simplices). The theoretical results are interesting, although they remain at the level of a (cute) observation. The numerical results only deal with networks at initialization.",
            "summary_of_the_review": "The paper provides an observation about the number of simplices in the polytopes of deep ReLU networks. Even if this observation is novel, the connection to gradient descent training and its implicit bias is not sufficiently well discussed to bring the paper above the acceptance bar. Another (minor) weakness is that the results hold only for networks in which the input dimension is significantly smaller than the number of neurons, and this number of neurons is the same in every layer. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2134/Reviewer_KuXu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2134/Reviewer_KuXu"
        ]
    },
    {
        "id": "osF5RFGkxr",
        "original": null,
        "number": 2,
        "cdate": 1666667423946,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666667423946,
        "tmdate": 1669057690892,
        "tddate": null,
        "forum": "uFWSIObdx5H",
        "replyto": "uFWSIObdx5H",
        "invitation": "ICLR.cc/2023/Conference/Paper2134/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "1) The paper establishes a theorem to explain why polyhedra produced by deep networks are simple and uniform and the linear region dominates. 2) The paper proves that deep learning does not overfit. 3) The paper promotes the theoretical research of ReLU. 4) The paper is submitted with a basic implementation.",
            "strength_and_weaknesses": "Strength:\n\n1. The research problem of the paper is very meaningful for deep learning.\n\n2. The paper explains the relationship between ReLU and deep neural network overfitting.\n\n3. The paper gives proof of the theorem. This makes sense for theoretical explanations of deep neural networks.\n\nWeaknesses:\n\n1. The paper explains why deep learning does not overfit. This is contrary to my previous perception. I want to ask what assumptions did the author make when proving this conclusion? Are these assumptions adequately accounted for in the paper?\n\n2. The paper assumes that the input space of an NN is a d-dimensional hypercube. What is the correlation between this assumption and the \nconvolutional neural networks? If The author's analysis here seems only to contain fully connected layers?\n\n3. What implications do the authors' conclusions have for subsequent research? I'm a little confused about what kind of inspiration this proof can bring us.\n\n4. The authors show that deep neural networks do not overfit. However, this conflicts with existing cognition. Has the author analyzed this conflict? Under what circumstances will deep neural networks not overfit?\n\n5. What is the meaning of 3-4-1 in Table 1? I'm a little confused.",
            "clarity,_quality,_novelty_and_reproducibility": "1. Clarity:\nSome of the proofs of the paper are obscure. Authors are advised to add a Jupiter notebook or more explanations to aid understanding.\n\n2. Quality:\nI cannot accurately assess the quality of the paper. I hope the author answers my question in the reply.\n\n3. Novelty:\nThe paper looks innovative. But I'm not quite sure about the impact of this innovation on subsequent work.\n\n4. Reproducibility:\nThe point of the paper is not to reproduce the code. I am more worried about whether the conclusions proved by the paper are in line with the actual situation. What assumptions did the author make?",
            "summary_of_the_review": "I am not very clear about some details and derivations of the paper. In addition, I do not know the impact of the paper on subsequent research work. I would like the author to reply to my question. Also, I would like to discuss this with the other reviewers to determine the final score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "There are no Ethics Concerns.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2134/Reviewer_H4R5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2134/Reviewer_H4R5"
        ]
    },
    {
        "id": "9hgui0SJUx",
        "original": null,
        "number": 3,
        "cdate": 1667108463993,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667108463993,
        "tmdate": 1667108463993,
        "tddate": null,
        "forum": "uFWSIObdx5H",
        "replyto": "uFWSIObdx5H",
        "invitation": "ICLR.cc/2023/Conference/Paper2134/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "It is well known that the function represented by a ReLU network is piecewise linear, with each linear region corresponding to an activation pattern. There have been papers showing that despite the potential number of possible activation patterns being exponential in the number of neurons, the actual number for a typical randomly initialised network is only polynomial in the number of neurons. This paper extends the idea further and argues that the number of faces of the polyhedral linear regions is also small, and hence typical neural nets are not as complicated as the worst case.",
            "strength_and_weaknesses": "Strength:\n\n1. A good mix of theoretical and empirical results for counting the number of simplices.\n\n2. Simplifying the core argument of \"expected number of polytopes\" in Hanin et al. to a simple general position argument clears up some mental space for other arguments.\n\nWeaknesses:\n\n1. The argument that the number of simplices or faces of the linear regions a measure of complexity seems reasonable but needs more validation. e.g. there are easy VC type bounds linking the number of pieces in a piecewise linear function family to generalisation bounds, similar bounds for the number of simplices (without going through the number of linear regions) would be valuable.\n\n2. The statement for Theorem 2 is slightly confusing. \"Maximal number of simplices is at least ...\" what is the maximum over? Do dring the dependence of the different variables clearly.\n\n3. The upper and lower bounds are quite tight (assuming general position assumptions), but the number seems too large to make any reasonable conclusion for even some moderately sized networks -- conditions on the parameters of the neural under which this can be significantly smaller (or larger) would give some insight into complexity of neural nets.\n\n4. The only constraint on the parameters I can see is its requirement to be in general position. For one layer nets that happens with probability 1 under typical inits. But what about the condition in Theorem 4 that generalises to multiple hidden layers? Can you argue that this also happens with probability 1 under typical initialisations?\n\n5. A study on when (for what parameter configurations especially) is the number of simplices small/large would be more valuable, when juxtaposed with other important properties of neural nets, such as generalisation/frequency bias. e.g. questions like are there more simplices after training with random data than true labels? e.g a ranking study of different networks of the same architecture (and same init) trained on same data (but different mini-batches or different learning rates or different optimisation algorithms) on the basis of generalisation error and number of simplices. Do the two rankings agree?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: \n\nThe paper is mostly clear on its technical contributions, but the discussions relating the results to actual phenomena in neural nets like generalisation and spectral bias is mostly imprecise.\n\n",
            "summary_of_the_review": "The paper attacks a novel question, whose significance is of questionable value. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2134/Reviewer_rZ3w"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2134/Reviewer_rZ3w"
        ]
    },
    {
        "id": "VJKjHbGPkkK",
        "original": null,
        "number": 4,
        "cdate": 1667615040896,
        "mdate": 1667615040896,
        "ddate": null,
        "tcdate": 1667615040896,
        "tmdate": 1667615040896,
        "tddate": null,
        "forum": "uFWSIObdx5H",
        "replyto": "uFWSIObdx5H",
        "invitation": "ICLR.cc/2023/Conference/Paper2134/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper refines the study of linear regions in neural networks by analyzing how each linear region can be decomposed into simplices. The authors argue through theoretical results and experiments that most linear regions can be decomposed into very few simplices; hence implying in yet another form that neural networks end up producing simple functions despite their potential to also represent much more complex functions.",
            "strength_and_weaknesses": "Strengths:\n- The introduction is very well written and gives great context for the problem of analyzing the complexity of neural networks under the optics of linear regions.\n- The idea of studying the complexity of linear regions in terms of their simplicial decomposition seem novel and relevant.\n- If confirmed, the results claimed by the authors provide further insight into what functions we can expect to obtain from neural networks.\n\nWeaknesses:\n- The numerical experiments lack consistency. For example, forms of initialization change between one experiment and another without any justification (sometimes 4 are used, sometimes only Xavier, sometimes only Kaiming). \n- Although Section 4 has ReLU in its title, Subsection 4.2 discusses results with maxout (why?).\n- The only experiment in which the input dimension goes beyond 3 clearly show some gain in complexity of the linear regions, but this seems to be ignored by the authors.\n- As far as I can understand, each plot is based on a single network, which is far from ideal.\n- It is not clear to me what the authors mean by the linear regions being uniform in Section 4.\n- I am curious and puzzled about Theorem 4. Given that linear regions are typically in general position in shallow networks, which implies a large number of linear regions and consequently simpler linear regions, I can easily buy Theorem 3. However, the number of linear regions drops when the network gets deeper. I don't see any intuition for why Theorem 4 should be true.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Here are some detailed points about the writing:\n- What the authors describe as a face starting in the bold part at the end Preliminary 1 could more precisely be called a *facet*.\n- The description of a polytope in Preliminary 3 is a little confusing with so many commas for different purposes in the set.\n- In Theorem 2, I would advise the authors against using the term *maximal* if *maximum* would be more precise (they don't mean the same thing).\n- Most plots presented in the paper lack axis titles or at least a description in the caption for what the axis title of each plot should be.\n- I believe the use of \"surprisingly\" in the title of Section 4 is completely unnecessary and actually clich\u00e9 for imitating previous papers.\n- In the second line of Section 4, I believe you meant to say \"linear regions\" when you wrote \"simplices\".\n- The use of \"thing\" and \"pretty small\" in Remark 1 is too informal and uninformative.",
            "summary_of_the_review": "The paper brings interesting ideas and communicates them in an accessible way for the most part. However, it is not clear to me if all results are correct and whether their experiments reflect what would happen in networks with larger inputs.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2134/Reviewer_htwS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2134/Reviewer_htwS"
        ]
    }
]