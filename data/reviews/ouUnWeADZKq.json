[
    {
        "id": "T2Dje1--XT",
        "original": null,
        "number": 1,
        "cdate": 1666589682251,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666589682251,
        "tmdate": 1666589682251,
        "tddate": null,
        "forum": "ouUnWeADZKq",
        "replyto": "ouUnWeADZKq",
        "invitation": "ICLR.cc/2023/Conference/Paper1211/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method for continual learning in text-image modeling. They propose a formulation that uses a historical and main neural networks whose parameters are used interchangeably\tbetween the two networks during parameter optimization as a weighed average. In experiments, the authors compare favorably against baseline methods through thorough evaluation and they also provide a thorough ablation to highlight the contribution of the different components and hyper parameters of the proposed method.",
            "strength_and_weaknesses": "Strengths:\n+ New formulation of continual learning with minimal forgetting\n+ Thorough evaluation and ablations\n+ Well written paper\n\n\nQuestions:\n- Performance on Task3 and Task4.\nThere seems to be a weakness of the propose model that shows in Table 1 for tasks Tasks 3 and 4. Do they authors have any analysis showing why this is happening. I would assume the performance should be best in the later Tasks than the earlier tasks.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, and the proposed method seems to be novel. The method seems to be replicable from the details in the paper.",
            "summary_of_the_review": "The formulation in this paper is interesting, and the authors made sure to ablate each portion of it to show the different behaviors with different pieces. In addition, the authors outperform the baselines on average. Therefore, I am leaning towards accepting this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1211/Reviewer_4eZi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1211/Reviewer_4eZi"
        ]
    },
    {
        "id": "y0B1ZOdogH",
        "original": null,
        "number": 2,
        "cdate": 1666626450706,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666626450706,
        "tmdate": 1666626450706,
        "tddate": null,
        "forum": "ouUnWeADZKq",
        "replyto": "ouUnWeADZKq",
        "invitation": "ICLR.cc/2023/Conference/Paper1211/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents an incremental learning approach for VL understanding (in particular, cross-modal retrieval). The authors established a benchmark by combining several popular VL datasets and defining an incremental (sequential) scenario. The proposed method involves applying EMA back and forth between old (offline) and new (online) models. Experiments show improvement in the studied scenario.",
            "strength_and_weaknesses": "Strengths\n1. The studied problem is interesting and important.\n2. The paper is easy to follow.\n\nWeaknesses\n\nI am familiar with VL understanding but I do not work in the continual learning field (I do know too much about it). I choose to write down my opinions below and wait for other reviewers' comments and discussions with the authors.\n\nI think the proposed method is reasonable but it does not provide new insights. It is about propagating information back and forth between an online (new) model and an offline (old) model. Intuitively, by absorbing knowledge from the old model, the recognition accuracy on old datasets is expected to grow, but that on new data is expected to drop. Experiments validate the hypothesis, where we see a relatively large accuracy gain on task T1, but the gain drops rapidly and eventually becomes a deficit on task T4. Although the average accuracy is higher than the competitors, I guess it comes from a better balance among the tasks -- that said, the core issue of catastrophic forgetting is not well addressed, but the approach seems to add weights among different, historical models toward a better average accuracy. Personally, I do not praise the contribution of the proposed method.\n\nI shall admit that I did not achieve a clear thought of evaluating this paper. It seems that replaying old data (with buffer) and average old and new models are the only way to alleviate forgetting, which is trivial to me. Is this the correct direction for incremental learning?\n\nThere are some minor issues, such as the missing of diagnosis of the key hyper-parameter, k.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: good, the proposed method is simple.\n\nQuality: limited, since I think the overall benchmark and pipeline do not seem to address the key issues of incremental learning.\n\nNovelty: hard to judge -- if the overall design is fine and the direction is ok, I will say the novelty is sufficient.\n\nReproducibility: seems good, the method is very simple anyway.",
            "summary_of_the_review": "I had a hard time evaluating the contribution of this paper. Temporarily, I do not think the paper made important contributions that shall be published at ICLR.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Not writing ethical concerns in the paper.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1211/Reviewer_xMpX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1211/Reviewer_xMpX"
        ]
    },
    {
        "id": "gw8uN1WFBG",
        "original": null,
        "number": 3,
        "cdate": 1666669076522,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669076522,
        "tmdate": 1666669076522,
        "tddate": null,
        "forum": "ouUnWeADZKq",
        "replyto": "ouUnWeADZKq",
        "invitation": "ICLR.cc/2023/Conference/Paper1211/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focuses on continual image-text embedding, reducing the computation and storage resources using all data in the training phase. For the first time, the paper identifies the important role of direct parameter transfer (between the historical and main models) in continual learning and the proposed DHA outperforms existing continual learning approaches, including rehearsal-based methods, regularization-based methods and hybrid models.",
            "strength_and_weaknesses": "Strength:\n\nS1: This paper identifies the important role of direct parameter transfer (between the historical and main models) in continual learning, and proposed a dynamic historical adaptation model.\n\nS2: The proposed model outperforms its counterparts, including rehearsal-based methods, regularization-based methods and hybrid models.\n\nS3: Extensive experiments are conducted to show the effectiveness of the proposed model.\n\nWeaknesses:\n\nW1: It is unclear how large the gap is between using all data to train a model and the proposed DHA.\n\nW2: I am wondering whether the order of tasks matters.\n\nW3: The style of Flickr30k is similar to MSCOCO, and there should be overlaps with MSCOCO, so zero-shot may not be appropriate.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and we can easily follow it. Basically, the proposed model is novel to me and I think we can reproduce it. ",
            "summary_of_the_review": "The paper focuses on continual image-text embedding, which is an important task. The proposed DHA model outperforms its counterparts, reducing the computation and storage resources of using all data to train models. In this phase, I give it a score of 8.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1211/Reviewer_4FxS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1211/Reviewer_4FxS"
        ]
    },
    {
        "id": "BA_Twu8kG92",
        "original": null,
        "number": 4,
        "cdate": 1666682038807,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682038807,
        "tmdate": 1666697888063,
        "tddate": null,
        "forum": "ouUnWeADZKq",
        "replyto": "ouUnWeADZKq",
        "invitation": "ICLR.cc/2023/Conference/Paper1211/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper addresses the problem of continual learning under a novel Continual Image-Text Modeling setting where the model learns a sequence of multiple image-text matching tasks. The authors claim that transferring the old knowledge from the historical model parameters and periodically updating the current model to the historical model addresses the problem, since the datasets used in the proposed CITM setting have a large domain gap. The experimental results on the proposed benchmarks show the effectiveness of the proposed framework compared to the baselines.",
            "strength_and_weaknesses": "- Strengths\n    - The proposed novel CITM problem has not been studied, but is a real use case, since many image-text datasets with large domain shifts have been proposed recently, and vision-language models are expensive to retrain in general.\n    - The proposed framework demonstrates better performance than other baselines for the newly constructed benchmarks, using existing image-text datasets.\n    - The idea of alternatively updating the historical model and the main model seems interesting, but the reviewer is not fully convinced yet.\n    - The ablation study well supports the claim that \u201cAdapt with Hist\u201d provides stability while \u201cDynamic Hist\u201d addresses plasticity.\n    \n- Weaknesses\n    - It seems the proposed framework is not fully aligned with the proposed CITM setting.\n        - First, the reviewer agrees with the authors\u2019 claim that the image-text datasets have a large domain gap, and thus the existing rehearsal-based and regularization-based methods may not be suitable to the CITM setting.\n        - Therefore, the main problem of the CITM setting (according to the paper) is domain shift.\n        - However, the domain shift problem arises from collecting multiple datasets, which is not incurred from the inheritance of multi-modal data.\n        - Thus the link between the proposed problem setting and the proposed framework is weak.\n        - For me, this kind of study should deliver some idea or solution which handles multi-modal learning via multi-modality itself or modality-specific aspects. There could be modality-specific forgetting, or modality-wise domain gap, etc.,.\n        - What makes the proposed framework special for the multi-modal task, not just for the datasets with large domain shifts?\n    - Discussion for the methodology\n        - Finding the best model for the last task using the test seems inappropriate. Although there could be some works beyond my knowledge using a test set of the previous task, continual learning usually assumes that we do not have access to the test set during incremental training steps.\n        - A more common way to choose the model of the last task is to choose the model after the last iteration.\n        - What if we just select the model after the last iteration for each task? Or, what is the mean and variance of epoch (or iteration) for each task under the current version of the framework?\n    - Discussion for the datasets\n        - It seems subsampling the same number of data from each dataset (e.g., $T_2-T_4$) diminishes the necessity of CITM setting, while this strategy addresses the dataset-imbalance problem for the experiments. In general, different image-text datasets have different magnitudes of sizes. The obvious examples are MSCOCO (123K images) and CC3M (3M images), which are used in this study.\n        - The order of the datasets is the crucial aspect that affects the performance of continual learning. The results for different dataset orders could make the authors\u2019 claim more robust. It could be a minor point if we sample the same number of data from each dataset as in this study. However, it would be crucial if we just naively use all data in the datasets with different magnitudes of size.\n    - Minor\n        - Typo : wrok \u2192 work : last sentence in Appendix B.",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity : The paper is well-written and easy to follow.\n- Quality : The presentation of the paper is neat.\n- Novelty : The proposed problem setting (CITM) has not been addressed so far, but is a relevant and novel problem to ML community.\n- Reproducibility : The authors state that they will release the datasets and code soon in the Section 4.2 (Implementation Details).",
            "summary_of_the_review": "Although the paper proposes a novel and interesting problem setting, the reviewer has some concerns to be addressed, as stated in the weakness and questions section.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1211/Reviewer_miUb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1211/Reviewer_miUb"
        ]
    }
]