[
    {
        "id": "glDPFGHfzge",
        "original": null,
        "number": 1,
        "cdate": 1665980383543,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665980383543,
        "tmdate": 1665980383543,
        "tddate": null,
        "forum": "23jfQBSUh4x",
        "replyto": "23jfQBSUh4x",
        "invitation": "ICLR.cc/2023/Conference/Paper966/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "* The paper attempts to bridge the gap between the continual learning settings used in academic work and industrial applications. It introduces the setting of Online Continual learning for Progressive Distribution Shift (OCL-PDS) that considers subtle, gradual, and continuous distribution shifts. \n* The paper proposes three modifications to existing CL settings:\n  * Online evaluation and training.\n  *  Remember recent and important knowledge described by regression set instead of the complete past knowledge.\n  * Infinitely large storage without the replay of all samples. \n* The evaluation is conducted on four benchmarks proposed for this setting based on the WILDS benchmark for supervised and semi-supervised settings.\n",
            "strength_and_weaknesses": "I am well-familiar with the literature and read the full paper in detail. Accordingly, now I will describe the strengths and weaknesses of the paper in the order of originality + significance, quality of the paper, and clarity. \n\n### Originality\n##### Strengths\n* The paper takes an important step to develop CL benchmarks based on the issues faced by the practitioners. The proposed benchmarks model the shifts in hot topics, time, and language use and would be of interest to the CL community.\n* It provides various insights into the existing methods in the proposed OCL-PDS setting. In Particular, observation two, three, and five would be valuable for developing future methods in this setting.\n\n##### Weaknesses\nThe paper lacks the positioning and comparison of the proposed benchmarks and observations with many prior works:\n* **Proposed benchmarks:** The proposed benchmarks are a direct extension of the WILDS benchmarks. Cai et al. [1] proposed Continual LOCalization (CLOC) \u2013 39 million images over nine years, with 712 classes. The paper refers to Lin et al. [2], which introduced CLEAR with 7.8M images based on the temporal evolution of visual concepts of Internet images in the footnote; however, it does not clarify the challenges in the creation of the regression set for CLEAR following the proposed approach. Both these benchmarks have a much larger scale than the benchmarks proposed in the paper. I would also suggest comparing the CL video benchmarks in the paper benchmarks section, providing the limitations of these already existing benchmarks and the necessity for the new benchmarks.\n* **Supervised and unsupervised methods:** The paper does not compare or refer to current online CL methods [3,4]. Further, while the paper does not consider many recent unsupervised/self-supervised CL methods [5,6].\n\n---\n\n### Quality\nThe paper evaluates multiple benchmarks that reciprocate real-world distribution shifts. It focuses on both the supervised and semi-supervised settings, strengthening the overall experimental evaluation. However, I have various concerns regarding the modifications and the proposed setup that I highlight below:\n* The assumption of infinite storage is impractical for most applications. Especially in the online setting, where a large number of instances are collected every second, it is not feasible to store the complete dataset. Furthermore, data storage is often restricted for many applications due to privacy restrictions.\n* The choice of the time window for knowledge retention needs to be clarified. There are no guidelines to select this hyper-parameter, and it will lead to the formulation of methods that can only remember the recent knowledge, where \u201crecent\u201d is artificially curated for each benchmark. Further, the importance/critical data for the regression set is not well-defined. It is also unclear whether the regression set should change or update depending on the change in the criticality of the data.\n\n---\n\n### Clarity\nThe paper was overall clear and well-written. Following are a few suggestions that highlight the missing details and should help improve the overall presentation:\n* ***Details about regressions set:*** The selection of the regression set should be elaborated in the paper. For instance, for FMoW-WPDS and Amazon-WPDS, how is the regression set constructed? Does it contain all the samples from America, Asia, and ten product categories for FMoW-WPDS and Amazon-WPDS, respectively?\n* ***Clarity of the figures:*** The figures for the experimental results are not interpretable. For instance, in Figure 2, each point corresponds to one algorithm according to the caption. However, the figure has no labels, and it is challenging to analyze the performance of any method in the figure. The tables in the supplementary material are much easier to read than the figures; however, the notations could be more straightforward and concise.\n\n---\n\n### Reproducibility\nThe paper included the code in the supplementary, which would promote the usage of these benchmarks for future CL papers.\n\n---\n\n### References\n[1] Cai et al. Online Continual Learning with Natural Distribution Shifts: An Empirical Study with Visual Data. ICCV 21.  \n[2] Lin et al. The CLEAR Benchmark: Continual LEArning on Real-World Imagery.  NeurIPS 21.   \n[3] Yin et al. Mitigating Forgetting in Online Continual Learning with Neuron Calibration. NeurIPS 21.   \n[4] Yoon et al. Online Coreset Selection for Rehearsal-based Continual Learning. ICLR 22.   \n[5] Madaan et al. Representational Continuity for Unsupervised Continual Learning. ICLR 22.   \n[6] Fini et al. Self-Supervised Models are Continual Learners. CVPR 22.   \n",
            "clarity,_quality,_novelty_and_reproducibility": "I have covered all these aspects in the above section. Therefore, I use this part of the review to clarify the remainder of the questions for the paper:\n* Since the paper assumes infinite storage, what was the buffer size for replay during continual learning? \n* How was the random label feedback adopted in the evaluation? Does the paper consider the fraction of users for evaluating the model output?\n* The paper experiments with pseudo-labeling semi-supervised methods; was there any specific reason to consider these methods instead of using self-supervised methods that do not require labels?\n",
            "summary_of_the_review": "While the paper is interesting and tackles a significant problem, it is not ready for acceptance in its current form. Remarkably, the paper lacks a comparison with existing benchmarks and CL methods, the modifications to the CL settings could be better-motivated and appropriate for many practical scenarios, and the paper's clarity (especially the results) needs to be significantly improved.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper966/Reviewer_UPWo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper966/Reviewer_UPWo"
        ]
    },
    {
        "id": "YQb5bpPmek",
        "original": null,
        "number": 2,
        "cdate": 1666548193920,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666548193920,
        "tmdate": 1666548193920,
        "tddate": null,
        "forum": "23jfQBSUh4x",
        "replyto": "23jfQBSUh4x",
        "invitation": "ICLR.cc/2023/Conference/Paper966/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper is intended to formally introduce the online continual learning problem with progressive distribution shift, and also presented four benchmark datasets and 12 algorithms (adapted from existing algorithms) for this setting, and finally presented empirical results of these algorithms on these datasets. ",
            "strength_and_weaknesses": "* The paper tries to be practical and bridge the gap between academic and industry, but I don\u2019t really see anything novel. Missing citation: Cai, Sener, Koltun, \u201cOnline Continual Learning with Natural Distribution Shifts: An Empirical Study with Visual Data\u201d, ICCV 2021. \n* An important contribution is the benchmark datasets, and a 3-step procedure is described, but no examples are shown in the main text how these 3 steps are executed, and how the distribution is shifting with some metrics to demonstrate. I\u2019m not very convinced these benchmark dataset are good. \n* Most of the results are presented in the format of scatter plot of \u201cworst reg perf\u201d vs  \u201cavg online perf\u201d, but it\u2019s not well motivated why this is a good way of demonstrating the benchmarks are good.\n",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity: overall well written, but as a paper introducing benchmark datasets, the procedure on how the datasets are constructed is only briefly discussed, and the experiments part can be improved, for example, figure titles are not informative at all. \n* Quality: fair\n* novelty: the novelty is limited, the problem is not not new, datasets are not new, algorithms are not new, missing citation of similar existing work  \n* reproducibility: appears to be good \n",
            "summary_of_the_review": "This paper attempts to establish some benchmark datasets and algorithms for online continual learning under progressive distribution shift. While a practitioners\u2019 perspective is emphasized, I failed to see much novelty of this perspective, and the empirical results are not presented in a convincing enough way to show the benchmarks are good enough for wide use for the community. \n\nI would recommend the authors to check out this paper and explain the differences: Cai, Sener, Koltun, \u201cOnline Continual Learning with Natural Distribution Shifts: An Empirical Study with Visual Data\u201d, ICCV 2021. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper966/Reviewer_6758"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper966/Reviewer_6758"
        ]
    },
    {
        "id": "GjblZm5S13",
        "original": null,
        "number": 3,
        "cdate": 1666598097058,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666598097058,
        "tmdate": 1666598097058,
        "tddate": null,
        "forum": "23jfQBSUh4x",
        "replyto": "23jfQBSUh4x",
        "invitation": "ICLR.cc/2023/Conference/Paper966/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a novel \u201cOnline Continual Learning for Progressive Distribution Shift (OCL-PDS)\u201d problem that widely exists in industrial applications from the practitioner\u2019s perspective, aiming to close the gap between academic research and industry. They propose three modifications to the related conventional settings, build 4 new benchmarks from the Wilds dataset, and implement 12 algorithms and baselines including both supervised and semi-supervised methods. Extensive experiments on the new benchmarks also bring some observations. ",
            "strength_and_weaknesses": "Strengths:\n1. This work first introduces and investigates the novel OCL-PDS problem, which more closely aligns with practitioners\u2019 needs in the industry;\n2. This work improves the setting of conventional DA and CL problems at three points, including task-free, forgetting-allowed, and infinite-storage, which is reasonable and more practical, and thus can close the gap between academic work and real industrial applications to some degree.\n3. This work requires only remembering the \u201crecent knowledge\u201d and \u201cimportant knowledge\u201d rather than the knowledge on all tasks and designs a \u201cregression set\u201d to describe the important knowledge.\n4. This work releases 4 new benchmarks using the 3-step procedure for the OCL-PDS setting, while adapting and implementing 12 OCL algorithms and baselines, including both supervised and semi-supervised. Their observations based on extensive experiments may help boost the development of OCL algorithms for handling PDS.\n\nWeaknesses:\n1. The \u201cinfinite storage\u201d this work proposes is somewhat inconsistent with the actual situation, especially in scenarios where the distribution changes gradually over time, such as a recommendation system. The space cost that increases linearly with time T will bring a heavy burden when T becomes large even for the industrial scenarios. \n2. According to observation 2, the online performance depends on how the regression set is defined, and how close it is between the regression set distribution and the overall distribution. So besides the proposed \u201cfrequent data\u201d and \u201ccritical data\u201d, is there a more general way to construct an appropriate regression set to describe the important knowledge? \n3. It is expected to add First Batch Only (FBO) without the training regression set as a baseline, which can serve as a better lower bound of the online performance than FBO. Because the critical data may not show in the first batch.\n4. The proposed i.i.d. offline may not be the upper bound of the online performance, because jointly learning multiple datasets may outperform learning each dataset independently. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good\n\nQuality: Good\n\nNovelty: Good\n\nReproducibility: Good",
            "summary_of_the_review": "The proposed setting, concepts, evaluation paradigms, and datasets are realistic and may have a large impact on industrial applications.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper966/Reviewer_FcFA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper966/Reviewer_FcFA"
        ]
    },
    {
        "id": "UubSCn7T5V",
        "original": null,
        "number": 4,
        "cdate": 1666930319327,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666930319327,
        "tmdate": 1666930319327,
        "tddate": null,
        "forum": "23jfQBSUh4x",
        "replyto": "23jfQBSUh4x",
        "invitation": "ICLR.cc/2023/Conference/Paper966/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Authors introduce the novel OCL-PDS problem - Online Continual Learning for Progressive Distribution Shift. Authors contrast their problem with that of continual learning and domain adaptation. Authors build 4 new benchmarks and implement 12 algorithms to test these benchmarks.\n",
            "strength_and_weaknesses": "Strengths:\n1) Paper is clearly written and the authors point to practical issues with the current approaches. \n2) Authors give very detailed justification of their choices, give details of experiments which will be helpful for other researchers to build on. \n\nWeaknesses: \n1) The proposed approach still has some practical issues (e.g. how does one decide the divergence threshold, how does one make sure that 3-step procedure benchmark OCL-PDS is applicable to real world problems? \n2) The final takeaway is not clear. Authors should discuss some of the real world problems and give some conclusions based on it. It is not clear what part of the discussion is helpful if a real world practitioner wants to use any of the knowledge in the paper. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is clearly written. There is novelty but author's claim that their method is more practical is not justified. ",
            "summary_of_the_review": "\n1) From Appendix B, one can understand why divergence should be asymmetric. But from the example given, it looks like one needs structured asymmetry. Is just having asymmetry enough? \n\n2) Figure 1: It is not clear what distribution shift we are talking about in \"FMoW-WPDS benchmark.\" Are most images in 2002 of prison? Are most images in 2009 of Helipads? \n\n3) Section 2.3: Work is also very related to domain generalization (DG) which is a harder problem compared to domain adaptation (DA) [1]. If one wants to be truly \"online\" then one DG might be a better setting than DA? Authors should add more discussion comparing and contrasting with DG too. \n\n4) In general, real world datasets do not have shift continuity. Or there could be too much non-stationarity. How would ODD check or shift continuity check work in that case?\n\n5) How does one decide threshold on Div (D_t || D_t+1)? In the real world dataset, this could be even harder to determine. \n\n6) I checked the hyperparameters considered In Table 14(in appendix). But the list of hyperparameters tuned does not look complete. The training data generation (domains, dist shift and threshold on div for continual shift) should be treated as hyperparameters too. Can authors comment more on this? \n\n\n\n\n[1] Blanchard, Gilles, Aniket Anand Deshmukh, \u00dcrun Dogan, Gyemin Lee, and Clayton Scott. \"Domain generalization by marginal transfer learning.\" The Journal of Machine Learning Research 22, no. 1 (2021): 46-100.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper966/Reviewer_FxrK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper966/Reviewer_FxrK"
        ]
    }
]