[
    {
        "id": "cP_Zgmfld_",
        "original": null,
        "number": 1,
        "cdate": 1666811537693,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666811537693,
        "tmdate": 1666811537693,
        "tddate": null,
        "forum": "ULzyv9M1j5",
        "replyto": "ULzyv9M1j5",
        "invitation": "ICLR.cc/2023/Conference/Paper6520/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a symbolic regression algorithm that uses a transformer backbone to learn a new feature extractor via joint supervised learning mechanism. The ill-posed problem mentioned in the paper was addressed by using the joint supervised learning mechanism combining supervised contrastive learning, which strengthens the similarity of feature vectors from the same skeleton. Experiments were done to prove the efficacy of the method.\n",
            "strength_and_weaknesses": "This paper is motivated by a practical issue. I like the idea of using the supervision of the whole expression skeleton and the supervision of the preorder traversal of its expression tree in contrastive learning (maybe with data augmentation) to deal with the case that different instances of the same skeleton can have very different shapes, and instances of very different skeletons can be very close.\nThe authors did extensive experiments, the presented algorithm performs very well on the benchmark dataset.\nThe paper has covered a wide range of related work.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to follow and straightforward. The novelty is not significant as it is a basic combination of contrastive learning and Transformers. The implementation is not hard but it works well.",
            "summary_of_the_review": "This paper proposes a good approach to tackle the symbolic regression problem. Although the presented algorithm seems to be a combination of contrastive learning and Transformers, its performance on benchmark data sets looks good. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6520/Reviewer_jvHV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6520/Reviewer_jvHV"
        ]
    },
    {
        "id": "6uu49vb_G-",
        "original": null,
        "number": 2,
        "cdate": 1667139390893,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667139390893,
        "tmdate": 1667139390893,
        "tddate": null,
        "forum": "ULzyv9M1j5",
        "replyto": "ULzyv9M1j5",
        "invitation": "ICLR.cc/2023/Conference/Paper6520/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a transformer-based method for symbolic regression using a new feature extractor and a joint supervised learning mechanism.  They evaluated the framework on synthetic datasets and compared it with several baseline methods. Experimental results show good performance of the proposed framework. ",
            "strength_and_weaknesses": "Strength: \n\n1. The problem is interesting. \n2. The proposed framework achieves good results. \n\nWeakness:\n\n1. It would be better if the authors could further clarify the potential application of symbolic regression. \n2. It is unclear to me why the authors adopt a point cloud-like feature extractor (like PointMLP). It seems that the tackled problem is a special regression problem, so why not use 1D convolution or directly use a transformer to handle it? Also, there are some works tackling tabular data, like TabNet. The authors should further clarify the motivation of network design. \n3. Since the proposed framework was trained and evaluated on the same synthetic dataset. There may be overfitting problems. The authors should discuss this point. ",
            "clarity,_quality,_novelty_and_reproducibility": "The whole paper is well-written and proposes a new solution for an interesting problem.",
            "summary_of_the_review": "This is a good paper to tackle an interesting problem. While the potential application of the proposed technique and method design should be further clarified. The technical novelty of this paper seems limited.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6520/Reviewer_dp8W"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6520/Reviewer_dp8W"
        ]
    },
    {
        "id": "C7HVQNs2Oa",
        "original": null,
        "number": 3,
        "cdate": 1667417924064,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667417924064,
        "tmdate": 1667417924064,
        "tddate": null,
        "forum": "ULzyv9M1j5",
        "replyto": "ULzyv9M1j5",
        "invitation": "ICLR.cc/2023/Conference/Paper6520/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a novel transformer-based model for symbolic regression (SR), which produces mathematical expression skeletons from data points. In the proposed method, a feature extractor using pointMLP is added and jointly trained using contrastive loss to realize efficient training. The experimental evaluation using benchmark functions demonstrates that the proposed method exhibits higher recovery rates and R2 scores compared to existing SR methods.",
            "strength_and_weaknesses": "**Strengths**\n* Introducing the idea of feature extractor and contrastive learning into the transformer-based symbolic regression model is convincing. Although each component of the proposed method was previously proposed in the context of other tasks, incorporating such methods into the SR model seems to be novel.\n* The numerical experiment supports the effectiveness of the proposed method.\n\n**Weaknesses**\n* In the experiment, the same dataset is used for training and testing. I am not confident whether such a setting is reasonable. From the machine learning perspective, the obtained model should be evaluated on test datasets.\n\n**Comments**\n* It would be nice if the proposed method was evaluated using recent benchmark datasets such as SRBench (https://github.com/cavalab/srbench).\n* In Figure 2, the redder color might indicate the cosine similarity is closer to **0**.\n* How is the computational cost of the proposed method compared to other SR methods?",
            "clarity,_quality,_novelty_and_reproducibility": "* This paper is well-written. The motivation and contribution are easily understood.\n* Although the components of the proposed method are existing ideas, introducing such promising techniques into the transformer-based SR model is novel.\n* The code is provided and the detailed setting of the experiment is reported.",
            "summary_of_the_review": "Basically, this paper is well-written, and the motivation and contribution are clear. The effectiveness of the proposed method is supported by the numerical evaluation.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6520/Reviewer_eWWS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6520/Reviewer_eWWS"
        ]
    }
]