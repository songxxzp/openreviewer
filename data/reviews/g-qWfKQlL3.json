[
    {
        "id": "j6PBgx_jDaT",
        "original": null,
        "number": 1,
        "cdate": 1666112297286,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666112297286,
        "tmdate": 1666112297286,
        "tddate": null,
        "forum": "g-qWfKQlL3",
        "replyto": "g-qWfKQlL3",
        "invitation": "ICLR.cc/2023/Conference/Paper3247/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a continuous normalizing flow architecture that is invariant to input permutations, which is useful for modelling densities of object _sets_. Authors design an equivariant dynamics function by only modelling point-wise and pair-wise interactions. Using this dynamics function with an invariant base distribution (like a standard normal) makes the modeled density permutation invariant. Authors evaluate the proposed flow on a set of synthetic and real tasks.",
            "strength_and_weaknesses": "Strengths:\n- The paper is of high quality and reads well. The introduction and background are particularly well done.\n- The studied problem is important: modeling densities of sets is useful across a set of applications.\n- Experiments on both pedagogical/synthetic and real datasets. Well-made figures and visualizations.\n- Ablation experiments that study the role of the components of the proposed dynamics function.\n\nWeaknesses:\n- The novelty of the work is not clear to me. Prior work has considered both pairwise interactions and attention-like mechanisms (Kohler et al., 2020; Bilos et al., 2021) to build permutation invariant flows. What is the fundamental difference between the proposed method and prior work? If there is one, it is not made crystal clear in the paper.\n- In line with the previous point, I'd expect the discussion of related methods to be deeper, and go beyond the claims that prior methods are evaluated on different objects (graphs), have additional invariances built in, or do not condition on side information (which is not difficult to do).\n- Additional, non-generative baselines for the bounding box prediction problem would help put the results in a broader context.\n- A single permutation invariant normalizing flow baseline is used for the traffic scenes problem: could additional baselines have been used?\n\nQuestions:\n- Have you considered/experimented with standard neural network regularization methods (L1/L2, dropout, etc.) as an alternative to the regularization scheme proposed in section 2.3?\n- Have you quantified the computational costs of the method? How do they compare to the baselines?",
            "clarity,_quality,_novelty_and_reproducibility": "Excellent clarity and quality. Novelty is questionable, as discussed above. Good reproducibility: the appendix provides extensive experimental details.",
            "summary_of_the_review": "I (weakly) recommend rejecting the paper in its current form. While the manuscript is excellent, the novelty of the work is not clear to me. I would be happy to increase my rating if the authors clarified this, and updated the text accordingly.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3247/Reviewer_YVfE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3247/Reviewer_YVfE"
        ]
    },
    {
        "id": "PBALsrKyP_C",
        "original": null,
        "number": 2,
        "cdate": 1666652936985,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666652936985,
        "tmdate": 1666654097038,
        "tddate": null,
        "forum": "g-qWfKQlL3",
        "replyto": "g-qWfKQlL3",
        "invitation": "ICLR.cc/2023/Conference/Paper3247/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a permutation invariant conditional normalizing flows based on a continuous version of graph normalizing flows. The proposed model is evaluated on the tasks of generating realistic traffic scenes and bounding box prediction.",
            "strength_and_weaknesses": "Strengths:\n\n1. The paper is well organized and well written.\n2. Experiment results show strong performance of the model.\n\n\nWeakness:\n\n1. The technical novelty of the paper is very limited. Graph normalizing flows and its continuous versions have been studied[1, 2]. The permutation equivariance/invaraince property of normalizing flows has also been studied before [3]. Clearly, the work is just an interesting application of existing models to set data. Moreover, the transformation of the continuous normalizing flow being used in the work is actually equivariant instead of invariant. What is invariant is the density. The title and the naming of the model are misleading. The author should be more precise about their contributions.\n2. Bounding box prediction results given the image are deterministic; it is not a conditional generative task. I\u2019m not fully convinced this is a good task to study a conditional normalizing flow model.\n\n[1] Deng, Zhiwei, et al. \"Continuous graph flow.\" arXiv preprint arXiv:1908.02436 (2019).\n\n[2] Xhonneux, Louis-Pascal, Meng Qu, and Jian Tang. \"Continuous graph neural networks.\" International Conference on Machine Learning. PMLR, 2020.\n\n[3] Bilo\u0161, Marin, and Stephan G\u00fcnnemann. \"Scalable normalizing flows for permutation invariant densities.\" International Conference on Machine Learning. PMLR, 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "I have no concerns for the correctness, clarity and quality of the paper. The technical novelty of the paper is very limited. Please refer to strength and weakness for more details.",
            "summary_of_the_review": "The paper is well written and experiment results demonstrate the proposed conditional permutation invariance normalizing flows. However, the technical novelty of the proposed work is limited and the claims of contributions should be more precise.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3247/Reviewer_VEu3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3247/Reviewer_VEu3"
        ]
    },
    {
        "id": "q0aUA7rAld3",
        "original": null,
        "number": 3,
        "cdate": 1666675205312,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666675205312,
        "tmdate": 1666675205312,
        "tddate": null,
        "forum": "g-qWfKQlL3",
        "replyto": "g-qWfKQlL3",
        "invitation": "ICLR.cc/2023/Conference/Paper3247/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes a continuous normalizing flow model, an exact likelihood generative modeling method, which is conditional and permutation invariant.  The flow is driven by dynamics computed from a shared global force term and a pairwise interaction term which have shared weights across all elements thus achieving permutation equivariance in a similar manner to DeepSets or a message-passing NN over a fully connected graph.    The model is tested over two toy datasets involving box placement and more realistic datasets involving traffic scene generation and bounding box placement.  The dataset outperforms non-permutation invariant baselines in the traffic scene generation experiment in both NLL and domain relevant metrics.  ",
            "strength_and_weaknesses": "## Strengths \n- The proposed method is simple and well-explained.  The need for permutation-invariance is well motived in the examples (allows generalization to different numbers of objects, avoids matching loss) and mathematically reasonable as inductive bias (it avoid makes arbitrary ordering decisions).  The addition of conditioning is also well motivated in the examples.  For example, in the traffic generation case, it is clear that map information will be relevant to the car location distribution.\n- The traffic scene experiment is pretty thorough including several non-equivariant baselines.  The results are convincing that permutation-equivariance is useful for the task.  Moreover, the results show good generalization over the number of cars.  The ablation shows the usefulness of the different global force term and pairwise interaction term and the analysis is insightful in noting the utility of each for staying on the road and not colliding.  I think the domain-relevant metrics are useful here. \n\n\n## Weaknesses\n- The effect of the efficient divergence computation in 2.2 and regularization in 2.3 are not evaluated in the experiments. \n- It would nice to have a permutation-equivariant baseline for the traffic scene generation task.  For example a non-flow based method. \n- It's not clear if the non-equivariant baselines in traffic scene generation are trained with ample data augmentation. \n- The bounding box prediction experiment has some potential issues.  There are no baseline comparisons here.  Only IOU is presented and with no variance.  Also, it is a bit of a strange task given that the target distribution is a point and so the fit distribution only represents uncertainty.  However, no serious evaluation of how well the model capture uncertainty (calibration, e.g.) is done.  On the plus side, this experiment does show the method can work with real world data. \n- It would be good to have some quantitative / qualitative evaluation on sample diversity and coverage.\n\n## Questions \n- The velocity term is simple, but seems quite constrained.  Are there potential issues with expressivity given this simple form imposed by equivariance and the fact the flow dynamics give a diffeomorphism of the space?  Even if theoretically expressive, could the flow dynamics have trouble fitting certain kinds of distributions from certain priors?\n- Can you say more the about the motivation to generate traffic scenes?   It's not completely clear to me how it is useful. \n- Can this method be applied to high-dimensional modeling with many objects or high-dimensional object features?  For example, could it be used for trajectory prediction with 100 objects? \n- Although this method is not specialized for it, could it be used for and compared to methods that generate point clouds or graphs? \n- For table 1 (b), I didn't fully understand the Data column.  What does \"6-4\" mean? \n\n## Minor Points \n- I would write $v_{\\theta,i}(x)$ on the line after equation (9). \n- Caption in Fig. 2 described the right two panels as \"to avoid the\". Should it be \"to bound the\"?\n- Page 6, Para 2, Line 5, typo \"flow flow\"\n- I liked the guessing game in figure 1.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Very clear paper.  The method appears to be novel based on comparison to related work (I may not be aware of other related work.)  While most of the elements have appeared before (or very similar) the combination is new.  No code is provided, although the method and experiments are clearly described and most experiments are performed on publicly available data.  ",
            "summary_of_the_review": "I felt the method was well-described, straightforward, and wholly suited to the a range of tasks where conditioning and permutation-invariance are useful properties.  The experimental results support the value of incorporating these features.  Overall, the weaknesses are largely minor and addressable.  (I'd probably opt for 7 if available, so I'll be conservative for now, but would be happy to upgrade my score if no serious concerns are raised.)  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3247/Reviewer_g69S"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3247/Reviewer_g69S"
        ]
    }
]