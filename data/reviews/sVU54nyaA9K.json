[
    {
        "id": "8WHhe952M9",
        "original": null,
        "number": 1,
        "cdate": 1666329891631,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666329891631,
        "tmdate": 1666329891631,
        "tddate": null,
        "forum": "sVU54nyaA9K",
        "replyto": "sVU54nyaA9K",
        "invitation": "ICLR.cc/2023/Conference/Paper2765/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies inhomogeneous adversarial linear mixture MDPs. It presents an efficient algorithm called LSUOB-REPS which provably achieves $\\tilde{\\mathcal{O}}(d S^2 \\sqrt{K} + \\sqrt{HSAK})$. The algorithm relies on occupancy measure based techniques, which maintains a confidence set of the unknown transition function and runs online mirror descent over the space of occupancy measures. One novelty is the construction of a specific linear regression objective function to solve for the transition parameter. To this end, this paper proposes to use an imaginary next state to construct the regression target. Furthermore, a lower bound of order $\\Omega(dH\\sqrt{K} + \\sqrt{HSAK})$ is proven, which shows that the algorithm has close-to-optimal performance. ",
            "strength_and_weaknesses": "Strength:\n\n1. This paper gives the first answer to a quite challenging problem, i.e., the adversarial linear MDPs. Both an upper bound and a lower bound (under certain assumptions) are given.\n\n2. The paper is very well-written. This is a very technical paper. Techniques are presented with rather detailed explanations, making it easier for the readers to follow.\n\n3. The paper has some novelty. The technical challenges are also discussed quite thoroughly, showing the technical contributions of the paper clear. For example, the imaginary next-state seems like a quite interesting idea to deal with the challenge of constructing a confidence ellipsoid when the classical self-normalized concentration technique cannot be directly applied. \n\n---\nWeakness: \n\nThere is no major weakness as far as I can tell. There are some comments though. \n1. The dependence of the upper bound on $|S|$ is unpleasant under the linear mixture MDP setting. \n\n2. The paper lacks a very detailed comparison with [1]. Although it seems that [1] studies tabular MDPs which is different from linear mixture MDP, the major idea of algorithmic design is very similar. Furthermore, in the case of representing a tabular MDP by a linear mixture MDP, we would have a relation $d = |S|^2 |A|$. In this case the bound in this paper would actually be worse than that of $1$ (but I can understand this since representing a tabular MDP by a linear mixture is inefficient. Still a more detailed comparison would be good to have).\n\n3. There is no discussion on computational efficiency of the algorithm, so it might be inappropriate to call the algorithm \u2018efficient\u2019.    \n\n[1] Jin, Chi, et al. \"Learning adversarial markov decision processes with bandit feedback and unknown transition.\" International Conference on Machine Learning. PMLR, 2020.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: This paper is clear in general.Theorems have no ambiguity to me. Technical challenges and the corresponding solutions are described clearly. Related work is also discussed properly with now ambiguity. \n\n\nQuality: The quality is good. This is a purely theoretical paper and the theorems are solid. The proof feels correct to me, though I did not check all the details. \n\nNovelty: The paper is novel. The technical contributions, e.g. how to construct the confidence set of the transition parameter in the adversarial setting; how to choose the imaginary next state; are all good ideas in my opinion.\n\n\nReproducibility: This is purely theoretical work with no empirical result. The proof looks reproducible to me as it is written clearly and not very hard to read.  \n",
            "summary_of_the_review": "My current recommendation is accept. \n\nThe reasons are the following:\n\n1. Solid contribution: this paper gives the answer to a quite challenging and important field of reinforcement learning theory. \n\n2. Some novelty: to solve certain technical challenges, some novel ideas have been proposed.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2765/Reviewer_ZddW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2765/Reviewer_ZddW"
        ]
    },
    {
        "id": "MbVSr4dmEH",
        "original": null,
        "number": 2,
        "cdate": 1666485642742,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666485642742,
        "tmdate": 1666485642742,
        "tddate": null,
        "forum": "sVU54nyaA9K",
        "replyto": "sVU54nyaA9K",
        "invitation": "ICLR.cc/2023/Conference/Paper2765/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies adversarial linear mixture MDPs with unknown transition and bandit feedback. The authors propose an algorithm with an upper bound $\\tilde{O}(dS^2 \\sqrt{K} + \\sqrt{HSAK})$, and prove an almost near-matching lower bound (in $d, K, A$). The authors highlight the use of a novel occupancy measure difference lemma for linear mixture MDPs, which might be of independent interest.",
            "strength_and_weaknesses": "Strengths:\n\n(+) The upper bound is accompanied by a near-matching lower bound. The authors also justify the dependence on $S$ and $A$ via the lower bound.\n\n(+) The use of a novel occupancy measure difference lemma (Appendix B.1).\n\nWeaknesses:\n\n(-) The bound depends on $S$, which is unusual and undesirable given the linear mixture MDPs assumption.\n\n(-) The writing can be improved, especially the main results.\n\nDetailed comments:\n\n- I am familiar with statistical RL theory, but not so much in the adversarial setting. Hence, I will comment more on the writing/correctness aspects of the paper rather than the novelty/contribution.\n\n- (main concern) Since the upper bound in Theorem 1 has a dependence on both $S$ and $A$, would this be just the tabular setting? I don\u2019t quite understand where the linear approximation comes in when we still have the dependence on $S$.\n\n- I encourage the authors to make it more explicit which elements are novel, particularly in your algorithm design. For example, how does your proposed algorithm differ from Jin et al. (2020b)?\n\n- The main results (Theorem 1 and 2) should be made more detailed and self-contained. I encourage the authors to at least briefly introduce the settings and various relevant notations in the Theorems.\n\n- The lower bound contains a term $dH\\sqrt{K}$, which is linear in the horizon $H$. However, the upper bound only has a $\\sqrt{H}$ dependence. Would this lead to a contradiction, or am I missing something here?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is generally well-written and easy to follow. The literature review and comparison with existing works are sufficient.\n\nNovelty: The analysis in the paper is sufficiently novel. The analysis utilizes a novel occupancy measure difference (Lemma 2), which is a non-trivial extension from Jin et al. (2020b). Although the tightness of Lemma 2 is unknown, it may be of independent interest and useful for the community.  \n\nSummary Of The Review: The paper studies adversarially linear mixture MDPs. The main results are interesting with a relatively novel analysis. However, the implications of the main results are unclear: what did we gain from the linear MDPs assumptions if the upper bound still depends on $S$?\n",
            "summary_of_the_review": "The paper studies adversarially linear mixture MDPs. The main results are interesting with a relatively novel analysis. However, there is little innovation in the algorithm design, and the implications of the main results are unclear: what did we gain from the linear MDPs assumptions if the upper bound still depends on $S$?",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2765/Reviewer_Buht"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2765/Reviewer_Buht"
        ]
    },
    {
        "id": "mBgYmHbttk",
        "original": null,
        "number": 3,
        "cdate": 1666594699267,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666594699267,
        "tmdate": 1666604541827,
        "tddate": null,
        "forum": "sVU54nyaA9K",
        "replyto": "sVU54nyaA9K",
        "invitation": "ICLR.cc/2023/Conference/Paper2765/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers the adversarial linear adversarial MDP and proposes the first efficient algorithm that achieves $\\sqrt{K}$ bound. Moreover, they also give a lower bound. Their techniques are based on the occupancy measurements which is initially proposed by Jin et al. (2020b). Compared to previous techniques, this paper adopts some nontrivial extensions, the main one, as stated in the paper, is the use of a carefully chosen \" imaginary next state\", which solves the dependence between the actual next states and thus allows the usage of regular linear regression to estimate the $\\theta$",
            "strength_and_weaknesses": "Strength: The results are significant. The techniques seem novel to me -- (1) the use of \" imaginary next state\" is novel (2) the further improvement on H, S compared to Jin et al. (2020b) seems also interesting (but it is not very clearly stated)\n\nWeakness: Some of the technique contributions are not clearly stated in the paper.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall well-written and easy to read. But as I mentioned above, I feel there are some technical novelties that are not clearly explained in the main paper. Specifically,\n\n1\\ When talking about how to choose the next state in Eqn.(2), the author also mentioned: \" for some technical reasons\". But from my perspective it is not that trivial, my understanding is that it is like some \"implicit exploration\", choosing to maximize the most uncertain states? I would like to see a little more discussion on that.\n\n2\\ In remark 2, you said that \"it is not a straightforward extension, even given the transition estimator obtained using the imaginary next-states.\" So my understanding is that, besides the imaginary next-states techniques, there are some other techniques that help you to further shave the dependency. I would like to see some discussion in the main paper.\n\n3\\ I personally think section 4.2 can be more concise since it basically gives a summary of the existing standard techniques.\n\n\n",
            "summary_of_the_review": "Overall I think it has good results and relatively novel techniques. But the explanation of some techniques seems not very clear to me. So I give 6 and would like to raise my score if I can better understand the novelty of the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2765/Reviewer_knov"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2765/Reviewer_knov"
        ]
    },
    {
        "id": "ypxCYit04B_",
        "original": null,
        "number": 4,
        "cdate": 1667409111475,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667409111475,
        "tmdate": 1667409184881,
        "tddate": null,
        "forum": "sVU54nyaA9K",
        "replyto": "sVU54nyaA9K",
        "invitation": "ICLR.cc/2023/Conference/Paper2765/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "\n\nThe paper studies RL in linear mixture MDP with unknown transition, adversarial loss, and bandit feedback. This paper gives the first algorithm in this setting whose regret scales with sqrt(#episode) and supplements a lower bound, which matches the upper bound for the $d$ and $K$ dependency, where $K$ is #epsiode and $d$ is the ambient dimension of the linear mixture MDP. ",
            "strength_and_weaknesses": "\n### Strength\n\n1. This paper studies a reasonable setting of \"adversarial\" RL with linear function approximation, and designs and proves the first algorithm with sqrt(K) regret. \n2. This paper goes beyond the classical VTR (value-targeted regression) framework of analysis for linear mixture MDP, coming up with a novel technique (imaginary roll out of state) to cope the challenge arouse in adversarial setting.\n\n### Weakness\n\n1. There are many settings of linear RL theory besides linear mixture MDP, such as linear MDP. Also, recently, there are unified framework such as Bellman-rank and bilinear classes for RL with general function approximation. In particular, these frameworks include linear mixture MDP as their special cases. While the theory of RL with function approximation is certainly an important topic, it could become much less important when the scope is restricted to linear mixture MDP.\n2. This paper does not prove tight lower bound to complete the theoretical research in their setting.\n",
            "clarity,_quality,_novelty_and_reproducibility": "\nThe writing is clear and of good quality. No apparent typos are noticed.",
            "summary_of_the_review": "\nThis paper contains some novel results and techniques, but it could be made better if the authors could come up with more complete results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2765/Reviewer_1UrW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2765/Reviewer_1UrW"
        ]
    }
]