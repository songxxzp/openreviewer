[
    {
        "id": "Owh4PI2x3u",
        "original": null,
        "number": 1,
        "cdate": 1666367088960,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666367088960,
        "tmdate": 1670584379440,
        "tddate": null,
        "forum": "j3mm8mci4u",
        "replyto": "j3mm8mci4u",
        "invitation": "ICLR.cc/2023/Conference/Paper1845/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "The paper analyzes the convergence of policy gradients on I/O unstable problems, in particular unstable LQR problems. Under a variety of assumptions, the authors claim to proof an bound on the learning rate, related to the largest spectral eigenvalue of the dynamics matrix of LQR. Experiments show that a log mapping of the objective stabilizes gradient descend on LQR's policy matrix K.",
            "strength_and_weaknesses": "I have to admit that I did not understand this paper. In particular, I cannot say how realistic Assumption 3.2 is, and how Theorems 3.14 and 3.15 proof stability. However, the experimental results look good, even though I find it hard to say how general they are.",
            "clarity,_quality,_novelty_and_reproducibility": "The connection with the LQR controller could be better clarified for a less involved audience. The paper motivates the use of LQR controllers, but then seems to prove theorems that are more general. \n\nI also did not understand how the theoretical insights (for example the log-transformation) are translated into Algorithm 1 and 2. Alg.2 seems to be gradient descend on standard LQR, whereas Alg.1 seems to do something similar for general differentiable transition functions some additional spectral norm regularization. However, it is not clear to me how this is related to the convergent guarantees of the theorems above.",
            "summary_of_the_review": "I admit that I was not able to follow the paper. I am uncertain whether this is the fault of the paper or mine. While I recommend to reject the paper, I am happy to change my mind if more qualified reviewers think the paper deserves publication.\n\n**Post-rebuttal**\n\nI thank the authors for their attempt to explain their paper, but I still feel that I do not understand the paper enough to give a certain recommendation. Due to this uncertainty I retain my previous recommendation to reject the paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1845/Reviewer_1dw6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1845/Reviewer_1dw6"
        ]
    },
    {
        "id": "0BVT35M-ki",
        "original": null,
        "number": 2,
        "cdate": 1666601861316,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666601861316,
        "tmdate": 1666601861316,
        "tddate": null,
        "forum": "j3mm8mci4u",
        "replyto": "j3mm8mci4u",
        "invitation": "ICLR.cc/2023/Conference/Paper1845/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focuses on the gradient-based optimization for a special branch of RL problems. Due to the unstable nature of the system, small deviation leads to exponentially growing effects on the state\nevolution trajectory and the reward/cost function, which raises issues for gradient-based optimizations. The authors proposed two methods to alleviate the effect of instability and their effectiveness is validated from\nboth theoretical and experimental points of view.",
            "strength_and_weaknesses": "Overall, the paper seems to contain interesting results. \nSome comments to improve the paper are summarized below:\n1) For an MDP with finite and discrete state and action spaces, the stable MDP is not clear. \nOnly for MDPs with continuous state and action spaces, that are main focus of the paper, stability is meaningful. \nIn abstract and introduciton, the system is not clearly indicated, and hence, it is very confuzing at the beginning on what stability means for MDPs.\nTherefore, it would be better to indicate that the system is an MDP with continuous spaces at the beginning. \n2) In assumption 3.2, it is not clear what is the basis function. In the explanation after assumption 3.2., it says that || A-BK||^2 corresponds to \\phi. \nHowever, || A-BK||^2 is scalar number, while \\phi needs to span the function space. This discussion seems to be unreasonable. \n3) The convergene results in Theorem 3.9 and Theorem 3.10 are not clear. It is not clear why the inequality leads to convergence. Some improvement of presentation may be needed.\n4) It would be better to indicate earlier in section 3.2.2. that the results are all for deterministic settings.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper seems to include novel results. \nThe presentation needs to be improved as mentioned in the previous comments.",
            "summary_of_the_review": "This paper focuses on the gradient-based optimization for a special branch of RL problems.\nOverall, the paper seems to contain interesting results. \nThe presentations need to be improved as mentioned in the previous comments. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1845/Reviewer_tyRg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1845/Reviewer_tyRg"
        ]
    },
    {
        "id": "JaZEfDJZOR",
        "original": null,
        "number": 3,
        "cdate": 1666604863082,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604863082,
        "tmdate": 1668889559254,
        "tddate": null,
        "forum": "j3mm8mci4u",
        "replyto": "j3mm8mci4u",
        "invitation": "ICLR.cc/2023/Conference/Paper1845/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper considers gradient descent algorithms for computing a parameter of the optimal policy according to a possibly unstable trajectory of a Markov decision process. It is shown that under technically strong assumptions such as continuity, convexity, and smoothness, the rates of convergence will be linear, assuming that the horizon is short enough. ",
            "strength_and_weaknesses": "I like the general idea of the paper; it has an understandable approach and puts forward an interesting and to some extent important problem. The writing in most of the manuscript is acceptable, but some improvements help. The technicalities seems based on strong assumptions though.\n\nThe deterministic nature of the dynamics restricts applicability of the approach to data-driven problems. Also importantly, in case of randomly or adversarially disturbed dynamics, the stabilization needs to be different since other than the initial state, the innovation can cause instability. Although the authors claim that the method is applicable to disturbed dynamics, the analysis does not seem so. Further, the existing literature of learning-based stabilization is not covered (enough). The setting and analysis of the GD does not seem innovative and seems a little artificial. The enumeration looks strange. In some places the language is not articulate enough, e.g., in Lemma 3.7. \n\nThe technical assumptions, e.g., 3.3 and 3.4, are a little restrictive and seem consequential. So, I think further justifications and intuitive arguments are needed. Importance of the main results Thm 3.9 and 3.10 are not clear, and it is also unclear what technical difficulties need to be addressed to obtain them. Finally, considering the step size upper bounds, applicability of the algorithms to only small time horizons renders the framework limited in the sense that the step size will be so small that the method will have no superiority to other learning based stabilization approaches, even if it is somehow applicable. \n\nThe edits the authors provided in the resubmitted version do not seem adequate. I suggest the authors to do further rewrites and to go deeper for proving interesting results.",
            "clarity,_quality,_novelty_and_reproducibility": "See above.",
            "summary_of_the_review": "I prefer to give the authors a chance to see how they can convince the reviewers that their paper is interesting, important, and innovative. \n\n--------------------------------\npost rebuttal: this reviewer carefully read the rebuttal and updated the review. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1845/Reviewer_xiDA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1845/Reviewer_xiDA"
        ]
    }
]