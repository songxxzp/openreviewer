[
    {
        "id": "tPCTXdBG0xi",
        "original": null,
        "number": 1,
        "cdate": 1666546904476,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666546904476,
        "tmdate": 1668872036279,
        "tddate": null,
        "forum": "38m4h8HcNRL",
        "replyto": "38m4h8HcNRL",
        "invitation": "ICLR.cc/2023/Conference/Paper5714/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper develops a federated neural contextual bandit algorithm FN-UCB which extends existing neural contextual bandits to the federated setting. The key idea of FN-UCB is that it adopts a weighted combination of two UCBs, where the first UCB allows every agent to additionally use the observations from the other agents to accelerate exploration, while the second UCB uses an NN for reward prediction. In theory, the regret bound of the proposed method is proved and its superior advantages are compared in extensive experiments.  \n",
            "strength_and_weaknesses": "Strength:\n\n1. The paper is well written and is very easy to follow.\n\n2. The considered federated neural bandit problem is interesting.\n\n3. Extensive experiments demonstrate the practical usefulness of the proposed algorithm. \n\n\nWeaknesses:\n\n1. Technical novelty: My major concern is its technical contribution beyond existing literature. The proposed federated neural bandit is a natural combination of neural bandit (Zhou et al., 2020; Zhang et al., 2021; Kassraie & Krause, 2022) and federated learning (Wang et al., 2020). Because of this nature, the algorithmic development and theoretical analysis were largely based on these two areas. In particular, a large part of the proof is to verify conditions used in Zhou et al. (2020) and Zhang et al. (2021). Based on my personal opinion, the technical novelty of this paper beyond these references is not strong. \n\n\n2. Limitation in the current theory: There is a major gap in the theoretical results. The derived main theorems is not for the proposed FN-UCB, but for a simpler version where they only choose the weight $\\alpha$ using the proposed method in the first iteration after every communication round and set $\\alpha = 0$ in all other iterations. This simpler version requires communication to occur after each iteration, which clearly contradicts with the communication complexity shown in Theorem 2. Since the balance of $\\alpha$ is a key novelty of the considered problem, it would be more convincing to derive the theoretical results for the proposed FN-UCB directly. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: It is easy to follow.\nQuality and Novelty: OK, but not strong.\nReproducibility: The proof is detailed and the code is provided. \n\n",
            "summary_of_the_review": "The considered federated neural bandit is a natural combination of neural bandit and federated learning. The idea is very natural and the technical novelty is OK but not strong. Moreover, the current theoretical results only hold for a simpler version of the proposed FN-UCB (require communication in each iteration). \n\nIn the rebuttal stage, I would like to see more justifications on the technical novelty beyond existing neural bandit and federated learning, as well as an improved analysis for the general FN-UCB algorithm.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5714/Reviewer_H38q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5714/Reviewer_H38q"
        ]
    },
    {
        "id": "lqPDjlAbwD",
        "original": null,
        "number": 2,
        "cdate": 1667109015952,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667109015952,
        "tmdate": 1667109015952,
        "tddate": null,
        "forum": "38m4h8HcNRL",
        "replyto": "38m4h8HcNRL",
        "invitation": "ICLR.cc/2023/Conference/Paper5714/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This research examines contextual bandits in a federated learning environment. This is the first study applying federated learning to neural contextual bandits. The author(s) proposed the FN-UCB algorithm, which is shown to suffer from sub-linear regret and communication rounds. Both synthetic and real-world experiments confirm that the newly proposed algorithm performs competitively against the baselines.",
            "strength_and_weaknesses": "Strength\n* This author(s) are the first to use neural netorks (NNs) in the setting of federated contextual bandits. Given that NNs have high representational capabilities, this opens up the possibility of more extensive real-world applications.\n* The proposed algorithm, FN-UCB, has superior empirical performance that has been confirmed through extensive experiments in addition to theoretical assurance.\n\nWeaknesses\n* Although the author(s) have provided empirical experiments to demonstrate the proposed algorithms with multiple agents outperforms the baselines with single agent in practice, how efficient the suggested algorithm is is still unknown. It might be better if the author(s) could provide the lower bound.",
            "clarity,_quality,_novelty_and_reproducibility": "Since this is the first work to apply NNs in a federated framework, the work appears novel. The proposed algorithm and supporting evidence seem solid to me, and the paper is well-written.",
            "summary_of_the_review": "This author(s) are the first using neural netorks (NNs) in the setting of federated contextual bandits. Although the proposed algorithm may not be optimal, due to the NNs' powerful representational capabilities, broader real-world applications may be possible. Hence I suggest accept.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I do not have any concerns.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5714/Reviewer_f21Q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5714/Reviewer_f21Q"
        ]
    },
    {
        "id": "I0JNjW2XCyX",
        "original": null,
        "number": 3,
        "cdate": 1667340325332,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667340325332,
        "tmdate": 1669359007516,
        "tddate": null,
        "forum": "38m4h8HcNRL",
        "replyto": "38m4h8HcNRL",
        "invitation": "ICLR.cc/2023/Conference/Paper5714/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work is analysing a new setting in which a set of multiple Neural Bandits are collaborating to minimize the regret for an online sequential decision problem. The authors provided an algorithm combining the feature of federated learning and neural bandits, with sublinear regret and communication cost. Finally, the authors demonstrate the capabilities of the developed methods with an experimental campaign.",
            "strength_and_weaknesses": "Overall the paper is clear and well-structured. The algorithm is easy to understand and properly analysed.\n\nMy only concerns are the experimental results provided by the authors, which somehow are not feeding each one of the analysed algorithms with the same number of samples at each round.\n\nDetails:\nI would like you to discuss the results you obtained w.r.t. the federated bandit setting and the neural bandit ones. I think this would highlight how the elements of the regret and communication complexity change by the fact that you are using the combination of these two settings.\n\nFor instance, I would like to have the expression of the bound on the regret when you are considering only local information and comparing them with the ones you have in Theorem 2.\n\nWith N=1 agents does the regret of Theorem 2 become the one of Neural Bandits? Overall, you should discuss more on the difference between Neural Bandits and your algorithm with N=1.\n\nIn the first experiment (5.1) I think that the comparison is not fair. In this case, you are receiving two samples, while standard algorithms are receiving only one realization of the reward. However, similar comments are also holding for the second experiment.\n\n\n\n\nMinor:\nPlease move the legend outside the figures, otherwise, they are hard to read.",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper is clear and well-structured. The algorithm is easy to understand and properly analysed.",
            "summary_of_the_review": "The paper is sound and interesting, but some concerns about the experimental part should be addressed by the authors.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5714/Reviewer_D1SJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5714/Reviewer_D1SJ"
        ]
    },
    {
        "id": "rwjWbpzU1I",
        "original": null,
        "number": 4,
        "cdate": 1667531065868,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667531065868,
        "tmdate": 1667531065868,
        "tddate": null,
        "forum": "38m4h8HcNRL",
        "replyto": "38m4h8HcNRL",
        "invitation": "ICLR.cc/2023/Conference/Paper5714/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose a novel federated neural contextual bandit algorithm to tackle the richer structure of rewards that conventional linear/kernel approaches may not handle. Regret bounds for the proposed algorithms are derived and experimental results show the efficacy of the proposed algorithms on both synthetic and real-world experiments. \n",
            "strength_and_weaknesses": "Pros: \n     (A) The proposed algorithm is a combination of two UCBs one of which is focused on exploration based on the neural tangent features. This has a higher weight\nduring the initial iterations. The second UCB kicks in once the neural networks are sufficiently trained and this corresponds to the exploitation phase. There is a\n nice explanation between these two phases. Combined with the regret guarantees over the iterations and communication rounds, they provide a good understanding and\n solution of the neural contextual bandit problem. \n     (B) Extensive set of experiments where they switch off one of the UCBs gives us a good understanding of the individual components (ablation study). Also, the\nperformance based on setting of D as well the number of agents is explored. \n\nCons:\n\n   (i) It was not fully clear on how alpha was set in the experiments? Section 3.3 describes the intuition as well as the mathematical formula for it but the experiments talk about a linear function. Any insight into this would be helpful. Also, the regret is analyzed for the setting where alpha=0 after first iteration. However, the experiments use non-zero alpha. \n   (ii) Are there experiments which show the scaling with N or dtilde? It would be interesting to know how tight these bounds bound are and could serve as a proxy for lower-bounds for the setting. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear with proof sketches for the main results. The problem setting incremental in the sense it is a natural extension of existing works but is sufficiently challenging and interesting to study.  Also, the main algorithms are shown in the paper and should be easily replicated.",
            "summary_of_the_review": "Overall, an interesting extension on the neural contextual bandit setting in the federated context. Some questions remain and I hope to discuss with the authors to clarify my understanding.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5714/Reviewer_oNap"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5714/Reviewer_oNap"
        ]
    },
    {
        "id": "xmIrU-nWok",
        "original": null,
        "number": 5,
        "cdate": 1667767626378,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667767626378,
        "tmdate": 1669507607736,
        "tddate": null,
        "forum": "38m4h8HcNRL",
        "replyto": "38m4h8HcNRL",
        "invitation": "ICLR.cc/2023/Conference/Paper5714/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the federated bandits with neural networks under the NTK regime. Theoretical regret analysis and experimental results are provided to show that the proposed algorithm could fully leverage the neural networks in the federated bandit setting.",
            "strength_and_weaknesses": "### Strength\n\n- This paper is well-written and easy to follow. The experiment is adequate and the proof is mathematically correct\n\n### Weakness\n\n- It seems that the major contribution made in this paper is combining the neural UCB and neural TS [1, 2] with federated bandits. The author might want to highlight their contributions and difficulties in this combination\n- The claim on communication cost is somehow ambiguous. The authors suggest that by using the *Less Comm.* version of the algorithm, the communication cost could reduce to $O(p)$. However, the performance impact by 1) using the averaged covariance matrix $V$ instead of $V_i$ and 2) using the diagonal elements to approximate the matrix $V$, is not well studied either from a theoretical perceptive or empirical perceptive. \n\n[1] Zhou, Dongruo, Lihong Li, and Quanquan Gu. \"Neural contextual bandits with ucb-based exploration.\" International Conference on Machine Learning. PMLR, 2020.\n[2] ZHANG, Weitong, et al. \"Neural Thompson Sampling.\" International Conference on Learning Representations. 2020.",
            "clarity,_quality,_novelty_and_reproducibility": "- [+] This pape is well-written and easy to follow. I did not find any reproducibility issues here.\n- [-] The novelty of this paper is somehow limited, especially given the neural UCB and neural TS paper and the bunch of federated bandits paper.",
            "summary_of_the_review": "This paper is overall interesting and well-written. My major concern is the technical novelty of this paper as discussed above. Given this, I am on the borderline of rejection. \n\n\n***\n\nThe author's response addressed some of my questions. Thus I raise my score accordingly",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5714/Reviewer_cGE9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5714/Reviewer_cGE9"
        ]
    }
]