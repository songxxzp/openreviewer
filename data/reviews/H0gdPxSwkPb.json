[
    {
        "id": "2y0Xa7ovUf",
        "original": null,
        "number": 1,
        "cdate": 1666602201679,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666602201679,
        "tmdate": 1666602305646,
        "tddate": null,
        "forum": "H0gdPxSwkPb",
        "replyto": "H0gdPxSwkPb",
        "invitation": "ICLR.cc/2023/Conference/Paper3075/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a self-supervised vessel segmentation method with denoising diffusion model and adversarial training. The proposed method separates the image background and vessel by learning the representation of background images with diffusion model. The main contribution is the combination of diffusion model and generation model for self-supervised vessel segmentation.",
            "strength_and_weaknesses": "Strengths: \n--proposed an effective vessel segmentation method composed of diffusion and adversarial training.\n--Obtained a significant improvement of vessel segmentation both on X-ray coronary angiography and fundus images.\n\n\nWeaknesses: \n--the innovation is limited. Diffusion and adversarial are the common approaches, but the authors have not claimed why they can together? In addition, the main dear of this work is cycle reconstruction. It is also common.\n\n--the motivation and writing are unclear. The authors claim that diffusion is employed to learn background image distribution, but the relationship between background distribution and vessel representation is not presented clearly.\n\n--The details of the model and implements are missed. Such as how to train path A and B simultaneously? How to switch SPADE?\n\n--The method may be hard to implement\n\n--It seems that path A of x^a and path B x^b are trained independently. How to make the training consistent?\n\n--In the experiments, the fundus image is introduced. But for training, how to obtain the real noisy background image?",
            "clarity,_quality,_novelty_and_reproducibility": "the originality is there, but novelty and clarity are limited.",
            "summary_of_the_review": "the proposed method seems effective and interesting, but the writing is unclear, and some details are missed.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3075/Reviewer_yNNg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3075/Reviewer_yNNg"
        ]
    },
    {
        "id": "GtuuN4O3yJQ",
        "original": null,
        "number": 2,
        "cdate": 1666629115263,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666629115263,
        "tmdate": 1666629115263,
        "tddate": null,
        "forum": "H0gdPxSwkPb",
        "replyto": "H0gdPxSwkPb",
        "invitation": "ICLR.cc/2023/Conference/Paper3075/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a diffusion adversarial representation learning (DARL) model, for self-supervised vessel segmentation. The major novelty appears to be the usage of a diffusion module for estimating latent features, which are then used by a generation model to estimate both vessel segmentation masks and synthetic angiograms, through switchable spatially-adaptive denormalization (SPADE) layers.\n\nThe estimated output depends on the input, which admits two paths: Path A accepts a real, noisy angiography image, and estimates the vessel segmentation mask (the main task). Path B accepts a real noisy background image and a vessel-like fractal mask, to generate a synthetic angiography image that attempts to incorporate vessels corresponding to the input fractal mask. The synthetic angiography images can then be forwarded through Path A to apply cycle consistency within the LSGAN framework. Experiments are done on the public XCAD datasets, and external XCA datasets, and also applied to out-of-domain retinal imaging datasets. DARL was shown to outperform both unsupervised baseline methods, and recent self-supervised methods such as STEGO, DA and SSVS.\n",
            "strength_and_weaknesses": "Strengths:\n\n1. Novel application of diffusion towards task-and-noise robust vessel segmentation.\n\n2. Ablation experiments performed to quantify contributions of various modules/losses.\n\n3. Extensive comparisons against other self-supervised and unsupervised methods.\n\n4. Additional experiments described in appendix.\n\nPossible Weaknesses/Considerations:\n\n5. The nature of the background angiography images might be explained further, as readers may not be familiar with the particular task. Are these background images obtained in the same way as the vessel images, just from areas without blood vessels? If so, should their background distribution be expected to be similar to the areas with blood vessels?\n\n6. Some of the most obvious/natural comparisons might not have been attempted. In particular, the inclusion of the diffusion module appears for the estimation of latent features. However, such an estimation of latent features appears doable with an (auto)encoder, possibly with fully-connected layers for both the encoder and decoder within. The support for the DDPM diffusion model for estimating the latent features thus might not be fully established.\n\n7. Similar to the above, the quality of the synthetic angiography/vessel segmentation images produced by the generation module does not appear benchmarked against state-of-the-art GANs for common metrics such as Inception score etc.\n\n8. Moreover, once synthetic angiography images are generated from corresponding (fractal) vessel masks in Path B, the image-vessel mask pairs should constitute acceptable training data for common image segmentation models (e.g. U-Net and variants; i.e. Type B Ground Truth). The same applies to the estimated vessel masks from Path A (i.e. Type A Ground Truth). The specific contribution of the proposed DARL framework might thus be clarified.\n\n9. For the experiments, it might be clarified as to whether any (global) image preprocessing (e.g. CLAHE) was applied. Unsupervised methods would appear particularly disadvantaged without such normalization.\n\n10. The quality of the vessel segmentations appears possibly sensitive to the fractal masks as generated by the fractal synthetic module (from Ma et al., 2021). In particular, the correlation between the (distribution of) thicknesses of the fractal vessels and the actual vessels in the synthetic angiography images, appears critical towards achieving good IoU scores. Was there any attempt to match true vessel thickness distributions, or to optimize the predicted vessel thicknesses against ground truth?\n\n11. For the ablation study in Section 4, it might be explained in greater detail how the model works without the diffusion module, i.e. what the inputs/data flow is then like, possibly in the appendix.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed DARL framework is generally clearly described, and the network architecture specified in the appendix. The incorporation of diffusion for latent feature estimation in this context appears largely novel. Network architecture details are provided in the appendix, and the datasets used are public.\n",
            "summary_of_the_review": "The proposed DARL framework introduces a diffusion module towards self-supervised vessel segmentation exploiting cycle consistency. Segmentation results appear superior to other recent approaches, and robust across input noise and specific task.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A\n",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3075/Reviewer_xqnu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3075/Reviewer_xqnu"
        ]
    },
    {
        "id": "EEmRZSj7gE",
        "original": null,
        "number": 3,
        "cdate": 1666636082281,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666636082281,
        "tmdate": 1666636082281,
        "tddate": null,
        "forum": "H0gdPxSwkPb",
        "replyto": "H0gdPxSwkPb",
        "invitation": "ICLR.cc/2023/Conference/Paper3075/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a self-supervised technique for vessel segmentation based on a combination of a denoising diffusion probabilistic model and adversarial learning. The network uses contrast and non-constrast images of vessels and uses the non-contrast images to learn a distribution of the background that is then used to identify the foreground vessels. The approach is evaluated for vessel segmentation in X-ray coronary angiography using two datasets and for retinal vessel segmentation using the DRIVE and STARE datasets in comparison to 6 other recent methods.",
            "strength_and_weaknesses": "Strengths\n---------\n- Addresses the important and relevant problem of vessel segmentation with limited supervision.\n\n- The approach makes sense and seems to show convincing results.\n\n- Novel use of diffusion models for self-supervised learning.\n\n- Results appear to be a good deal better than state of the art.\n\n\nWeaknesses\n----------\n- The method appears to rely on both contrast and non-contrast images and this could limit the usability of the approach as not all usecases have both. Perhaps the authors could clarify the importance of this requirement and limitation in the paper?\n\n- I find it unclear what amounts of labelled and unlabelled data is used for the self-supervised experiments. Could the authors clarify this? Unsupervised and self-supervised learning is mostly relevant if it can be used to achieve clinically relevant results with fewer labels. The results reported on the DRIVE and STARE datasets do not seem particularly convincing compared to what has been reported by supervised techniques. I would find it relevant to discuss this and compare to fully supervised methods.\n\n- Another potential problem with relying on both contrast and non-contrast images is that differences between the modalities are actually a quite large source of signal for these problems. Of course one can claim that this source of information is in some sense free from supervision, but to make the comparison with the other methods more fair, perhaps it would make sense to comment on the degree the other methods can actually exploit this information as well.\n\n- The increasing training complexity of the two adversarial networks is used as an argument against Ma et al. in the Introduction. Is there any concrete evidence of this being a drawback in comparison to the proposed work? What is the training complexity of these approaches? For comments like that to be supported, I would expect measurements of FLOPS or similar.\n\n- Figure 2 legend do not describe the content with enough detail. What are all the variables, subscripts and superscripts?\n\n- \"Experimental results show that our method outperforms existing unsupervised and self-supervised learning methods in the absence of labeled data for training.\". I find a good argument for including exactly these methods as comparison methods to be lacking. Could the authors justify why these methods are a good representation of the state of the art?\n\n- \"most unsupervised methods fail to endure drastic performance degradation when they are applied to vessel segmentation tasks.\", are you sure this is what you mean to say?\n\n- No code repository makes it hard to reproduce.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- I don't find the writing particularly clear and had to read it a few times to understand the details. While this may just be a reflection of this reviewer's intellect, I would appreciate attempts at making the meaning clearer.\n\n- The quality could be improved a bit by clarifying experimental details (see above) and further discussion of limitations and the relevance of the results as requested above.\n\n- As far as I am aware this is novel work and I am interested in trying it out myself.\n\n- I am not sure the experiments are easy to reproduce. There is no mention of code repository and given my difficulties in understanding the work, I am not convinced I could reproduce it exactly.\n",
            "summary_of_the_review": "I have put this as marginally above the acceptance threshold based on the above reasons, but I think the manuscript could be strengthened quite a bit by going over the writing.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3075/Reviewer_qGAg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3075/Reviewer_qGAg"
        ]
    },
    {
        "id": "_eXdMb1dKvP",
        "original": null,
        "number": 4,
        "cdate": 1666755138635,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666755138635,
        "tmdate": 1666755138635,
        "tddate": null,
        "forum": "H0gdPxSwkPb",
        "replyto": "H0gdPxSwkPb",
        "invitation": "ICLR.cc/2023/Conference/Paper3075/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents a DDPM based method for vessel image synthesis and segmentation. The idea is to train one base DDPM for both tasks, using a switchable SPADE as a means for incorporating the dfferences between these two tasks. Further, the DDPM is trained in a self-supervised manner. Experiments on the benchmark datasets, including both vessel and non-vessel datasets, demonstrate that the proposed method is effective and achieve better performances that competing SOTA methods.",
            "strength_and_weaknesses": "Strength:\nGood writing and easy to follow. Decent novelty. Solid experiments\uff08but with the below weaknesses)\n\nWeaknesses:\n\nThe paper claims a fully self-supervised manner for learning the model. In fact, for the segmentation path A that takes an image as input and outputs the segmentation mask, the adversarial loss is used on the mask output. Practically speaking, this is a bit uncessary as the real segmentation masks are used in the loss function. For each real segmentation mask, it comes with a real input image. Therefore, it is possible to conduct supervised training at least for this path.  I am afraid that the good performances in fact arises from this part.\n\nThere are two experiments that can can be done to verify the effectiveness of the proposed method.\n1) Change the path A to a fully supervised one while keeping the path B unchanges and then  compare with fully supervised segmentation approach\n2) Change the output masks of path A to synthetic masks.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is written clearly.\n\nNovelty: The key idea appears novel to me. While the idea of buiding one base model with switchable componets to deal with multiple tasks is not unseen, doing so in the context of DDPM is new.\n\nReproducibility: The paper is easy to understand but may be not so easy to reproduce without the codes. \n\nQuality: The paper is of high quality with good motivation, decent novelty, and solid experiments.\n",
            "summary_of_the_review": "Overall, the paper is of high quality with good motivation, decent novelty, and solid experiments. The experiments should be augmented with new results to make the paper even stronger. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3075/Reviewer_dTPf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3075/Reviewer_dTPf"
        ]
    }
]