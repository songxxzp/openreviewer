[
    {
        "id": "U6SdcLNhnRa",
        "original": null,
        "number": 1,
        "cdate": 1666449472545,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666449472545,
        "tmdate": 1666449472545,
        "tddate": null,
        "forum": "NnHz2rU0Hjp",
        "replyto": "NnHz2rU0Hjp",
        "invitation": "ICLR.cc/2023/Conference/Paper4648/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper presents a general masking strategy for visual representation learning with siamese neural network architectures. The approach is applicable to CNN-based or ViT-based neural networks.\nIt consists in pre-processing the input with a high-pass filter and then doing different augmentations that mask out parts of the input images with a certain probability, inspired from the natural language processing domain.\nExperimental results have been applied to different baseline models, notably to SimCLR and BYOL, and show an improved performance using the pre-trained models for image classification on ImageNet, and transfer lerning for classification, detection and instance segmentation on other datasets.\n",
            "strength_and_weaknesses": "Strengths:\n- Good experimental results\n- Genericity of the approach\n\nWeaknesses:\n- The description of the approach is unclear at some places\n- Some of the results are not clearly presented\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper lacks some clarity in the explanations, and also the results are not clearly presented.\n\nMore specifically:\n- What is the effect of the high-pass filter on the performance with non-masked images?\n- There may be other ways of masking without introducing spurious edges.\n- Figure 4 is not clear. What do you mean by \"off-the-shelf ConvNet encoder\"? The joint embedding loss is not detailed. Some details are missing on how the different (positive/negative) pairs are formed (within the batches).\n- The relation to Assran et al. (2022) and Baevski et al. (2022) is not clear. Can MSCN be applied to ViT architectures (and be compared to MSN)?\n- The text in section 6.1. states that the approach performs slightly worse for BYOL but from Table 1 this seems not to be the case.\n- For Table 2, what is the task and dataset?\n- It is not obvious how to interpret and read Table 4, and what to conclude. The underlining is somewhat arbitrary and confusing.\n- The standard deviations are not presented in the results tables. I presume the results correspond to only one run.\n\n",
            "summary_of_the_review": "The presented method is interesting and relatively novel although largely inspired from other papers using masking. The results show the benefit of the proposed approach for self-supervised representation learning with general siamese neural network architectures. But the presented results lack some detail and rigor.\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4648/Reviewer_Kw3b"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4648/Reviewer_Kw3b"
        ]
    },
    {
        "id": "VoTScmkUCF",
        "original": null,
        "number": 2,
        "cdate": 1666553872093,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666553872093,
        "tmdate": 1669325175355,
        "tddate": null,
        "forum": "NnHz2rU0Hjp",
        "replyto": "NnHz2rU0Hjp",
        "invitation": "ICLR.cc/2023/Conference/Paper4648/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a pre-processing method to enable the masking strategy available for siamese networks with ConvNet backbone under self-supervised settings. It is motivated by performing random masking would cause missing information and parasitic edge issues. Also, systematic masking strategies are studied, including noisy mask, channel-independent mask (RGB), focal mask, and asymmetric augmentation. Extensive experiments on various tasks are conducted, including semi-supervised classification in IN-1K, transferred image classification results on iNaturalist and Places-205, and object detection & instance segmentation on VOC & COCO. The results show consistent improvements in combining the proposed processing method, high-pass filter, and masking strategies.",
            "strength_and_weaknesses": "This paper makes the masking strategies available for convolutional-based siamese networks for SSL. The color histogram and convolutional visualization observation about the masking augmentation causing missing information and parasitic edges are interesting. The systematic studying of masking strategies can offer a way for other researchers to follow. Overall the paper is very easy to follow.\n\nThe experiments are conducted thoroughly, including various tasks (semi-supervised classification, transferred image classification, object detection, and instance segmentation) and datasets (IN-1K, iNaturalist, Places-205, VOC, and COCO). Results show the proposed method helps the standard SSL methods achieve higher performance. The related ablation studies are included to prove the effectiveness of different masking strategies. \n\nThe proposed preprocessing method may reduce the information in the image, which will cause the performance drop. In the current manuscript, all the comparisons include both the preprocessing methods and the comprehensive masking strategies; the reviewer is not clear if the preprocessing method brings improvements or masking strategies bring improvements. It would be better to test SimCLR, SimCLR + MSCN, BYOL, and BYOL + MSCN performance with simple/standard masking strategies. \n\nHow does the proposed processing method change the color histogram and learned convolution kernels, as shown in Figure 1? Since the proposed method is motivated by those observations, it would be more self-contained to include the updates once introducing the new methods. ",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity is good due to the simplicity of the proposed method and tricks. Also, it should be easy to replicate the results. Regarding the novelty, the reviewer is unsure if all the proposed components meet the bar of ICLR and need to discuss with other reviewers and the AC. ",
            "summary_of_the_review": "The reviewer feels that all the empirical studies presented in this paper will likely benefit the relevant community. However, the proposed masking strategies still heavily involve human priors. Also, the reviewer is unsure if the improvements come from introducing the preprocessing method or the hybrid masking strategies. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4648/Reviewer_29aC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4648/Reviewer_29aC"
        ]
    },
    {
        "id": "HoSkU599r5",
        "original": null,
        "number": 3,
        "cdate": 1666603111337,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666603111337,
        "tmdate": 1666603111337,
        "tddate": null,
        "forum": "NnHz2rU0Hjp",
        "replyto": "NnHz2rU0Hjp",
        "invitation": "ICLR.cc/2023/Conference/Paper4648/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "\nSummary:\nThis paper explores solving the masking augmentation problem in convolutional neural networks. This topic is very important. The authors' method is also very clever. However, unfortunately, its performance is not satisfactory. Moreover, it does not solve the more important problem of masking image modeling. Therefore, this article is a borderline article, leaning towards being rejected. If the authors can answer my important questions, I will consider raising the rating. If this article can solve the problem of masking image modeling, I will give it a high score.\n",
            "strength_and_weaknesses": "\n(Positive) The subject studied in this paper is important. Exploring the role of masking as augmentation in self-supervised learning of convolutional networks is encouraged.\n\n(Positive) After analysis, the authors believe that convolutional networks cannot correctly ignore the null information of masked areas through the attention mechanism like VIT. This is very reasonable.\n\n\n(Positive) The authors argue that masking brings artificial edges, which will hurt the learning of convolutional neural networks. This is very reasonable.\n\n\n(Negative) When the authors discuss Siamese networks, their formulation ignores the commonly used and very important projectors in SSL algorithms. Please add a projector to the formulation.\n\n(Positive) Regarding the principles that augmentation needs to adhere to in self-supervised learning, the author's conclusion is correct: Preventing easy solutions is very important; the augmentations are hoped to be class-aware.\n\n\n(Positive) The authors use high-pass filtering to suppress the null information in the masked area, which is very clever.\n\n\n(Positive) The authors use high-pass filtering to suppress artificial edges, which is also very clever.\n\n\n(Negative) However, in the masking strategy, the author uses a noisy mask. I think this contradicts the motivation of the authors. We all know that noise masks, especially Gaussian noise, bring a lot of high-frequency signals. High-pass filtering preserves these signals. The authors claim that this kind of noisy mask is useful, isn't that slapping one's own face?\n\n\n(Positive) The Channel-Independent Mask proposed by the authors is a bit interesting.\n\n(Negative) The caption \"Few-shot Semi-supervised Learning on ImageNet-1K\" in Table 1 is misleading. Also included here is an evaluation of the very important linear probing in SSL. Please modify this caption.\n\n\n(Negative) The proposed method has obvious gains on SimCLR. But the gain is not obvious on BYOL.\n\n(Negative) The application of the proposed method in ViT even leads to performance degradation, which is very worrying.\n\n(Negative) In the Object detection and instance segmentation tasks, the authors are missing one of the most important comparison objects, which is the baseline on which the authors' method is based. I'm guessing it could be BYOL or SimCLR. Given that the authors' method doesn't gain much, I'm worried that the authors' method won't outperform this baseline.\n\n\n(Negative) The authors have repeatedly emphasized that masking is the most general augmentation. This is worrying. This expression is too subjective.\n\n\n(Negative) In fact, the biggest challenge of Masking augmentation in convolutional networks is masked image modeling. Unfortunately, after reading the whole article, I found that the authors' method does not solve this problem. This is quite disappointing for readers.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "\nThe quality and clarity are median. The originality is good.\n",
            "summary_of_the_review": "\nSee \"Summary Of The Paper.\" This article is a borderline article, leaning towards being rejected. If the authors can answer my important questions, I will consider raising the rating. If this article can solve the problem of masking image modeling, I will give it a high score.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "\nThere is no ethics concern.\n",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4648/Reviewer_nzgE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4648/Reviewer_nzgE"
        ]
    }
]