[
    {
        "id": "3tcLXbw0-c",
        "original": null,
        "number": 1,
        "cdate": 1666443564034,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666443564034,
        "tmdate": 1666443564034,
        "tddate": null,
        "forum": "mMaInr0r0c",
        "replyto": "mMaInr0r0c",
        "invitation": "ICLR.cc/2023/Conference/Paper4388/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors proposed a method for implicitly learning continuous face-varying dimensions, without the need of asking an annotator to explicitly categorize a person. The result can be used in auditing datasets for diversity. The authors also proposed FAX, a novel dataset of 638,180 face similarity judgments over 4,921 faces. This dataset can be of interest for researchers from multiple disciplines.",
            "strength_and_weaknesses": "Strength: \n\nThe presentation of this paper is clear. The design of the dataset and the experiment is introduced in great details. \n\nThe authors have provided detailed supplementary materials to support the main paper. \n\n\nWeakness:\n\nIt is not very clear to me how the proposed method is used for auditing dataset diversity, and how well/effective such audition will be, in terms of boosting the performance of related computer models. I wonder the correlation between human perceptual face similarity and objective machine classifications. \n\nThe previous studies on face similarity should be mentioned and discussed, for example, the following papers:\n\n\nSomai, Rosyl S., and Peter JB Hancock. \"Exploring perceived face similarity and its relation to image-based spaces: an effect of familiarity.\" Journal of Vision 21.9 (2021): 2149-2149.\n\nSadovnik, Amir, et al. \"Finding your lookalike: Measuring face similarity rather than face identity.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. 2018.\n\nThe authors are honest in pointing out several limitations. The efficacy of this work is based on the hypothesis that the proposed stimuli set is sufficiently diverse and there is no ideal way to prove this. Perhaps the authors can tune down their claim a bit. \n\n It is not clear to me why the authors chose the \u201codd-one-out\u201d in triple group paradigm, though the authors have mentioned earlier work using the similar method. Why not use ranking, or \u201codd-one-out\u201d in a quadruple group?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper\u2019s presentation is clear. It is of good quality and originality. ",
            "summary_of_the_review": "The paper has good contributions, though its actual efficacy in real application is not very clear. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4388/Reviewer_r72x"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4388/Reviewer_r72x"
        ]
    },
    {
        "id": "eNOmJL2YnZ",
        "original": null,
        "number": 2,
        "cdate": 1666699244697,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666699244697,
        "tmdate": 1666699244697,
        "tddate": null,
        "forum": "mMaInr0r0c",
        "replyto": "mMaInr0r0c",
        "invitation": "ICLR.cc/2023/Conference/Paper4388/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a way to implicitly learn a set of continuous face-varying dimension with weak human annotations. By introducing a novel large-scale novel dataset, authors have shown the learned implicit face embeddings are human-interpretable and related to gender, race, age, as well as face and hair morphology categories. ",
            "strength_and_weaknesses": "Strength:\nThe proposed topic of human-centric face representation is interesting, and the dataset introduced in this paper will contribute to the community.\nWeakness:\nIn this paper, the proposed embedding is based on a weak human annotation (choose the person that looks least similar to the two other people, a.k.a, odd-one-out). How is the proposed embedding different from the self-supervised learning-based face embedding?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Writing is clear. Novelty is good. Not sure whether the author is going to release the proposed dataset or code.",
            "summary_of_the_review": "This paper introduces a way to learn human-centric face representations. By introducing a novel dataset with weak human annotation, the learned embeddings are proved to be human-interpretable and related to gender, race, age, as well as face and hair morphology categories. The proposed topic of will contribute to the evaluation of data diversity and the dataset introduced in this paper will contribute to the community. Therefore, I recommend this paper to be accepted. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4388/Reviewer_pZsn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4388/Reviewer_pZsn"
        ]
    },
    {
        "id": "PTNiRlKyjp",
        "original": null,
        "number": 3,
        "cdate": 1667288949994,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667288949994,
        "tmdate": 1667288949994,
        "tddate": null,
        "forum": "mMaInr0r0c",
        "replyto": "mMaInr0r0c",
        "invitation": "ICLR.cc/2023/Conference/Paper4388/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a new face representation learned from similarity judgments and contributes a novel annotation dataset with 4900 faces  (a subset of FFHQ dataset). The main purpose of this representation is to allow us to measure sample diversity without explicit annotations. In this context, the diversity is defined mainly on demographic basis, i.e. race, gender, and so on. The annotation was made on sample triplets where the annotators were asked to choose a least-similar example out of 3 samples. The representation is learned by maximizing the similarity between the other two examples, with an annotator-specific weight vector, which is also learnable. Experiments show that the representation captures important demographic dimensions such as race, gender and also other ones such as smile, which the authors tried to avoid to learn. ",
            "strength_and_weaknesses": "(+) Overall it's on an interesting and important topic.\n(+) The paper is relatively well written and lots of details are provided in appendix. \n(-) But I suggest to move important details to the main body, for example, how you estimate attributes to make intersectional groups to sample from FFHQ. It was not clear that the sample subset was balanced, which would be problematic because FFHQ is unbalanced. \n(+) New dataset and applicable model\n\n(-) My main reservation is validation. The paper shows many experiments, but everything from 3.1 - 3.5 is more of basic verification. Only 3.6 is about the demonstration of the utility of this dataset. As the primary contribution of this paper is a new dataset, I expect the authors show a lot more justifications on its usefulness than what was done in 3.6. \n\nMost experiments (especially 3.6) focus on showing that the learned representation (each dimension) corresponds to demographic attributes such as race and gender. This is not surprising. This doesn't make the proposed dataset useful. If we just do k-means clustering, you will also discover these groupings automatically. So why do we need these new annotations? Is the primary goal of this paper to discover gender, race, age without annotating them directly on target data? If so, I think there are much cheaper ways. Why don't we just use a classifier to estimate these labels? While the paper argues that they want to avoid this, but the way the proposed representation is used and validated is pretty much the same (i.e. it has separate dimensions for these attributes). In other words, this demographic information is not \"distributed\", so I don't know if this is very different from other classifiers. \n\nAlso, 3.6 only uses CC and CFD. Both are very clean datasets. Will this work for in-the-wild dataset such as fairface? \n\nAnother question is that the representation still captures non-sensitive attributes such as smiling. The authors explicitly tried to avoid this. But it's still learned, which means the annotators still used expression. \n\nOverall, I think the paper will benefit significantly from (1) having a clear discussion about how humans perceive and define similarity and (2) designing and performing evaluations aligned with that discussion. The current paper focuses only on gender, race, etc, and I don't see much benefit of this paper over explicit classifiers. \n",
            "clarity,_quality,_novelty_and_reproducibility": "See above. ",
            "summary_of_the_review": "I think this paper has a good potential and value. In my opinion, it's not fully demonstrated. In particular, Sec 3.6 needs to be expanded further. Competing baselines for this paper are not classifiers. I think they should be clustering, scaling, diversity sampling methods, etc. \n\nIn addition, I disagree with some statements like \"we do not encode, reify, or propagate stereotypes\". Even though the authors didn't ask the annotators to \"use\" stereotypes, there is no way to enforce it. The paper already shows that the annotators heavily relied on gender and race to define similarity. We categorize faces based on those dimensions. It's a known fact. (it may be interesting to show the amount of variance in annotations that can explained by gender age race) \n\nAlso, \"Implicit in these annotations is the assumption that human annotators can consistently and objectively map observable characteristics to categorical labels.\" -> there's no assumption like this in prior work. It is well understood that annotators are biased and subjective. That's why these annotations are almost always obtained from multiple annotators. In any case, I don't clearly see how this proposed method can be safe from these issues because again, the evaluation shows the annotators did use the same signals. This can be clarified better or toned down. On the other hand, there's a clear benefit to not annotate these attributes (legal, privacy issues). I think it may be better to focus on that direction in motivation. \n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4388/Reviewer_L52N"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4388/Reviewer_L52N"
        ]
    }
]