[
    {
        "id": "C_B1AwQ_RdQ",
        "original": null,
        "number": 1,
        "cdate": 1667028517049,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667028517049,
        "tmdate": 1667028517049,
        "tddate": null,
        "forum": "1DOS0kifqeP",
        "replyto": "1DOS0kifqeP",
        "invitation": "ICLR.cc/2023/Conference/Paper3460/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work introduces a new data structure based on a binary tree. Each node is split using PCA on the node data. With respect to existing data structure EMT are easier to learn in streaming tasks. The most similar work to EMT are CMT which have similar structure internally and pretty identical mechanism to route and score data. EMT differ in term of self-consistency guaranteeing such property. \n\nExperiments are performed on bandits as a use case for streaming tasks requiring a memory structure.\n\nEMT alone is not really competitive with respect to other mechanism on bandit problems, but the parametric variant is able to outperform many existing memory structures on most of the 206 tasks taken into consideration.\n\n",
            "strength_and_weaknesses": "Strengths\n- The analysis of memory properties is well executed and the algorithm motivation is clear\n- Code is provided for full reproducibility\n\nWeaknesses\n- Method is very close to CMT\n- The comparison is kind of limited given that modern libraries such as FAISS could be used for example",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written but could improve its visualization. Some visualization of the data structure, such as showing how data is partitioned by nodes (using some low-dimensional projection like t-SNE for example) could help the reader understand the inner working of the approach.",
            "summary_of_the_review": "The paper is clearly explained and the method has some interesting properties, unfortunately to outperform the competition the structure must be stacked with an existing parametric approach. Moreover the approach is also very close to CMT. Some other data structures, e.g. the plethora of indices in FAISS could be taken into consideration when performing the experiments.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3460/Reviewer_UauN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3460/Reviewer_UauN"
        ]
    },
    {
        "id": "-qWwX2YeQy",
        "original": null,
        "number": 2,
        "cdate": 1667097494900,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667097494900,
        "tmdate": 1667097494900,
        "tddate": null,
        "forum": "1DOS0kifqeP",
        "replyto": "1DOS0kifqeP",
        "invitation": "ICLR.cc/2023/Conference/Paper3460/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposes a novel episodic memory model for sequential learning, termed an Eigen Memory Tree (EMT). EMT adds to an important but under-studied topic in online learning: efficient online memory models. To evaluate the effectiveness of EMT, the authors tested 206 datasets from OpenML and compared with another online memory model, CMT, and a parametric CB learner. EMT outperforms CMT across the board, while outperforming parameters in 44 out of 206 datasets.",
            "strength_and_weaknesses": "Overall, the paper is well-written and easy to follow. The experimental results demonstrate that the proposed method is promising. The authors use fixed top-eigenvector routers, pairwise feature differences, and a loss function according to ranking in EMT, enabling CMT improvement.\n\nIn Section 4.5, even with an extremely conservative memory budget of 1,000 samples, PEMTCB only incurs a reward loss of 0.0075 on average. Very little memory can beat parametric methods in isolation. Is this conclusion related to the data set? If you can try the performance on these data sets~ (AmazonCat, Wiki10, Amazon [1]), the conclusion will be more convincing.\n\nA typo:\n1. \u201ceThe EMT incorporates two particular design decisions\u201d\n\n[1]. Jasinska-Kobus, Kalina, et al. \"Online probabilistic label trees.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow.",
            "summary_of_the_review": "See Strength & Weaknesses",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3460/Reviewer_RGJi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3460/Reviewer_RGJi"
        ]
    },
    {
        "id": "K31_oUpEcT",
        "original": null,
        "number": 3,
        "cdate": 1668046861919,
        "mdate": null,
        "ddate": null,
        "tcdate": 1668046861919,
        "tmdate": 1668046861919,
        "tddate": null,
        "forum": "1DOS0kifqeP",
        "replyto": "1DOS0kifqeP",
        "invitation": "ICLR.cc/2023/Conference/Paper3460/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes Eigen Memory Tree to serve as an efficient data structure for online memory. ",
            "strength_and_weaknesses": "Pros: potentially useful.\n\nCons: I am not convinced ICLR is the right place for this paper. While there is connection to machine learning, the key contribution of a more efficient and practical data structure should be evaluated by community who focus on such issues. I believe database would be a better venue. It is hard to evaluate such work in the context of ICLR without comparing to other similar data structures.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is fine. Similar data structures like K-D tree and trees using projection exist. I think this should be evaluated in such context which should be the focus of a different community. \n",
            "summary_of_the_review": "I don't think ICLR is the right venue for this paper.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3460/Reviewer_ibPD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3460/Reviewer_ibPD"
        ]
    }
]