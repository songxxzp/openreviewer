[
    {
        "id": "pfASZxU2rut",
        "original": null,
        "number": 1,
        "cdate": 1666561855082,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666561855082,
        "tmdate": 1666561855082,
        "tddate": null,
        "forum": "uYFRjvSJXbQ",
        "replyto": "uYFRjvSJXbQ",
        "invitation": "ICLR.cc/2023/Conference/Paper1937/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aimed to discover high-entropy alloys with high yield strength, by first predicting the yield strength. This work presented a dataset called X-Yield for this task and proposed a bi-level optimization method called Bi-RPT as their corss-quality few shot transfer workflow.",
            "strength_and_weaknesses": "This work is very well motivated. Discovering new materials is an important task in science and making sure a good predictor exists is a primary sub goal. \n\nTo make machine learning methods work on real world tasks is not trivial. The authors have done extensive analyses on the dataset and specialized the method that not only works on their task of interest, but also has the potential to be used for other transfer learning tasks that involves multi-fidelity. Preliminary results were shown on image data.\n\nThe main weakness that I see is that the authors only focused on the prediction accuracy, and mentioned nothing about the uncertainty predictions that would be critical to the subsequent experimental design task for new material discovery. I worry that when proceeding to the next step, the authors will have to redo their modeling because of this missing uncertainty prediction component.\n\nMoreover, since discovering new material with high yield strength is the task, I think it wouldn't be too much trouble for this paper to show some preliminary results on simulated new material discovery given their existing dataset. This will also avoid the issue on missing component in the modeling choice in the first place.\n\nAnother weakness is the lack of baselines and related work. Closely related works are not discussed, e.g. on multi-fidelity machine learning, domain adaptation and sim to real transfer. The followings are some I found with a quick search.\n\nhttps://www.sciencedirect.com/science/article/abs/pii/S0927025616306188\nhttps://www.sciencedirect.com/science/article/abs/pii/S0045782517307612\nCitations in https://en.wikipedia.org/wiki/Multifidelity_simulation\npapers mentioned in https://www.v7labs.com/blog/domain-adaptation-guide\nhttps://link.springer.com/chapter/10.1007/978-3-030-33950-0_25\nhttps://arxiv.org/pdf/2009.13303.pdf",
            "clarity,_quality,_novelty_and_reproducibility": "The paper has good clarity overall, except the method section (section 4). I had to read several times to get the gist. The problem here includes\n1. the use of sparse regularizers are not well motivated: there's recent success on those methods, but why using them here? \n2. Too many notations without a clear structure. Some notations, e.g. the dot operator introduced in Equation (1), theta, L_t, R, L_s did not seem to be formally defined. Some of these notations, e.g. theta was introduced before using them in equations.\n\nThis section is one of the most important parts in this paper and it needs to be better structured. Try writing a summary paragraph before introducing all these different methods, and always define the notations before using them.\n\nIt is difficult for me to assess the quality of the contributions on dataset since I don't have any background on material science. But the two parts of the dataset are already published so maybe that indicates a strong quality. The results of the new method look very good as it consistently outperform baselines. But at the same time, I think the baselines are rather basic here. I think it will be more convincing to at least add an experiment comparing to a multi-fidelity machine learning model, e.g. based on Bayesian linear regression.\n\nAs mentioned above, the proposed method does not provide any clarifications on how uncertainty can be predicted in their model, which is a big drawback on the quality of the method.\n\nThere is also a significant problem on novelty: the dataset is composed of subsets of simulated data from Maresca & Curtin (2020) and the high-fidelity data from Borg et al. (2020). I don't think the X-Yield dataset can be novel by directly combining two existing dataset. Can the authors clarify what exactly are the work done by them to create this dataset? Claiming it is the first multi-fidelity dataset for HEAs, in my view, touches on a grey area and raises concerns on plagiarism. \n\nAnother red flag to me is that the subsets were \"carefully filtered\" from the original data, raising a question of whether the test data are cherry picked. I hope the authors can clarify more on this issue.\n",
            "summary_of_the_review": "This paper brings a very interesting problem in material science to the machine learning community. However, given the technical issues and potential integrity problems, I cannot recommend acceptance at this point but encourage the authors to address those issues in the rebuttal so that it's possible for me to adjust the rating.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Legal compliance (e.g., GDPR, copyright, terms of use)",
                "Yes, Research integrity issues (e.g., plagiarism, dual submission)"
            ],
            "details_of_ethics_concerns": "The open sourced dataset consists of simulated data from Maresca & Curtin (2020) and the high-fidelity data from Borg et al. (2020). Please double-check the copyrights on using these data from existing work. \n\nDespite these sources, the authors claimed their dataset is novel: \"While there are existing experimental databases (Borg et al., 2020) and models to predict high-temperature yield strength in HEAs (Maresca & Curtin, 2020), to our best knowledge, this is the first multi-fidelity dataset in the public domain that combines real experimental measurements and large quantities (over 100K) of simulation data for mechanical property prediction in HEAs.\" In my opinion, this raises potential integrity issues that need to be further reviewed.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1937/Reviewer_THpP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1937/Reviewer_THpP"
        ]
    },
    {
        "id": "37Oza1qKRV",
        "original": null,
        "number": 2,
        "cdate": 1666687542801,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666687542801,
        "tmdate": 1666687542801,
        "tddate": null,
        "forum": "uYFRjvSJXbQ",
        "replyto": "uYFRjvSJXbQ",
        "invitation": "ICLR.cc/2023/Conference/Paper1937/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors proposed a large-scale material science benchmark with 240 experimental measurements and over 100K simulated high-entropy alloy yield strength annotations. To address the scarcity of experimental annotations and the quality gap in the imperfectly simulated data, the authors present a noise-robust feature learning regularizer at the pre-training stage, and as a data-efficient learning regularizer at the few-shot transfer stage. ",
            "strength_and_weaknesses": "Strength:\n1. This work presents a large-scale material science benchmark.\n2. This work presents a two-stage method to address the scarcity of experimental annotations and the quality gap in the imperfectly simulated data.\n\n\nWeaknesses: \n1. The simulated data would have much noise because of the gap between real and theoretical scenarios. How did you address this problem? Although the authors give a sparsity solution, it lacks theoretical analysis to explain its effectiveness.\n2. How did you tune the accurate sparsity in the paper? From tables A5-6, one could find that some sparsity rates are so specific.\n3. It is better to discuss this work with noisy labels. Why did you utilize the techniques of learning with noisy labels to address the noise?\n4. The utilized techniques are not originally proposed by the authors. These techniques have been widely used in other applications, which limits the novelty.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and easy to follow. Some techniques have been widely used in other applications, which limits the novelty.",
            "summary_of_the_review": "This work is interesting. However, some techniques have been widely used in other applications, which limits the novelty.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1937/Reviewer_NW7Q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1937/Reviewer_NW7Q"
        ]
    },
    {
        "id": "MblTOHcVC_",
        "original": null,
        "number": 3,
        "cdate": 1667001558574,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667001558574,
        "tmdate": 1667001558574,
        "tddate": null,
        "forum": "uYFRjvSJXbQ",
        "replyto": "uYFRjvSJXbQ",
        "invitation": "ICLR.cc/2023/Conference/Paper1937/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "- The paper targets determining yield strength for high entropy alloys which has numerous practical applications\n- The first contribution of the paper is to organize a large-scale material science dataset termed X-Yield. The dataset is composed of  >100K synthetic data points and 240 experimentally measured real data points.\n- Since there is a domain gap between the real and synthetic data, the authors propose a technique based on sparsity regularization to learn from source while adapting the model to the target data. ",
            "strength_and_weaknesses": "Strengths:\n- I like the problem setup, the applications of the proposed dataset and the approach are well motivated. \n- The paper proposes a new benchmark dataset for enabling machine learning research for HEA yield strength prediction.\n- I like the connections that the paper draws to few shot learning in the ML for science domain. \n- The paper proposes a technique for few-shot + domain transfer which is based on sparsity regularization. \n- The approach is fairly simple and potentially applicable elsewhere. The authors do verify that it works well compared to some simple baselines on a image based few-shot transfer task. \n- The experimental setup is sound and the proposed approach brings about improvements for the task at hand\n\nWeaknesses:\n- Baselines : The problem setup falls in the ML research areas of few-shot learning/cross-domain few shot learning, (supervised) domain adaptation/transfer learning. For example, refer to [a,b] These areas have been well studied and are very active areas of research. It is not clear why this particular approach was chosen, and how the approach compares to other popular approaches in these areas. \n- Section 3: It would help to add a table comparing the kinds of datasets that exist to supplement the Section 3.\n- Section 3: I found the construction of the real part of the dataset (in Dataset Construction) seems misleading - Till that point I was under the impression that both real and synthetic parts were contributions, but according to that paragraph the real part was curated from an existing one. Please explain how your subset is different. In my opinion the contributions should be adjusted as well. \n- What happens if you use the weight masking strategy without a two-stage approach ? How does that compare to the variants presented in Table 1 ? \n- Question : Given that only 11 elements were used, why encode this as an image - which is mostly sparse? \n- Question : Are all configurations of the selected elements realistic. What happens if the model is given an unrealistic combination ? \n- Suggestion : Please move \"Data representation\" above \"Architectures and Baselines\". I was not expecting a CNN-based model and it was not clear to my why that was used till I got to Data Representations. \n- Question : Fig. 3 : Is the drop in relative performance for 1273K due to less data in this regime ?\n\n\n\n[a] Guo, Yunhui, et al. \"A broader study of cross-domain few-shot learning.\" ECCV 2020\n[b] Zhuang, Fuzhen, et al. \"A comprehensive survey on transfer learning.\" Proceedings of the IEEE\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity : The paper is well written. Motivations are clear. \n- Quality : Selected approaches and baselines are well analysed. But, the paper missed out on other potential baselines common in the ML community. \n- Novelty : Borderline : The paper proposes a new dataset for use by the ML for material science community. The synthetic component is simulated. While reading it seems that the real component comes from an existing dataset. The approach used to train models is motivated from an existing one. \n- Reproducibility :  The authors provide a code\n ",
            "summary_of_the_review": "The paper proposes a new benchmark dataset which might be useful for the material science community. The paper is well written but I have a few concerns regarding baselines and novelty of the dataset. My initial rating is 6. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1937/Reviewer_iZzs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1937/Reviewer_iZzs"
        ]
    }
]