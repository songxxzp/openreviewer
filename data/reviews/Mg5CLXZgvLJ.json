[
    {
        "id": "Og6r_gB2szJ",
        "original": null,
        "number": 1,
        "cdate": 1666578059635,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666578059635,
        "tmdate": 1668889000862,
        "tddate": null,
        "forum": "Mg5CLXZgvLJ",
        "replyto": "Mg5CLXZgvLJ",
        "invitation": "ICLR.cc/2023/Conference/Paper2671/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this work, the authors improve the time efficiency of EfficientZero by dividing various computational elements across asynchronous nodes. Concretely, by splitting compute tasks (i.e., PER refreshing, Reanalyze/Rollouts, Gradient calcs) across different nodes which communicate asynchronously, the authors are able to massively increase overall data throughput.\n\nThis introduces issues with respect to data/priority staleness causing unstable learning, resulting in the introduction of Priority Refresh workers, which act to continuously refresh the priority weights of all data points in the buffer. They show this is addresses the issues induced by stale weights, and reduces variance across seeds.\n\nThe authors then show that with a given time budget, their method significantly out performs prior work on the Atari ALE benchmark. Some ablations are then presented showing the impact of removing/changing various components (such as Priority Refresh, batch size).",
            "strength_and_weaknesses": "Strengths:\n* The overall idea appears good, and creating asynchronous nodes makes sense when constructing effective compute strategies for model-based/off-policy approaches.\n* The proposed P-Refresh algorithm is simple but appears important in the high-throughput problem setting that the authors consider.\n\nWeaknesses:\n* I have several concerns with the experimental methodology of this work. \n    * The benchmarking does not appear to make sense; it would appear the only difference between the 30 and 60m SpeedyZero agents is the type of compute node used, yet the results (specifically the Median) appear vastly different. I would be willing to accept a difference if there was also a change in hyperparameters (for instance fewer rollout steps), but it appears the same algorithm was deployed in each case. This high variance is a concern as it is unclear how strong the performance really is. Weirdly enough, the authors appear to attribute the stronger performance of the 60m run to the slower machine: *\"...if SpeedyZero is allowed to run for 1 hour, it performs even better...\"*.\n    * Similarly, the EfficientZero algorithm is run on a different node altogether, which makes direct comparison hard. To my understanding, A100 GPUs run faster than the 3090 GPUs used on the EfficientZero cluster. As a higher note, it makes no sense that these algorithms were run on vastly different hardware, specifically given a key comparison is in their run times, so controlling for this would appear vital.\n    * Related to the initial point, the number of seeds seems very low. This may explain the extreme variance that we see across the 30 and 60m runs.\n    * It seems unfair to compare to other approaches when using 3x the data (300k v.s. 100k). A key factor behind using model-based approaches is precisely the sample-efficiency gains. I could buy an approach which aims to improve throughput for the purposes of real-life robotics (such as [1]) but this is not the case here. On a related note statements made are simply false: *\"SpeedyZero breaks the record on 12 out of 26 games in the Atari 100k benchmark\"*; this is clearly factually incorrect given the use of 300k steps.\n        * Given the priority on run-time, it therefore makes sense to compare performance at 300k steps against model-free approaches, which may be less sample-efficient, but should run faster than model-based methods. For instance, [2,3] should have publicly available code.\n        * In the interests of fairness, SpeedyZero with 100k datapoints should also be compared. This should run very fast (10 mins), and it may be possible to increase compute (e.g., number of updates) such that, while slower than the algorithm presented in the paper, may recover adequate performance.\n    * There are some issues with the language, and the authors should proofread their work again. Ones that I spotted:\n        * Notably, this phenomenon persists no matter we use distributed... -> Notably, this phenomenon exists when using either DPER or uniform sampling...\n        * We hypothesis -> We hypothesise\n        * paralleled -> parallelized\n        * reanalyze -> Reanalyze (since it is an algorithm); reanalyzers -> Reanalyze workers\n        * our model is tiny -> our model is small enough to fit onto a single GPU\n        * This suggests the superior -> This suggests the superiority\n\n[1] A Walk in the Park: Learning to Walk in 20 Minutes With Model-Free Reinforcement Learning, Smith et al 2022, arXiv:2208.07860\n\n[2] Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels, Yarats et al, ICLR21\n\n[3] Stabilizing Off-Policy Deep Reinforcement Learning from Pixels, Cetin et al, ICML22\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper appears fairly clear despite aforementioned proofreading issues, and I was easily able to identify the novelty and understand the methodology. Given the authors did not include code, the reproducibility is questionable, and I implore the authors to release the code when ready.",
            "summary_of_the_review": "Overall the paper presents an appealing idea, which is to improve the throughput of model-based methods, and shows promising results on the Atari benchmark. However, there are significant experimental shortcomings that I've listed above. Accordingly, in the event these are not addressed, I cannot recommend accepting the paper in its current form.\n\n---\n\nReviewers addressed some issues regarding experimental completeness, but questions still remain for me around reproducibility (as reflected in the commments).",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2671/Reviewer_Rw6q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2671/Reviewer_Rw6q"
        ]
    },
    {
        "id": "F-0zHXvywR",
        "original": null,
        "number": 2,
        "cdate": 1666656991532,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666656991532,
        "tmdate": 1668647835990,
        "tddate": null,
        "forum": "Mg5CLXZgvLJ",
        "replyto": "Mg5CLXZgvLJ",
        "invitation": "ICLR.cc/2023/Conference/Paper2671/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a distributed model-based RL algorithm building on MuZero/EfficientZero which is designed to reduce the wall-clock time required to train the agent. While EfficientZero is sample efficient, it still takes a long time to train. This work identifies and addresses several system-level inefficiencies, resulting in an algorithm called SpeedyZero which is evaluated on a modified version of the Atari 100k benchmark. \n\n\n\n\n\n",
            "strength_and_weaknesses": "Strengths\n- The problem this paper is addressing is an important one: model-based methods, while known to be more sample efficient than model-free ones, are also known to be significantly slower to train. Therefore, speeding up these methods  would be useful both for the research community and for potential applications. \n- The paper goes in depth into the system-level details of the algorithm, and identifies several inefficiencies, resulting in what seems like a very large speedup (10-20x) in wall-clock time\n\nWeaknesses:\n- A big problem with this work is that for some reason, they evaluate their algorithm with 300k steps from Atari, whereas previously published works use 100k (the standard). Therefore, despite the speed improvement, it's not at all clear how this algorithm does in terms of performance. I can't think of why this work would not use the standard 100k steps, unless the proposed algorithm would do worse than the others with 100k steps? This is very suspicious. I would suggest the authors use the standard 100k steps, and if they want to compare at 300k steps then they should rerun all the baselines at 300k as well. \n- The proposed improvements are very much system-level, and I believe it will be hard for this work to be of use to others unless the code is released. However, there is no mention of code release, and the paper does not include a checklist which addresses questions of reproducibility. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n- Medium-high. The paper is overall pretty well written. \n\nQuality:\n- Low. Comparing the proposed method and baselines with different sample complexity budgets is a big methodological flaw. \n\nNovelty:\n- Medium-high. The system-level optimizations are to my knowledge new. However, it's not clear how the absolute performance compares to existing methods. \n\nReproducibility:\n- Low. The paper does not mention releasing code, the reproducibility checklist is absent, and all the code-level optimizations seem hard to reproduce from the paper alone. \n",
            "summary_of_the_review": "Overall, the problem is well-motivated and the proposed algorithm is interesting, but there are some major issues (inconsistent sample complexity budgets, unreleased code) which would need to be addressed for this paper to be acceptable for publication. \n\n\n===========\nIn their new revision of the paper during the rebuttal period, the authors have added a comparison of their algorithm with 100k steps and uploaded their code. There is still a noticeable gap in performance between their algorithm and EfficientZero, but the speedup of their method is appreciated, and the fact that they release code could open the door to more community work in fast model-based RL methods. Therefore, I've updated my recommendation to weak accept. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2671/Reviewer_Qh8r"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2671/Reviewer_Qh8r"
        ]
    },
    {
        "id": "bMYcVmJDRn",
        "original": null,
        "number": 3,
        "cdate": 1667540509538,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667540509538,
        "tmdate": 1668666387920,
        "tddate": null,
        "forum": "Mg5CLXZgvLJ",
        "replyto": "Mg5CLXZgvLJ",
        "invitation": "ICLR.cc/2023/Conference/Paper2671/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a a distributed RL system built upon a state-of-the-art model-based RL\nmethod, EfficientZero, with system support for fast distributed computation. The paper also proposes a novel technique to stabilize massively parallel model-based training. Empirical evaluations demonstrate the efficacy of the approach.",
            "strength_and_weaknesses": "Strengths\n\n1. The paper is well-written and easy to follow.\n2. The proposed technique achieves significant speed up on the Atari benchmark.\n\nWeaknesses\n\n1. This work looks like a conglomeration of model-free and model-based RL methods. This is not necessarily a weakness, especially if this conglomeration was not obvious. I would like to understand this better.",
            "clarity,_quality,_novelty_and_reproducibility": "The work seems original and novel. The writing is clear. I did not try to reproduce this work.",
            "summary_of_the_review": "I am not an expert in this area, and based on a quick search on this topic, I am not aware of any similar work. I am giving a rating of 6 for now. But, I can change my rating after reading the authors' rebuttal and discussing with the other reviewers.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2671/Reviewer_xxoB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2671/Reviewer_xxoB"
        ]
    }
]