[
    {
        "id": "tdRZsypdcMT",
        "original": null,
        "number": 1,
        "cdate": 1666628928522,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666628928522,
        "tmdate": 1666628949892,
        "tddate": null,
        "forum": "_apb5VI2_0o",
        "replyto": "_apb5VI2_0o",
        "invitation": "ICLR.cc/2023/Conference/Paper4193/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper generally follows a previous publication TOHAN (NeurIPS) to solve the few-shot hypothesis adaptation (FHA) problem. Like TOHAN, this paper proposes a method called DEG-Net consisting of two modules, i.e., the generation module and the adaptation module. The generation module generates diverse data from random noise and given the generated data and labeled target data, the adaptation module adapts the classifier to the target domain via adversarial training. The only difference between DEG-Net and TOHAN is the data generation module. DEG-Net uses a weight-shared conditional generative network instead of K (class number) generators. Besides, DEG-Net encourages the diversity of generated data by minimizing the HSIC measure of the generated data\u2019s features. Experiments on Digits and CIFAR10-STL10 show that DEG-Net outperforms existing FHA methods in most cases.",
            "strength_and_weaknesses": "### Strength\n- The targeted problem of few-shot hypothesis adaptation is meaningful and challenging.\n\n- Enhancing the diversity of generated data is reasonable and theoretically motivated.\n\n- The paper is well-written and well-organized.\n\n### Weakness\n- The proposed method lacks novelty. The only differences compared to TOHAN are the weighted-shared generator, feature-based similarity loss, and diversity loss. The two former designs are common in previous works [1, 2]. As a result, the only novelty is the diversity loss. However, there exist very related works proposing to solve the diversity problem in image generation for better target task performance, such as [3].\n\n- The proposed method includes many hyper-parameters ($\\lambda$, $\\beta$, $\\gamma$). Since it is challenging to tune them since we do not have a labeled target validation set for hyper-parameter tuning in FHA or other unsupervised domain adaptation settings. I am also curious how authors determine such hyper-parameters in all adaptation tasks because the paragram \"Hyper-parameter Settings\" do not include the validation method.\n\n- The empirical results do not show that \"DEG-Net outperforms existing FHA methods and achieves the state-of-the art performance\", as claimed by the authors before Section 2. When labeled samples are very few like 1 or 2, DEG-Net usually underperforms TOHAN, as shown in Table 2. \n\n- The experiments only consider toy datasets like digits and CIFAR10-STL10. I understand that this paper generally follows TOHAN in the method design and experiment design. But in a very related topic called source-free domain adaptation, it is common to perform the empirical evaluation on popular domain adaptation benchmarks like Office, Office-Home, VisDA, and DomainNet. FHA is a very practical problem setting as aware by the authors, evaluation on toy benchmarks is not convincing.\n\n- More baselines should be considered for comparison, such as recent test-time adaptation methods like Tent [4].\n\n[1] Model Adaptation: Unsupervised Domain Adaptation without Source Data, CVPR 2020\n\n[2] Perceptual Losses for Real-Time Style Transfer and Super-Resolution, ECCV 2016\n\n[3] Contrastive Model Inversion for Data-Free Knowledge Distillation, IJCAI 2021\n\n[4] Tent: Fully Test-time Adaptation by Entropy Minimization, ICLR 2021\n",
            "clarity,_quality,_novelty_and_reproducibility": "1. Clarity: Good. This paper is well-written and presents a good flow.\n2. Quality: Medium. This method is well-motivated and theoretically justified. The empirical part is not convincing due to missing important benchmarks and baselines.\n3. Novelty: Low. The proposed method shares many similarities with existing works. There are no new insights.\n4. Reproducibility: Low. The proposed method is very complex due to its many hyper-parameters. Code is not provided.",
            "summary_of_the_review": "This paper focuses on the challenging few-shot hypothesis adaptation problem and proposes to improve an existing method TOHAN by enhancing the diversity of generated data. My concern lies in the weak novelty, weak empirical evaluation, and large complexity of the proposed method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4193/Reviewer_1mfd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4193/Reviewer_1mfd"
        ]
    },
    {
        "id": "MTcXmBJGZNy",
        "original": null,
        "number": 2,
        "cdate": 1666699158802,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666699158802,
        "tmdate": 1666699158802,
        "tddate": null,
        "forum": "_apb5VI2_0o",
        "replyto": "_apb5VI2_0o",
        "invitation": "ICLR.cc/2023/Conference/Paper4193/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors propose to improve the unlabeled data generation for few-shot hypothesis adaptation (FHA) which transfer a source hypothesis to target domain with only a few labeled data in target domain. They first provide theoretical proof that dependency among generated data (measured by log-coefficient) affects performance of FHA, and show that when unlabeled data is weakly dependent one can still learn a good classifier. They further propose a novel diversity-enhancing generative network that generates high diversity unlabeled while adapting the classifier to the target domain, by using HSIC. Extensive experiment results are shown on image datasets where proposed method achieves SOTA when there is good amount of target data.\n\n",
            "strength_and_weaknesses": "Strength\n\n- The authors identify sample diversity as an important factor in auxiliary unlabeled data generation for FHA and support the finding with solid theoretical analysis. \n- They further come up with practical solutions with HSIC based regularization and propose effective and non-trivial modification to TOHAN model (Chi et al). \n- The empirical results are quite comprehensive and the proposed method achieves better performance in most of the cases, and the discussion on failure cases and ablation study is clear. \n\nWeakness\n\n- The framework of unlabeled data generation is based on existing work TOHAN, and the theoretical analysis is based on prior work related to data dependency and semi-supervised learning. \n- The improvement relative to TOHAN on 6 digits FHA tasks is less significant with overlapping confidence interval.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall clear and well-written, with solid theoretical and empirical results. It is based on prior works, but the contribution is novel enough. ",
            "summary_of_the_review": "The paper proposes a better unlabeled data generator for FHA problem with diversity enhancing loss. It is grounded with theoretical guarantees and achieves reasonably good empirical results.  ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4193/Reviewer_7iBa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4193/Reviewer_7iBa"
        ]
    },
    {
        "id": "GGlQlyzKvfG",
        "original": null,
        "number": 3,
        "cdate": 1666723979955,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666723979955,
        "tmdate": 1670518646206,
        "tddate": null,
        "forum": "_apb5VI2_0o",
        "replyto": "_apb5VI2_0o",
        "invitation": "ICLR.cc/2023/Conference/Paper4193/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers the task of few-shot hypothesis adaptation (FHA), in which a classifier trained on a source domain is to be adapted to a target domain containing only a few labeled examples. Previous FHA approaches synthesize additional data with a generative model, but the performance boost may be limited due to lack of diversity in the generated data. The main contributions of this paper are twofold: an analysis extending previous non-i.i.d. learning theoretical results to the FHA setting thereby suggesting that the diversity of the data is important, and the proposal of a regularizer that encourages diversity in the generated examples via the Hilbert-Schmidt independence criterion.",
            "strength_and_weaknesses": "Strengths:\n- Investigating the effect of diversity in generated data for training few-shot classifiers is an interesting direction that should be of fairly broad interest. \n- The connection between non-i.i.d. learning theoretic results (Dagan et al., 2019) and data generation in FHA is interesting.\n\nWeaknesses:\n- Both main contributions can be viewed as relatively minor extensions of TOHAN (Chi et al., 2021). On the one hand, Theorem 1 adapts the corresponding result of Chi et al. (2021) to incorporate the log-coefficient capturing dependency of the data. On the other, the methodological contribution consists primarily of adding a regularizer to TOHAN.\n- The relationship to data-generation, i.e. \"hallucination,\" approaches in few-shot learning is not discussed. At a deeper level, I did not get a strong sense why FHA was the chosen setting as opposed to standard few-shot learning (or possibly studying both), as both can rely on generated data.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is reasonably clear. Implementation details are included in Appendix C and should be relatively straightforward to reproduce. The novelty is relatively low and consists primarily in making the connection between the results of Dagan et al. (2019) and data-generation approaches for training few-shot classifiers.\n\nRegarding quality: at a basic level, Theorem 1 states that if there is a large degree of dependence in the data, then a large amount of unlabeled data will be necessary to learn a good classifier. However, if I am understanding the theoretical results correctly, this degree of dependency depends on the data distribution itself rather than the synthetic data generated by a generative model. More specifically, the results of Dagan et al. (2019) assume that the marginal distributions match but there may be correlations between randomly drawn samples. This is quite a bit different from the case in FHA, where there is no guarantee that the generative model exactly matches (or is even close to) the true data distribution. From this perspective, the claim that data diversity in the generated data is important does not follow from, but is rather only loosely suggested by, the theoretical results.\n\nAnother concern is the discrepancy between the tools being used for assess dependency in the theoretical analysis, i.e. log-influence, and the regularizer used to encourage independence in the generated data, i.e. the Hilbert-Schmidt Independence Criterion. It is understandable that the log-influence is difficult to estimate, but it is unclear how, if at all, the HSIC is related to the log-influence.\n\nA related concern is why the log-coefficient was chosen for the theoretical analysis rather than, say, Dobrushin's coefficient, which is more general.",
            "summary_of_the_review": "Post-rebuttal update: I would like to thank the authors for their responses. In particular, I appreciated the clarification from the authors that the novelty lies primarily in the theoretical analysis rather than a novel algorithm. From this perspective, the two remaining concerns I have are: (1) the disconnect in assumptions between the true and synthetic data distribution, and (2) the relationship between log-influence and HSIC.\n\nI did not see a response from the authors that addressed (1), namely that the theoretical analysis focuses on the extent to which dependency in true data distribution causes decreased generalization, but the idea behind this paper is to improve diversity in the synthetically generated data. The two may be related but it this is not clear based on the contents of the current version of the paper.\n\nRegarding (2), the authors state that the connection between log-influence and HSIC is \"obvious\". I can understand that both log-influence and HSIC are both measures of independence, but if the goal is to use HSIC, then I believe that either HSIC should be used in the theoretical analysis or a more detailed discussion of the relationship between HSIC and log-influence should be included in the paper.\n\nOverall, due to these concerns, and after having read the other reviews, I will maintain my original rating.\n\n---\n\nThis paper investigates an interesting problem: whether data diversity in data-generation approaches to FHA is important, and what can be done to encourage such diversity. However, there are significant issues with both novelty and quality (outlined above), and therefore requires revision.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Research integrity issues (e.g., plagiarism, dual submission)"
            ],
            "details_of_ethics_concerns": "I am concerned about the degree of overlap between this paper and that of Chi et al. (2021), which proposed TOHAN. Specifically, please compare Section 3 & 4 of this submission, starting with \"Let $f^*$...\", to Section 3 & 4 of Chi et al. (2021). This similarly persists down to the level of sentence structure and mathematical exposition, with minor phrase substitutions in the former case and notational substitutions in the latter. Compare also Algorithm 1 and Tables 1-2, which have substantial formatting and content overlap with Chi et al. (2021). Although Chi et al. (2021) is cited in the submission, the degree of similarity between the two works, particularly in Sections 3 and 4, struck me as rather excessive.\n\nChi, Haoang, Feng Liu, Wenjing Yang, Long Lan, Tongliang Liu, Bo Han, William Cheung, and James Kwok. 2021. \u201cTOHAN: A One-Step Approach towards Few-Shot Hypothesis Adaptation.\u201d In Advances in Neural Information Processing Systems, 34:20970\u201382. Curran Associates, Inc. https://proceedings.neurips.cc/paper/2021/hash/af5d5ef24881f3c3049a7b9bfe74d58b-Abstract.html.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4193/Reviewer_TLkA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4193/Reviewer_TLkA"
        ]
    }
]