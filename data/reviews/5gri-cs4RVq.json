[
    {
        "id": "G9Ezzad_gG",
        "original": null,
        "number": 1,
        "cdate": 1666760274916,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666760274916,
        "tmdate": 1666853919785,
        "tddate": null,
        "forum": "5gri-cs4RVq",
        "replyto": "5gri-cs4RVq",
        "invitation": "ICLR.cc/2023/Conference/Paper1617/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper discusses NC - intra-class features collapse to the class mean and different class means are maximally separated. The authors argue that NC is an undesirable property for fine-grained classification. Thus they constrain the features of the same class should lie in a cone instead of collapsing to the mean. A feature extractor pre-trained by this method improves fine-grained classification on multiple datasets.",
            "strength_and_weaknesses": "Strengths:\n- The paper presents a simple idea and is easy to follow. \n- The method is appropriately designed following the main idea. \n\nWeaknesses:\n- My main concern here is that the paper doesn't offer an explanation of why NC is undesirable for fine-grained classification, i.e., the main idea isn't well justified. I think NC should be characterized carefully in order to support the main idea.  In particular, I disagree that \"collapsing to the class mean\" is a good enough reason to say NC is undesirable for fine-grained classification. The authors can convince me by quantifying the collapse and demonstrating how it correlates with the fine-grained classification performance. As of now, I need to believe that it's the case and without any proof of concept. Personally, I think \"collapsing to the class mean\" is quite vague and unclear. For example, one possible interpretation is that the distances between features of the same class are small w.r.t the distance between classes. In this case, it doesn't mean that the feature doesn't encode enough fine-grained information for each instance since intra-class variance can still be high. \n\n- Likewise, since the method is based on a weak motivation (to me), I am not sure how rearranging features into a cone helps with fine-grained classification. There are methods that propose feature space re-arrangement before (Mag-face, arc-face) and they are very clear about why their geometrical constraints boost their performance. I don't see a similar explanation here. Is there any relation between the proposed  MSC and intra-class variance [1]? If there is a connection here that would add depth to the paper and offer an explanation for what is happening.\n[1] Variational Feature Disentangling for Fine-Grained Few-Shot Classification - ICCV21\n\n- The paper introduces some hyperparameters that need to be tuned. \n\n- The paper doesn't improve the performance on the most challenging case of the imagenet-LT.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good\nQuality: Good\nNovelty: Generally a new technique but it's not a surprising one. Similar ideas have been proposed for faces [mag face, arc Face]. I would like the authors to discuss them and clarify their novelty.\nReproducibility: Good.",
            "summary_of_the_review": "Overall, I am on the fence. The paper is simple and the method seems to work in some cases. The numbers are not substantially strong. The explanation and motivation aren't clear. I am not an expert in this area so please fell free to correct me.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1617/Reviewer_ur4C"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1617/Reviewer_ur4C"
        ]
    },
    {
        "id": "FC_WnK0rSXk",
        "original": null,
        "number": 2,
        "cdate": 1666934980713,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666934980713,
        "tmdate": 1666934980713,
        "tddate": null,
        "forum": "5gri-cs4RVq",
        "replyto": "5gri-cs4RVq",
        "invitation": "ICLR.cc/2023/Conference/Paper1617/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the undesirable Neural Collapse (NC) phenomenon for specific classification tasks, including fine-grained classification and long-tailed classification. The authors then propose to learn deep features that have the maximal-separating-cone (MSC) property by optimizing towards their designed hinge loss function. Empirical results verified their motivation and the effects of the proposed approach.",
            "strength_and_weaknesses": "Pros:\n\n+ Well-motivated approach: Investigates an intriguing phenomenon of NC, and its undesirable properties for fine-grained classification adaptation.\n+ Technically sound solutions with a novel hinge function design.\n\nCons:\n- It is unclear to me why learning MSC features can also benefit long-tailed classification tasks. Experimental results in Table 2 also seem to show weaker performance gain on long-tailed datasets.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and technically sound, which proposed a novel feature property named maximal-separating-cone.  ",
            "summary_of_the_review": "This paper is decent research towards learning deep features with MSC property, and hence tackles certain specific classification problems where NC is undesirable. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1617/Reviewer_6L41"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1617/Reviewer_6L41"
        ]
    },
    {
        "id": "MEXbxi4y7D9",
        "original": null,
        "number": 3,
        "cdate": 1666980632162,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666980632162,
        "tmdate": 1666980632162,
        "tddate": null,
        "forum": "5gri-cs4RVq",
        "replyto": "5gri-cs4RVq",
        "invitation": "ICLR.cc/2023/Conference/Paper1617/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors present a method that tries to rectify feature collapse for classification, arguing that this is an undesirable property for the case where coarse labels are used for training, but we are (also) interested in a finer-grained downstream task. They advocate to fix the classifiers and use a hinge loss. They experiment on coarse-to-fine as well as long-tail classification.",
            "strength_and_weaknesses": "### Strengths\n\n* The paper dealing a very interesting property of learning with cross-entropy, that of class collapse\n\n* the paper is  experimenting on interesting tasks like long-tail recognition and coarse-to-fine learning.\n\n### Weaknesses\n\nW1) Novelty of the paper is questionable: There are some missing references and comparisons that are very related to the proposed. [A] refers to the same issue tackled here, class collapse for transfer learning. Feng et al in [A] do in some sense provide an answer to the question asked in the intro and propose a loss that avoids collapse. Grafit from Touvron et al [B] is even closer to the task and formulation of this paper: it presents an approach for learning with coarse labels and the loss proposed in [B] is a kNN loss therefore also avoiding collapse. The authors should not only discuss but also compare to such methods.  Another missing reference that should be discussed and compared to is wrf fixed classifiers is [C]. \n\n\nW2) Experimental validation is lacking in many regards: \n\n*  It is unclear how this supervised learning method affect the training task of ImageNet in 4.1 The authors compare against SimCLR, a self-supervised method, but not supervised methods like [A,D] in Table 1. They also do not report performance on the training task of imagenet (one more column should be added). As [Kornblith et al 2021], [E] and other papers have mentioned, there exists a tradeoff between training and transfer accuracy.  What is the performance of all methods at the end of training? \n\n* For long-tail, the method is not outpuerforming multiple methods of Table 2 on the larger and less toy-scale ImageNet-LT. Also Fig 5c shows that setting the main hyperparameter \\tau is far from trivial. Moreover it is unclear what model is used in each dataset and method in Table2 - are all methods using the same backbone?\n\n### References\n[A] Feng, Yutong, et al. \"Rethinking supervised pre-training for better downstream transferring.\" ICLR 2022\n\n[B] Touvron, Hugo, et al. \"Grafit: Learning fine-grained image representations with coarse labels.\"CVPR 2021\n\n[C] Hoffer, Elad,et al  \"Fix your classifier: the marginal value of training the last weight layer.\" ICLR 2018.\n\n[D] Khosla, Prannay, et al. \"Supervised contrastive learning.\" NeurIPS 2020\n\n[E] Sariyildiz et al \"Improving the Generalization of Supervised Models.\" arXiv 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is generally written in a very confusing way; the \"core\" of the method contains unclear parts while it is unclear what Theorem 1 offers.The analysys of NC comes from Papyan et al., 2020 in 2.2, and I dont see how this paper \"examines the Neural Collapse phenomenon\" as stated in the conclusion. There are also implementation details that are missing in many places and therefore reproducibility is questionable.\n\n### Notes \n\n* Paragraph \"Hinge Loss\" in 3.2 is unclear in many places, while Eq9 is written in a very confusing way.\n\n* the first paragraph of the intro is in practice merely advocating for the use of learned vs handcrafted features for computer vision, yet, this is common practice in the AI classification since AlexNet won the Imagenet challenge. It can therefore be significantly trimmed. Same with 2.1 that merely describes classification with  cross entropy loss, again the default loss\n\n* The question asked in the introduction is ill-posed as expressed there. \"the\" desired property implies that it would be the only, while \"deep features\" have a multitude of uses- which use does this paper care about is not mentioned till there in the intro. The authors right after mention how they are only looking at a specific task, that of coarse-to-fine classification. The intro needs revision. \n \n\n",
            "summary_of_the_review": "The paper has a number of weaknesses detailed above. I encourage the authors to provide answers to the concerns and questions.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1617/Reviewer_tRGD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1617/Reviewer_tRGD"
        ]
    }
]