[
    {
        "id": "6MFjlH-bp1",
        "original": null,
        "number": 1,
        "cdate": 1666413042310,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666413042310,
        "tmdate": 1666413042310,
        "tddate": null,
        "forum": "p0yrSRbN5Bu",
        "replyto": "p0yrSRbN5Bu",
        "invitation": "ICLR.cc/2023/Conference/Paper1920/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work aims to improve the effectiveness of the prompting method.  The prompt tuning approaches have attracted growing interest due to its parameter efficiency. However the limited training samples in few-shot settings, prompt tuning fails to match the performance of full-model fine-tuning.  The authors design an ensemble method to deal with few shots and improve the effectiveness of transfer learning.  The empirical study shows promising results. \n",
            "strength_and_weaknesses": "Strengths:\n1. A method developed based on well though through motivations.\n2. Empirical study shows better results.\n\nWeaknesses:\n1. To ensure this method work, the source models are expected to be robust.  In other words, some robust source models must be trained to be borrow.  But it may not be true that these source models are always available and comparable.\n2. Can the source models trained on top of other pre-trained models?  \n",
            "clarity,_quality,_novelty_and_reproducibility": "Well written paper, with problem stated and motivations explained.  This work is orthogonal to the work like chain-of-thoughts, which improve prompt generation itself.  Instead, this method improves data efficiency with both an ensemble and improved transfer learning.  I believe it can be reproduced.",
            "summary_of_the_review": "Prompt tuning is a hot topic since 2021. There have been several \u201chacks\u201d showing promising results,  But realistically, there were so many unreported failure cases.  It is good to see a paper using principled approaches to systematically improve performance.  Since I have worked on this subject with several interns, I know the challenges and appreciate the improvements that this work could achieve.\n\nMy question is how the source models are obtained, and given a novel task, how can you identify the most useful source models from which to transfer information.  If source models are not available, what is your fall back scheme?",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1920/Reviewer_bhqg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1920/Reviewer_bhqg"
        ]
    },
    {
        "id": "X1xxTwH_GcP",
        "original": null,
        "number": 2,
        "cdate": 1666610798937,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666610798937,
        "tmdate": 1666610798937,
        "tddate": null,
        "forum": "p0yrSRbN5Bu",
        "replyto": "p0yrSRbN5Bu",
        "invitation": "ICLR.cc/2023/Conference/Paper1920/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new approach for transferring knowledge from source tasks to a target task that has only a few examples available. Specifically, they use source models based on a pre-trained (and frozen) language model, where each source model consists of a trained prefix (obtained via prefix tuning on that source task). Their approach is the following: first, they finetune the prefix of each source task using data from the target task. Then, keeping all parameters frozen (both the language model as well as the per-source learned prefixes), they train an attention model which, given (the tokens of) a (max-pooled) input sequence representing a single example from the target domain, and given the logits produced by each source model for the target task, figures out how to ensemble those logits on a per-example basis, so as to do best on that target example. After having trained the attention model on the few-shot data from the target task, it is deployed to make predictions for other examples from the target task. They show empirically that their method outperforms previous approaches for transferring knowledge that weren\u2019t explicitly designed for the few-shot setting. They also demonstrate that they outperform ensembling baselines, that their approach can work well for larger numbers of shots too, and they verify different empirical decisions (like ensembling the logits instead of interpolating the prompts themselves to create a new prompt for the target domain).",
            "strength_and_weaknesses": "Strengths\n========\n[+] The paper is clearly written and easy to understand\n\n[+] The proposed method outperforms the previous approaches and baselines considered on a variety of datasets\n\n[+] The authors empirically verify different design choices and baselines and perform interesting analyses (like the effect of using the top-k most similar source domains for each target task)\n\nWeaknesses\n===========\n[-] Some useful ablations / exploration of alternative design choices still missing (see below)\n\n[-] The proposed method requires several forward passes through the language model (one per source task, that uses a different prefix) in order to perform a single prediction, thus adding computational overhead at test time compared to other methods. Would be good to add some discussion on this.\n\n[-] While the paper is clearly written for the most part, I would have liked to see a detailed description of the tasks used, both as source tasks and the target tasks considered. I couldn\u2019t find details of them in the Appendix either, though please let me know if I missed it. This is important as understanding the tasks considered is useful for interpreting the results.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\n=====\nThe paper is clear for the most part. Some minor comments on this front below:\n\nAs mentioned already, please provide details for each dataset used both for the source and target tasks, e.g. explain the acronyms in the task names, what is the task in each case, how much training data is available for each source task, and so on. Why are the particular tasks from GLUE and Super GLUE chosen as target tasks? Why not use all of them instead of picking a subset?\n\nIn Section 3.2.1, 2 lines above Equation 2, I wasn\u2019t sure what the notation meant of the horizontal bar between X and h_x.\n\nIn Algorithm 1 (In the Appendix), M should be M_T? Write a description of this algorithm that explains in a few words what is happening (e.g. in the min and max operations), for better readability.\n\n\nNovelty\n======\nThe specific approach for ensembling prompt-tuned source models is novel to the best of my knowledge.\n\nReproducibility\n===========\nHyperparameter details are reported in the Appendix that can help with this. I encourage the authors to release their code as well.\n\nQuality detailed comments\n=====================\nIn Table 3, why are some of the previous methods and baselines missing? Also, when it comes to varying shots, it would be also interesting to report results on fewer than 32 shots. In vision benchmarks, even 1-shot and 5-shot settings are commonly considered.\n\nRegarding efficiency, aside from the parameter efficiency discussed in the paper, computational efficiency at inference time is also a potential concern. Ensembling requires forward-passing through the language model several times (once for each prefix). It would be useful to also comment on this aspect, and the relationship to previous knowledge transfer works in terms of this.\n\nIt would be useful to also report results for another ablation: applying the proposed model without first finetuning the prefix of each source model on the target data (that is, directly using the prefix that was trained for each source task, and applying the attention model on logits produced with those prefixes).\n\nAnother interesting analysis would be comparing to a \u2018hard ensembling\u2019 variant: after attention weights are computed, set the argmax position to 1 and all remaining entries to 0s. If this hard variant performs worse than the proposed method, it would show that ensembling is useful compared to selecting the single most appropriate source model.\n\nMinor comments\n==============\n\u2018Parameter efficiency\u2019 doesn\u2019t really belong in the \u2018Empirical Analysis\u2019 section since there\u2019s nothing empirically determined in that discussion. Maybe this discussion is better suited in the Methods section.\n\nIn Figure 1, it would be visually nicer to align the diagrams showing for the different source tasks. Or is there some reason I\u2019m missing for why some are more indented than others?\n",
            "summary_of_the_review": "Overall, I found the paper well-written, the problem explored is interesting and relevant and the proposed method seems to outperform previous work on a variety of datasets. The empirical analysis is interesting but a couple other design choices / ablations should also be explored (see above). I\u2019m not an expert in NLP so it\u2019s hard for me to judge if the previous work considered covers all the relevant related work and whether the datasets used are the most relevant to study. However, I recommend weak acceptance for the above reasons. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1920/Reviewer_eQBR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1920/Reviewer_eQBR"
        ]
    },
    {
        "id": "GhtlD8dK8A",
        "original": null,
        "number": 3,
        "cdate": 1666655889461,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666655889461,
        "tmdate": 1666659250357,
        "tddate": null,
        "forum": "p0yrSRbN5Bu",
        "replyto": "p0yrSRbN5Bu",
        "invitation": "ICLR.cc/2023/Conference/Paper1920/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes model ensemble for few-shot prompt tuning in knowledge transfer tasks. The paper use an attention module to do the sample-specific ensemble for different tasks' soft prompt and apply the new ensemble of logits to the new task. Numerical experiments are presented to show the effectiveness of the idea. ",
            "strength_and_weaknesses": "Strength:\n\n1. The idea to use ensemble is straightforward while effective. It makes the idea simple and easy to implement.\n2. The experiment results are good and improve the previous SOTA on most of the tasks considered in this paper.\n3. The paper is well written and easy to understand.\n\nWeakness: I am not an expert in knowledge transfer and prompt tuning, thus I do not know the explicit weakness of this paper. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. The quality is high. To the best of my knowledge, the paper is novel.",
            "summary_of_the_review": "Based on my lack of expertise, I think this paper is interesting. I would like to weakly accept this paper while maintaining a low confidence.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1920/Reviewer_HJCk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1920/Reviewer_HJCk"
        ]
    },
    {
        "id": "ZDH1ym-hjCw",
        "original": null,
        "number": 4,
        "cdate": 1666702912311,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666702912311,
        "tmdate": 1666702982715,
        "tddate": null,
        "forum": "p0yrSRbN5Bu",
        "replyto": "p0yrSRbN5Bu",
        "invitation": "ICLR.cc/2023/Conference/Paper1920/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper prose SESoM can adjust the contribution of each model when ensembling the model outputs. SESoM uses an attention module to calculate the attention of each model\u2019s output. The proposed SESoM can achieve SOTA performance in both full-data settings and few-shot settings.",
            "strength_and_weaknesses": "The main strengths: \n1. The paper is well-written and the idea is well-motivated. \n \n2. The experiments are quite comprehensive. The empirical analysis section answers several interesting questions. \n \n3. The empirical study that compares the prediction ensemble with the prompt ensemble is quite interesting and can inspire many related fields. \n \nThe main weaknesses: \n1. The idea that combining the output of several models using the attention strategy is not novel in deep learning. \n\n2. I can not understand why sample-specific rather than task-specific preference is important for prompt tuning. What if a similar sample exists in a quite different source task? Will the attention model pays more attention to this similar sample resulting in a negative impact on the target task performance since the source task and target task are quite different? ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written but the idea is not novel. ",
            "summary_of_the_review": "The paper prose SESoM can adjust the contribution of each model when ensembling the model outputs.  The experiments are comprehensive. The idea is not novel. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1920/Reviewer_ATJm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1920/Reviewer_ATJm"
        ]
    }
]