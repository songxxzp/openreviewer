[
    {
        "id": "ahfsU7_qii",
        "original": null,
        "number": 1,
        "cdate": 1666643268744,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666643268744,
        "tmdate": 1666643268744,
        "tddate": null,
        "forum": "UkU05GOH7_6",
        "replyto": "UkU05GOH7_6",
        "invitation": "ICLR.cc/2023/Conference/Paper449/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work introduces LIPO (Learning Incompatible Policies), a MARL method that uses a policy compatibility-based objective and a mutual information regularizer in order to learn a diverse set of behaviours in cooperative tasks. LIPO is evaluated in a wide set of environments and shows a superior capacity to discover policies against the compared baselines. Additionally, the work also includes a comprehensive study of the parameter values and their effect on the learned behaviours.",
            "strength_and_weaknesses": "Strength:\n- Diverse of benchmarks and baselines\n- Comprehensive study of the impact of the parameters\n- Ample discussion of results, as well as limitations of the method\n\nWeakness:\n- A missing more detailed discussion on scalability, in terms of number of agents, since the current work assumes always 2 agents.  ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly and well-written. It is novel and original, as it uses the concepts of policy compatibility and mutual information in novel manners to create a diverse set of behaviours for cooperative tasks. The work includes a reproducibility statement and is accompanied by the code (however I did not run the code myself).",
            "summary_of_the_review": "All in all, I think this is an interesting and well-presented contribution.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper449/Reviewer_obTi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper449/Reviewer_obTi"
        ]
    },
    {
        "id": "VohtFpNWo2",
        "original": null,
        "number": 2,
        "cdate": 1666697882022,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666697882022,
        "tmdate": 1666697882022,
        "tddate": null,
        "forum": "UkU05GOH7_6",
        "replyto": "UkU05GOH7_6",
        "invitation": "ICLR.cc/2023/Conference/Paper449/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces the LIPO (Learning Incompatible Policies) algorithm for generating diverse policies via a mutual information objective. This is then demonstrated empirically in two simple environments (a cooperative matrix game and a 2D navigation task), as well as in the Overcooked domain.",
            "strength_and_weaknesses": "Strengths\n- While conceptually simple, the proposed framework for generating diverse populations of agents is a powerful idea that could have applicability beyond cooperative domains, e.g., for designing agents that can compete effectively against agents or where optimal strategies are difficult to find.\n- The inclusion of the anonymized source code is appreciated, and all of the details in the appendices aid reproducibility.\n- The paper is written clearly and includes solid theoretical justification for the implementation of an additional MI objective.\n\nWeaknesses\n- The related work section could be earlier in the paper, and possibly compared with LIPO in more detail. For example, what would the \"domain knowledge\" required by QD look like in the experimental settings described here?\n- Figure 8 could include more context; is the goal to generate something that looks like the uniform distribution? Or are some choices clearly better than others in this environment? Essentially, interpreting this requires additional background knowledge about Overcooked and about what an ideal solution would look like.",
            "clarity,_quality,_novelty_and_reproducibility": "Generally, the paper is very clear and, as mentioned above, the reproducibility of the demonstrated results is high. Since this framework does not specifically require domain knowledge, it can be broadly applicable to multiple unknown settings, where domain knowledge is difficult to obtain. It would be useful to compare LIPO further with MEP (Zhao et al. 2021) to discuss the qualitative/quantitative differences in policies that both obtain.\n\nLine 1 of Appendix A: \"proof\" should be \"prove\"",
            "summary_of_the_review": "Overall, this is a strong paper with good results. It is likely to be useful to researchers seeking to design cooperative agents with diverse behaviors, as well as possibly for designing agents in non-cooperative and mixed cooperative-competitive settings.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper449/Reviewer_PWGa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper449/Reviewer_PWGa"
        ]
    },
    {
        "id": "n2Pm9pp02Lz",
        "original": null,
        "number": 3,
        "cdate": 1666897755245,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666897755245,
        "tmdate": 1666897755245,
        "tddate": null,
        "forum": "UkU05GOH7_6",
        "replyto": "UkU05GOH7_6",
        "invitation": "ICLR.cc/2023/Conference/Paper449/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents the LIPO framework for learning diverse sets of policies for cooperative multi-agent reinforcement learning tasks.  Given an existing population consisting of tuples of joint policies, the LIPO objective maximizes the performance of a new joint policy, while penalizing it for performing well when paired with other policies within the population.  LIPO also, optionally, maximizes the diversity of the trajectories generated by an individual team of policies using policies parameterized by a randomly sampled latent variable, and an additional a mutual information objective.\n\nExperiments demonstrate that LIPO is better than several recently developed alternatives at identifying the space of solutions to cooperative games, including simple matrix games, the cooperative particle environments, and the much more complex Overcooked! environment.  They demonstrate that LIPO is able to more reliably identify the full set of possible solutions, rather than just a subset of these solutions.  The also evaluate \"generalist\" policies trained against the population of policies generated with LIPO (or one of the baseline methods).  They demonstrate that policies trained against the LIPO population were significantly more robust (compared to the baseline methods) in terms of their performance when paired with members of a \"test\" populations.",
            "strength_and_weaknesses": "The main strength of this paper is the intuitive nature of the LIPO approach, and the empirically demonstrated performance in both solution enumeration and as the basis for training generalist cooperative policies.\n\nOne potential weakness of LIPO, and related approaches, is the fact that they focus on enumerating the space of near-optimal solutions.  This means that generalist policies trained against these populations may perform poorly when paired with significantly sub-optimal partners.  In real-world settings, using LIPO-like methods could therefore lead to policies that are not robust to realistic partners who are unlikely to behave in a truly optimal way.\n\nAnother potential weakness is that there is no guarantee that the space of behaviors represented by a single policy parameterized by a latent state will represent a unique class of solutions.  Without the ability to recognize unique solutions, LIPO may not be able to recognize solutions that are unlikely to occur in a ad hoc setting (since other agents would not choose strategies that are likely to mis-coordinate).",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written, and has no obvious technical faults.  The approach to policy diversity is relatively novel, particularly the idea of explicitly training new policies to mis-coordinate with existing members of the population.  The authors provide their code, though this has note been checked.",
            "summary_of_the_review": "The decision to accept is based on the empirical success of the proposed LIPO framework in training policies for ad hoc cooperative settings.  The method also represents something of a departure from existing approaches to learning diverse policies, which previously have focused on maximizing direct measures of the diversity of the policy space.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper449/Reviewer_CTS6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper449/Reviewer_CTS6"
        ]
    },
    {
        "id": "ZtYa7QyVeb",
        "original": null,
        "number": 4,
        "cdate": 1666929298917,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666929298917,
        "tmdate": 1666929298917,
        "tddate": null,
        "forum": "UkU05GOH7_6",
        "replyto": "UkU05GOH7_6",
        "invitation": "ICLR.cc/2023/Conference/Paper449/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors develop a training procedure for two-player cooperative games that generate diverse policies. The idea is to generate policies that are incompatible when paired together and train agents with this loss function. This is tested in two toy environments and an Overcooked grid world. In all cases, LIPO finds diverse solutions (when possible) as well as diverse solutions. \n",
            "strength_and_weaknesses": "\nThe paper is very clearly written and well organized it is easy to read and follow the logic. The toy environments are highly diagnostic and give strong insights into why this algorithm outperformer baselines and other approaches. It was nice to see the algorithm tested both for its ability to generate diverse populations and show that those populations matter for behavior. \n\nOne key weakness is that the algorithms were all tested on new benchmarks created just for this manuscript. Since there are now many competing approaches to this kind of diversity generation, it would have been nice to see this algorithm outperform others on a task designed by others. \n\nFurther, I would like to see some ablation experiments to understand the role of the \\lambda_MI in the Overcooked environment. It is further not clear in what contexts this term will be important. ",
            "clarity,_quality,_novelty_and_reproducibility": "What would be needed to extend these results to more than two players?\n\nThe results shown in Figure 9 are interesting, but is there a way to distill the key differences? I think the color scheme is hurting, as it isn't clear what cells are supposed to be compared. ",
            "summary_of_the_review": "The paper presents a new algorithm that is clearly motivated with theoretical and empirical support. I recommend the paper is accepted if my above comments can be addressed. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper449/Reviewer_cwpF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper449/Reviewer_cwpF"
        ]
    }
]