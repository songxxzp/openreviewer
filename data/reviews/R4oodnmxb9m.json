[
    {
        "id": "MoM_MN8s6g",
        "original": null,
        "number": 1,
        "cdate": 1666593918604,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666593918604,
        "tmdate": 1666593918604,
        "tddate": null,
        "forum": "R4oodnmxb9m",
        "replyto": "R4oodnmxb9m",
        "invitation": "ICLR.cc/2023/Conference/Paper2791/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors analyze the new challenges in offline communication learning, and introduce a benchmark of offline communication learning which contains diverse tasks. The author propose an effective algorithm, Multi-head Communication Imitation (MHCI), which aims to address the problem of learning from single-source or multi-source datasets, and our method shows superior outperformance in various environments of our benchmark.",
            "strength_and_weaknesses": "Pros: \n1. The motivation is clear. \n2. The paper is well-written and organized. \nCons: \n1. More results on more challenging datasets are needed to verify the superiority of the proposed method. \n2. Some related works are missing, e.g., Multi-caption Text-to-Face Synthesis: Dataset and Algorithm.",
            "clarity,_quality,_novelty_and_reproducibility": "See Strength And Weaknesses.",
            "summary_of_the_review": "See Strength And Weaknesses.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2791/Reviewer_UfVH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2791/Reviewer_UfVH"
        ]
    },
    {
        "id": "fo1eeUyYg6F",
        "original": null,
        "number": 2,
        "cdate": 1666633713067,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666633713067,
        "tmdate": 1666633713067,
        "tddate": null,
        "forum": "R4oodnmxb9m",
        "replyto": "R4oodnmxb9m",
        "invitation": "ICLR.cc/2023/Conference/Paper2791/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work investigates learning the communication strategy in MARL from offline communication datasets. The authors proposed a multi-head attention method to encode the messages to support learning data from multiple sources. The proposed method is evaluated using a custom window environment and a custom StarCraft environment. ",
            "strength_and_weaknesses": "**Strength**\n- This paper is relatively easy to follow.\n- The proposed network seems to have better performance compared to the chosen baselines.\n\n**Weakness and Questions**\n- How are the different datasets generated (e.g. export, medium, etc)? Does the model still work well if the communication protocol changes completely? More details should be provided. \n- The method should also be evaluated under more combinations of communication messages to understand the performance related to the difference in the multi-source data. How do combining different trajectories in different datasets and different communication protocol affects the performance of the proposed algorithm? Can the algorithm learn to use communication strategy learned from some trajectories to a different trajectory to improve performance? More ablation would be helpful here.\n- In the evaluation section, it would be a good idea to provide the performance of the different benchmarks under the online learning case. For example, comparing the proposed method to online techniques (e.g. I2C) in MMM. \n- In the motivating example, more details should be provided in terms of how the two models (learning communication from scratch and feed dataset communication) are trained. \n",
            "clarity,_quality,_novelty_and_reproducibility": "*Clarify: This paper is well-written and overall clear.\n*Novelty: The problem of this work is somewhat novel, but the design of the network seems to be similar to prior work.\n*Reproducibility: code is provided ",
            "summary_of_the_review": "This work is a looking at the communication problem in offline MARL. It tries to learn from communication data that is multi-sourced. The proposed method seems to be effective and the problem is relatively new; however, the challenge of the research problem seems limited which limits the novelty of the proposed method. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2791/Reviewer_zXRw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2791/Reviewer_zXRw"
        ]
    },
    {
        "id": "FOT-2kybUu",
        "original": null,
        "number": 3,
        "cdate": 1666644323858,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666644323858,
        "tmdate": 1666688082222,
        "tddate": null,
        "forum": "R4oodnmxb9m",
        "replyto": "R4oodnmxb9m",
        "invitation": "ICLR.cc/2023/Conference/Paper2791/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper mainly considers communication in offline multi-agent reinforcement learning (MARL). The authors propose a new benchmark that contains a set of offline MARL communication tasks with single/multi-source datasets. The \u201cmulti-source\u201d means that the messages are from different communication protocols. The authors show that there exists a universal communication protocol that can represent all sources. Also, the authors propose a multi-head structure for communication Imitation learning. Experiments show a good performance in a few scenarios in SMAC and Room.",
            "strength_and_weaknesses": "Pros:\n\n- This paper takes on an interesting problem in MARL: the combination of communication and offline MARL.\n- The experiments are completed.\n\nHowever, I have several concerns here:\n- To my understanding, this paper is mainly to learn a universal communication protocol to achieve higher accuracy. This point is interesting from the perspective of MARL communication but is not adequate. Since we can just view this problem as simple supervised learning. End-to-end communication offline learning is more attractive.\n- Why do we need an offline MARL dataset with communication messages? The objective of offline RL/MARL is to obtain good policies from the dataset for direct deployment. We can have an offline MARL dataset by running communication but discarding communication messages. Since the messages are mainly from the observations of each agent. Will agent communication during deployment? If not, we can mimic such a dataset for deployment. If so, we can also have a communication mechanism inside the policy learning without mimicking the multi-source messages.\n- In Fig.1, Left = Mid + Right. No need to plot redundant figures.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: The paper is clear to me.\n- Quality: There is still much space for improvement in terms of the motivation/justification of the core idea, the presentation of graphs, and the notations.\n- Novelty: The idea is interesting. However, I think some justifications are needed for this setting.\n- Reproducibility: the authors provide part of the source code.\n",
            "summary_of_the_review": "I like the idea of incorporating communication into offline MARL. However, I think the authors should improve the current version.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2791/Reviewer_gcz9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2791/Reviewer_gcz9"
        ]
    },
    {
        "id": "AZeuSqsNu7",
        "original": null,
        "number": 4,
        "cdate": 1666671560112,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666671560112,
        "tmdate": 1666671560112,
        "tddate": null,
        "forum": "R4oodnmxb9m",
        "replyto": "R4oodnmxb9m",
        "invitation": "ICLR.cc/2023/Conference/Paper2791/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper is about how to learn offline environments that can communicate between agents in multi-agent environments. Each agent learns a function that generates messages from their observations, based on the messages in the datasets. The communication function is learned with a multi-head attention structure, and in the evaluation, agents transfer messages derived from a linearly random mixing of messages learned from each head. Experiments have been performed in environments that require intensive communication, based on Room and StarCraft 2. The proposed structure shows higher performance than learning communication without message information in datasets or imitation learning without a multi-head attention structure.",
            "strength_and_weaknesses": "Strengths\n\nThis paper presents a new problem of how to learn the offline multi-agent RL datasets with communication and proposes an algorithm based on a multi-head attention structure to solve it.\nThe paper shows the performance of the proposed method by creating a new benchmark, and it shows higher performance than the existing offline RL algorithm.\nMathematical concepts explain well how the proposed algorithm can get a high return in an environment where datasets are generated from various distributions.\n\nWeaknesses\n\nIt seems more necessary to analyze whether the proposed multi-head structure is suitable for problem-solving. When learning based on various datasets, it is necessary to analyze whether each head is learned diversely as intended and to provide evidence of performance increase. \n\nThere is also a lack of explanation on how to obtain the dataset. There will be a variety of ways to design the communication function. Since the created message is included in the dataset, the algorithm performance may change significantly depending on the algorithm that created the dataset.\n\nSince it is an algorithm designed to learn datasets made from various distributions well, it is also effective to show the performance change according to the number of distributions included in the dataset.\n\nThe explanation and backgrounds for linear fusion are poor. The multi-head attention structure is designed to learn messages from various distributions separately, but it is too naive to randomly mix all heads in actual use. In the process of randomly mixing multi-heads, the basis of the structure seems to disappear. The possibility of a structure that uses learned multi-head more efficiently is open.\nThe explanation of the base algorithm ICQ seems to be poor, and it is necessary to explain why this algorithm is chosen.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written in composition and order with proper mathematical theories. \n\nIt is meaningful and novel in that the paper proposes a new kind of multi-agent offline RL environment, with agents with communication.\nThe motivation is, if the method learns the communication of the dataset, it will increase the performance rather than learning from scratch without the dataset. But it seems natural to perform better with using more information. Of course, the comparing result with simple imitation learning is included, and more powerful motivation (e.g. the existing imitation learning structures are not suitable for learning communication) is needed.\n\nTypo: page2 DAIL, RAIL -> DIAL, RIAL / figure2 $h_j^t$\n",
            "summary_of_the_review": "This paper is meaningful in that it attempts to approach a new kind of multi-agent offline RL environment. However, the paper is poor at showing the process of generating the datasets, showing the performance of the proposed method(more evaluation and ablation that shows the advantages of the structure should be provided), and the lack of explanation and analysis of linear fusion.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2791/Reviewer_311E"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2791/Reviewer_311E"
        ]
    }
]