[
    {
        "id": "wJPs1FKv6G",
        "original": null,
        "number": 1,
        "cdate": 1666511651819,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666511651819,
        "tmdate": 1670789490052,
        "tddate": null,
        "forum": "9Jaz4APHtWD",
        "replyto": "9Jaz4APHtWD",
        "invitation": "ICLR.cc/2023/Conference/Paper3389/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper first compares the performance of contrastive and non-contrastive methods on the graph link prediction task. Second, a novel model i.e. Triplet-BGRL (T-BGRL) is proposed based on Bootstrapped Graph Latents (BGRL). The proposed T-BGRL is categorised as a non-contrastive method and it relies on an efficient corruption method to generate cheap negative samples. Extensive experiments demonstrate that T-BGRL can achieve competitive performance for both the transductive and inductive settings with a good efficiency. ",
            "strength_and_weaknesses": "### Strength:\n\n1. The discussion of contrastive and non-contrastive methods for the link prediction task is comprehensive. \n\n### Weakness:\n\n1. In Section 3.1, it\u2019s unclear why the experiments only focus on the performance of the encoder and adapt the same decoder for all evaluated models. Moreover, it\u2019s unclear why the encoder and decoder are not trained together. If this is following some existing works, please cite them and discuss the reason(s).\n2. ML-GCN is only loosely defined but used as an important baseline. Is ML-GCN just a GCN model using the margin-loss? Also, what is \u2018the supervised GCN\u2019 (Section 3.1.1)? Is it just an end-to-end GCN?\n3. Figure 1 does not have an x-axis. \n4. \u2018collapse\u2019 is used without only once in Section 3.1.1 without definition and further discussion or claim. \n5. Why ML-GCN and BGRL are both claimed as \u2018our\u2019 best-performing contrastive/non-contrastive models?\n6. Is the SHUFFLEFEATRANDEDGE the same as the SHUFFLEFEATRANDOMEDGE method described in A.6? It\u2019s unclear why a randomly generated adjacency matrix can help the effectiveness of BGRL. In fact, if the proposed method only generates a random matrix, then there is no corruption. \n7. It\u2019s unclear why some arguments/conclusions are stated in the caption of the figures e.g. figures 1&3. \n8. It\u2019s unclear why the early-stop is only used by ML-GCN.\n9. This paper is poorly organised. Usually, there is no connection between two sections. Furthermore, many sections (e.g. the last subsection of Section 3.1.1) end without a solid conclusion or constructive advice. \n\n### Typos:\n1. On page 3, \u2018none evaluate or target link prediction tasks.\u2019 \uf0e0 \u2019none evaluates or targets the link prediction task.\u2019\n2. On page 5, \u2018which relative to an anchor node u is expressed as follows\u2019. This sentence needs to be rewritten.\n3. On page 5, \u2018wen & Li (2022) looks at xxx\u2019\uf0e0 \u2018wen & Li (2022) looked at xxx\u2019\n",
            "clarity,_quality,_novelty_and_reproducibility": "The quality of this paper needs to be improved since it is not organised very well and some claims are not fully supported. The novelty is somewhat limited since the main content is focusing on the discussion of existing works while the proposed model is based on BGRL. ",
            "summary_of_the_review": "This paper needs to be polished, and some experimental setup needs to be justified to support the proposed claims. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3389/Reviewer_N6ym"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3389/Reviewer_N6ym"
        ]
    },
    {
        "id": "pKvJsG5SR-",
        "original": null,
        "number": 2,
        "cdate": 1666601274057,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666601274057,
        "tmdate": 1669016338681,
        "tddate": null,
        "forum": "9Jaz4APHtWD",
        "replyto": "9Jaz4APHtWD",
        "invitation": "ICLR.cc/2023/Conference/Paper3389/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on investigating the performance of existing \nnon-contrastive methods for link prediction in both transductive and inductive \nsettings. In their experiments, they find that BGRL generally performs well in transductive settings, but poorly in the more realistic inductive settings, which motivates them to develop an extension of BGRL named T-BGRL to alleviate its overfitting phenomenon.",
            "strength_and_weaknesses": "Strength\n\n1.The writing of this paper is good and easy to follow.\n2.The experimental results on non-contrastive learning for link prediction is convinced and comprehensive.\n\nWeakness\n1.The novelty and theoretical analysis of the developed method is not enough",
            "clarity,_quality,_novelty_and_reproducibility": "I appreciate the effect of the authors to provide comprehensive experimental results of non-contrastive learning methods for link prediction, and also the intuitive analysis of their performance. However, this paper is more like a technical report of these non-contrastive learning methods to me, rather than a paper focusing on a new developed method.\n\n1.The motivation is mainly derived from the experimental results rather than the theoretical analysis of shortcomings of existing non-contrastive learning methods for link prediction. In chapter 3.1.1, the author did not provide a convinced explanation for the reason why BGRL can work well in the transductive setting.\n\n2.I can understand why the loss of ML-GCN can work well on link prediction, but what\u2019s the connection between the loss of BGRL and ML-GCN? Why the loss of BGRL can also work well on link prediction?\n\n3.The extension of BGRL is based on the hypothesis that ``One possible reason for the poor \nperformance of BGRL in the inductive setting is that it is unable to correctly differentiate unseen \npositive from unseen negatives, i.e., it is overfitting on the training graph.\u2019\u2019 But there is no experiment to support this hypothesis.\n\n4.Additionally, I am not sure whether other non-contrastive learning methods also perform poorly on link prediction. The best solution could be provide a theoretical analysis on why these methods tend to fail on link prediction.\n\n5.Some suggestions. \nIt will be better to release the full name of BGRL when you first cite it.\n\n6.Typo\nPage 5. which relative to",
            "summary_of_the_review": "This paper is more like a technical report of these non-contrastive learning methods to me, rather than a paper focusing on a new developed method.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3389/Reviewer_myZB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3389/Reviewer_myZB"
        ]
    },
    {
        "id": "2FA7n_pIgGl",
        "original": null,
        "number": 3,
        "cdate": 1666687857415,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666687857415,
        "tmdate": 1668912213093,
        "tddate": null,
        "forum": "9Jaz4APHtWD",
        "replyto": "9Jaz4APHtWD",
        "invitation": "ICLR.cc/2023/Conference/Paper3389/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper follows BGRL, and notices that it generalizes poorly due to a lack of negative examples.\nThey propose a non-contrastive framework for link prediction named T-BGRL that uses cheap \u201cnegative\u201d samples to improve generalization. \nExperiments show that T-BGRL improves BGRL\u2019s inductive performance in 5/6 datasets and is more efficient than contrastive methods.",
            "strength_and_weaknesses": "Strength:\n\n[1] This paper finds that BGRL tends to overfit the training graph, and thus can only perform well in the transductive setting. They introduce cheap \u201cnegative\u201d samples to improve generalization on the indictive setting.\n\nWeaknesses:\n\n[1] They said it's the first work to explore link prediction with non-contrastive SSL methods. However, BGRL is a non-contrastive model and can be applied to link prediction tasks easily.\n\n[2] These papers didn't compare with subgraph-based methods due to they are slow during inference. however, these subgraph-based methods perform well on large datasets. How about the performance of T-RGRL on large datasets (i.e. ogbl-ppa and ogbl-collab)?",
            "clarity,_quality,_novelty_and_reproducibility": "[1] This paper is clearly written and well organized.\n\n[2] They have proof of the advantage of T-BGRL on small datasets but haven't evaluation on large datasets.\n\n[3] This paper is an extension of BGRL and the implication of cheap \u201cnegative\u201d samples is novel.\n\n[4] The method is easy to reproducible.",
            "summary_of_the_review": "The analysis of BGRL makes sense and the proposed T-BGRL performs well in the inductive setting.\nI am open to raising my score if the authors can conduct experiments on ogbl-collab or ogbl-ppa.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3389/Reviewer_tANx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3389/Reviewer_tANx"
        ]
    },
    {
        "id": "od4Td8RfuK7",
        "original": null,
        "number": 4,
        "cdate": 1666827181170,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666827181170,
        "tmdate": 1666827181170,
        "tddate": null,
        "forum": "9Jaz4APHtWD",
        "replyto": "9Jaz4APHtWD",
        "invitation": "ICLR.cc/2023/Conference/Paper3389/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper is trying to tackle the area of graph self-supervised learning, which aims to derive useful node representations without labeled data. The paper proposes T-BGRL, a novel non-constrastive model to solve the link prediction problem. ",
            "strength_and_weaknesses": "Strength:\n1. The problem the paper is trying to solve is important research problem.\n2. The method proposed is easy to implement and the experiments show that the performance did improve on most datasets.\n\nWeakness:\n1. I do not quite understand why we want to apply non-contrastive learning methods for link prediction. What is wrong with those contrastive learning methods?\n2. Moreover, I do not understand why the proposed method falls in the category of non-contrastive learning methods. So it is very hard for me to judge the significance of the method.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear in terms of the algorithm and experiments but the importance and originality of the work needs to be addressed more clearly.",
            "summary_of_the_review": "Overall, the paper needs some improvement on explaining the significance of the work for it to be accepted.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3389/Reviewer_Qz7f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3389/Reviewer_Qz7f"
        ]
    }
]