[
    {
        "id": "gzwe3Zb-9i1",
        "original": null,
        "number": 1,
        "cdate": 1666209421231,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666209421231,
        "tmdate": 1668718175085,
        "tddate": null,
        "forum": "cytNlkyjWOq",
        "replyto": "cytNlkyjWOq",
        "invitation": "ICLR.cc/2023/Conference/Paper2668/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper describes a tranformer-based architecture for policies for multi-agent (video) games, that tokenises image-based inputs plus entity-component-system-based inputs (representing data of entities in video games), allowing the architecture to process inputs from various different games in a single and consistent manner. Policies are trained in three different video games (Honor of Kings, Neural MMO, and StarCraft II Micromanagement), some of which have multiple different scenarios. Several experiments show that it is effective to train in some games, transfer to others, and then finetune in the other games.",
            "strength_and_weaknesses": "## Strengths:\n\nThe primary strength of the paper is that the empirical results look convincing, and sufficiently extensive with some ablations. To the best of my knowledge, the proposed architecture is also novel, and it has some interesting insights.\n\n## Weaknesses:\n\nThe primary weakness is that several parts of the paper are unclear, and some statements even seem wrong. See below for detailed comments related to this.\n\n---\n\n**Note after discussion with authors**: I feel that the paper has been substantially improved during the discussion phase and have updated my score accordingly.",
            "clarity,_quality,_novelty_and_reproducibility": "My primary concerns with this paper are related to clarity, and sometimes quality (in the sense of correctness).\n\n## Detailed comments\n\n- \"we analogize games as languages\" (in abstract) --> I think this is potentially confusing. When I first read this, I thought it would mean that the authors would use a single language in which to describe (the rules of) the different games. But the only relation to languages seems to be that tokenization is also commonly-used there... which hardly seems an important enough similarity to describe it as \"analogize\" like this.\n- \"due to trail-and-error, RL is inclined to overfit to training environments\" --> how is this related to trial-and-error? If, hypothetically, we could exhaustively enumerate the complete space of all possible trajectories and learn from that (so no more need for trial-and-error), would we not still overfit to the environment for which we trained anymore?\n- \"we investigate whether a single model, with a single set of parameters, can be trained by playing multiple multi-agent games in an online manner.\" --> this sentence highly suggests, especially due to the phrasing and mention of a single set of parameters, that a single model will be trained that can play *all* games at the same time, with the same weights (i.e. not separated by training runs in between the different games). If I understood all the experiments correctly, there is no experiment where truly the exact same set of weights is used for multiple different games. I have a similar issue with describing the agents as \"generalist agents\" in the Conclusion. This is an important difference with agents such as Gato.\n- Throughout most, or maybe all, of the paper, there are several mentions of permutation invariance, but it is not actually clear in what ways there is permutation invariance: for which dimensions of the input space do we want permutation invariance, and why? After having read the full paper I can understand that the permutation invariance is between different entities: we should not care about the order in which different entities are presented as inputs to the model. But this is not clearly described in the paper, at least not nearly early enough. This intuition is very simple, and would be very helpful to describe early in the paper, but it isn't. In contrast, the phrase \"permutation-invariant\" already does show up several times early in the paper (e.g., towards the end of the Introduction), but without the intuition about the dimensions of the input space for which we want permutation invariance, and why, this is difficult to follow.\n- It is not clear to me how \"words\" are \"typically composed of images and vectors\". It would probably help to give some examples of what things would be images, and what things would be vectors.\n- One subfigure of Figure 8 is missing the red line, and one is missing the green line. Where did they go?\n\n## Other minor comments\n\n- \"(2020), Furthermore\" --> looks like a comma instead of a period ending the sentence\n- \"AlphaStar requires [...] half a month\" --> should provide references for all these agents and numbers\n- many instances of \"casual\" which I think should probably be \"causal\"?\n- several cases of \"radio\" which I think should be \"ratio\"?\n- Subsection 3.3 just lists a bunch of publications that used video games, but does not discuss that work in any way. In this form, I'd say the entire subsection seems unnecessary and could be removed.\n- \"can be represented as (1)\" --> what is (1)?\n- Legends in Figures 8 and 9 are impossible to read unless I zoom in to 150%, which probably means they would be unreadable in print.\n- The caption of Figure 12 mentions P3, but I dont see P3 anywhere.",
            "summary_of_the_review": "The paper is interesting and has some interesting and potentially significant contributions, but in its current form has too many issues in terms of clarity.\n\n**Note after discussion with authors**: I feel that the paper has been substantially improved during the discussion phase and have updated my score accordingly.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2668/Reviewer_gmYJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2668/Reviewer_gmYJ"
        ]
    },
    {
        "id": "hdDCfPozLLx",
        "original": null,
        "number": 2,
        "cdate": 1666541900704,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666541900704,
        "tmdate": 1666541956190,
        "tddate": null,
        "forum": "cytNlkyjWOq",
        "replyto": "cytNlkyjWOq",
        "invitation": "ICLR.cc/2023/Conference/Paper2668/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors proposed a novel transformer architecture to solve multi-agent games. The model contains two major parts (1) game specific tokenizers and output layers which encode different game observations into the same token space and output the right actions (2) the main transformer model with \u200b\u200bpermutation invariant pooling and encoder-decoder modifications. With a multi-stages training, the proposed method is able to fast adapt to novel games or new game settings. \n",
            "strength_and_weaknesses": "The strengthnesses of the paper:\n1) Proposed a single transformer architecture to solve multiple different battle games.\n2) Ablation studies to test the performance of the model(s) at different training stages.\n\nThe weaknesses of the paper:\n1) The clarity of the paper can be improved. For example in section 4.2 authors discuss the encoder-pooling and the modified encoder-decoder architectures, but leave many missing details: the latent variable z_i seems to be a scalar with encoder pooling due to the symmetry requirements, which looks rather stranger (or is that the case?).  \n2) Need more details on the architecture, i.e. how many encoders/decoders/attention heads are used, etc. \n3) Also, the performance comparison plots use different x-values: some use samples and some use time. This is a bit confusing. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is mostly clear with some details missing. The results and ablation studies are plenty. The originality of the work seems minor since the authors test only minor modifications to the transformer architecture. ",
            "summary_of_the_review": "While the paper is mostly clearly written, the novelty of the paper is limited.  ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2668/Reviewer_D4zs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2668/Reviewer_D4zs"
        ]
    },
    {
        "id": "i9kkUnVhtY",
        "original": null,
        "number": 3,
        "cdate": 1666681588344,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681588344,
        "tmdate": 1666681588344,
        "tddate": null,
        "forum": "cytNlkyjWOq",
        "replyto": "cytNlkyjWOq",
        "invitation": "ICLR.cc/2023/Conference/Paper2668/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces MAGENTA, which is a variant of PPO with a transformer architecture. Based on experiments in large cooperative video games, MAGENTA appears to be able to transfer knowledge across games. \n",
            "strength_and_weaknesses": "I think this is a nice paper. Although similar research has been done in language, offline RL, and multi-game RL, this is the first to show that the same trend of scale helping generalization also works in cooperative multiagent RL.\nThe experiments are on very large video games, and it is not obvious that so much would transfer to different video games, especially because the representation is not the part that gets transferred, but the transformer that decides which actions to take. \nOne thing I would have liked to seen would be better small-scale experiments where comparisons with many baselines could be tested. \nThe results are not striking, but I think they clearly show the benefit of MAGENTA\nI think this paper will have some impact in the related literature on cooperative RL and transformers for decision making\nFigure 7 should be clearer, I think this is head to head against the FC+LSTM\n",
            "clarity,_quality,_novelty_and_reproducibility": "I thought it was quite clear. The authors do not have code and do experiments on large games, so I don't think it is very reproducible.  ",
            "summary_of_the_review": "I think this paper is the first to show what many might have suspected: that large models transfer and generalize in cooperative multi-agent environments. This is interesting and I think future work can build off of this fact. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2668/Reviewer_5qFD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2668/Reviewer_5qFD"
        ]
    },
    {
        "id": "O7EYyG_s78",
        "original": null,
        "number": 4,
        "cdate": 1666822883431,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666822883431,
        "tmdate": 1669747607857,
        "tddate": null,
        "forum": "cytNlkyjWOq",
        "replyto": "cytNlkyjWOq",
        "invitation": "ICLR.cc/2023/Conference/Paper2668/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work proposes a learning framework, MAGENTA, that can tackle multiple multi-agent environments with one transformer agent. The authors focused on real-time strategy games in this work, including Honor of Kings (HoK), Starcraft II micromanagement (SMAC), and Neural MMO (NMMO). They treat agent entities as tokens and learn separated tokenizers, a unified transformer body, and separated output layers. It shows that it is possible to train generalist agents for multiple multi-agent environments in an online manner (using PPO), and shows that such online generalist agents can rapid adapt to never-seen-before games or scenarios with fine-tuning. The results empirically show that the proposed model learn common knowledge about multi-agent games across various categories.",
            "strength_and_weaknesses": "Strengths\n* It is a good proof of existence of generalist agents for multiple multi-agent environments. I think showing the community how to learn such agent is a valuable empirical contribution.\n* The transfer-to-unseen-scenario results and transfer-to-new-game results are convincing, showing that training the pre-trained model with more games are usually beneficial.\n\nWeaknesses\n* I found Sec. 5.5 (scaling and comparison to single-game agents) confusing. With only scores normalized by single-agent performance at each size tick. I think it doesn't have enough information for me to interpret the results and the conclusion \"We interpret this result as overparameterization, where a richer model is fitting than necessary\" is kinda hand-wavy. I would suggest adding raw scores, which could help the reviewers to inspect the claim and help reader to understand better.\n* The learning curriculum (Figure 5) is adhoc, and there is no ablation on the curriculum. The current curriculum basically uses Honor of Kings as an anchor. I think even just explaining what could happen otherwise would be helpful. ",
            "clarity,_quality,_novelty_and_reproducibility": "As pointed out above in weakness, clarity has some room for improvement. Some further questions/comments I have include:\n* There are many different (sub-)version of models. I think having a table to list them and also list the transfer experiments would be helpful.\n* Why in Figure 4 both decoder and pooling outputs $z_i$?\n\nNitpick:\n* Gammer error in \"How the performance of the entity transformer in single game?\" (beginning of Sec. 5)",
            "summary_of_the_review": "I'm not able to interpret the results given the current manuscript, so couldn't recommend acceptance now. I hope the authors would be able to fix this.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2668/Reviewer_9Jjr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2668/Reviewer_9Jjr"
        ]
    }
]