[
    {
        "id": "1RyVkWOh6I",
        "original": null,
        "number": 1,
        "cdate": 1666552462314,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666552462314,
        "tmdate": 1666552462314,
        "tddate": null,
        "forum": "7i6OZa7oij",
        "replyto": "7i6OZa7oij",
        "invitation": "ICLR.cc/2023/Conference/Paper4512/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the impact of the strength of inductive bias on the generalization performance of the trained model. First, the authors prove that in kernel learning with convolutional kernels, a phase transition occurs in the noisy data setting. Specifically, when the level of inductive bias exceeds a particular threshold, interpolation is harmful. But, it is harmless when the inductive bias is sufficiently weak. For the noiseless data setting, no similar transition occurs and interpolation is provably harmless. In addition, the authors prove that in the noisy data setting, the model with the weak inductive bias fits some of the noise (variance on the training sample is below the data variance). However, the latter statement does not really prove that interpolating noise is necessary since nothing is mentioned about the optimal inductive bias. Finally, the authors present two experiments, which suggest that such conclusions seem to hold in deep neural networks as well. \n",
            "strength_and_weaknesses": "This is a well-polished paper that studies the important topic of generalization in modern neural networks. The authors present an interesting insight in terms of inductive bias that is quite novel and is supported both theoretically and experimentally. The experiments are also well-executed. \n\nThe primary weakness is that the settings studied theoretically and experimentally are contrived but I don\u2019t think this is a major issue given the insight this paper provides. It would have been valuable to figure out how to quantify inductive bias in typical training settings, e.g. in standard benchmark image datasets with convolutional neural networks, but this is quite challenging given the lack of knowledge about the ground truth. \n\nAnother weakness is already acknowledged by the authors. The main theoretical results make strong assumptions about the distribution of the data that cannot be easily relaxed. \n\nFinally, while the authors prove that models with weak inductive bias interpolate some of the noise, this does not mean that interpolating noise is necessary since it is not clear whether the optimal bias is below or above the threshold $\\beta^\\star$. Please correct me if I have miss-interpreted this part.\n\nI have two minor suggestions:\n\n- Please clarify the meaning of the $\\Theta$ notation for quantities that are bounded from below by zero and go to zero such as writing $\\sigma^2 = \\Theta(d^{-\\ell_\\sigma})$. I personally read this as $O$ notation but if there is more than that, please clarify in the paper. \n- The statement of the theorems should be self-contained. Currently, there are hidden assumptions on the ground truth and eigenfunctions in the proof that are not stated in the main theorems. Please mention them explicitly. \n\nTwo typos:\n\n- Line 32: \u201cinterpolators interpolators\u201d\n- Line 208: \u201cdouble descentpredicts\u201d\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and is of a high quality. Both the theoretical and experimental results are insightful and novel in my opinion. Also, the authors describe the experimental settings in sufficient length for reproducibility. ",
            "summary_of_the_review": "This is a nice, insightful paper that is well-executed. However, I haven't verified the correctness of the proofs.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4512/Reviewer_KVHo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4512/Reviewer_KVHo"
        ]
    },
    {
        "id": "WYDeyBoTrD",
        "original": null,
        "number": 2,
        "cdate": 1666590146655,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666590146655,
        "tmdate": 1666590146655,
        "tddate": null,
        "forum": "7i6OZa7oij",
        "replyto": "7i6OZa7oij",
        "invitation": "ICLR.cc/2023/Conference/Paper4512/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the harmless interpolation in the setting of high-dimensional kernel regression with convolutional kernels. Here, harmless interpolation means that the performance (measured by test error) gap between the interpolated models and optimal-regularized model is small. The authors gave the non-asymptotic bounds of test error (in terms of bias-variance decomposition) for both regularized and interpolated models. The authors further showed the impact of filter size of convolutional kernels: harmless interpolation will not happen for small filter size (strong inductive bias), but will occur for large filter size. Also, it is shown that for large filter size, the optimal-regularized models have to fit part of the noise, i.e., training error smaller than noise level. Experiments are provided to justify the theoretical results.",
            "strength_and_weaknesses": "Strength:\n- The paper is overall clearly written and easy-to-follow.\n- Understanding the generalization properties of interpolated models is an important and interesting direction of the theoretical machine learning, and this paper gives interesting results towards this direction.\n- The results are interesting and novel to my knowledge, which show the relation between filter size and the performance of optimal-regularized and interpolated models.\n- The results are clearly stated with assumptions. Proof sketch is provided in the main text with full proof in the appendix.  \n\nWeaknesses:\n- The proof techniques may not be easy to generalize to other settings beyond kernel and linear settings.\n- It would be great if authors could provide a formula (or the order) of some quantities in the main text or appendix, such as $\\beta^*$ and $\\lambda_{opt}$.\n\nMinor:\n- line 208: missing a space between descent and predicts\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n- Overall the paper is well-written and easy-to-follow.\n\nQuality:\n- The quality of this paper is overall good. Theorems and assumptions are clearly stated. Proof sketch is provided in the main text with full proof in the appendix. (I didn\u2019t check the full proof).\n\nNovelty:\n- The harmless interpolation/benign overfitting is an active research direction and studying the impact of such biases is an important problem.\n- The results are novel to my knowledge, which shows the impact of implicit bias on the performance in the noisy setting.\n\nReproducibility:\n- This is a theoretical work with several experiments. Full proofs are provided in the appendix and codes are provided in the supplement material, but I didn\u2019t check/run them.\n",
            "summary_of_the_review": "In summary, the paper studied the generalization error of optimal-regularized and interpolated models in high-dimensional kernel regression setting. The results showed impact of filter size to the test error, which appears to be new and interesting. Therefore, I\u2019m leaning towards accept.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4512/Reviewer_NQJb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4512/Reviewer_NQJb"
        ]
    },
    {
        "id": "T7UgnU77oAy",
        "original": null,
        "number": 3,
        "cdate": 1666631430935,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666631430935,
        "tmdate": 1666631430935,
        "tddate": null,
        "forum": "7i6OZa7oij",
        "replyto": "7i6OZa7oij",
        "invitation": "ICLR.cc/2023/Conference/Paper4512/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies how the strength of inductive biases affect harmless interpolation or benign overfitting, where models can generalize well despite interpolating a (possibly noisy) test set. To study this question, the authors adjust the filter size in convolutional kernels. Smaller filter sizes encode for functions that depend nonlinearly only on local neighborhoods of the input features, whereas this bias is weakened for larger filter sizes. The paper shows theoretically that for high-dimensional kernel regression with convolutional kernels, there is a phase transition between harmless and harmful interpolation in filter size (Theorem 1). The authors show that interpolation is harmless for weak inductive biases, and that for strong inductive biases, they show interpolation can be harmful. Further, they show fitting noise is necessary for strong inductive biases to achieve optimal performance. These theoretical results are supported by experiments in neural networks, where the same phenomenology is observed.",
            "strength_and_weaknesses": "**Strengths**\n- The paper studies an important problem of benign overfitting and finds a new condition (strength of inductive bias) that it is predicated on.\n- The paper is easy to follow and well written. It states the main claims clearly and provides evidence for them.\n\n**Weaknesses**\n- The difference between the strength of inductive biases and parameter count is not fully resolved in the neural network experiments. Is it possible to just control the number of parameters by adjusting the width to compensate for change in filter size?",
            "clarity,_quality,_novelty_and_reproducibility": "- How is the optimal regularization strength found in the estimator of Thm 2? Is this an optimization that is performed exactly? \n- There are no results on the bias and variance of the neural network trained in Sec 4. It should be possible to estimate this from experiments. Do the authors expect to see similar multiple descent curve?",
            "summary_of_the_review": "The paper makes a nice contribution and is of interest to the ICLR community. It is clearly written with nice figures. From my read of the paper's main text, the theorems seem correct.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4512/Reviewer_fKcA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4512/Reviewer_fKcA"
        ]
    }
]