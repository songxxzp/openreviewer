[
    {
        "id": "LyYcfvf-SCN",
        "original": null,
        "number": 1,
        "cdate": 1666547977938,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666547977938,
        "tmdate": 1666547977938,
        "tddate": null,
        "forum": "h-tOz83WrC",
        "replyto": "h-tOz83WrC",
        "invitation": "ICLR.cc/2023/Conference/Paper793/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new neural network interpretation and attribution framework which looks at heat flow to achieve multi-scale interpretation of a scalar-valued function",
            "strength_and_weaknesses": "\nPros:\n- It is an interesting and novel idea to use the diffusion equation for the attribution problem\n- The paper is generally well written\n\nCons:\n- Evaluation strategy and analysis (see comment 1 below)\n- Related literature (see comment 2 below)\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the paper is clearly written.\n\nQuality: there are concerns about the evaluation strategy, as as things stand, the evaluation is limited and does not match up with state-of-the-art evaluation practices. \n\nOriginality: the idea builds upon the existing ideas of using heat equation, but it is applied in a different domain of interpretability of machine learning models, and therefore is novel. The efforts must be made to refer to existing machine learning approaches using heat equation (see Question 2).\n\nComments on quality:\n1. Evaluation strategy can be improved in multiple ways. First, there is a doubt about the existing experiments. The first question would be : is MNIST a good dataset for evaluating interpretation? There is not much of a texture, and nearly any peak around the  contours of a symbol could be seen as a successful attribution. The results from the appendix, section A.9, make more sense to me. I think it would be great if the authors could comment on usability of MNIST dataset, maybe the reviewer misses something.  It is also important to show the legends for the heatmaps, see e.g. Figure 2 (which would clarify that say lower values are blue and the higher values are red). For Figure 4, it would be also important to include other datasets, including high-textured ones. Another question to answer is how it performs on the tasks related to the attribution, as it would help understand whether we can highlight specific features of the image (and also make it visually comparable to the other works). Simonyan et al, for example, use high-resolution dataset ILSVRC-2013. Xu et al (2020) use ImageNet and Diabetic Retinopathy data.  Also, do the predictions help identify causes of failures/what would the attribution look like for erroneous predictions?\n2. Related literature: the paper discusses explanation methods, but it also needs to cover somehow the background of diffusion models and heat equations which has also recently been popular in the literature (see Kingma et al, 2021). \n3. P5: increasing larger ts -> increasingly larger ts",
            "summary_of_the_review": "The experimental evaluation needs to be more extensive, matching existing published models for interpretability and attribution (see Comment 1 above). Therefore, I do not recommend acceptance as things stand at this stage (but I welcome clarifications and improvements)",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper793/Reviewer_Nuvr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper793/Reviewer_Nuvr"
        ]
    },
    {
        "id": "v0LMVFgG8sL",
        "original": null,
        "number": 2,
        "cdate": 1666673026183,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666673026183,
        "tmdate": 1666673026183,
        "tddate": null,
        "forum": "h-tOz83WrC",
        "replyto": "h-tOz83WrC",
        "invitation": "ICLR.cc/2023/Conference/Paper793/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the author proposes the HeatFlow. \nIt calculates the feature attribution using the model's outcome and local average values.\nIt provides multi-scale explainability results.",
            "strength_and_weaknesses": "Pros:\nThe proposed FeatFlow is proved to be an additive model and satisfies the four axioms of the Shapley value. \nThis proof provides solid theory support that FeatFlow can provide fair feature attributions.\n\nCons:\nThis paper is a little hard to follow.\nAlthough the authors define each symbol, \nit's still hard to connect these abstract symbols to the explainability task.\n\nFor example, in section 2.1, \nI think it can be better if more details about the Laplacian-Beltrami operator are given and provided some sample examples to show the relationship or motivation to apply this method on explainability.\n\nA detailed pseudo-algorithm may be a better way to show the methodology clearly.\n\nQuestion\uff1a\nIn Figure 4, it seems like IG gets the best result on the MNIST exclusion curve and it's better than the proposed HeatFlow.\nHowever, in the UTKFace exclusion curve, it seems like IG has a much lower MAE than heat and SG.\nCould you provide some insight into this phenomenon? I am curious about this.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The idea is interesting to use the diffusion process in explainability. But the writing of this paper is hard to follow and the connection between the math symbol and explainability task should be added.",
            "summary_of_the_review": "Above all, I think this paper provides an interesting framework to apply the PDE method to the explainability task. \nHeatFlow can provide a fair attribution assignment by obeying four axioms in Shapley value.\nHowever, the paper is hard to follow, and more details should be included to help the readers to understand.\nI am willing to raise my score if the paper flow becomes easier to follow.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper793/Reviewer_s9nq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper793/Reviewer_s9nq"
        ]
    },
    {
        "id": "d1MuVPEsv1",
        "original": null,
        "number": 3,
        "cdate": 1666686763483,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666686763483,
        "tmdate": 1666686763483,
        "tddate": null,
        "forum": "h-tOz83WrC",
        "replyto": "h-tOz83WrC",
        "invitation": "ICLR.cc/2023/Conference/Paper793/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper under review uses heat diffusion process to understand some multi-scale behavior of the learned model around a test point. Summary scales which characterizes the model on different scales can be drawn. ",
            "strength_and_weaknesses": "Strength: This paper is clearly written and well-organized. \nWeakness: The paper introduces many math notations, while no enough emphasis on why heat flow can help us better understand the functions represented by neural networks for instance. There is no really crucial part which help us advance the understanding of DNN for instance. The results showed here are too toy models. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good. Quality: Fair; Novelty: Fair; It is a theoretical paper. I do not check the reproductivity. But the proof is right but the results are somehow standard in math community. ",
            "summary_of_the_review": "I would not suggest to accept this paper. It would be better developed before resubmit to a journal or a conference proceeding. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper793/Reviewer_uXwu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper793/Reviewer_uXwu"
        ]
    },
    {
        "id": "yH95cuVpr_",
        "original": null,
        "number": 4,
        "cdate": 1666689024806,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666689024806,
        "tmdate": 1666689706950,
        "tddate": null,
        "forum": "h-tOz83WrC",
        "replyto": "h-tOz83WrC",
        "invitation": "ICLR.cc/2023/Conference/Paper793/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "The authors propose HeatFlow, a framework based on the heat equation on a Riemannian manifold, to interpreting a representation of givn deep learning model. Especially, they focus to analyze the multi-sale behvariors of the model, which cannot be revealed by using a naive gradient-based model interpretation approach. The authors show that the proposed HeatFlow framework obeys some nice properties that frequently used in the interpretable AI field, e.g., attribution axioms. The authors compare the proposed method with four baselines including Grad, IG, SG and BlurIG",
            "strength_and_weaknesses": "Disclaimer:\n\n I am not an expert of the model interpretaion and explainable AI fields. My evaulation on this paper is not exhaustive and might be incorrect.\n\nStrength:\n\n1. The paper is based on solid theoretical properties from differential geometry and PDE. It seems that the proposed method is technically sound.\n\n2. Experimental results show that the proposed HeatFlow is likely to interprete the model more convincely compared to other baselines.\n\nWeakness:\n\n1. The proposed method can only address a scalar case, i.e., 1D regression problem or binary classification. However, it can be by-passed by investigating each output of multi-class/multi-dimensional models separately.\n\n2. The paper is a little dense and hard to read. It might be because I am not familar with the math used in this paper.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n\nThe paper is a little dense and hard to read. It might be because I am not familar with the math used in this paper.\n\nQuality:\n\nThe mathematical background used in this paper seems to be solid.\n\nNovelty:\n\nTo me, the use of the heat equation on a Riemannian manifold to interpreting deep learning models is novel. However, I do not know modern literatures on this field well-enough to evaluate correclty.\n\nReproduciblity:\n\nThe paper contains an incomplete set of used model architectures and hyper-parameters. Experimental code is not made publicly available (although it might be not a ciritcal issue considering this paper is theoretical one).\n",
            "summary_of_the_review": "While it is an educational guess, I think this paper contributes both a solid theoretical background and practial method for the relevant field. I would like to vote to accept this paper. However, since I am not an expert in this field, I cannot evaluate this paper exhaustively; thus, my rating might be updated after discussing with the authors and other reviewers.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper793/Reviewer_VgMK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper793/Reviewer_VgMK"
        ]
    }
]