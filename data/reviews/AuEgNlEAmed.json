[
    {
        "id": "d8SJMViqX7",
        "original": null,
        "number": 1,
        "cdate": 1666649311851,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649311851,
        "tmdate": 1666650324713,
        "tddate": null,
        "forum": "AuEgNlEAmed",
        "replyto": "AuEgNlEAmed",
        "invitation": "ICLR.cc/2023/Conference/Paper6054/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper studies inductive bias from the model class in contrastive learning. The paper proposes some mild and practical assumptions and studies the optimal solution of the spectral contrastive loss from the eigenfunction perspective. The paper argues that when the model has limited capacity, contrastive representations would recover certain special clustering structures (depending on model architecture) but ignore other clustering structures in the data distribution. Moreover, the paper also studies different model classes including linear functions, ReLU networks, Lipschitz continuous functions, and Convolutional neural networks. ",
            "strength_and_weaknesses": "Strength:\n1. As far as I know, this is the first work to study inductive bias originating from the model class in contrastive learning. The paper is based on some reasonable assumptions and gets a non-trivial conclusion. In my opinion, Assumption 2 is the most critical one. The function class cannot be too powerful so that we can guarantee the generalization. The authors also introduce novel tools, eigenfunction methods, in analyzing contrastive learning. \n2. The paper has a clear motivation and a good structure. \n\nWeakness and Questions:\n1.  I am not familiar with Eignfunction methods. I have some questions for Section 4. What is the relationship between $k$ orthogonal eigenfunctions and equations (9) and (10)? Are equations (9) and (10) additional assumptions here or can they be induced from $k$ orthogonal eigenfunctions? What is the connection between Assumption 6 and Assumption 2 and 3? I cannot get full insights into how is Therom 2 generalized from Theorem 1. \n2. One concern I have is that in practice the model has more than millions of parameters, e.g. vision transformer. Then, how to guarantee assumption 2 in a real empirical scenario. Note that Assumption 2 considers the whole function space. If assumption 2 is not guaranteed, how to explain the success in MoCo v3 [3]? \n3. There are some subtle weaknesses in the problem settings. The paper studies generalized spectral contrastive loss rather than the InfoNCE family loss. The authors also did not consider the sample complexity in the pre-training like [1,2]. \n4. The experiments part is weak.  It is acceptable considering it is a theoretical paper. The $b_r$ is not a clear metric for reader to understand the partition effect, e.g. for $r=500$, how bad is $b_r=0.315$. More explanation is needed here.\n\nTypos:\n1. In Figure 2, there are no orange points. \n2. In page 16, \u201cwiht\u201d -> \u201cwith\u201d.\n\n[1] Arora, Sanjeev, et al. \"A theoretical analysis of contrastive unsupervised representation learning.\" arXiv preprint arXiv:1902.09229 (2019).\n\n[2] HaoChen, Jeff Z., et al. \"Provable guarantees for self-supervised deep learning with spectral contrastive loss.\" Advances in Neural Information Processing Systems 34 (2021): 5000-5011. \n\n[3] Chen, Xinlei, Saining Xie, and Kaiming He. \"An empirical study of training self-supervised vision transformers.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper has good clarification and motivation. \n\nQuality: I checked most proofs in the appendix. The statements look good to me. \n\nNovelty: The paper has its novelty as far as I know. \n\nReproducibility: I believe the experiments part can be reproduced. \n",
            "summary_of_the_review": "Although there are some questions I mentioned in the Weakness part that blocked me, the paper has its novelty and I tend to accept it. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6054/Reviewer_HMnY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6054/Reviewer_HMnY"
        ]
    },
    {
        "id": "EXYPy9BoUA",
        "original": null,
        "number": 2,
        "cdate": 1666713326559,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666713326559,
        "tmdate": 1666713326559,
        "tddate": null,
        "forum": "AuEgNlEAmed",
        "replyto": "AuEgNlEAmed",
        "invitation": "ICLR.cc/2023/Conference/Paper6054/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides a theoretical analysis of contrastive learning in the setting where the hypothesis class has significantly smaller dimension than the data distribution (as measured by the number of clusters). They instantiate their framework on a few example settings and show that their results provide theoretical guarantees where previous approaches do not.",
            "strength_and_weaknesses": "Strengths:\n\n- The paper is well-written and the authors provide intuition around each provided result, and motivate the problem well.\n- The authors present the example from Saunshi et al (2021) and show how their results shed light on the actual behavior of contrastive learning in that setting.\n\nWeaknesses:\n\n- The experimental section is a bit confusing and I don't quite see the connection between the theory and the experimental results. In particular, the experiment shows that as the number of clusters gets higher, the loss of a contrastive classifier also gets higher. My issue with this experiment is that I do not see what the alternative is to the results shown in the table in page 9---clearly as r -> infinity the loss must increase, and for r = 1 the objective is trivial, so I'm not sure what I should take away from the loss increasing (the numbers themselves are not interpretable to me).\n- A much more compelling experiment would be to show that the bounds proved in the previous sections are actually predictive of model behavior in some non-obvious way (e.g., by implicitly varying P_min and P_max, or by varying alpha and beta) and showing that Theorem 1 is predictive in this setting (at least in terms of trend)",
            "clarity,_quality,_novelty_and_reproducibility": "The work is clear and high-quality. I am not an expert in contrastive learning and cannot judge the novelty---I also skimmed the proofs for correctness but cannot attest to how theoretically interesting they are.",
            "summary_of_the_review": "This paper presents a theoretical analysis of inductive biases in contrastive learning. Their main result is that when the function class being learned over is restricted, one needs a representation size that is far smaller than the number of clusters in the data distribution. The paper is clearly written, the results seem correct, and also address issues raised by prior work. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6054/Reviewer_XWTN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6054/Reviewer_XWTN"
        ]
    },
    {
        "id": "gRZSjPuKom",
        "original": null,
        "number": 3,
        "cdate": 1666810637193,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666810637193,
        "tmdate": 1669572979216,
        "tddate": null,
        "forum": "AuEgNlEAmed",
        "replyto": "AuEgNlEAmed",
        "invitation": "ICLR.cc/2023/Conference/Paper6054/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Prior work by Saunshi et al. 2022 had highlighted the insufficiency of previous theoretical analyses that are function-class agnostic to completely explain the success of self-supervised learning. This paper provides theoretical guarantees for self-supervised learning that do incorporate the function class building on the framework of HaoChen et al 2021. \n\nIn particular, the paper presents a notion of *minimal implementable clusters* for a function class $\\mathcal{F}$, that is, the size of the smallest disjoint partition of the input space such that the positive pairs lie with high probability in the same cluster and the clusters within each partition are non-sparse under the geometry enforced by the underlying function class $\\mathcal{F}$. At a high level, this notion intends to captures the ability of the function class $\\mathcal{F}$ to break the underlying positive-pair graph (vertices = augmentations of images, edges = if two augmentations can be generated from the same image) into too many clusters. The main theorem then says that the embedding dimension needed to guarantee good downstream performance is dependent on the minimal implementable clusters which may be exponentially smaller than the total number of clusters independent of the the function class.",
            "strength_and_weaknesses": "**Strengths**:\n- The main result in the paper improves the current theoretical understanding of self-supervised learning and formalizes the example presented in Saunshi et al. (2020).\n- The eigenfunction perspective is a nice generalization and probably has connections directly to spectral clustering/kernel PCA.\n- The authors do a good job of including several examples to instantiate the theorem.\n\n**Weaknesses**:\n- The main weakness of the paper is writing. The paper is written for a narrow set of the audience who is very familiar with the existing works of HaoChen et al. 2021, 2022 and Saunshi et al. 2022. Very little effort has been put to make the core ideas accessible to a broader audience. Furthermore, figure 1 is very hard to understand given that it has no \u201corange\u201d points. Considering this is the main figure used to motivate the underlying study, this already makes it very hard to follow the paper.\n- The experimental evaluation is not very convincing. Assumption 2 depends on all $f \\in \\mathcal{F}$ but the evaluation is based on a specific value of the learned $f$ from the contrastive solution (which encodes the inductive biases of the algorithm as well). It is hard to understand what these numbers mean and whether the trend is enough.",
            "clarity,_quality,_novelty_and_reproducibility": "The results are novel and reproducible from the proofs, however as discussed before, the paper requires a lot of work on the writing side to be accessible to the ICLR audience. Here are some particular suggestions:\n- Fix Figure 1\n- Explain HaoChen et al. 2021, particularly the positive-pair graph. Maybe add a figure.\n- Further emphasize the role of dimensionality here, and the fact that the improvement is in terms of this\n- Since the $m$-way partition is defined independent of $\\mathcal{F}$, and tied to that using Assumption 1 & 2, it took me a bit of back and forth to understand. Would be great to abstract the definition separately from the assumptions, and then talk about the assumptions.\n- Add more discussion regarding the assumptions, as to why they are necessary, especially Assumption 4, which seems redundant given that we use a linear map on top to predict anyway. Furthermore, the setting could be defined first (which includes assumption 1 & 5 which are only assumptions on the data generating process), and then the assumptions on the function class.\n- Would be good to add a comparison to HaoChen et al. 2021, and whether you get their results assuming $\\mathcal{F}$ is the class of all functions.\n- More discussion on why the condition in the eigenfunction section compares to the assumption in the previous section, how the quantities relate\n- Typos:\n    - Wrong paper cited in the abstract\n    - \\cite \u2192 \\citep in appropriate places",
            "summary_of_the_review": "Overall, I think the paper makes progress towards understanding the role of function class for contrastive learning and formalizing the observations in Saunshi et al. 2022. Given that the prior work did already propose a setting where the role of function class was highlighted, this paper\u2019s primary contribution is a more refined theoretical treatment of this observation, and not the observation itself. This diminishes the contribution of the work slightly, however I still think it would be interesting to the ICLR audience. My major concern is writing and the experimental section, which is reflected in my comments above. Therefore, currently I think the paper is not ready for acceptance. I will be happy to increase my score if these are improved.\n\nPost rebuttal: 5-> 6",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6054/Reviewer_1bvx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6054/Reviewer_1bvx"
        ]
    },
    {
        "id": "6Ulle-4il4l",
        "original": null,
        "number": 4,
        "cdate": 1667509473522,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667509473522,
        "tmdate": 1670760975402,
        "tddate": null,
        "forum": "AuEgNlEAmed",
        "replyto": "AuEgNlEAmed",
        "invitation": "ICLR.cc/2023/Conference/Paper6054/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies contrastive learning from a theoretical perspective. Previous works on this topic showed the benefits of contrastive learning, assuming the pretraining loss is minimized over all sets of functions with no specific form. In this work, it is assumed that the pretraining loss is minimized by certain classes of functions, such as linear predictors and neural networks. Under different assumptions on the data and architecture, it is shown that contrastive learning can learn useful representations for downstream tasks. The results show that this can be achieved with representations of lower dimensionality compared to previous results.",
            "strength_and_weaknesses": "Strengths\n1. Solid theoretical results.\n\n2. Novel results for self-supervised learning with contrastive loss.\n\nWeaknesses\n\nThe main weakness is that the presentation of the results and mathematical details are not very clear.\n\nHere are the details:\n\n1. The relevance of Theorem 1 in this paper is not clear. It is presented as the main result but is not used in the paper. Theorem 2 is used instead. It is claimed that Theorem 2 generalizes Theorem 1. However, because of the various assumptions, it is not shown if this generalization is strict, or there are cases where Theorem 1 guarantees better results. Generally, the connection between the assumptions in Section 3 and Section 4 are not clear. \n2. The details of the proof of Theorem 2 are not clear:\n(a) Where is Eq. (57) used in the proof? Also, $\\tilde{W}$ appears in the proof (Eq. 57), but later disappears. Where does it appear in the calculations?\n(b) How is Eq. (59) derived from Lemma 1 and Eq. (55)? The details are not shown.\n3. In Example 3, what does \u201ccontains lots of disconnected subsets\u201d mean formally?\n4. In Theorem 1, does the result hold for k>m? In Theorem 3, can we set k > s?\n5. The experiments are not very convincing. The optimization method that first optimizes the contrastive loss and then whitens the result may not minimize Eq. (18).\n6. Are the results in Section 5 specific to the regularization used? For example, if we slightly change the distribution in Example 1 to a general product distribution, do the results still hold?\n7. The orange points in Figure 1 are missing.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality. \n\nStrong theoretical results, but some of the mathematical details are not clear. Experiments are not very convincing.\n\nClarity.\n\nThe paper is mostly well-written, but as showed above, some of the details can be clarified.\n\nNovelty.\n\nThe paper contains several novel theoretical results.",
            "summary_of_the_review": "This paper shows novel theoretical results on self-supervised learning with the contrastive loss. In several parts, the presentation of the mathematical results and writing are not clear.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6054/Reviewer_tjye"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6054/Reviewer_tjye"
        ]
    }
]