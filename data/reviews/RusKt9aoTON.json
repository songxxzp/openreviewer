[
    {
        "id": "vp8akIfLJT3",
        "original": null,
        "number": 1,
        "cdate": 1666676482806,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666676482806,
        "tmdate": 1666677022006,
        "tddate": null,
        "forum": "RusKt9aoTON",
        "replyto": "RusKt9aoTON",
        "invitation": "ICLR.cc/2023/Conference/Paper1289/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In Strength And Weaknesses",
            "strength_and_weaknesses": "This paper speedups model training by maximizing GSNR in FL and provides the optimal local updates from a theoretical viewpoint. However, I'm not an expert in FL and have a heavy review load. Due to my limited time, I can't be more positive at the current stage. I encourage the authors pay more attention on other reviewers' responses as I will make my confidence the lowest.\n\nThough I'm not an expert in FL but I find the theoretical results in Sec 3 are interesting. Thus, I will only give some comments and ask some questions about this part. My questions may be highly biased due to I didn't go through all details in the paper. I would be glad if the authors could point out my misunderstandings.\n\n1. About the upper bound Eqn (6). Why is the target distance (5) approximately minimized when the upper bound is minimized? There might be a gap. It would be better if the authors provide a simple example to verify its possibility in the current setting.\n2. I'm confused by Lemma 3.2 and Lemma 3.4. It seems Lemma 3.4 is to calculate the asymptotic mean and variance by initial weight $w_1$. And the step size goes infinity. But Lemma 3.2 let the minibatch $B$ goes infinity. Could the author tell me more about how to connect Lemma 3.2 and Lemma 3.4 with different asymptotic parameters ($B$ and $r$)?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "In Strength And Weaknesses",
            "summary_of_the_review": "In Strength And Weaknesses",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1289/Reviewer_Dx1S"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1289/Reviewer_Dx1S"
        ]
    },
    {
        "id": "qQBju05QM3h",
        "original": null,
        "number": 2,
        "cdate": 1666757019867,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666757019867,
        "tmdate": 1666757019867,
        "tddate": null,
        "forum": "RusKt9aoTON",
        "replyto": "RusKt9aoTON",
        "invitation": "ICLR.cc/2023/Conference/Paper1289/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In Federated Learning with heterogeneous data, the gradient of each client is pointing in a different direction when running a local algorithm s.t. local SGD. Since each client performs several local steps, the algorithm deviates from the theoretically better algorithm that would follow the averaged direction of the gradients. \n\nThis paper proposes a technique to reduce this deviation effect and speedup the training algorithm. Based on the Gradient Signal to Noise Ratio, they compute the \"optimal\" number of local steps to reduce the deviation effect. In particular, the number of local steps is not the same for every client.\n\nThe approach relies on making some gaussian approximation for the local training and the global training, computing the Wasserstein distance for the deviation between both and computing the number of local steps to minimize the deviation.",
            "strength_and_weaknesses": "Strength\n\n- The approach to compute the optimal number of local updates is original and flexible, can be applied to virtually any local optimization algorithm\n\n-The method allows for a different number of local updates for each client, and allows for measuring the contribution of each client\n\nWeaknesses\n\n-GSNR is computed on the basis of several approximations. We don't know how far is the estimated optimal number of local updates from the true optimal number of local updates. In general, the fact that the approach is based on several approximations is really not discussed\n\n-The goal of the GSNR approach is to accelerate the training. Acceleration is only shown experimentally",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and quality:\n\nI enjoyed the overall story of the paper, but when I tried to check the details I was bothered by some clarity issues.\n\nIs Lemma 3.4 saying that running gradient descent is equivalent to running gradient descent without updating the gradient? This approximation seems too crude to give a good approximation of the optimal number of local steps. Besides, I would have expected the optimal number of local steps to be just one (since the communication constraint is not encoded in the GSNR)? \n\nIn Eq 5, p_w are not defined. It is not clear what this equation means.\n\nTh 3.5. is the main theorem, but its statement is really confusing. The optimal number of local updates is not mathematically defined. What is the criterion to be optimized (I needed to check the proof to understand)? Are there constraints? Same for the optimal distance (here it is also not clear what \"distance\" refers to). I suggest putting the proof of Th 3.5 in the main text. \n\nFinally, these optimal numbers are obtained after making several approximations: CLT, Lemma 3.4. This is not recalled, nor discussed. \n\nThe GSNR appears only in page 7, after it is used to compute the optimal number of local steps. Wy this choice? This is confusing. Moreover, in the current form, Section 2.2 seems useless because it is not related to the rest of the paper (only implicitly for the proof of Th 3.5), am I correct?\n\n\nExperiments show the flexibility of the approach to evaluate local contribution, this is an interesting feature of the approach. They also check the test accuracy, justify the necessity of optimal local steps and obtain a convergence speedup. There are some experiments for justification of local steps, but I am not sure to understand what the outcome of this experiment is. However, they do show model convergence speedup.  \n\nNovelty:\n\nThe idea of monitoring the deviation between local and global training is original. I believe that it could give good results in practice.\n",
            "summary_of_the_review": "The idea is original but not well executed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1289/Reviewer_8mk1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1289/Reviewer_8mk1"
        ]
    },
    {
        "id": "vrLxqxGWUm",
        "original": null,
        "number": 3,
        "cdate": 1667399110548,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667399110548,
        "tmdate": 1667399110548,
        "tddate": null,
        "forum": "RusKt9aoTON",
        "replyto": "RusKt9aoTON",
        "invitation": "ICLR.cc/2023/Conference/Paper1289/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors investigate the possibility of optimizing a number of local steps in the FedAvg algorithm by minimizing the Wasserstein Distance between global and local gradient distributions.",
            "strength_and_weaknesses": "The paper provides a nice and (as far as I know) novel idea of how to use the statistical properties of local datasets in order to optimize the optimization procedure of the distribution problem.\nHowever, I believe that the paper is too empirical and contains the following problems:\n\nMajor:\n1. The paper does not provide convergence rate comparisons of the new method and FedAvg (see https://arxiv.org/pdf/1910.06378.pdf). It is not enough to say \"The convergence of FedGSNR is obvious, as we just change the number of local updates.\" I believe that it is not a trivial task to obtain precise convergence rates for the new method.\n2. Lemma 3.4 and the discussion implies that we can estimate $\\eta_r \\widehat{g}$ with $\\eta_r \\bar{g}$ if $\\eta_r \\approx 0.$ I think that it is not a strong result and probably misleading. This result virtually holds for any two random vectors, not only for gradients. In practice, we want to take $\\eta_r$ as big as possible. Moreover, the smaller $\\eta_r$, the worse we get the convergence rate.\n3. In the proof of Theorem 3.5, the authors say: \"the global gradient distribution can be approximately interpreted as normal distribution.\" It is a very weak argument for the main theorem of the paper. I would like to see more rigorous mathematical calculations.\n4. Theoretically, it is not clear how the maximization GSNR is connected to faster convergence. For instance, is it possible to show that we can guarantee the convergence rate faster than the vanilla FedAvg if we maximize GSNR?\n\nMinor:\n1. In order to calculate $n^{opt},$ the method required the global $\\mu_g$ and $\\Sigma_g$ and local $\\mu_l$ and $\\Sigma_l.$ The authors propose to estimate them using sampling. It would be nice to have an alternative to Theorem 3.5.\n2. How does the formula in (7) depends on $r$?\n3. In order to estimate $\\Sigma_g$ or $\\Sigma_l$, would the method require a large batch size?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "-",
            "summary_of_the_review": "While the idea of the paper is nice, the theory seems to be weak (see Strength And Weaknesses).",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1289/Reviewer_kU4r"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1289/Reviewer_kU4r"
        ]
    },
    {
        "id": "qbW4s_PMRX7",
        "original": null,
        "number": 4,
        "cdate": 1667513084104,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667513084104,
        "tmdate": 1667513430187,
        "tddate": null,
        "forum": "RusKt9aoTON",
        "replyto": "RusKt9aoTON",
        "invitation": "ICLR.cc/2023/Conference/Paper1289/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "This paper proposes a framework for federated learning with non-iid data. The authors tackle this problem by optimizing Gradient Signal to Noise Ratio (GSNR). They decompose local gradients calculated on the non-iid training data into the signal and noise components and then speed up the model convergence by maximizing GSNR. Based on this, they develop the FedGSNR method, which can be applied to existing gradient calculation algorithms. \n",
            "strength_and_weaknesses": "The proposed framework is general and seems to be applied to various existing methods. The non-iid data issue is important in this fields, and the authors address the problem well. Unfortunately, I am not familiar to this topic. Therefore, I cannot assess the exact strength and weakness of the proposed framework. I read the paper and could not find significant faults. ",
            "clarity,_quality,_novelty_and_reproducibility": "In Lemma 3.2: When the samples are significantly non-iid, we cannot apply the CLT in general. However, the authors apply the CLT to show Lemma 3.2. Could you explain why it is possible? In addition, I think that the statement should be \"$\\sqrt{B}(g - \\mathbb{E}[g])$ converges to a multivariate normal distribution as $B\\to \\infty$,\"  and the authors should clarify that what CLT theorem they used in the proof.",
            "summary_of_the_review": "The paper is well-written, although I could not evaluate it with confidence. However, there are several parts where theoretical explanation is insufficient. For example, the authors define the expected value in Section 2, but because the data is non-iid, we can consider samples that do not have the expectation. The authors more carefully discuss them because this paper discusses non-iid data. Furthermore, I could not understand why Lemma 3.2 holds. I would like the authors to clarify it. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1289/Reviewer_zXke"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1289/Reviewer_zXke"
        ]
    }
]