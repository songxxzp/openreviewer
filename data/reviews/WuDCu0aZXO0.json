[
    {
        "id": "w8UL50pnOJr",
        "original": null,
        "number": 1,
        "cdate": 1666469775922,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666469775922,
        "tmdate": 1671169298562,
        "tddate": null,
        "forum": "WuDCu0aZXO0",
        "replyto": "WuDCu0aZXO0",
        "invitation": "ICLR.cc/2023/Conference/Paper266/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "First, the paper introduces a new task of incremental video highlights detection aiming to adapt to more data and new domains. To that end, they propose a framework Global Prototype Encoding (GPE). They employ transformer-based temporal encoder to aggregate frame-level CNN features to generate temporally aware representations of a video. Next, each frame is classified by two groups of learnable prototypes -  highlight prototypes and vanilla prototypes. The utilization of prototypes help incremental learning by keeping the distance between the learned prototype in the new domain and previously observed prototypes close to each other.  A major contribution of this paper is the LiveFood dataset. Performance of their incremental GPE method are compared with other incremental methods relying on complex exemplar selection or complicated replay schemes, and the author observed that GPE produces encouraging results in the incremental setting. ",
            "strength_and_weaknesses": "The idea of learnable global prototypes leads to a simpler video highlight detection framework and an apt method for incremental learning. The dataset contribution is also significant, as the previous related datasets are either smaller in scale or do not have domain tags. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. They provide satisfactory details to understand the concepts, and potential implementation in the manuscript. They also provided the source code, although I wasn't able to run the code due to time constraints. ",
            "summary_of_the_review": "The paper presents a new task - incremental video highlights detection. The framework is based on simple ideas around global prototype encodings. The dataset contribution is also significant. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper266/Reviewer_HURe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper266/Reviewer_HURe"
        ]
    },
    {
        "id": "-GDeOna3ast",
        "original": null,
        "number": 2,
        "cdate": 1666486166222,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666486166222,
        "tmdate": 1666527515534,
        "tddate": null,
        "forum": "WuDCu0aZXO0",
        "replyto": "WuDCu0aZXO0",
        "invitation": "ICLR.cc/2023/Conference/Paper266/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new task of video highlight detection (VHD) in a domain-incremental setting. First, the authors define the task of incremental video highlights detection and introduce a gourmet dataset named LiveFood that they've carefully collected to facilitate research in this new task. Second, they argue that all the previous approaches fail to address this new task and have limited scalability. To this end, the authors present a new method named Global Prototype Encoding (GPE) that learns two groups of prototypes that are used to optimize a classification loss for incremental learning. The proposed method shows good performance on R-MNIST as well as LiveFood.",
            "strength_and_weaknesses": "Strength:\n- The introduced task of incremental VHD looks interesting and quite practical.\n- The proposed dataset has domain annotations that are missing in the previous VHD datasets.\n- The presented method achieves state-of-the-art performance on the dataset.\n\nWeakness:\n- W1. First of all, the paper does not provide enough information about the proposed dataset, even if it is the major contribution of the paper. The most important and distinctive aspect of the dataset is the presence of domain annotations, but there is no visualization of the four domains. For example, the \"eating\" domain is not depicted in any of the figures. Moreover, the information on the labeling interface or annotation tool is also missing. I also believe that the quality control section can be more elaborated for better understanding.\n\n- W2. According to the description of annotated domains in Table 1, the \"eating\" scene contains people and their faces. I believe that it might arouse some ethical concerns so the authors should have stated this in the paper.\n\n- W3. Apart from the dataset, the proposed method does not have a technical novelty. It seems like GPE is merely a combination of ConvNext, transformer encoder, and prototypical learning. For example, all the equations from 1 to 7 do not convey any novel concept because they explain a simple softmax function (eq. 2), BCE loss (eq. 3), L2 distance (eq. 4), etc. I wonder how exactly GPE is different from the previous incremental learning methods based on prototypes. As far as I know, prototypical networks have been used a lot in class-incremental learning, and I also would like to know what novelties GPE has when compared to [ref1] and [ref2]. Especially, [ref1] looks very similar to GPE.\n\n- W4. In addition, GPE's higher performance seems merely due to the use of the improved feature encoders, i.e ConvNext and a transformer. If that is the case, we cannot say that the proposed method using the prototypes contributes to the performance increase because other methods can also benefit from the high-performing feature encoders. At this point, I am not even sure why the authors mentioned \"Inspired by Carion et al., GPE employs a ConvNext, ...\"; I wonder how DETR inspires the usage of ConvNext.\n\n- W5. The paper lacks an in-depth qualitative analysis of the prototypes. I strongly believe that the authors should visualize the learned prototypes in the feature space to validate the effectiveness of the proposed learning strategy.\n\n- W6. There exists another important baseline called Co2L that was published in ICCV 2021 [ref3]. I don't think GPE is a new state-of-the-art method in terms of the average classification accuracy on R-MNIST, which is wrongly argued by the authors in Table 4.\n\n\n[ref1] Constrained Few-shot Class-incremental Learning, Hersche et al. (CVPR 2022)\n\n[ref2] Prototype Augmentation and Self-Supervision for Incremental Learning, Zhu et al. (CVPR 2021)\n\n[ref3] Co2L: Contrastive Continual Learning, Cha et al. (ICCV 2021)",
            "clarity,_quality,_novelty_and_reproducibility": "It is unclear whether the performance increase is merely due to ConvNext/transformer. Although the dataset looks original, the paper lacks detailed information about the dataset. The proposed method does not seem to outperform the work published in ICCV 2021.",
            "summary_of_the_review": "The paper has two contributions, which are LiveFood and GPE; but both of them have non-negligible issues.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety"
            ],
            "details_of_ethics_concerns": "The dataset contains a lot of scenes where people and their faces are present. I believe that it might arouse some ethical concerns so the authors should clarify this.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper266/Reviewer_6gVY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper266/Reviewer_6gVY"
        ]
    },
    {
        "id": "hcwbzo6HX4",
        "original": null,
        "number": 3,
        "cdate": 1666525897722,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666525897722,
        "tmdate": 1666526296309,
        "tddate": null,
        "forum": "WuDCu0aZXO0",
        "replyto": "WuDCu0aZXO0",
        "invitation": "ICLR.cc/2023/Conference/Paper266/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Most of the paper is clearly written. A new dataset for incremental learning is provided. The fixed and dynamic modes of Global Prototype Encoding is proposed and outperform the state-of-arts. ",
            "strength_and_weaknesses": "Strength: Most parts are explained clearly for the equations.Most of the procedures seems reasonable.\n\nWeakness: \n1) How to learn the two groups of trainable prototypes by equation (3)? Do the  two groups of trainable prototypes are trained by 2 class clasiification by equation 3. More explanation should be given for k*m before equation (1) and how the k*m matrix is used in Figure 4. The distance based clustering of Figure 4 is not mentioned in the paragraphs.\n2) What does it mean by Average the metrics of current stage and Average the metrics of all stages in Algorithm 1.No explanation.",
            "clarity,_quality,_novelty_and_reproducibility": "The work is mostly novel.",
            "summary_of_the_review": " It offers a new dataset and a new method for future research in its direction, which sounds reasonable. The details of the protype learning should be explained more clearly.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper266/Reviewer_nvTS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper266/Reviewer_nvTS"
        ]
    },
    {
        "id": "j0QP1QCxFl",
        "original": null,
        "number": 4,
        "cdate": 1666916470181,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666916470181,
        "tmdate": 1666916470181,
        "tddate": null,
        "forum": "WuDCu0aZXO0",
        "replyto": "WuDCu0aZXO0",
        "invitation": "ICLR.cc/2023/Conference/Paper266/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper addresses a crucial problem in computer vision: Video Highlights Detection (VHD) which aims to target the appealing domains for the given video(s). More general approaches are based on world assumptions which lead to poor scalability and to address this issue the author proposes a new method called Global Prototype Encoding (GPE) which learns incrementally for adaptation of the new domains. Additionally, the author also uses the LiveFood dataset which is a finely annotated dataset for the experiments. Together with strong and exhaustive experimental results, the authors showcase the practical usability and competitive performance against the prior work for specific LiveFood datasets. ",
            "strength_and_weaknesses": "Strengths: \n\n++ The proposal of the GPE is incremental and end-to-end. The main advantage of GPE is that it can identify the domains via learning vanilla prototypes, whereas prior approaches fail for the same as the fixed number of highlight categories have been defined before learning. It can also be detected in the experiments which have been performed on the LiveFood dataset by improving the performance by a good margin. \n\nWeaknesses:\n\n-- After reading the manuscript and performing research on this there have some concerns my mind which is stated below: \nThe language for the use of the dataset is quite unclear in the entire manuscript, as from the first point-of-view, it looks like the author has curated/created the dataset, whereas moving ahead the dataset has been collected from some XYZ sources, and there has been no direction that from which settings/how the dataset has been curated/collected. Could the author clarify this more if I have missed something in the manuscript for the same?\n\n-- In regards to the dataset statistics, I believe the dataset does not have larger statistical effects as the average video lengths or the total number of videos are less compared to the open datasets as mentioned in Table 2. Can I ask the authors if they can give clear direction on why they need to propose a dataset? ",
            "clarity,_quality,_novelty_and_reproducibility": "Novelty:\n\n++ The task formulation and the proposed solution are concise, convincing, and novel. A seemingly reasonable approach has been proposed in this manuscript for the VHD. Compared to the prior work and baseline introducing GPE it achieves competitive results. \n\nClarity:\n\n++ Some of the manuscript sections have been written exceptionally well whereas there has been clear confusion in the dataset section. However, a brief insight into the problem and background information has been provided which is necessary to understand the major issue in the prior work. \n++ The manuscript also clearly describes the improvements and adequately contextualizes the contributions in such a way that it makes a good starting point for a novice reader.\n\nReproducibility:\n\n++ The author has agreed to release the code and dataset made publicly available in some point of time in the future. However, looking at the algorithmic prototype and architecture, it can be reproducible at some point. ",
            "summary_of_the_review": "Overall, currently at this stage, this is a good manuscript. I like the simplicity and wide applicability of the proposed GPE approach. There are some concerns which has been raised in the weakness section regarding the dataset proposal which holds me with the current rating, however, if given strong reasons and clarity, I'm happy to increase the rating for the same. A detailed literature review, a complete overview of each component, and detailed experiments and ablation studies help to give a good insight into the manuscript. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper266/Reviewer_LRmd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper266/Reviewer_LRmd"
        ]
    }
]