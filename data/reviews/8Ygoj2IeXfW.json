[
    {
        "id": "7U0QqWPTw57",
        "original": null,
        "number": 1,
        "cdate": 1666714556325,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666714556325,
        "tmdate": 1666714556325,
        "tddate": null,
        "forum": "8Ygoj2IeXfW",
        "replyto": "8Ygoj2IeXfW",
        "invitation": "ICLR.cc/2023/Conference/Paper6494/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper provides a new sampling strategy for domain and datapoint sampling in the domain generalization context. The method encourages sampling diverse domains and diverse datapoints within each domain. To achieve domain diversity, the authors train a class-adversarial neural network (the inverse of the DANN method in [1]) and use a Determinantal Point Process (DPP) with the features produced by this network. To achieve datapoint diversity, the authors train standard ERM on the datapoints sampled randomly from the sampled domains, and also use a DPP.",
            "strength_and_weaknesses": "## Strengths\n\n**S1**: The proposed method makes intuitive sense.\n\n**S2**: Empirical results show improvements compared to the baselines with multiple base domain generalization methods.\n\n## Weaknesses\n\n**W1**: I think some of the presentation regarding the \"object spurious correlations\" vs \"domain spurious correlations\" is somewhat imprecise\n\n**W2**: Some of the design decisions are not very clearly motivated and not ablated, in particular the use of invDANN\n\n**W3**: The Empirical evaluation is focusing primarily on Rotated MNIST and Rotated FashionMNIST, which are small-scale synthetic datasets, rather than more standard domain generalization datasets.",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity (W1)\n\nOverall, the paper is written reasonably well. The one issue I found is that he authors appear to define the _domain_ quite narrowly, as basically the backgrounds of the images. I believe what authors call _object_ could also be a part of domain in the general sense. In the toy example that the authors use, the color of the object (cat or lion) can and should also be a part of the domain label. My understanding of the distinction between the object and domain then is that the authors assume that the domain information is incomplete and doesn't cover all of the relevant spurious features.\n\nFormally, I think I can object to the presentation is Section 4.3, where the authors suggest that Proposition 1 in [2] is wrong. However, this proposition is a formal statement that is proved by [2]. I believe the issue is again that the \"object-side\" spurious feature $\\hat x$ distribution is not the same across the training and testing domains in the toy cat-lion example, the authors assume that for the test domain the distribution of the object color (tan) $\\hat x$ conditioned on the class label $y$ will be different compared to the training domains. I believe this setup contradicts the assumptions of Proposition 1 in [2].\n\n## Methodology (W2)\n\nMethodologically, it wasn't clear to me why we need to train a domain featurization which is class independent with invDANN? In particular, why couldn't you just apply ERM on the domain labels? What is the role of class invariance?\n\nSimilarly, couldn't you completely remove the first step of the procedure and just do the following?\n1. Train ERM on all data with no domain information\n2. Use a DPP with the ERM featurization to produce a diverse sample of datapoints (and the corresponding domains)\n\nIs there a reason for the added complexity of the two-step procedure?\n\nFurther, the authors ablate the need for the second stage (adding diversity within sampled domains) but not the first stage of the procedure. What is the performance if you sample the domains randomly, but then use the ERM-based DPP to sample diverse datapoints?\n\n## Experiments (W3)\n\nThe experiments show promising results, but are quite limited currently.\n\nThe authors only report performance on the Rotated MNIST and Rotated FashionMNIST datasets. This choice is unclear to me:\n- Both datasets are small-scale. Further, these are not the most standard benchmarks in domain generalization to the best of my knowledge.\n- The method is motivated by having a large number of domains and a large number of datapoints in each domain. While the number of domains is fairly large (65), it is unclear if the quadratic cost of using all the domains would already be an issue at this scale.\n- It is unclear what the second stage of the procedure is supposed to be doing in these datasets. What is the spurious correlation that you are trying to address within each domain? Or maybe I am missing the point of the second stage here.\n\nGenerally, I think these datasets would be reasonable _if_ they were a part of a larger evaluation, which also included more realistic datasets where the motivation for the method is more clear. In fact, in the Appendix the authors also consider the iWildCam dataset, although they mention a few issues with the results, e.g. large computational overhead compared to the baselines and only using the FISH base domain generalization method, which performs relatively poorly on this dataset. At the same time, it does seem like the authors achieve some improvement on this dataset with FISH.",
            "summary_of_the_review": "This is an interesting paper, with promising results. Above, I highlighted a few questions and concerns about the presentation, methodology and experiments. The limited empirical evaluation is the main issue in my opinion.\n\n## References\n\n[1] [_Domain-Adversarial Training of Neural Networks_](https://arxiv.org/abs/1505.07818);\nYaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, Victor Lempitsky\n\n[2][_Domain Generalization using Causal Matching_](https://arxiv.org/abs/2006.07500);\nDivyat Mahajan, Shruti Tople, Amit Sharma",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6494/Reviewer_3y4o"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6494/Reviewer_3y4o"
        ]
    },
    {
        "id": "_KFi1l1Xze",
        "original": null,
        "number": 2,
        "cdate": 1666721976801,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666721976801,
        "tmdate": 1666721976801,
        "tddate": null,
        "forum": "8Ygoj2IeXfW",
        "replyto": "8Ygoj2IeXfW",
        "invitation": "ICLR.cc/2023/Conference/Paper6494/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Summary\nThe authors consider the problem of domain generalization (DG). In specific, they are addressing the issues of scalability and objective.\n Scalability: The state-of-the-art DG methods involve computational\n complexity of \ud835\udcaa (n2) corresponding to pairwise domain operations with n\ndomains. In addition, each domain may contain a large number of data points. This is computationally prohibitive.\nObjective: The existing methods entirely focus on excluding domain-side impacts, i.e., spurious correlations, and don\u2019t consider the data-side impacts.\nThe authors address the above two issues by proposing a two-level sampling method called the Diversity boosted two-level sampling framework (DOMI).\nThe authors argue that diverse domains of data help exclude spurious correlation (observation 1). In regard to this, they propose to sample diverse domains using invDANN as featurizer and DPP as a sampler in the first level.\nThe authors observe excluding domain-induced correlations is insufficient for learning a robust model (observation 2). To alleviate this, they propose to sample diverse data batches from the selected domains (domains obtained from first-level sampling) using ERM and DPP in the second level.\nThe authors validate their algorithm with five backbone DG algorithms on two simulated benchmarks (Rotated MNIST and Rotated Fashion MNIST).",
            "strength_and_weaknesses": "Strengths\nThe problem of DG considered and the issues highlighted such as scalability and objective in this work is very relevant.\nThe authors provide an important counter-example, i.e., cats and lions to draw attention to the issue of data-side impacts. They also present the comparison of various sampling methods such as random sampling, and different diversity-boosted sampling methods to illustrate the importance of their work and their effect on both object-side spurious correlations and domain-side spurious correlations.\n       \nThe authors give reasonable arguments for observation 1 using concepts such as good, casual, and spurious correlations. In addition, observation 2 is well explained using the structural causal model.\nThe solution proposed, i.e., diversity-boosted two-level sampling to mitigate the issues highlighted seems intuitively well grounded.\nThe experimental results show the validity of their algorithm. The proposed method outperforms level 0 and level 1 sampling schemes across 5 backbone DG methods and two simulated benchmark datasets.\nThe authors provide a decent analysis of the gap between test accuracy and maximal accuracy as well as the impact of the choice of the hyper-\nparameter \u03b4 (proportion of data points) . \n\nDrawbacks:\n\nNo analysis regarding the choice of the hyper-parameter \u03b2 (proportion of domains) is presented.\nThe statement \u201cspurious correlations essentially result from imbalance data\u201d is not entirely true. The spurious correlations result from the existence of anti-causal paths. You could have the same data and different causal models, some of which result in spurious correlations.\nIt would be better if the authors elaborate on causality-related concepts such as causal correlations and unobserved confounders or give proper references.\nThere are a couple of typos (is composed by Featurizer, Classifier ..., while the test accuracy of level 0 .... that of level 2 centers, and ...)\nThe experiments on large-scale datasets are missing. ",
            "clarity,_quality,_novelty_and_reproducibility": "Please see the comments before. ",
            "summary_of_the_review": "The authors consider the problem of domain generalisation (DG). In specific, they are addressing the issues of scalability and objective.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6494/Reviewer_eKSv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6494/Reviewer_eKSv"
        ]
    },
    {
        "id": "3f6hX2bmV8",
        "original": null,
        "number": 3,
        "cdate": 1667412274737,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667412274737,
        "tmdate": 1670860381645,
        "tddate": null,
        "forum": "8Ygoj2IeXfW",
        "replyto": "8Ygoj2IeXfW",
        "invitation": "ICLR.cc/2023/Conference/Paper6494/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "Authors looks into Domain Generalization for a large number of domains. They propose to sample (using two stage procedure) both the domains and the data within each domain, in order to help the model to filter out spurious correlation.  They show a motivational example that the assumption that domains usually have shared causal features and differ in spurious correlation features does not always hold. For the first stage sampling (choosing the domains), they  train an inverse DANN (classify domains while not being able to assign the class labels correctly) to get to extract only domain specific features. Then using these features, they construct domain similarity matrix . For the second stage sampling,  DPP samples diverse domains and diverse data points within the domains (using similarity matrix constructed by ERM)\n",
            "strength_and_weaknesses": "Pros:\n- good observations (spurious correlations)\n- interesting idea to choose diverse domains and data points\n- clarity - pretty easy to follow\nCons:\n- overly complicated multi-stage method that requires many expensive computations (train inverse DANN, construct matrix of pairwise domain similarity, construct matrix of data points similarities, train ERM etc) \n- no comparison with no sampling whatsoever - so impossible to say if it was needed in the first place\n- only image experiments. Is it because\u00a0you can't find non image DG datasets with such a large number of domains? is it possible to generate some synthetic data? why not to try WILDS and\u00a0OGB-MolPCBA that you mention? Or DRUG OOD",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: excellent, easy to follow, well explained\nNovelty: unsure. While the sampling methods seems to be working well compared to other sampling, it is not the contribution of the paper since they use the existing DPP. \nReproducibility: good",
            "summary_of_the_review": "Update:\nRaising my score a bit, since authors included new experiments. TLDR: without subsampling the performance does improve but on some datasets the drop with sampling is small enough considered time saved\n\n\nOverall my main complains about this paper are\n1) multi step procedure with each step step being expensive (train inverse DANN, construct matrix of domain similariities, construct data points similarities matrix etc). Each step will require its own tuning. Unclear how your method compares in terms of time/computation to any methods you labeled as expensive\n2) No comparison with no sampling at all for the table 3. Without this, it is impossible to tell whether the sampling is required at all\n3) You state that DANN works with pairwise domains (n^2)??? You have an adversarial head that classifies\u00a0into the number of domains, how is it n^2??? Also it is misleading to state this for  MMD too - it will indeed work on pairs, but only on pairs from the batch, so it is batch_size^2 max\n\nMinor: DPP related work - repulsive (interactions) is a strange word to use here. Spurious? Non intended?\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6494/Reviewer_kTC5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6494/Reviewer_kTC5"
        ]
    },
    {
        "id": "xHlphxJlE2T",
        "original": null,
        "number": 4,
        "cdate": 1667598905598,
        "mdate": 1667598905598,
        "ddate": null,
        "tcdate": 1667598905598,
        "tmdate": 1667598905598,
        "tddate": null,
        "forum": "8Ygoj2IeXfW",
        "replyto": "8Ygoj2IeXfW",
        "invitation": "ICLR.cc/2023/Conference/Paper6494/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper:\n* solves the domain generalization problem\n* presents several observations that diversity helps mitigate serious correlations\n* proposes a sampling method that helps train robust models\n* conducts experiment on Rotated MNIST and Rotated Fashion MNIST to show the effectiveness of the proposed algorithm",
            "strength_and_weaknesses": "The paper is easy to follow and the proposed algorithm is easy to understand. The idea is not totally new but seems promising. Since the work is likely considered as adopting and improving existing method, I believe the experimental results should be strong. However, I am not fully convinced by the current experiments. Here are my complaints:\n* The paper can be more professionally written. For example, the definition of set $C$ is very vague. What is precisely a \"good\" correlation?\n* The experiments are very limited. Why not try some large scale experiments mentioned in DomainBed? It is important to show the proposed algorithm on larger and tougher dataset. I am also curious to see how it works on ColoredMNIST.\n",
            "clarity,_quality,_novelty_and_reproducibility": "* Please see above. The paper can be more professionally and well written. The idea is new and promising but needs more support.\n* Source code is provided.",
            "summary_of_the_review": "I think the paper is not ready for publication at this point. If the authors can show more evidence and support, I am happy to raise my scores.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6494/Reviewer_xNqP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6494/Reviewer_xNqP"
        ]
    }
]