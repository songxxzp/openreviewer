[
    {
        "id": "ierei_RQYF",
        "original": null,
        "number": 1,
        "cdate": 1666494055046,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666494055046,
        "tmdate": 1666494055046,
        "tddate": null,
        "forum": "tAfyE2V7oye",
        "replyto": "tAfyE2V7oye",
        "invitation": "ICLR.cc/2023/Conference/Paper3268/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proves that the min-max excess risk of nonparametric classification algorithms is bounded by the number of minority samples when there is a distributional shift between train and test, and therefore concludes that in the worst case, undersampling is optimal unless there is a high degree of overlap between the train and test distributions, or if the algorithm leverages additional structure about the distribution shift. They conducted an experimental case study on a label shift dataset and showed that the test accuracy of robust neural network is constrained by the number of minority samples.",
            "strength_and_weaknesses": "Strength:\n1. The conclusion of the paper is very interesting in that it shows the optimality of a simple undersampling scheme, and dictates the need to design tailored algorithms that exploit the structure of distributional shift between train and test, instead of aiming to design a universal robust algorithm that is agnostic to the type of distributional shift. This is fairly important to lead to a directional change in designing robust algorithms to deal with distributional shift. \n\n2. The idea is explained very well, using succinct language to explain complicated mathematical theorems so that it is easy to understand. The theoretical results are also justified well by the experimental studies.  \n\nWeakness:\n1. The paper makes the assumption that the test set is balanced. I am curious about whether these results still hold when the test set is somehow also unbalanced, but there still exists some distributional shift between the train and test. When the positive - negative ratio is unknown in the test set, how should undersampling be implemented? In this case, do we prefer other state-of-the-art robust algorithms to undersampling, since the test distribution is unknown?\n\n2. The experiments add evidence in supporting the theoretical results. In Fig. 2, the left pane, why the green curve is only up to 500 samples? Can we add the other half of the green curve? Also, if the green and red curves add the same number of minority samples, we expect their performance to be quite close, based on the theoretical results, right? But why do we still see a performance gap in those plots?\n\n3. The experiments used importance weighted classifiers to demonstrate the importance of minority samples. Personally I am also interested in seeing the comparison of undersampling with other robust algorithms, and to understand whether it is true that simple undersampling (without any importance weighting) performs as good as state-of-the-art. In Section 2, the 2nd paragraph, the authors also mentioned that importance weighting is ineffective when it comes to over-parameterized neural networks. If that's the case, I expect undersampling to outperform importance weighted classifiers.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written very clearly. The conclusions are novel and could potentially lead to a directional change in the study of distributional shift. ",
            "summary_of_the_review": "Overall I am satisfied with the quality of the paper. I think it has a fairly important contribution to guide the research direction in robust algorithms dealing with distributional shift. The theoretical results also nicely supporting their conclusions. The experimental section can potentially be improved, by incorporating a comparison between undersampling and other robust algorithms, and may also be extended to other datasets, classification algorithms such as Random Forest. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3268/Reviewer_9dze"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3268/Reviewer_9dze"
        ]
    },
    {
        "id": "-gbPDIMMHHS",
        "original": null,
        "number": 2,
        "cdate": 1666557932289,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666557932289,
        "tmdate": 1673187952890,
        "tddate": null,
        "forum": "tAfyE2V7oye",
        "replyto": "tAfyE2V7oye",
        "invitation": "ICLR.cc/2023/Conference/Paper3268/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper explores the minimax optimality of undersampling. Specifically, for balanced test sets assuming Lipschitz label shift or group covariate shift, the lower bound on the minimax excess risk depends on the number of samples in the minority class at the rate n_{\\min}^{-1/3}, in the univariate case. Undersampling with a binning estimator has the same rate, and so undersampling is minimax optimal.\n",
            "strength_and_weaknesses": "Strengths\n\n* Clear paper.\n* Reasonable theory result.\n\nWeaknesses\n\n* Restricting to the univariate covariate case is lazy, or, if the group covariate shift upper bound Theorem 5.2 cannot be generalized to higher dimensions at the same -1/3d rate, deceitful.\n* My understanding of the subsampling phenomenon is that we are interested in why subsampling seems to work when the test distributions are not balanced, as they are artificially in this case. My intuition for that phenomenon is just artifacts of SGD training for neural networks. That subsampling is optimal in this case just follows from the fact that the uncertainty of the minority class is still dominant, and this manifests in these lower bounds. So this answers an undersampling problem, but not the undersampling problem.\n",
            "clarity,_quality,_novelty_and_reproducibility": "* Clearly written.\n* Seems high-enough quality.\n* Not having read the proofs in detail, it's unclear if there is anything particularly novel.\n\nUpdate\n* Late in the review process, some additional questions around novelty and presentation were raised by other reviewers and the meta-reviewer. I\u2019ve adjusted some scores downward as a result.",
            "summary_of_the_review": "* This is a clear, well-typeset paper. The theoretical arguments are nice and should be published, but whether they answer the real questions around undersampling is debatable.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3268/Reviewer_1VuN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3268/Reviewer_1VuN"
        ]
    },
    {
        "id": "-noa7z3lxlR",
        "original": null,
        "number": 3,
        "cdate": 1666610370179,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666610370179,
        "tmdate": 1666610370179,
        "tddate": null,
        "forum": "tAfyE2V7oye",
        "replyto": "tAfyE2V7oye",
        "invitation": "ICLR.cc/2023/Conference/Paper3268/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This draft studies the problem of learning with a distribution shift. The authors show that in the worst case of label shift or group-covariate shift, with the measure of minimax excess risk, no other algorithm can provably outperform the undersampling algorithm without further investigating the structure of distribution shift. The results are also consistent with previous empirical studies.",
            "strength_and_weaknesses": "Strength:\n+ This work theoretically shows that in the worst case of label shift and group-covariate shift problem, with the measure of minimax excess risk, a simple undersampling algorithm has obtained the minimax optimal result. This result is intuitively obvious, but there is no theoretical proof for it. This work provides a formal formulation and proves this intuitive result. In these two cases, the lower bound of undersampling matches its upper bound. This result also matches the empirical results proposed by other researchers.\n+ Overall, the draft is well organized, and its theoretical results are clear.\n \n\nWeaknesses:\n- This work analyzes the worst-case scenario for label shift or group-covariate shift. Without any test (labeled) data or knowing the structure of distribution shift, it is easy to see that no other method could provably outperform the undersampling method. This result does not help in the design of a practical algorithm to handle the problem. For example, how to decide whether to use undersampling or other approaches to handling the label shift and group-covariate shift?",
            "clarity,_quality,_novelty_and_reproducibility": "This draft is well-organized and easy to follow. The theoretical results are solid and consistent with previous results. The results are intuitively obvious but there is a lack of theoretical analysis for this problem. The reproducibility of this work is good.",
            "summary_of_the_review": "This paper provides a theoretical analysis for the problem of worst-case label shift and group-covariate shift. They prove that in the worst case of label shift and group-covariate shift problem, with the measure of minimax excess risk, a simple undersampling algorithm has obtained the minimax optimal result. This result is intuitively obvious, but there is no theoretical proof for it in the literature. The proposed analysis is sound and the empirical studies verify their proposal.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3268/Reviewer_yVEH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3268/Reviewer_yVEH"
        ]
    },
    {
        "id": "xh0Y4zw7p2",
        "original": null,
        "number": 4,
        "cdate": 1666764616841,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666764616841,
        "tmdate": 1670823864669,
        "tddate": null,
        "forum": "tAfyE2V7oye",
        "replyto": "tAfyE2V7oye",
        "invitation": "ICLR.cc/2023/Conference/Paper3268/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors investigate the minimax optimality of classification problems under label and covariance shift on groups. They show that the minimax classification error is characterized by the sample size for the minor group essentially, indicating that increasing the major group's sample size does not affect the classification accuracy. They also demonstrate that the undersampling-based estimator achieves the optimal minimax.",
            "strength_and_weaknesses": "Strength:\n- Well-written with a clear claim\n- Technically sound\n- The claim of characterization with a minor group's sample size is interesting\n\nWeakness:\n- Lack of significance of techniques.\n- The results are limited to too simple cases. ",
            "clarity,_quality,_novelty_and_reproducibility": "The robustness is a crucial issue in machine learning. The minimax optimality for the robust classification is thus well-motivated. This paper is clearly written and easy to follow. The results are technically sound. The paper's claim is quite clear, i.e., the minimax optimal error of the group robust classification is characterized by the minor group's sample size and is achieved by undersampling.  \n\nThe main weakness of this paper is a lack of originality in the technical contribution. The basic direction of the analyses is equivalent to the traditional techniques of the minimax optimality analysis; that is, the technique for analyzing the Besov space using the wavelet analyses, such as\n- Donoho et al. Minimax Estimation via Wavelet Shrinkage. The Annals of Statistics, 1998. \n\nSuch standard techniques cannot directly apply to reveal the characterization with the minor group's sample size. However, the adaptation is easy by constructing a set of distributions such that the distributions for the major group are invariant. Consequently, I'm unsure about the technical contributions of this paper compared to the existing techniques. \n\nOne weakness of this paper is that the results are limited to the Lipschitz density. The existing techniques can handle more various spaces, including Holder, Sobolev, and Besov spaces. I cannot find any difficulty in extending to various such spaces. If my thinking needs to be corrected, I'd like the authors to clarify the difficulty in extending such spaces.",
            "summary_of_the_review": "This paper is well-written and technically sound. However, the significance of the technical contribution is unclear. I thus recommend rejection at this time. It is welcome to clarify the significance during the rebuttal. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3268/Reviewer_dgxz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3268/Reviewer_dgxz"
        ]
    }
]