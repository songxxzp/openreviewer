[
    {
        "id": "PjxVWIPzstq",
        "original": null,
        "number": 1,
        "cdate": 1665980219824,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665980219824,
        "tmdate": 1669343145286,
        "tddate": null,
        "forum": "9-umxtNPx5E",
        "replyto": "9-umxtNPx5E",
        "invitation": "ICLR.cc/2023/Conference/Paper829/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors focus masking frequencies in the input image for self-supervised pretraining rather than masking out sections of the spatial domain. The insight is that the masked frequencies will carry more information about the patterns in the underlying image as compared to spatial patches.",
            "strength_and_weaknesses": "## Strengths\n\n- The method is agnostic to architectures\n\n- It is interesting that denoising is closer to MFM and the effect of noise also intensifies all frequencies of the spectrum. Would it be possible to compare with masking as a corruption as well to see what that does to the overall frequency of the image?\n\n## Weaknesses\n\n- Figure 1 is hard to interpret. I can see that there are differences between MFM and the applied corruptions, but the frequency domain has no axis labels and it is difficult to gain intuition behind why the frequency domain plots look different from the corruptions, and what significance this implies.\n\n- Figure 2, which frequencies in the \"mask frequencies\" brackets in the figure are low and high frequencies? Or are they frequencies and amplitudes? What is the red circle in the first part of the figure? Is that the selected radius which is specified in equation 2?\n\n- After equation 3, it says that the filtered images are \"fed to and encoder as input, following a Bernoulli distribution.\" This statement is not clear, what does it mean?\n\n- After equation 3, the authors state that the model still takes the spatial images as input as well. It would be good to state this earlier in the paper. Until this point, I was under the impression that the model would only receive the frequency domain as input. \n\n- Given the confusion from the previous points, it would be nice to see a better diagram of the entire model architecture in a figure (maybe revamping figure 2) to allow the reader to visualize what the entire model flow looks like. It is not clear to me when and where the frequency inputs come into the model as inputs. For example, figure 2 looks like like the frequencies are input into the encoder, but the MFM Encoder section says nothing about this.\n\n- Did you ever consider using difference unit circle norms as shapes for ablation c (cirlce = 2 norm, square = infinity norm, etc)? The reason I ask this is because the frequency domain charts seem to show some interesting designs which would be captured by unit cirlce norms < 1 which would form a star-like shape.\n\n- Building on the point above, what is the shape of the rhombus in this context. Would this be equivalent to the 1-norm unit circle?\n\n- page 8: \"representation learning benefits from all lens of frequencies...\" What does this mean?\n\n- mask tokens are not used, which means that pretraining should be much more expensive than other MIM approahces, right? Because most MIM models produce a shorter sequence length to the transformer. Can you provide a breakdown of the pre-training per iteration computational cost in terms of wall-clock time between MFM and some baselines?\n\n## Minor\n\nSection 2 MIM section: \"Besides, iGPT...\" IT is not clear why besides is used here, besides what?",
            "clarity,_quality,_novelty_and_reproducibility": "## Clarity\n\nAs indicated in the weaknesses points above, I think the calrity of the paper could be improved. I was left with a number of questions regarding the figures and the overall flow of the MFM model. Addressing the concerns I raised above could solve most of these issues.\n\n## Novelty\n\nThe idea appears to be sufficiently novel to my knowledge\n\n## Quality\n\nAside from the clarity issues above and a few small grammar issues, the quality is adequate.",
            "summary_of_the_review": "Overall, I think the idea is interesting and novel. It is also intuitive that the frequency domain may capture a wider range of information that is covered by multiple corruptions. However, I would like to see some of the above mentioned clarity issues resolved.\n\nAdditionally, it is not clear to me why someone would choose to use this strategy. The bottom line results are somewhat ambiguous, and there are several recent SSL baselines which *could* be added that achieve higher performance.  Therefore I think it could be better to include more information analyzing the benefits of using MFM and possible future research directions which may be able to make further use of this work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper829/Reviewer_Nxgg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper829/Reviewer_Nxgg"
        ]
    },
    {
        "id": "baAGA2Y3lsy",
        "original": null,
        "number": 2,
        "cdate": 1666262126158,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666262126158,
        "tmdate": 1666262126158,
        "tddate": null,
        "forum": "9-umxtNPx5E",
        "replyto": "9-umxtNPx5E",
        "invitation": "ICLR.cc/2023/Conference/Paper829/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a self-supervised representation learning method by applying high-pass or low-pass filters on the image and restoring the missing frequency components. The experiments also include results for self-supervised learning via other common image restoration methods such as denoising, super-resolution and deblurring. ",
            "strength_and_weaknesses": "Strengths:\n\n1. The paper provides empirical evidence on the possibility of using various low-level image processing methods for self-supervised learning, including high-pass or low-pass filtering, denoising, super-resolution and deblurring, which will be a useful contribution to the community.\n\n2. The proposed method could achieve comparable performance for ViT-S, ViT-B, Resnet50 and improved robustness for ViT-B.\n\n3. The paper is generally well-written and easy to follow. \n\nWeaknesses:\n\n1. The major concern is that the methodology contribution is straightforward:\n- The masked frequency modeling proposed is straightforward and limited to low-pass and high-pass filtering, which are basically blurring and sharpening. To be a principled method, it would be better to include more general forms of frequency manipulations, which would correspond to modeling more complex periodical patterns in the spatial domain.\n- Although the authors attempt to provide a unified perspective of the method by relating to denoising, super-resolution and deblurring (Section 3.2), such perspective is very natural to have since most image processing methods in the spatial domain would have a corresponding interpretation in the frequency domain. \n\n2. The authors claim that no extra model (e.g. momentum teacher) and no mask token are advantages of MFM over other self-supervised methods. However, these differences are more about implementation choices rather than principled advantages. \n\n3. Although the experiments show promising results, they lack further analysis and insights:\n- Why is no gain observed for CNNs? \n- Why could masked frequency modeling achieve better robustness than MAE?\n- etc.\n\nMinor issues:\n- In Figure 2, what does the FFT after the linear head mean? This seems to be contradicting the text.\n- It is unclear how the linear head would output the frequency map of the same size as the original image, especially for CNNs encoder.\n- In Eq.4, the lowercase symbols f_r and f_o seem to be redundant and unnecessary.\n- In Table 1(f), are the l1 and l2 losses in spatial domain? This is not clearly stated.\n- In Table 6, the robustness is not compared to other self-supervised methods for ResNet.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper has good overall clarity with several minor issues, marginal novelty due to straightforward method and interpretation, and good reproducibility with well-described training recipes.",
            "summary_of_the_review": "This paper presents some interesting empirical results about using different image corruptions for self-supervised learning. However, the proposed method is currently not principled enough to be a significant technical contribution. I would recommend incorporating frequency analysis in a more general form beyond low-pass and high-pass filtering.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper829/Reviewer_34gh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper829/Reviewer_34gh"
        ]
    },
    {
        "id": "uus60RdG_WZ",
        "original": null,
        "number": 3,
        "cdate": 1666627500310,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666627500310,
        "tmdate": 1669227780546,
        "tddate": null,
        "forum": "9-umxtNPx5E",
        "replyto": "9-umxtNPx5E",
        "invitation": "ICLR.cc/2023/Conference/Paper829/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an empirical study of different masking-noise strategies for an image auto-encoder model. In contrast to the recent masked auto-encoded, authors propose to mask the inputs in the frequency domain by randomly dropping high or low frequency components. Their approach learns a representation in a self-supervised manner by reconstructing the missing component in the frequency domain.\n\nAuthors demonstrates the soundness of their approach on ImageNet finetuning, ADE20K segmentation task and various robustness tasks where they show comparable or better results compared to the previous work.\n",
            "strength_and_weaknesses": "Strengths:\n- To my knowledge, the proposed masking strategy is novel and sound.\n- Authors evaluate their representation on various downstream tasks requiring different level of abstraction (classification, segmentation).\n- Authors propose an ablation of the masking design choice.\n\nWeaknesses:\n- One of the main advantage of the masked auto-encoder is its scalability as the encoder does not need to process the masked patches. The current MFM proposal requires to process the full-images and therefore comes with higher computational cost. It is not clear to me if this approach is viable to train larger model such as VIT.L or VIT.H.\n- Some baselines are missing in the experimental study. Data2Vec (Baevski et al., 2022) for instance, is a masked image modeling approach which achieves 84.2 top-1 on imagenet finetuning with a VIT.B. MSN (Assran et al., 2022) is another approach combining mask image modeling and siamese networks which exhibits good robustness results (see table 14 in their paper). \nGiven that those approaches using patches masking obtain good results, it is unclear to me why one should prefer the use of mask frequency modeling.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is clear an easy to follow. The proposed empirical study appears novel to me, and authors say they will release code and pretrained models to foster reproducible research.\n\nOn the quality side, few ablations could be added to better demonstrate the value of the approach:\n- It would be nice to add a direct comparison with random patches dropping in table 1 to directly compare MFM to patches-masked denoising.\n- It is surprising that MFM only uses a linear decoder as other auto-encoders to use a deep decoder. It would be also nice to explore the impact of the decoder depth in the ablation.\n\nI have additional questions:\n- Why is the loss computed in the FFT domain as it should be somewhat similar to compute it in RGB space. Did you try the later? Do you expect a certain inductive bias by working in the frequency domain.\n- Do you need to convert back the image to RGB domain for pretraining? Couldn\u2019t you apply the FFT transform to the input for the finetuning stage?\n",
            "summary_of_the_review": "The paper proposes an empirical study of the masking noise in auto-encoder which seems novel and is an interesting study. However, the practical impact of the study is somewhat limited. It is unclear to me why one practitioner should prefer masking in the frequency domain compared to the patches masking scheme, as the later provides good scalability or can leads to strong results as Data2Vec or MSN demonstrate.\n\n=== After reading rebuttal.\n\nThank you for your rebuttal. While I appreciate the additional ablation experiments that compare MFM with MIM and different predictor depths, my main concern regarding the paper is not fully addressed.  It is unclear to me why one practitioner should prefer masking in the frequency domain compared to other patch masking scheme,",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper829/Reviewer_Un1w"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper829/Reviewer_Un1w"
        ]
    },
    {
        "id": "xp5P3AwVWPJ",
        "original": null,
        "number": 4,
        "cdate": 1667416515604,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667416515604,
        "tmdate": 1667416515604,
        "tddate": null,
        "forum": "9-umxtNPx5E",
        "replyto": "9-umxtNPx5E",
        "invitation": "ICLR.cc/2023/Conference/Paper829/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper investigates the possibility of masked frequency modeling for representation learning. It covers several research topics centered on MFM: a method that does MFM; connecting previous pre-training methods to MFM (e.g., super resolution); architecture change (from ViT to ConvNets) as an advantage of MFM over masked image modeling (the more popular methods for self-supervised pre-training); more tasks and benchmarks beyond classification with MFM pre-training. The results are not state-of-the-art per-se, but the complete assessment of MFM is interesting and of value.",
            "strength_and_weaknesses": "Strengths:\n- The exploration of a simple masked frequency modeling algorithm is interesting and valuable to the community, given the recent success of masked image modeling methods for representation learning.\n- The paper's exploration is quite complete, covering a simple basic method for MFM, MFM in the context of previous methods, different architectures, different tasks and benchmarks.\n- The paper is also relatively well-written and well-polished.\n\nWeaknesses:\n- In an ideal world, the newly proposed approach should advance the state-of-the-art in a meaningful way. Unfortunately, this work is still yet to reach that level of performance.\n- It would also be great if bigger models are trained to show the power of pre-training (if the computation permits).\n- With MAE-style design, MIM is made very efficient that it does not need to compute for all the patches in the encoder. Right now MFM still looks at the full-sequence. This is a potential downside in speed.\n- (minor) At page 6 last paragraph, the paper states an hypothesis about the mask shape being largely correlated with the category statistics of pre-training datasets. Is there evidence for this?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: As a said above, the paper is clearly written, with clean illustrations and nice ablations. \n\nNovelty: It is definitely a new and neat exploration to masked frequency modeling. I haven't seen any work sufficiently similar to this. \n\nReproducibly: The paper promises to release the code and pre-trained models. It also provides hyper-parameters in sufficient details. So I don't see a problem for reproducibility here.",
            "summary_of_the_review": "Overall I think this paper has already reached its maturity. It has a simple, basic method for MFM, and has explored a lot centered around this simple methods (I especially appreciate the connection to other pre-training methods, and experiments on ResNet). Although the method has not advanced state-of-the-art, I would still vote for acceptance given the added knowledge and value from this work to the research community.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper829/Reviewer_Lxfd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper829/Reviewer_Lxfd"
        ]
    }
]