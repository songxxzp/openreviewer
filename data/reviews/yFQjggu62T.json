[
    {
        "id": "UVHeumvekR",
        "original": null,
        "number": 1,
        "cdate": 1666261234078,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666261234078,
        "tmdate": 1666261664805,
        "tddate": null,
        "forum": "yFQjggu62T",
        "replyto": "yFQjggu62T",
        "invitation": "ICLR.cc/2023/Conference/Paper1921/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a computational graph-based method for graph generation, in which computational graphs for nodes, used in graph neural networks to compute node-level outputs, are the generation objective, rather than the graphs themselves. To this end, the paper first balances the node-level computational graphs, i.e., the k-ary trees (where k is the number of sampled node neighbors) defining the computation, by adding redundant neighbor nodes and creating duplicate nodes to break cycles. This scheme is called the duplicate encoding scheme in the paper. As the trees of this scheme are balanced and k is typically fixed, the size of these trees is therefore a constant. As such, the paper then proposes a modification of the XLNet transformer, which they term computational graph transformer (CGT), to apply to these sequences. In CGT, query and context attention masks are dictated by the computational graph structure for improved inductive bias, and positional encodings are introduced at every layer to distinguish the different layers. For privacy enhancement, a clustering scheme (such as k-means) is used to anonymize and group feature vector into a discrete set of features (the cluster centroids), and shown to yield improved privacy when used with CGT. Hence, the approach can be summarized as 1) A computation graph extraction, 2) duplicate encoding, 3) feature clustering and replacement, and 4) application of CGT to compute outputs. For generation, the reverse applies: CGT is used to infer a combination of discrete feature vectors, which can then be mapped back to a duplicate encoding computational graph.\n\nEmpirically, this method is verified on a variety of benchmarks through an experimental setup based on performance similarity. In particular, the protocol looks to generate analogous computational graphs to the original inputs using the approach, and seeks to compare the performance of a variety of models on the original and generated computational graphs. The generation is then perceived to be high-quality if the model performances are similar across both original and generated graphs. In the paper, the authors report that this is the case. Finally, the authors consider manipulations to the input graph, and apply the same protocol to these situations, showing correlations between performance changes as well as similar performance values.",
            "strength_and_weaknesses": "# Strengths: \n- The approach is scalable and thus can apply to large graph structures, which is not common in the graph generation domain.\n- The use of label information during generation is a good inductive bias and a useful property.\n- The model is simple to understand.\n# Weaknesses: \n-  I have major concerns about the soundness of reducing graph structures to fixed sequences. In particular, the duplicate encoding scheme is problematic, as it can lead to otherwise structurally different nodes obtaining identical computational graphs! For example, the computation graph of a node A in a triangle A -> B -> C  and is identical to that of the latter A in a line graph with identical A-featured nodes at extremes, i.e., A -> B - > C -> A (both A nodes distinct). As a result, the model is losing information in the generation process by default, and this stands regardless of the dimensionality of features used. The authors argue that the features can encode the lost structure, and discuss this near the end of the paper. However, this is not plausible in the general case, i.e., some information can be saved, but not all. Therefore, this generation procedure is effectively flattening the graph structure, which itself means that it cannot respect key structural properties of the input graphs and instead can only recover feature information. As a result, I have strong concerns that this approach can yield structure-preserving generated samples. \n- The empirical protocol, though intuitive, does not fully prove the quality of the graph generation: Given the large space of potential target functions over computation graphs, it is possible to learn different tasks of similar difficulty, particularly as the generation itself 1) could make arbitrarily difficult features with enough randomness, and 2) the encoded structure of the computation graph loses information relative to the original graph, making it harder to learn the original function in some cases. Therefore, I recommend also using a similar experimental protocol to the literature, based on visualizing graphs and comparing structural properties. I understand that the baselines are small in this case, but this is essential to appraise the quality of the generated computational graphs (both label-agnostic and per label).\n- The empirical results are not convincing: The gaps between synthetic and generated dataset numbers are quite substantial in Table 1. Moreover, the correlation experiment results are not surprising: It is natural that adding noise reduces performance irrespective of model choices, so this correlation in my opinion is to be expected. I feel the same about sampling neighborhood and its effect on performance. \n- The discussion on privacy in this work is very limited and makes no meaningful contribution: It simply uses a clustering algorithm prior to applying the model. Therefore, I find that the privacy contribution in this paper is significantly oversold, not least in the title. I suggest that this be downplayed when revising the paper.\n- Minor: Citations should be surrounded by brackets throughout the paper.",
            "clarity,_quality,_novelty_and_reproducibility": "# Clarity: \n- The paper is written well and its ideas are easy to follow\n\n# Quality: \n- I have major concerns about the quality of the generation procedure, as it is based on a lossy encoding which loses key structural information.\n\n# Novelty: \n- The work is not particularly novel. The CGT model is an incremental change on XLNet, and the privacy contributions are primarily imported from existing literature and are a direct result of applying clustering algorithms prior to using CGT. \n\n# Reproducibility: \n- I have no concerns about the reproducibility of the reported empirical results.",
            "summary_of_the_review": "Overall, I understand the paper's motivation to flatten of the graph structure into a balanced tree, so as to produce a fixed-size structure and use more established and scalable generation procedures. This flattening makes the paper's approach very efficient, but in turn loses significant structural information, and practically discards several key complexities that are inherent to graph-based tasks. In fact, it is easy to come up with scenarios where this generation procedure will ambiguate clearly distinct use cases. Moreover, I am not convinced by the empirical evaluation protocol and results. Therefore, I lean towards rejecting the paper as it stands. However, I am happy to discuss my concerns with the authors, and am open to change my verdict should they offer compelling arguments addressing my concerns.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1921/Reviewer_q2ks"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1921/Reviewer_q2ks"
        ]
    },
    {
        "id": "tB8bMOsT6JR",
        "original": null,
        "number": 2,
        "cdate": 1666342517196,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666342517196,
        "tmdate": 1666342517196,
        "tddate": null,
        "forum": "yFQjggu62T",
        "replyto": "yFQjggu62T",
        "invitation": "ICLR.cc/2023/Conference/Paper1921/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper re-define the problem of graph generation with concerns from three aspects: scalability, benchmarking, and privacy-preservation. In response, the authors proposes an interesting minibatch-based problem formulation and accordingly apply transformer to encode the computation graphs. Many tailored details about modeling are discussed and addressed. The proposed method is extensively evaluated from those three aspects, showing superiority over existing methods.",
            "strength_and_weaknesses": "Strengths:\n1. The paper is well-written.\n2. The re-defined problem with the three aspects of concerns appropriately reflect the latest demands in practice, which must be a contribution to the community. I am willing to seeing more and more works solving this problem.\n3. The duplicate scheme is simple yet effective, in my opinion. It transforms the problem in a way that drastically reduces the search space.\n4. The empirical studies are comprehensive.\n\nWeaknesses:\n1. How to sample node features from the cluster id and how to sample computation graphs from the learned transformer should be elaborated.\n2. The privacy concern is addressed from only the attributive perspective. As for the structural perspective, there is a lack of discussion. In my opinion, the discretization of node features also helps this method reduce the risk of composing the original graph from a collection of sampled computation graphs.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: This paper is readable, giving me a feel of following a step-by-step hands-on tutorial. One mistake might be the statement that \"higher $k$ and smaller $\\epsilon$ hinder the generative model...\". I agree with that smaller $\\epsilon$ leads to stronger privacy, but higher $k$ should preserve more information in the original node features.\n\nQuality: The design of this method has comprehensively considered the introduced three aspects of concerns in graph generation problem. The duplicate scheme seems simple yet effective in reducing the search space, which is a key technical contribution in my opinion. The modeling is natural and tailored to graph generation problem. It is great to see the authors focus on evaluating their method from those three aspects while remembering to discuss the traditional graph statistics.\n\nNovelty: The definition of the problem is novel to me, which happens to match the demand raised from my real-world applications. The duplicate scheme seems to be novel. Those minor tricks in modeling are straightforward, but I treasure the comprehensiveness of the authors' thinking.\n\nReproducibility: All the datasets, baselines, and implementations are publicly available.",
            "summary_of_the_review": "I have went through the whole main paper and found it is interesting and technically sound. According to my experience in federated graph learning, I think the problem re-defined and somewhat resolved in this paper is important. Thus, I tend to accept this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1921/Reviewer_qqDr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1921/Reviewer_qqDr"
        ]
    },
    {
        "id": "m-sQEfQfYJ2",
        "original": null,
        "number": 3,
        "cdate": 1667497874269,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667497874269,
        "tmdate": 1667497874269,
        "tddate": null,
        "forum": "yFQjggu62T",
        "replyto": "yFQjggu62T",
        "invitation": "ICLR.cc/2023/Conference/Paper1921/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a scalable and privacy-enhanced graph generative model to learn and reproduce the distribution of real-world graphs with node attributes/labels. The proposed model satisfies benchmark effectiveness, scalability and privacy guarantee.\n",
            "strength_and_weaknesses": "**Strength** \n- The proposed graph generative model fills the gap in existing works to handle privacy and node attributes/labels on large graphs\n- The paper proposes a clear and novel formulation for such a graph generation problem\n- Designs (e.g. computation graph minibatches, duplicate encoding scheme, quantization) are well motivated and technically sound\n\n**Weaknesses**\n- Important details (e.g. how to align cluster assignments across batches, how to do de-quantization etc) are not introduced\n- More experiments are needed to further verify the usefulness of generated graphs\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well written with clear motivation and technical details. Novel techniques are proposed to deal with a newly formulated problem. The reproducibility should also be fine given the detailed description.\n",
            "summary_of_the_review": "This work in general provides clear problem formulation and interesting ideas to transform the problem of graph generation into sequence generation. The design and evaluation would be more convincing if the following questions can be answered.\n\n**Method**\n\n1. What could be the advantages/disadvantages for using the computation graph, compared with a random walk based method to sample the graph? The reason for asking this question is that the cost-efficient version of CGT can be directly achieved by random walks. Meanwhile, I am curious about how sensitive this proposed method is to the sample size of neighbors $s$? \n\n2. The cluster assignments across different computation graphs or minibatches might be different as the quantization is not conducted over all the nodes. For example, two nodes with similar features might be assigned with different cluster ids (thus are different tokens) as they are quantized separately in two batches. How to handle such a misalignment of cluster assignment?\n\n3. The method section cuts off after introducing CGT. However, it is also important to explain how the de-quantization is conducted to finally generate computation graphs.\n\n4. With label conditioning, can this method handle heterophilic graphs? \n\n**Experiment**\n\n5. Is the size of original and generated graphs comparable in the evaluations?\n\n6. The goal of generated graphs is to train a useful GNN model that can be applied to real-world data. Therefore a more important setting should be tested: compare the performance of two GNNs on the same real-world test data, and these two GNNs are trained on the original or generated graphs respectively.\n\n7. To verify the effectiveness of the generated graphs, it would be better if the proposed method is compared with some existing graph generative models on small datasets, such as molecular datasets.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1921/Reviewer_Dpqx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1921/Reviewer_Dpqx"
        ]
    },
    {
        "id": "lCEUNPCsFMU",
        "original": null,
        "number": 4,
        "cdate": 1667563997090,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667563997090,
        "tmdate": 1667568155141,
        "tddate": null,
        "forum": "yFQjggu62T",
        "replyto": "yFQjggu62T",
        "invitation": "ICLR.cc/2023/Conference/Paper1921/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper aims to tackle the privacy issue when collecting datasets from online databases by introducing a novel graph generative model, which is called Computation Graph Transformer (CGT), that can learn the distribution of real-world graphs in a privacy-enhanced manner. The proposed algorithm can generate synthetic\nsubstitutes of large-scale real-world graphs, which can be used to benchmark GNN models. First, CGT operates on computational graphs of mini-batches rather than the whole graph, avoiding scalability issues. Second, a novel duplicate encoding learns a single, dense feature matrix instead of learning the adjacencies and features simultaneously\n",
            "strength_and_weaknesses": "#### Strengths\n1. To the best of my knowledge, I think the computation graph transformation method proposed by this paper is a novel approach to enhance privacy (more specifically, to achieve the k-anonymity privacy guarantee) on the fly and efficiently.\n2. The authors considered using Pearson & Spearman ranking correlations to measure how the performance order of GNNs is preserved on the synthetic graph.\n\n#### Weaknesses\n1. One major issue is that the \"benchmark effectiveness,\" which concerns how the synthetic graph preserves the performance ranking of GNNs, is definitely the most important metric of the proposed methodology. However, how the proposed CGT method achieves this goal is still hard to understand given the following reasons (please correct me if I am wrong): (1) The descriptions in sections 3 and 4 are mostly focused on the design and implementation of the CGT algorithm. However, it is hard to find the intuition or theoretical guarantee that ensures the benchmark effectiveness of CGT. (2) Tables 1 and 2 measure the Spearman rank correlations on multiple datasets; however, the number of GNN architectures considered (which are only GCN, GIN, SGC, GAT according to appendix A.7.1) is too small to draw a meaningful and conclusive result. Many more architectures are needed to add to the pool. Another issue is that the authors should also consider simpler and more meaningful graph generative model baselines in Table 5 in appendix A.2 (I also suggest moving Table 5 to the main paper). Otherwise, it is hard to understand the correlation metrics of CGT.\n2. In terms of the scalability of the proposed CGT method, (1) the theoretical complexities claimed in Claim 3 still suffer from the exponential dependence on the number of layers, similar to a standard neighbor sampling scheme, and this hinders the application to deeper GNNs. (2) I only see a few experimental results on the scalability comparison (e.g., Table 5 in appendix A.2 only shows some methods out of memory). Some more measures like the computational time and memory usage of CGT and some simpler yet meaningful graph generative model baselines are encouraged to be added.",
            "clarity,_quality,_novelty_and_reproducibility": "1. I think the clarity of sections 3-5 need some improvement, in the sense that I hope the authors could spend more space on the central questions and claims, i.e., benchmark effectiveness and scalability of the proposed method.\n2. To my best knowledge, I agree with the novelty of this work, but I think more careful experiments and also more tailored theoretical analysis are helpful to improve the quality.\n3. The reproducibility depends on whether the authors will release the code (conditioned on the acceptance) and cannot be judged now.",
            "summary_of_the_review": "Overall I recommend the rejection of the current manuscript. I agree with the novelty and the importance of the problem considered: to enhance the privacy of the real-world, large-scale graphs collected from online databases. But due to the current insufficient theoretical analysis and experiments that justify CGT solves the benchmark effectiveness and scalability goals as the paper claimed, I cannot recommend acceptance now. Either some theoretical guarantees on how the benchmark effectiveness is achieved, or a much larger GNN architecture pool to measure the rank correlation is needed.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1921/Reviewer_jEpM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1921/Reviewer_jEpM"
        ]
    }
]