[
    {
        "id": "n7BXecRDkAg",
        "original": null,
        "number": 1,
        "cdate": 1666557367576,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666557367576,
        "tmdate": 1666557367576,
        "tddate": null,
        "forum": "xBeGd7sAND",
        "replyto": "xBeGd7sAND",
        "invitation": "ICLR.cc/2023/Conference/Paper1922/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method for growing neural networks during training. The authors formulate the problem as an optimization problem. Specifically, when the network lacks expressivity, there will be no gradient updates in the weight space that will lead to a change in the outputs that align with the desired functional gradient, i.e., $v_{goal}$. To mitigate this issue, the authors propose to expand the network by adding extra neurons and assigning the weights by solving an optimization problem detailed in section 3. Empirically, the authors conduct preliminary experiments on MNIST datasets.\n",
            "strength_and_weaknesses": "Strength:\n- First of all, I think the problem of growing neural networks on the fly is very interesting and important, especially putting it under continual/lifelong learning scenarios. \n- In terms of the methodology of this paper, I enjoyed reading the motivation and the derivation of the method, which I feel is pretty natural. In particular, I like the toy example for illustrating the issue of lacking expressivity. \n\nWeakness:\n- The most critical weakness of this paper is that the authors seem to miss many important related kinds of literature, and failed to make a comparison with them. To my knowledge, the problem of growing neural networks on the fly is not new. There have already been many works. \n - - For example, the work by Wu et al., 2019, is very similar to your idea. The high-level idea is that adding more neurons will turn local optima in the small neural networks to be a saddle point. They derive a simple criterion for deciding the best subset of neurons to split and a splitting gradient for optimally updating the off-springs, which is a second-order functional steepest descent for escaping saddle points in an $\\infty$-Wasserstein metric space. There are also follow-up works by Wu et al., 2020 and Wang et al., 2019. \n- - The work by Chen et al., 2015, is a bit more empirical but is also very relevant. In their work, they add new neurons with carefully designed weights that don't change the computed function. The only difference is that they need to manually decide when to add neurons.\nTherefore, I believe a detailed discussion and comprehensive comparisons of these methods are necessary.\n\nThere are also a couple of additional concerns:\n- The derivation in the paper is only about one layer. How can it generalize to multiple layers?\n- How do you decide the number of neurons be added? Or do you need to enumerate all the possibilities? \n- The experiments are quite lacking. I would suggest the author follow the experiment setup in [1-4].\n\n\nReferences:\n\n[1] Wu, Lemeng, Dilin Wang, and Qiang Liu. \"Splitting steepest descent for growing neural architectures.\" Advances in neural information processing systems 32 (2019).\n\n[2] Wu, Lemeng, Mao Ye, Qi Lei, Jason D. Lee, and Qiang Liu. \"Steepest descent neural architecture optimization: Escaping local optimum with signed neural splitting.\" arXiv preprint arXiv:2003.10392 (2020).\n\n[3] Wang, D., Li, M., Wu, L., Chandra, V., & Liu, Q. (2019). Energy-aware neural architecture optimization with fast splitting steepest descent. arXiv preprint arXiv:1910.03103.\n\n[4] Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. \"Net2net: Accelerating learning via knowledge transfer.\" ICLR 2016.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and the derivation was easy to follow. The originality of the work may be limited, as the idea is quite similar to or not as novel as prior works, e.g., Wu et al., 2019. ",
            "summary_of_the_review": "Overall, I think the problem studied in this paper is interesting and important. The motivation is clear and well-justified. However, my major concern is that the authors missed many related literatures and hence failed to make a comparisons with them. The position of the paper is unclear. Detailed comments can be found in Strength And Weaknesses section.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1922/Reviewer_ae2U"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1922/Reviewer_ae2U"
        ]
    },
    {
        "id": "V-v7lD0KYx",
        "original": null,
        "number": 2,
        "cdate": 1667158948454,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667158948454,
        "tmdate": 1667158948454,
        "tddate": null,
        "forum": "xBeGd7sAND",
        "replyto": "xBeGd7sAND",
        "invitation": "ICLR.cc/2023/Conference/Paper1922/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper suggests a novel approach to extend neural networks during training using the functional gradient. The approach starts with an impoverished network and iteratively adds neurons to the network making sure to follow the true gradient direction. The authors mathematically derive an optimal technique to grow the architecture in the manner proposed. They also present experiments on MNIST showing that their approach performs better than classically trained networks with similar architectural constraints and networks extended by randomly adding neurons.",
            "strength_and_weaknesses": "# Strengths\n- The paper is very thorough and clearly describes all the math involved in their approach.\n- To my knowledge, the paper presents a novel approach for extending neural networks using functional gradient information.\n- The suggested method for extending neural networks seems very powerful if works as claimed and could have a large impact on the way we train networks.\n\n# Weaknesses\n- One hypothesis why Deep Learning works so well is that the fixed architecture provides an implicit regularization that ensures the network doesn't overfit while SGD and variants optimize the training loss. The approach presented in this paper removes this form of implicit regularization. \nWhile this approach may work, the generalization of this method needs to be validated through experiments. \nThe only experiments conducted in this paper are small-scale experiments on MNIST using impoverished networks.\nMNIST is too small of a dataset to suffer the actual generalization consequences that may come from using this method. I would like to see experiments on larger datasets like CIFAR-10 with larger overparameterized baselines as suggested by most of the contemporary deep learning literature.\n- Most contemporary deep learning models are overparameterized, meaning they are able to achieve 100 train accuracy without needing to add any more parameters. While there may be an expressivity gap at each training step for these models, there does not seem to be any expressivity gap for the actual task since the models can easily overfit on the training set. This suggests that the key assumption made in this paper regarding the expressivity gap is flawed.\n- I would like to see other experiments comparing this method to alternative methods like pruning that also attempt to identify \"lottery ticket\" architectures. If the method proposed here achieves a similar generalization metric to those methods, I would be more convinced of the claims made by the paper.\n- This approach is analogous to taking a low-degree polynomial and increasing its order to fit the data. While the approach considered is novel considering the way the network is extended using the gradient information, the final success of this approach will lie entirely on its ultimate generalization performance for which the current experiments are not convincing enough.\n- It's unclear why the experiments use time on the x-axis.\n- Primarily my objections boil down to the limitations of using MNIST to evaluate an architectural search problem and the use of small networks that do not express the interpolation regime behavior to which we attribute the success of deep learning models.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper was relatively clear to read. There were several minor details that were difficult to parse as well as some sections that could benefit from more elaboration.\n- The quality of the paper is high in the technical math content. However, left a lot to be desired in the experimental content.\n- To my knowledge the approach considered in this paper is novel.\n- I did not attempt to reproduce the results of this paper.\n\n# Clarity issues\n- It is not clear to me how the first equation in the gradient descent reminder turns into the latter part of the second one.\n- In section 2.3 Ideal updates, backbone propagation should be backpropagation and preactivities should be preactivations. Also $a^l$ should be $a_l$.",
            "summary_of_the_review": "While the contributions of this paper are novel to my knowledge and the math describing the motivations and details of the approach is extensive. The hypothesis of this paper remains experimentally unverified in my opinion (See weaknesses section). As a result, without more experiments, I don't think this paper is ready for publication in its current form.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1922/Reviewer_vKnn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1922/Reviewer_vKnn"
        ]
    },
    {
        "id": "Hh2OFJoWt6",
        "original": null,
        "number": 3,
        "cdate": 1667292153730,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667292153730,
        "tmdate": 1667292153730,
        "tddate": null,
        "forum": "xBeGd7sAND",
        "replyto": "xBeGd7sAND",
        "invitation": "ICLR.cc/2023/Conference/Paper1922/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a new approach to widen layers of a neural network during training. The method is motivated by the functional gradient and looking at the desired activations for a given data input. Proof-of-concept experiments on MNIST are used to compare the method to conventional training.",
            "strength_and_weaknesses": "The idea is well explained and motivated, and the designed approach seems promising and novel.\n\nThe main weakness is the lack of empirical results to properly evaluate the method and test its practical implications.\n\nTo be more specific, there are previous works whose goal is to grow a network -- i.e. start from a small network and sequentially add neurons / filters / layers -- in order to save training time. These methods are typically evaluated on CIFAR-10 and ImageNet, and MNIST is too much of an easy dataset to properly evaluate these methods: the required network size to perform well on MNIST is very small. Some examples of growing methods are: MorphNet, NetAdapt, FireFly, and Net2Net.\n\nAnother concern is whether solving the quadratic problem is feasible for larger networks of different families, like CNNs.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly-written and the idea is well-motivated and, to the best of my knowledge, novel.",
            "summary_of_the_review": "See 'strengths and weaknesses' for more details.\n\nThe idea seems promising, and I suggest the authors to further investigate it through more rigorous experiments. Unfortunately it's hard to evaluate a growing method -- whose goal is to ultimately save training time by starting from a small network and growing it through training -- on a dataset as small and easy as MNIST. CIFAR-10 and ImageNet experiments are the most commonly-adopted ones when evaluating and comparing growing methods. A discussion on related works that also focus on growing networks would also be extremely valuable.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1922/Reviewer_9tpv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1922/Reviewer_9tpv"
        ]
    },
    {
        "id": "bwczyOl5Osc",
        "original": null,
        "number": 4,
        "cdate": 1667549669905,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667549669905,
        "tmdate": 1667549669905,
        "tddate": null,
        "forum": "xBeGd7sAND",
        "replyto": "xBeGd7sAND",
        "invitation": "ICLR.cc/2023/Conference/Paper1922/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a method to learn the optimal architecture via back propagation. ",
            "strength_and_weaknesses": "Strenghts:\n\n1. Interesting Idea and compelling problem statement\n\nWeaknesses:\n\n1. I do not think the quality of the paper is upto ICLR standards. The writing is shabby at places with multiple typos and is difficult to follow. The way it is presented, the algorithm the authors propose is incredible hard to decipher.\n\n2. Experimental evaluation is weak. I would expect to see results on other datasets beyond MNIST. Even for MNIST where even simple 2-layer networks get 96-97% accuracy, the plots for the classical method (standard training with fixed architecture) seems too poor for a baseline.\n",
            "clarity,_quality,_novelty_and_reproducibility": "While the approach seems to be novel and interesting I think the paper is not ready for publication and is very rushed. Experimental evaluation is also weak. ",
            "summary_of_the_review": "Due to concerns on presentation and experimental strengths I recommend rejection. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1922/Reviewer_fbfu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1922/Reviewer_fbfu"
        ]
    }
]