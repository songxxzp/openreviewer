[
    {
        "id": "5rwzoBKswoe",
        "original": null,
        "number": 1,
        "cdate": 1666580655569,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666580655569,
        "tmdate": 1666580655569,
        "tddate": null,
        "forum": "9IlzJa5cAv",
        "replyto": "9IlzJa5cAv",
        "invitation": "ICLR.cc/2023/Conference/Paper5078/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a novel Decision Tree GNN architecture, which is fully explainable. DT+GNN firstly trains a fully differentiable layer that is restricted to categorical state spaces for nodes and messages. Secondly, they distill these layers into decision trees. Finally, pruned these trees to ensure they are small and easy to interpret. DT+GNN performs comparably to GIN in synthetic and real-world datasets. \n",
            "strength_and_weaknesses": "Strength:\n\n[1] By introducing the Decision Tree to GNN, humans can inspect and understand the decision-making of DT+GNN at every step, which is valuable for the community.\n\n[2] Pruning these decision trees will make them easier to interpret, and small trees are efficient for inference.\n\n[3] Experiments show DT+GNN performs almost identically to GIN in real-world datasets and produces competitive explanations in synthetic datasets.\n\nWeaknesses:\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "[1] This paper is clearly written and well organized.\n\n[2] Most of the claims are well supported by visual examples or experimental results.\n\n[3] The idea of distilling neural networks into trees to make them explainable have seen before, but the way to realize it in GNN seems novel to me.\n\n[4] The code is provided for reproducibility. ",
            "summary_of_the_review": "This paper proposed a novel DT-GNN for understanding decision-making at every step. Most of their claims are well supported by visual examples or experimental results. It deserves to be accepted by this conference.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5078/Reviewer_9FEb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5078/Reviewer_9FEb"
        ]
    },
    {
        "id": "pNNEJjK2ao",
        "original": null,
        "number": 2,
        "cdate": 1666621314318,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666621314318,
        "tmdate": 1666621314318,
        "tddate": null,
        "forum": "9IlzJa5cAv",
        "replyto": "9IlzJa5cAv",
        "invitation": "ICLR.cc/2023/Conference/Paper5078/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a new Decision Tree GNN (DT+GNN) architecture to help make GNN predictions more explainable. The proposed approach uses a new layer inspired by stone age model, distills all MLPs to Decision Trees, introduces a pruning mechanism for there trees, and reports experimental results to empirically evaluate the method's performance and explainability with other alternative approaches. Experimental results show that DT+GNN has comparable performance with GIN, a GNN based method. Results also show that DT+GNN can achieve comparable explainability scores with a few other alternative methods.",
            "strength_and_weaknesses": "Strength\n- The paper is easy to read and adequate amount of explanations are provided to make the proposed concepts easier to grasp for the reader.\n- Literature review looks good for the most part, except some more general recent efforts on replacing Neural Networks with DTs (e.g. Neural Networks are Decision Trees by Aytekin et. al.) that can be applicable to GNN as well.\n- Experimental results are comprehensive and support the claims.\n\nWeaknesses\n- As mentioned by authors, there is a shortcoming in the proposed method's performance for domains with large number of node input features.\n- There is a disconnect between studying the performance of DT+GNN and its explainability since alternative methods reported for explainability comparisons are not used in the performance comparison, therefore, one cannot get a wholistic picture of the trade-off between explainability and performance for the alternative methods.\n- Experimental results do not seem to highlight significant benefits neither for performance nor for explainability.\n- Also refer to Novelty section in the next box.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n- No major concern. Authors have added a link to their website with visualization in page 2 that helps better understanding how the proposed method works which is great.\n\nQuality:\n- No major concern.\n\nNovelty:\n- Contributions such as using stone age model, pruning the trees, representing MLP with decision tree, etc. are not individually novel and utilizing the combination of these techniques make the work slightly novel.\n\nReproducibility:\n- No major concern.",
            "summary_of_the_review": "The paper addresses an important topic in GNN, i.e. explainability, which is an active research area. The proposed method is explained clearly and experimental results are provided to support its benefits.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5078/Reviewer_gfpK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5078/Reviewer_gfpK"
        ]
    },
    {
        "id": "2kYN-mbn3o",
        "original": null,
        "number": 3,
        "cdate": 1666646757835,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666646757835,
        "tmdate": 1666646757835,
        "tddate": null,
        "forum": "9IlzJa5cAv",
        "replyto": "9IlzJa5cAv",
        "invitation": "ICLR.cc/2023/Conference/Paper5078/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a novel GNN architecture that uses a small categorical space for messages and states instead of traditional synchronous message passing. Moreover, after training, they replace all the MLPs in their layers with decision trees to give a fully interpretable model",
            "strength_and_weaknesses": "## Strenghts: \n\nAuthors address a real-world problem. \nExplanation method is simple and comprehensible. \nTheir method is empirically solid. \n\n## Weaknesses\n\nAs the authors pointed out, their explainability method works only on small graph dataset, or datasets with limited number of features. \nSince their method is theoretically less expressive than message-passing, it should have been interesting to provide performance analysis of their classifier (not the explainable module) for large datasets like Cora. \n",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity: Explain better the section of Distilling the DT+GNN. Write the formulation of the stone age model.   \n* Quality: yes\n* Novelty: yes\n* Reproducibility: do they provide their code? \n",
            "summary_of_the_review": "The authors address a real-world issue. While their method is theoretically less expressive than message-passing, it is empirically competitive. The authors noted that their method is better suited to graph datasets with fewer features, since the complexity of the method increases with the number of features. This method is not suitable for large graph datasets.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5078/Reviewer_Sxw4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5078/Reviewer_Sxw4"
        ]
    },
    {
        "id": "h1xjaCm_dmh",
        "original": null,
        "number": 4,
        "cdate": 1666763204755,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666763204755,
        "tmdate": 1669266356387,
        "tddate": null,
        "forum": "9IlzJa5cAv",
        "replyto": "9IlzJa5cAv",
        "invitation": "ICLR.cc/2023/Conference/Paper5078/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Explainability in Graph Neural Networks (GNNs) is in an upcoming research direction, where most recent works have focused on developing perturbation-, surrogate-, or prototype-based post hoc explanation methods. However, these methods fail to identify how a GNN model processes the input layer-wise. In this work, the authors combine decision trees (DT) with GNN to introduce a fully explainable new architecture DT+GNN, which builds on a novel differentiable GNN layer that is restricted to categorical state spaces for nodes and messages and, similar to existing post hoc GNN explainers, outputs node-level importance scores. Empirical results on real-world GNN benchmarks show that DT+GNN achieves on-par or better results than their vanilla counterparts.",
            "strength_and_weaknesses": "**Strengths**\n\n1. The paper presents DT+GNN, a novel architecture that consists of a new differentiable Diff-DT+GNN layer inspired by a simplified distributed computing model known as the stone age model.\n2. The paper provides an interactive user interface that can be used to explore the decision process of the DT+GNN model trained on different datasets.\n3. In addition to the thresholds of the decision tree, DT+GNN can also be used to generate graph-level explanations.\n\n**Weaknesses and Open Questions**\n1. The paper lacks sufficient details about the DT+GNN model in Section 3. The readability will drastically improve if we describe the message-passing scheme of DT+GNN using mathematical equations. Further, the figure captions are unclear and not self-explanatory.\n2. What is the loss of information when constructing a categorical state space of DT+GNN using $\\mathcal{O}(n)$ bits to encode the information from the continuous embeddings?\n3. Is there a hard threshold on the number of decision leaves per tree, which is restricted in the training process?\n4. Most DT+GNN architecture use more than two layers for synthetic and real-world datasets. It is unclear whether both GIN and DT+GNN use these many layers during training. If yes, then it is very counterintuitive that GIN needs 5 layers to get high performance for small datasets like BA-Shapes and Tree-Cycles.\n5. The limited number of categorical states in DT+GNN limits its applicability to large benchmark graph datasets. ",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nThe paper lacks clarity about the details of the DT+GNN architecture.\n",
            "summary_of_the_review": "The paper presents a novel interactive tool to understand the information flow of the fully explainable DT+GNN architecture but lacks sufficient motivation and technical details about the model.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5078/Reviewer_6BLn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5078/Reviewer_6BLn"
        ]
    }
]