[
    {
        "id": "RvjmuUP27X",
        "original": null,
        "number": 1,
        "cdate": 1666577693902,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666577693902,
        "tmdate": 1666577693902,
        "tddate": null,
        "forum": "F91SROvVJ_6",
        "replyto": "F91SROvVJ_6",
        "invitation": "ICLR.cc/2023/Conference/Paper769/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a balanced sampling strategy to make data distribution spurious-free. It is based on the causal assumption of invariant data generating process. The model trained on the unbiased data is assumed to be minimax optimal across different environments. The authors also provide identifiability guarantee of the causal model. Experiments on the DomainBed dataset show its favorable out-of-distribution generalization performance. The method is basically sound and the writing is good.",
            "strength_and_weaknesses": "Strength:\n1.\tThis paper proposes to debias the data distribution through a balanced mini-batch sampling, and then it uses the balanced data to train the model. It is technically sound.\n2.\tThe authors give theoretical analyses for the insights of this sampling strategy. \n3.\tThe authors implement the experiments on the public DomainBed codebase with seven datasets. It is considered fair and reproducible.\n4.\tThe writing is good and easy to follow.\nWeakness:\n1.\tSince there are numerous causality-based domain generalization methods, e.g., [1-9], and many of them are also based on the invariant causal structure assumption like this paper. I would like to see more in-depth discussions about the difference between them and this work. For example, some papers [1, 4] may assume that X is the cause of Y, some papers [2, 3, 5, 6, 9] may assume that there is not a direct causal relation between X and Y, but this paper supposes that Y causes X. What are the differences between them and this work? And what is the novelty of this paper in designing the causal graph in Fig. 1?\n2.\tAs stated in Algorithm 1, the sampling strategy should be performed for each sample in the dataset. So, I guess it may not be efficient. The authors may discuss more about this limitation. For example, the total running time before/after introducing balanced sampling process.\n3.\tI see the main improvement of average accuracy comes from the CMNIST dataset. For example, it improves the accuracy of ERM from 51.5% to 60.1%. But the improvement on other datasets is not such significant, or even worse on RMNIST and VLCS dataset. I suggest the authors to give more discussions about this.\n4.\tFor Fig.4 (a), if I understand correctly, training data is from the source domain and test data is from the target domain. So, I don\u2019t see why the accuracy of training data is lower than the accuracy of test data. Could the authors explain it?\n5.\tWhy does the results in Table 4 with KLD metrics are not consistent with the results of CMNIST in Table 2?\n\n[1] A Causal Framework for Distribution Generalization [TPAMI 2021]\n[2] A Style and Semantic Memory Mechanism for Domain Generalization [ICCV 2021]\n[3] Domain Generalization using Causal Matching [ICML 2021]\n[4] Learning Domain-Invariant Relationship with Instrumental Variable for Domain Generalization [arXiv 2021]\n[5] Learning Causal Semantic Representation for Out-of-Distribution Prediction [NeurIPS 2021]\n[6] Recovering Latent Causal Factor for Generalization to Distributional Shifts [NeurIPS 2021]\n[7] On Calibration and Out-of-domain Generalization [NeurIPS 2021]\n[8] Invariance Principle Meets Information Bottleneck for Out-Of-Distribution Generalization [NeurIPS 2021]\n[9] Invariant Information Bottleneck for Domain Generalization [AAAI 2022]\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well written. The proposed method is clear and the theoretical analyses is sound. The used datasets in this paper are public, and the experiments are conducted on the public codebase of DomainBed. So, I believe the experiments are fair and reproducible.",
            "summary_of_the_review": "This paper introduces a causality-inspired balanced mini-batch sampling method for domain generalization. The details of the proposed method and the theoretical insights are introduced clearly. The experiments on seven popular datasets and the DomainBed codebase are fair and good. My concerns about this paper are its novelty in causal graph, its sampling efficiency, and its performance improvement.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper769/Reviewer_KTyH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper769/Reviewer_KTyH"
        ]
    },
    {
        "id": "90LAY3ApEz_",
        "original": null,
        "number": 2,
        "cdate": 1666620040788,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666620040788,
        "tmdate": 1666620040788,
        "tddate": null,
        "forum": "F91SROvVJ_6",
        "replyto": "F91SROvVJ_6",
        "invitation": "ICLR.cc/2023/Conference/Paper769/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims to design a domain generalization model based on causal balancing. To this end, the authors assume that the observation is causally determined by the label and some latent factors and a random variable. Based on such assumption, the authors have provided many theories to demonstrate that the causal model is identifiable. In the experiments, a lot of experiments have been conducted to demonstrate the effectiveness of the proposed model.",
            "strength_and_weaknesses": "\nIn general, the paper is well written, and the assumptions are well described and the theories are solid. The balancing problem is important for domain generation, and the authors have provided a valid solution to this problem. \nMy concerns are mainly about the assumption made in this paper. I would like to see how strong of these assumptions, for example, in assumption 3.1, whether is it possible to drop the exponential assumption. If the noise variable can not be added to the function f, how about the conclusion of this paper. \nIn addition, shall we have more advanced methods for addressing the balancing problem, for example representation learning and so on.\n\nOverall, I think this is a good paper. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written, and the studied problem is novel.",
            "summary_of_the_review": "See the above comments.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper769/Reviewer_AxQ6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper769/Reviewer_AxQ6"
        ]
    },
    {
        "id": "PVfgOzsnvm",
        "original": null,
        "number": 3,
        "cdate": 1666749796285,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666749796285,
        "tmdate": 1669681220622,
        "tddate": null,
        "forum": "F91SROvVJ_6",
        "replyto": "F91SROvVJ_6",
        "invitation": "ICLR.cc/2023/Conference/Paper769/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper develops a method for using multiple environments during training to obtain a model that performs well on an unseen test environment. The method has both theoretical and experimental support.",
            "strength_and_weaknesses": "Strengths:\n\nThe method developed in the paper is based on an interesting way to model different environments, and the idea of selecting the minimax model across the training environments is an interesting idea.\n\nThe results are very promising on ColoredMNIST and the 10-class version.\n\nWeaknesses:\n\nThe improvements on the datasets other than ColoredMNIST are much more modest.\n\nSome of the assumptions about how the environments are related are relatively strong (for example, it is quite possible that some of the datasets have more noise than the others).",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is reasonably well written, with some minor issues in the bibliography (Beery 2018a and 2018b are duplicates, Li 2017a and 2017b are duplicates; many citations have unusual capitalization/formatting).",
            "summary_of_the_review": "The paper develops an interesting method for attempting to generalize well to unseen test environments. The theoretical support is interesting, with some strong assumptions, and the method shows significant improvements on some datasets (with much more modest improvements on some others).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethics concerns",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper769/Reviewer_ypmL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper769/Reviewer_ypmL"
        ]
    },
    {
        "id": "-PxqXXAuo-M",
        "original": null,
        "number": 4,
        "cdate": 1667319118106,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667319118106,
        "tmdate": 1667319118106,
        "tddate": null,
        "forum": "F91SROvVJ_6",
        "replyto": "F91SROvVJ_6",
        "invitation": "ICLR.cc/2023/Conference/Paper769/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims to address OOD generalisation by providing a two step method that aims to generate samples from a 'balanced distribution' that can be used to train subsequent off the shelf classifiers that generalise to new environments well. This involves a two step procedure, the first involves learning p(V) using a Variational Autoencoder, and then using a matching method to create balanced mini batches. Finally, experimental validation is performed on DomainBed, where an improvement is demonstrated. ",
            "strength_and_weaknesses": "Strength: This paper provides identifiably results regarding the auto-encoder and its ability to recover the parameters of true distributions. The balanced mini-batch sampling strategy allows for the use of any ML classifier after, which is very nice. The experimental results are good.\n\nWeakness: I would like to see a more rigorous discussion about why the DAG that models the data generating process is suitable for this problem as this would benefit readers. Additionally, the condition regarding the Cartesian product of support of Y and the support of E-train I would like to see discussed more and it's relation to dimensionality and the amount of data points across various environments needs. ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well presented and the results are well justified. In terms of novelty there is a slight similarity to the minimax results provided here: https://ieeexplore.ieee.org/abstract/document/9476906, I'd encourage the authors to take a look. ",
            "summary_of_the_review": "Overall, this paper provides a novel framework to first learn the balanced distribution that has invariance properties across different environments, and then train a classifier based on samples generated using the proposed sampling algorithm. Theorems regarding identifiability and minimax results are proved, and finally experimental validation on the DomainBed datasets show improvement in performance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper769/Reviewer_2Bti"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper769/Reviewer_2Bti"
        ]
    }
]