[
    {
        "id": "ms6pkT42CbU",
        "original": null,
        "number": 1,
        "cdate": 1665996326601,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665996326601,
        "tmdate": 1668850459785,
        "tddate": null,
        "forum": "AWZgXGmsbA",
        "replyto": "AWZgXGmsbA",
        "invitation": "ICLR.cc/2023/Conference/Paper3114/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents Powderworld, a fast simulated environment capable of producing diverse tasks for either supervised learning or an RL agent. The paper demonstrates that Powderworld can be used for both learning world models and training RL agents in a sandpushing task. ",
            "strength_and_weaknesses": "### Strengths\n- The paper is well-written and well-motivated, as training agents on large, diverse task distributions has become increasingly popular and important as we seek more general agents.\n- The environment seems very fast, given it runs on a GPU, which is great for iteration speed for research.\n\n### Weaknesses\n- The world modelling task is definitely interesting but it is hard to see how it is directly relevant outside of this environment. We would likely never have access to a Markovian state in such a controlled setting. The section appears to be motivated by works such as World Models and Dreamer, but in those cases 1) the models are learned directly from pixels without a Markovian state 2) there is an agent taking actions in the world. So this is a totally different paradigm. The fact that the model generalizes better with more data here is expected, as the authors note this has been the case in a variety of other settings already.\n- How can we be sure the hand designed tasks are unbiased? For all we know they could be somewhat arbitrary.\n- While the motivation in the intro is that this world is more general than others such as MiniGrid/Crafter/MiniHack, the only RL task presented is just sand pushing. How is this more diverse and useful than for example the tasks in Crafter/MiniHack which vary from navigation to tool use?\n- It looks like the experiments were all just one seed. When we know RL training is volatile, it seems like an oversight to have done this given the environment is meant to be fast. \n- One of the motivations in the intro is the potential use for UED, but there is no demonstration of this. It would be interesting to see if this environment offers something unique here vs. the alternatives. It may be beyond the scope to run this for a rebuttal but it would likely see an increased score.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and supposedly reproducible with open-source code forthcoming. The novelty is more challenging. How is this more useful than Crafter/MiniHack?",
            "summary_of_the_review": "At the surface the paper presents an interesting and unique environment that may facilitate future research. However, the two presented use cases are a world modelling task which is not directly relevant outside powderworld, and an RL task where the main result confirms what we already know from Procgen et al. Overall I do not think the paper contributes anything new at present. \n\nPost discussion:\n\nThe paper is completely revised so now provides some useful, fast settings that can be used for work in PCG and UED for RL. Analysis shows this can be a worthy testbed and may help researchers enter what is a growing and important field. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3114/Reviewer_oDrU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3114/Reviewer_oDrU"
        ]
    },
    {
        "id": "5nvhWtNR8EZ",
        "original": null,
        "number": 2,
        "cdate": 1666722661895,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666722661895,
        "tmdate": 1666874524279,
        "tddate": null,
        "forum": "AWZgXGmsbA",
        "replyto": "AWZgXGmsbA",
        "invitation": "ICLR.cc/2023/Conference/Paper3114/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents Powderworld, a platform to build environments on which to train world models and RL agents. The main purpose of this platform is to investigate generalization. \n",
            "strength_and_weaknesses": "### Strengths\n\nThe platform supports the design of environments with different levels of complexity and many degrees of freedom (i.e. many different elements can be added to the environment).\n\nIt can also run many instantiations (multiple worlds) in parallel on a GPU, which translates into runtime efficiency. \n\nEnvironments can be either manually or procedurally generated, which means that one can quickly generate thousands of different worlds to train on.\n\nThe environments are also modular in the sense that the different elements interact only locally with their neighbors. \n\nThe paper provides extensive experimentation, especially for the world model case.  The results are intuitive and generally agree with our intuitions of how adding more, tasks and/or complexity increases generalization.\n\n### Weaknesses\n\nAccording to the paper, the interactions between elements are computed via convolutional matrix multiplications. This means that the transition dynamics can be model **exactly** with a convolutional neural network (CNN). That is, theoretically, a CNN can be trained to zero loss, provided you can find the global optimum. An increase in complexity (i.e. adding more elements to the environment) can be resolved by adding more kernels to the CNN such that each kernel can potentially model each of the possible interactions. Can the authors comment on this? Or even better, provide results showing whether zero loss can be obtained for simple environments. Note that this won\u2019t affect my score but I am curious to know if this is the case.\n\nSince the main purpose of this paper is training RL agents I am missing more experiments showing what can be done with this platform. So far I can only think of tasks like moving objects (elements) from one place to another or removing ceratin elements. Can the authors provide examples of other tasks?\n\nRelated to my previous question, have you considered adding agents (e.g. robots) that can interact with the elements?\n\nIn the last RL experiment, you mention that increasing the complexity of the environments decreases generalization performance. Have you tried to start with simple environments and gradually increase the complexity as the agent improves its policy?\n\nIn the first reference, there is a link to a site where there is a game called powder game. Is this the Powderworld platform?\n\nPerhaps this question is too technical but, how do you take care of the non-linear operations (e.g. gravity), how can those be performed on a GPU?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is very clear. The authors provide a lot of comments and intuitions about their experimental results. The work is novel.  Code is provided so experiments should be reproducible. \n",
            "summary_of_the_review": "This is a strong paper introducing a new platform for designing RL environments. I believe Powederworld can be very valuable to the community. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3114/Reviewer_fLgh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3114/Reviewer_fLgh"
        ]
    },
    {
        "id": "okcUBFdlpt",
        "original": null,
        "number": 3,
        "cdate": 1666921094990,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666921094990,
        "tmdate": 1670290785583,
        "tddate": null,
        "forum": "AWZgXGmsbA",
        "replyto": "AWZgXGmsbA",
        "invitation": "ICLR.cc/2023/Conference/Paper3114/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new simulation environment (Powderworld) to facilitate the study of generalization across tasks which share rules. The environment is extensible and designed for speed and modern GPU hardware. Experiments demonstrate how Powderworld can be used to study generalization in world modeling and RL.\n",
            "strength_and_weaknesses": "Strengths\n  - Novel environment designed to facilitate study in key topic in agent design (generalization across tasks). The design makes it easy to extend the environment, vary task distributions and generate training data inexpensively.\n  - Efficient design and implementation of the simulator, leveraging modern GPU hardware.\n\nWeaknesses\n  - Some parts of the experimental setup could be more clearly described. An illustration of the trajectory generation process for training and inference might help improve clarity in this part of the paper.\n    - I was confused by the implemetation details and scaling law claims in Sec 4.1.1. \n      - Were each of the 5 models in Fig 5 trained on the same total amount of simulation data or not? Does the phrase \"training data\" in the line \"world models trained on increasing amounts of training data display higher performance on a set of test tasks\" refer to the number of tasks while keeping the total number of simulations constant across all 5 models? If yes, how exactly were these trajectories sampled? And does it mean that Fig 5 right is a sample observation (W_15) from the predicted logit probs (W').\n      - What exactly is a run and a trial? I found the statements \"each run trains on 10x more data as the previous\" and \"Runs are trained for three trials and the average test loss over training time is displayed\" confusing.\n    - A similar question arises in Sec 5. How exactly are the 2.5M datapoints for the RL agent generated for agents restricted to T training tasks?\n  - (More a question than a weakness) How well does powderworld support human agents? More concretely, how easy would it be to compare a RL agent with a human agent in Powderworld?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality\n  * The proposed ideas and implementation tackle an important problem. The formulation and methods are technically sound.\n\nClarity\n  * The paper is reasonably well written but some parts are unclear. In particular, training data (trajectory) generation and test time eval for world modeling and RL might benefit from additional detail or illustration. \n\nNovelty\n  * The simulation environment seems quite novel.\n\nReproducibility\n  * No issues here as code is released.",
            "summary_of_the_review": "The primary contribution is a novel tool consisting of a simulation environment. Its release might help advance the community better study an important problem in agent design. Difficult to predict the adoption of this tool but I don't see any reason to not add it to the toolbox. The experimental clarity of the 2 demonstrated uses of Powderworld (world modelinng and RL) could be improved.\n\n-----\n\nUPDATE: I thank the authors for their detailed feedback and engagement with the reviewers. The revised paper seems much improved. After reading the other reviews and the author response, I'm more inclined to accept this paper. It doesn't meet my bar for a strong accept though.\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3114/Reviewer_EMHS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3114/Reviewer_EMHS"
        ]
    },
    {
        "id": "msLnbb2LG2E",
        "original": null,
        "number": 4,
        "cdate": 1667019928048,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667019928048,
        "tmdate": 1668861687650,
        "tddate": null,
        "forum": "AWZgXGmsbA",
        "replyto": "AWZgXGmsbA",
        "invitation": "ICLR.cc/2023/Conference/Paper3114/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors present a new environment for supporting RL research, especially for more physics-oriented tasks.  In the environment, each \"pixel\" may be occupied by a certain type of material, and the material properties and environmental forces define how the update should be updated to the next state, and can be accomplished through very localized and efficient computation.  Special care was given such that the environments are simple to specify (and have a matrix representation), a diverse number of environments is easily configurable, and with the provide set of materials and rules, model generalizability to novel situations is easy to test.  The authors apply RL and world model baselines to an example set of environment worlds.\n\n\n\n\n",
            "strength_and_weaknesses": "It seems difficult to find an argument against this work and this environment.  In favor of this work, the environment seems very well thoughtout, and it occupies a niche that seems to be important and unfulfilled at the moment -- an environment that is easy for users to specify novel worlds and tasks, and in which the world interactions that occur at each step are complex and take place throughout the environment (thus maybe facilitating more explorations towards more real-world scenarios, while still maintaining many of the setup and computation we enjoy with toy environments).  Frankly, if I worked in an area where this environment would be more applicable, I would be strongly inclined to use it, and therefore I'm strongly inclined to accept it.  It looks great to me!  \n\nThe downsides of this work is that the experimental sections offer little in terms of useful experimental results.  The experiments exist only to sanity-check that the environment is suitable for the types of generalization experiments that are of the most interest to the authors, and to further reproduce tried-and-true beliefs about the relation between train environments, models, and generalization.  As such, assessing the merit of the paper as a publication is really (mostly) about considering the value of the software as a resource.\n",
            "clarity,_quality,_novelty_and_reproducibility": "In terms of clarity and quality, it's a good paper.  I did find a few typos (apologies I did not write them down).  The environment is sufficiently novel and useful.",
            "summary_of_the_review": "The authors provide an environment which is:\n- fast\n- easily configurable\n- has a small set of fixed rules and properties controlling a rich space of observable interactions\n- mostly unique wrt other environments I'm familiar with\n\nThrough the paper discussion and experiments, they make a compelling case for using this environment if the task domain is relevant to ones research.  They outline a number of possible task scenarios that seem useful, but moreover, the dataset seems flexible enough to cover many unmentioned task scenarios.  I find it hard to find fault in the environment, and suggest not accepting the paper only if it is considered not publication-worthy in terms of its research content (though precedent on similar environment papers would make a good case for accepting it).\n\nUpdate: I'm updating the correctness score 1 -> 3.  It was incorrectly entered and so I hope it didn't cause too much confusion juxtaposed next to my otherwise positive review.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3114/Reviewer_pDhR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3114/Reviewer_pDhR"
        ]
    }
]