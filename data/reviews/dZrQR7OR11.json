[
    {
        "id": "loXWG6CoaM",
        "original": null,
        "number": 1,
        "cdate": 1666267957638,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666267957638,
        "tmdate": 1666267957638,
        "tddate": null,
        "forum": "dZrQR7OR11",
        "replyto": "dZrQR7OR11",
        "invitation": "ICLR.cc/2023/Conference/Paper4382/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a curious algorithm to adapt federated learning in the variational inference framework. In particular, it uses a scalable version of EP to do so. The contribution seems solid although, given its practical application, I miss a real case scenario, for example in hospitals, of the algorithm.  ",
            "strength_and_weaknesses": "Strength: Solid methodology adapting EP, clarity.\nWeaknesses: Low empirical evidence. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is very well written, explaining EP in detail, and it is very didactic.\nQuality: EP is a solid algorithm whose usefulness is proven on previous literature.\nNovelty: Maybe another weak point, as here it is a little engineering enhancement of EP.\nReproducibility: Authors state that the paper will be shared upon acceptance. ",
            "summary_of_the_review": "First thanks for the paper, I have enjoyed its reading. I would like to emphasize here the clarity of this paper and its organization. It is very easy to read although the topic is complex. My main issue that justifies not giving it a better recommendation is that this approach seems to be a practical real-case scenario but the experiments and somehow limited. For instance, your example of hospitals is great, but then you do not apply it to a real case scenario (maybe stackoverflow is the more complicated one). It would be a great paper if a more complex experiment could be done.\n\nConcerning technical details I find some decisions a little bit arbitrary. Why have you used EP and not some version of VI? (Justify this ;-)) Why do not you use EP in the client inference? You can also use it and it would be a full EP approach? Have you considered using PowerEP instead of EP? How can I determine or tune which is the optimal algorithm for the EP client inference? (It would be just great to use Bayesian optimization here to develop an auto-variational-inference approach here). And lastly you need to justify the dumping and whether the non-convergence of EP is a problem. It would also be great to talk about the complexity of your method and some drawbacks about this approach with respect to other variational inference approaches. This are basically all the questions that I have asked myself when reading this.   \n\nSome minor issues or enhancements to the paper are including a paragraph with the organization of the paper in the introduction, introduce a further work paragraph in the conclusions section as I believe that this opens new research lines, put the related work section (IMHO) before, better describe the results obtained by the toy experiment, include in section 1 a reference to other divergence functions instead of KL and in section 2 to variational families and justify why have you used an improper uniform prior (advantages and drawbacks of the decision).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4382/Reviewer_Z7LG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4382/Reviewer_Z7LG"
        ]
    },
    {
        "id": "zpkUxKGEw3",
        "original": null,
        "number": 2,
        "cdate": 1666377716629,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666377716629,
        "tmdate": 1669227148651,
        "tddate": null,
        "forum": "dZrQR7OR11",
        "replyto": "dZrQR7OR11",
        "invitation": "ICLR.cc/2023/Conference/Paper4382/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper presents an empirical study of different Expectation Propagation algorithmic choices applied to several federated learning settings. Important aspects to an empirical studies are missing.",
            "strength_and_weaknesses": "The strengths of this paper lie in the experimental settings and exposition. \nCifar100 with ResNet18 does serve as an example for model-scale (as far as bayesian methods are concerned), although SEP with (I) or maybe also (V) could be applied to even larger models. It would be interesting to see these methods compared against adaptive FedAVG on e.g. a wide resnet 50.\nStackoverflow experiments serve as a good example for a large number of clients with a simple LR model. \nThe exposition is good, explaining EP and its variants in sufficient details. \n\nThe weakness of this paper lie in the level of contribution to ICLR. None of the proposed algorithms is significantly novel as far as I can tell. This paper might be better suited as a workshop contribution. \n\nAnother weakness lies in that for an empirical study especially, I'd have expected more than a single seed for the proposed experiments. While most results seem significantly far apart based on my experience with these methods and data-sets, I would like to see standard-error across several seeds to judge significance. Learning curves show the strengths of EP in principle compared to FedAvg but don't allow to compare different methods and prior work (FedPA).\n\nFor an empirical effort, I would expect to see the search-space for the chosen Hyperparameters in Table 6 and a discussion on how (and if) the optimal hyperparameters chosen here generalize across the different algorithms. E.g. does FedEP(L) require the same hyper-parameters as FedSEP(V). Were these parameters tuned on the non-bayesian baseline? I can imagine that the stochasticity inherent to the bayesian optimization procedures warrants different hyper-parameters. \n\n\n\nSmall things:\nTypo section 3.1: \"Fig. 1 illustrates a simple case where posterior averaging [performs] sub-optimally.\"\nFigure 4: What is the difference between the two FedEP runs in middle and right sub figure?\nTables 1-4, please improve readability, especially by separating captions between Table 2 & 4. I might suggest reducing the font-size across the tables. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is high, quality is high with the exception of the lack of multiple seeds and hyper-parameter explanation. Novelty is not very high. Reproducibility seems good given Table 6. I feel confident I could replicate these experiments. \n\nI see the lack of multiple seeds as a reason for rejection for this paper. Should the authors include those results across >=3 seeds, and should they provide at discussion of the hyperparameters, I will raise my score. I will further raise my score if the authors show an ablation study across the different hyperparameters of Table 6 in order to understand their influence on the different algorithms. ",
            "summary_of_the_review": "Interesting analysis showing the applicability of EP in FL settings. The R18 and SOF setting is convincing wrt. the aspect of scale. The empirical evaluation is lacking at the moment wrt. seeds and hyperparameter selection. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4382/Reviewer_jmPj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4382/Reviewer_jmPj"
        ]
    },
    {
        "id": "YKRcuOdvgNj",
        "original": null,
        "number": 3,
        "cdate": 1666601983351,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666601983351,
        "tmdate": 1669456004018,
        "tddate": null,
        "forum": "dZrQR7OR11",
        "replyto": "dZrQR7OR11",
        "invitation": "ICLR.cc/2023/Conference/Paper4382/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper presents FedEP, a federated learning approach based on expectation propagation in which a global inference task is constructed as local inference tasks. The authors also present several ways to scale the model for modern neural networks. The authors compared their method to baselines on CIFAR-100, StackOverflow, and EMNIST-62.",
            "strength_and_weaknesses": "Strength:\n* A Bayesian approach that in some sense generalizes previous approaches.\n* An important aspect of the work is the emphasis on scaling the model, which I deem as very important for Bayesian models.\n\nWeaknesses/Questions:\n* Novelty. While I appreciate the contribution in terms of scalability I am not sure that it is enough. I do not see how the approach is different than previous methods that also used EP for FL (and specifically, [1], [2]). Can the authors comment on that?\nFurthermore, the methods to scale the model are also common solutions. So overall it seems like the paper combines existing elements from previous studies. I will state though, that in my opinion, the bigger issue is with the experimental section which I will present next.\n* Experiments. I think that there are several issues with this part.\n  * First, information is missing. How did you split the data among clients? How were the hyper-parameters optimized? Was there a validation set? \n  * Second, in the paper you stated that you chose the best accuracy based on a running average of 100 rounds. What does that mean exactly? Why not take the metric results based on the last round or the best round based on a validation set? As far as I know, FL papers do not use this approach.\n  * Third, the baselines in this paper are not enough. I think the method should be compared to additional Bayesian methods (for example, [3]), and to leading methods in FL (and not only FedAvg and FedPA).\n  * In Fig. 2 and Fig. 3, where are the lines of FedEP until 400 and 800 steps respectively? currently, it looks a little bit odd. Also, how can you explain the jump at those points? Did you use a scheduler with a lr drop at those points?\n  * Finally, one of the motivations for being Bayesian is the ability to quantify uncertainty accurately. How is FedEP compared to other methods in that aspect?\n* Minor.\n  * Tables 1-4 could be organized better. Also, their numbering should be according to the reference in the text.\n  * The colors of the lines in the figures are too similar in my opinion.\n\n[1] Bui, T. D., Nguyen, C. V., Swaroop, S., & Turner, R. E. (2018). Partitioned variational inference: A unified framework encompassing federated and continual learning. arXiv preprint arXiv:1811.11206.\n\n[2]  Ashman, M., Bui, T. D., Nguyen, C. V., Markou, E., Weller, A., Swaroop, S., & Turner, R. E. (2022). Partitioned Variational Inference: A framework for probabilistic federated learning. arXiv preprint arXiv:2202.12275.\n\n[3] Achituve, I., Shamsian, A., Navon, A., Chechik, G., & Fetaya, E. (2021). Personalized Federated Learning with Gaussian Processes. Advances in Neural Information Processing Systems, 34, 8392-8406.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear.  It is not original. The results in the paper are not reproducible. Explanations are missing and code wasn't provided.",
            "summary_of_the_review": "I think that a Bayesian approach to FL is a good direction; however, in terms of novelty, and more importantly, the experiments, this paper can greatly be improved. I am willing to reevaluate my review based on the authors' response.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4382/Reviewer_Hh8V"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4382/Reviewer_Hh8V"
        ]
    },
    {
        "id": "K0zL6DxwXT",
        "original": null,
        "number": 4,
        "cdate": 1666850538429,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666850538429,
        "tmdate": 1666850823738,
        "tddate": null,
        "forum": "dZrQR7OR11",
        "replyto": "dZrQR7OR11",
        "invitation": "ICLR.cc/2023/Conference/Paper4382/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to use EP together with approximate inference methods for federated learning. The approach shows promising results on toy examples and real data.  The method works with any approximate inference methods, and different choices are evaluated and compared. ",
            "strength_and_weaknesses": "Strengths:\n- I found the toy experiment in Section 3.1 to be very illuminating, along with Table 4. FedEP greatly improves over FedAvg and FedPA.\n- The experiments on real data are also convincing, and the comparison of the difference approximate inference schemes was interesting to see. \n- The overall algorithm is agnostic to the approximate inference method, so advances in approximate inference may further improve FedEP.\n\nWeaknesses:\n- Some parts of the paper were not clear / easy to read (see next section).\n- The algorithm seems not too novel, since EP and the used approximate inference schemes are well-known in literature. \n- It was a bit disappointing to see that a very \"simple\" approximate inference method (scaled identity) works best. This somehow suggests that the good performance may not be due to the EP formalism, but some other effects.  The paper would be much stronger (and I would increase my rating in that case), if it could be shown that more accurate approximate inference would lead to more accurate results. For example the accuracy of the approximate inference methods could be scaled up on small problems by doing a gradually more expensive MCMC estimation of the posterior, or my increasing the number of samples in the NGVI algorithm. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity / Reproducibility:\n- From the paper alone, it seems not easy to reproduce the results. In particular, the NGVI update is only shown for the precision/covariance matrix but not for the mean. NGVI algorithms typically require a lot of tricks to make work well in practical deep learning. Just by reading the paper, it is not clear to confirm whether the unimpressive performance of NGVI is due to a poor implementation or due to NGVI itself.  Perhaps the pseudo-code for NGVI can be provided in appendix, similar to MCMC Algorithm 2.\n- For readers without a background in EP, the equation (3) may be hard to understand. Perhaps a few sentences could be added explaining the intuition between the update, i.e. explain why the minimizer in Eq. (3) will be a good approximation of p_k. \n- Using a uniform distribution as a prior seems problematic -- especially if the parameter space is unconstrained. There is no uniform distribution on the real numbers. What is an \"improper\" uniform distribution? \n\nMinor comments, typos, etc.:\n- Algorithm 3: Serve Inference -> Server Inference\n- In the NGVI update, it should be beta_NGVI instead of beta.\n",
            "summary_of_the_review": "The proposed FedEP algorithm is shown to perform well in practice on toy examples and real data.  The comparison of the different approximate inference methods is interesting, and highlights how the method can use any approximate inference scheme.  I believe this work will be interesting to the bayesian deep learning community as well as people working in federated learning. I am therefore leaning towards acceptance of this work, despite the outlined weaknesses.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4382/Reviewer_za1u"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4382/Reviewer_za1u"
        ]
    }
]