[
    {
        "id": "W7Mt751IcR",
        "original": null,
        "number": 1,
        "cdate": 1666042875171,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666042875171,
        "tmdate": 1668549774331,
        "tddate": null,
        "forum": "gwTP_sA-aj-",
        "replyto": "gwTP_sA-aj-",
        "invitation": "ICLR.cc/2023/Conference/Paper1978/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors use interval-bound propagation to work with few-shot learning problems. Interval arithmetic was used to model the manifold of data devoted to task interpolation. Finally, the authors apply interval architecture to model-agnostic meta-learning and prototype-based metric-learning paradigms.",
            "strength_and_weaknesses": "1. Related work section is poor. It does not describe a few-shot learning method. The chapter on manifold learning is poor. There exist many flows, NKK methods, and VAE-based method, which was even mentioned. \n2. Equation (4) is misleading. It is not trivial to understand what exactly mean I_i^s(\\epsilon.)  \n3. The idea of keeping small interval bounds was described in the paper: https://www.esann.org/sites/default/files/proceedings/2020/ES2020-57.pdf and should be mentioned in the paper.  \n4. It is unclear why we add losses deducted to the center of the interval and its two borders $L_{LB}$, $ L_{UB}$. We can use the only distance between borders.\n5. According to Tab 1. the authors claim, \"We see that MAML+IBP outperforms vanilla MAML in terms of 5-way 1-shot classification accuracy on the miniImageNet and tieredImageNet (Ren et al., 2018) datasets.\"\nIt is too strong since MAML has a significant variance on miniImageNet, and MAML+IBP is very close. It looks like a slight difference. Maybe the authors should use some statistical comparison of the models.\n6. It is possible to see worst-case accuracy instead of interpolation. Does it steal work well? \n7. If we do not use worst-case accuracy, we do not want any guarantees. Why we work with relatively complex intervals, we can simply work with a probability distribution (for example, Gaussian ones). Is it possible to use Gaussians instead of intervals?\n8. Why are experiments presented on miniImageNet-S instead of miniImageNet? ",
            "clarity,_quality,_novelty_and_reproducibility": "1. The paper is well-written and easy to follow.\n2. The idea of using interval arithmetic is interesting, but in my opinion, the motivation is unconvincing. \n3. Evaluation of the model is well written, but I prefer miniImageNet instead of miniImageNet-S.",
            "summary_of_the_review": "The paper is very interesting, but I see some problems in the motivation of using Interval arithmetic without worst-case classification loss. In such scenario, we can use simpler objects than intervals. \n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1978/Reviewer_yeNC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1978/Reviewer_yeNC"
        ]
    },
    {
        "id": "q3SHNJ-uoiV",
        "original": null,
        "number": 2,
        "cdate": 1666501992829,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666501992829,
        "tmdate": 1666672302769,
        "tddate": null,
        "forum": "gwTP_sA-aj-",
        "replyto": "gwTP_sA-aj-",
        "invitation": "ICLR.cc/2023/Conference/Paper1978/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Authors propose a solution for few-task few-shot learning. Their solution is based on two steps:\nFirst they take the task and use interval bounds to estimate two other losses (if the task was in the neighborhood manifold) one upper bound and one lower bound. Then during optimization, they look at the loss of the task and make sure it should be minimized plus the feature representation of the model for the task should be close to the feature representation of the interval lower and upper bound feature representation. They furthermore take the softmax of the three losses and minimize it which is an interesting idea. \n\nSecond, they create artificial tasks from the latent space of the model. Since the upper and lower bounds are in proximity of original task, we can interpolate the features of original task with any of these bounds to create artificial tasks.",
            "strength_and_weaknesses": "Strength:\nWell-structured\nNice idea of looking into intervals during training\n\nWeakness\nThe experiments do not compare with baselines to show the strength of the method. For example, what if instead of using lower and upper bounds for intervals, I just add some noise to the feature representation? That would be an interesting baseline to test against. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is great and the paper is well structured.  The experimantal validation could be more related to why decisions in paper made\nNovelty is interesting, but not a very new idea of using lower and upper bounds. Interpoloating in latent spaces and limiting the updates by regularization has been explored in previous work too. \nReproducibility: I prefer having the running code on an anonymous git rather than the python files in the form of a paper, and I suggest the authors to try this, but I think there is good amount of info that makes reproducibility possible, so I give it 8 / 10",
            "summary_of_the_review": "Based on the above comments, I vote for borderline reject. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1978/Reviewer_Ww7U"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1978/Reviewer_Ww7U"
        ]
    },
    {
        "id": "Gvy-X0ZYki",
        "original": null,
        "number": 3,
        "cdate": 1666591392019,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666591392019,
        "tmdate": 1666591392019,
        "tddate": null,
        "forum": "gwTP_sA-aj-",
        "replyto": "gwTP_sA-aj-",
        "invitation": "ICLR.cc/2023/Conference/Paper1978/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper, the authors propose to extend the idea of interval bounds from the provably robust training literature to few-shot classification and introduce task-level interval bounds based regularization for the training of few-shot classification models (MAML + protonets). \nTo further improve the model robustness under the challenge of insufficient training tasks, the authors introduce interval bounds interpolation to synthesize more plausible augmented tasks to improve the task diversity for training. ",
            "strength_and_weaknesses": "**Strength**\n\nThe challenge of training a few-shot learning model with few tasks is indeed a very interesting direction as the small number of tasks leads to a poor approximation of the task distribution. And interpolating in the task space is clearly a promising way of addressing this challenge. \n\nThe idea and the implementation are clearly presented. \n\n** Weaknesses**\n\n1. Task manifold\n\nMy primary concern regarding this paper is the definition of 'task manifold'. While manifold is a well-studied concept, task manifold seems new to me, and the connection between tasks manifold and data manifold remains very much unclear to me after reading this paper. \nSpecifically,  according to the definition of $\\epsilon$-neighborhood of a task, I do not see a clear difference between the interval bounds of a task and the interval bounds of a collection of samples. And based on the little difference, the 'task manifold' in this paper seems almost identical to data manifold to me. And this is also confirmed by the realization of the method, which is basically achieved by injecting **sample-wise** noise. \nIn this case, what is the contribution of this paper to the study of task-level few-shot learning? \n\nWhile I appreciate the theoretical analysis provided by the authors, I believe the analysis is still very much based on samples instead of tasks. \n\n\n2. Cost\n\nThe discussion of the limitation of the proposed method on cost is appreciated. However, I believe it is still necessary to provide in the experiment section comprehensive comparisons of the training cost between the proposed method and the other methods. \n\nBased on the cost issue, it might be necessary to discuss other alternatives. For example, can adopting spectrum normalization achieve similar results by simply promoting Lipschitz continuity?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The overall presentation is clear. However, this is a gap between the concept of task manifold and data manifold. \n\nIn order to clarify the novelty, the authors are expected to discuss the contribution of this method on a task level, which should be something more than simply applying an established sample-wise operation to every sample in a task, and calling it a task-level operation. \n\n",
            "summary_of_the_review": "More discussions are expected to clarify the contribution of this paper on a task level. Please refer to the Strength And Weaknesses question for details. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1978/Reviewer_NpKQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1978/Reviewer_NpKQ"
        ]
    },
    {
        "id": "NfYubyJzRP",
        "original": null,
        "number": 4,
        "cdate": 1666691223628,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666691223628,
        "tmdate": 1666691223628,
        "tddate": null,
        "forum": "gwTP_sA-aj-",
        "replyto": "gwTP_sA-aj-",
        "invitation": "ICLR.cc/2023/Conference/Paper1978/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The notion of interval bounds is used to enhance few-shot learning, especially in the situation where only few tasks are in the training set.  Interval bound propagation (IBP) through network layers and the use of the modified training loss ensure that the model outputs stay close to the interval bounds in the embedding space of initial layers. This improves the chances for the artificially formed tasks to remain on the task manifold. A theorem is established that guarantees that artificially created (via IBP interpolation) support sets are essentially as good as those from the actual distribution. Experiments on both MAML and prototypical few-shot learning show improved performance over baselines.",
            "strength_and_weaknesses": "Strengths: The authors propose an interesting and effective solution to few-shot, few-task learning. A theoretical analysis is provided. Ample experimental results are given validating the proposed method. Figures 1 and 2 are very helpful in understanding the proposed ideas.\n\nWeaknesses: \n\nIt is a bit difficult to fully understand the descriptions of interval bound propagation without any background on related topics. It would be better to have more detailed insights, explanations, discussions on this and add them to the Related Works or Preliminary section.\n\nThe theoretical analysis seems to say nothing about the algorithm in terms the efficacy of minimizing L_{LB} + L_{UB}; the analysis focuses only on CE loss by making the remaining terms arbitrarily small (also lacking any insights into the effectiveness of the proposed task interpolation). The generalization error with bounded loss function is somewhat obvious from stat theory point of view.\n\nNot necessarily weaknesses but some questions:\n\n1. In Table 4, why does +IBI perform worse than +IBP in some cases even with the augmented tasks?\n\n2. If the authors are concerned about whether the new task would be on the task manifold or not, then why don\u2019t they consider just interpolating between the task and the neighboring one, where the neighboring task lies within the epsilon ball centered from $f_{\\theta^{S}}(x_{i,r}^s)$?\n\n3. Applying IBP boosts the performance even without task interpolation, which I found intriguing. Could the authors provide more insights into how preserving the neighborhoods can assist the model to generalize well on unseen tasks?\n",
            "clarity,_quality,_novelty_and_reproducibility": "A reasonably good paper with clear motivations and well-presented methodology (except for the background on IBP). The work uses the already known IB and IBP concepts/methods, but how the concept is employed in few-shot learning provides significant insights. \n\nIt seems hard to reproduce the algorithm. Do the authors have the plan to share the code?",
            "summary_of_the_review": "A reasonably good paper overall. Although the IB and IBP method/concept is not new, the application to few-shot few-task learning is interesting and insightful. A theoretical analysis that reflects the effect of bound losses would have been better, as they are in the core of the proposed method. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1978/Reviewer_9giy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1978/Reviewer_9giy"
        ]
    }
]