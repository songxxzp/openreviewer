[
    {
        "id": "max__0t-prt",
        "original": null,
        "number": 1,
        "cdate": 1666245749758,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666245749758,
        "tmdate": 1666245766559,
        "tddate": null,
        "forum": "qLOaeRvteqbx",
        "replyto": "qLOaeRvteqbx",
        "invitation": "ICLR.cc/2023/Conference/Paper715/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the fine-grained causes of unfairness in DPSGD and identifies gradient misalignment due to inequitable gradient clipping as the most significant source. They show that excess risk, the notion of fairness, can be decomposed into both non-private terms, clipping bias, noising bias according to previous work. Based on that work, they further analyze the gradient misalignment as a cause for unfairness. They show a lower bound for excessive risk gaps which is tight.",
            "strength_and_weaknesses": "Pro: The paper provides a new angle in understanding the disparate impact of DP-SGD - gradient misalignment. The mitigation solution, gradient scaling, is different from previous works like global clipping and [1]. The lower bound is much tighter in fig.5 than [1] - the two curves almost overlap, which is intriguing.\n\nCons: Despite the differences with previous work [1], the decomposition of excess risk into clipping bias and noising bias is not new. And that DP-SGD hurts fairness was already understood as the combination of per-example gradient clipping and gradient noise injection. \n\n[1] Differentially Private Empirical Risk Minimization under the Fairness Lens",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and the experimental results are strong. The problem and the basic building blocks are not new but they show by experiments that DPSGD-Global-Adapt improves DP-SGD Global and FairLens. Code is included for reproducibility. ",
            "summary_of_the_review": "The paper provides an interesting view, gradient misalignment, for analyzing the unfairness of DP-SGD. The technique is not new and can not resolve the privacy-fairness tradeoff but empirically DP-SGD-Global-Adapt can work. The fairness problem in DP can be important and related to societal impact since many trustworthy aspects are connected and some applications might require both.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO.",
                "Yes, Discrimination / bias / fairness concerns",
                "Yes, Privacy, security and safety"
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper715/Reviewer_Sern"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper715/Reviewer_Sern"
        ]
    },
    {
        "id": "jwEyGU6SB4",
        "original": null,
        "number": 2,
        "cdate": 1666569042026,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666569042026,
        "tmdate": 1666569042026,
        "tddate": null,
        "forum": "qLOaeRvteqbx",
        "replyto": "qLOaeRvteqbx",
        "invitation": "ICLR.cc/2023/Conference/Paper715/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper examines the cause of disparate impact on unbalanced datasets (tabular and MNIST) and finds gradient misalignment to be the cause. Furthermore, they introduce techniques to mitigate these disparities. ",
            "strength_and_weaknesses": "Strengths: \n1. Nice, clean decomposition of magnitude vs direction error. It would be great to see this for other datasets as well. \n2. Thorough comparison to previous techniques. \n\nWeaknesses: \n1. Authors compare only 1 epsilon per dataset.  It is unclear whether results also hold in other epsilon regimes. \n2. Would like to see more discussion on why DPSGD and DPSGD-F diverge so much in Figure 3. Has proper hyperparameter tuning been done? It looks like DPSGD would further improve with more epochs?\n3. It is unclear whether this analysis extends to more complex image datasets like CIFAR10 and CIFAR 100. It would be nice to see a discussion on why or why not. \n4. How does noise compound issues of gradient misalignment? In Table 1, the authors compare the effects without noise. It is not immediately clear to me that similar results could hold for a fixed amount of noise. \n5. The authors mention that DPSGD-Global has the potential to exacerbate disparate impact by discarding gradients, but I don't see this happening empirically in Figure 3 or Table 2. Please explain further. \n",
            "clarity,_quality,_novelty_and_reproducibility": "This work does not suffer from clear clarity or reproducibility issues. \n\nA few things are notable novel about this work: \n1. Showing that clipping does not necessarily increase excessive risk (if gradients are aligned) is a nice and useful result. \n2. Adapts existing private algorithm (DPSGD Global) for the purpose of reducing disparities\n",
            "summary_of_the_review": "There are several areas on which this paper can elaborate on. But overall, it is a useful contribution.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper715/Reviewer_pvjf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper715/Reviewer_pvjf"
        ]
    },
    {
        "id": "qpMs2l7m4u",
        "original": null,
        "number": 3,
        "cdate": 1666690897307,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666690897307,
        "tmdate": 1668749997487,
        "tddate": null,
        "forum": "qLOaeRvteqbx",
        "replyto": "qLOaeRvteqbx",
        "invitation": "ICLR.cc/2023/Conference/Paper715/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper identifies the gradient misalignment as the main reason why applying privacy-enhancing methods may lead to more unfairness. The authors use an existing method, DPSGD-Global, and a variant of it, DPSGD-Global-Adapt, to prevent misalignment and reduce this unfairness.",
            "strength_and_weaknesses": "Major strengths:\n1. Proposition 3 is closely related to the focus of this paper on the disparate impact caused by gradient misalignment.\n2. The authors have very detailed experiment results which supports their statements.\n\nMinor strengths:\n1. This paper is easy to follow and the algorithms are intuitive and can be implemented easily.\n\nMajor weaknesses:\n1. The experiment results seem to be confusing. In Figure 3, the DPSGD is not working in terms of the train loss while the DPSGD-Global is even as good as the non-private result. Such results are not shown in Bu et al, 2021. In Figure 4, the DPSGD-Global and Adapt solves the direction excess risk, but the magnitude of this direction excess risk seems to be much smaller than the excess risk from the magnitude error. Additionaly, the excess risk from the noise error is analyzed in the supplementary material where I think the magnitude of them is much larger than the excess risk from the gradient misalignment and the magnitude error. \nFor example, for the Dutch dataset, I do not understand how the excess risk is break down into the three parts in the way that the authors claim the direction one contributes the most while has the smallest magnitude.\n2. Proposition 3 does not show why $|R_a^{dir} - R_b^{dir}|$ is larger than $|R_a^{mag} - R_b^{mag}|$. It uses the inverse of the largest eigenvalue of the Hessian among different groups as an upper bound for the learning rate. It seems to be hard to satisfy such constraint. In Figure 5, this lower bound (I guess it is derived from the proof of Prop 3) is shown to be very good. Therefore, there is a lack of an explanation about the learning rate being used and the upper bound from the assumption of Prop 3.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written. The statements in the paper are clear and concise. The novelty in the Propositions are not as significant as in the experiments. The code provided by the author is well-organized but I have not tried to reproduce the results.",
            "summary_of_the_review": "This paper shows detailed experimental results to support their statement that the unfairness is mainly caused by gradient misalignment. The interpretation of the results may have some problems which weaken the validity of the analysis.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper715/Reviewer_ktiq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper715/Reviewer_ktiq"
        ]
    },
    {
        "id": "TYJw-r5s9a",
        "original": null,
        "number": 4,
        "cdate": 1666696250377,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666696250377,
        "tmdate": 1666696250377,
        "tddate": null,
        "forum": "qLOaeRvteqbx",
        "replyto": "qLOaeRvteqbx",
        "invitation": "ICLR.cc/2023/Conference/Paper715/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper conducts a fine-grained analysis of DP-SGD to show that gradient misalignment is  a principal cause of the disparate impact that occurs when DP-SGD is applied to a dataset. This analysis compares two key components of the DP-SGD: clipping and noise addition. Ultimately, this paper shows that clipping further impacts and exacerbates gradient misalignment, which greatly increases the disparate impact of DP-SGD. This insight is nicely illustrated in a simple experiment that keeps the noise level in DP-SGD fixed, but changes the level of gradient alignment to show that when the gradient is more misaligned, it leads to more disparate results. The fix proposed by this paper is to  scale down all per-sample gradients in a batch by the same amount. The improved results are demonstrated experimentally on the MNIST and adult datasets.",
            "strength_and_weaknesses": "### Strengths\n\n- This paper refines the cause of disparate impact in SGD, which is an important problem. \n\n- The experiment and analysis presented in Section 4 clearly show the main take home of this paper.\n\n- The proposed modification to DP-SGD is quite simple and straightforward. The proposed optimizer can be easily plugged-in to other settings.\n\n### Weaknesses\n- One of the benefits of the proposed DP-SGD-Adapt global is that it does not need group identifiers. However, it is unclear whether the methods that use group identifiers lead to models with better utility. While the comparison is not 1:1 here, it would still be good to know how these results compare to when one actually takes into account group identifiers.\n\n- The datasets considered the paper are small and somewhat toyish even though these are the datasets that were used in previous papers. It is unclear how this proposal scales to larger models and bigger setups. However, I think future work can likely address these issues.\n\n- The theorems and analysis presented applies or explicitly assume convexity or in some cases that the loss is twice differentiable. It is nice that the analysis generalizes to model classes that do not satisfy these assumptions but this issue could be better highlighted.\n\n- This work highlights gradient misalignment as a key cause of disparate impact, but it is hard to judge how much that is more important than say group difficulty as measured by the trace of the hessian of the loss per group. It could be that more difficult to learn groups have hessian-trace values that are substantially different than other groups. \n\n-  (Minor) The term 'excessive risk' is used quite a bit in a number of places in the paper. I believe it should be 'excess risk'. ",
            "clarity,_quality,_novelty_and_reproducibility": "The writing in this paper is quite clear and easy to follow. I have a minor suggestion above, but overall, each section is written and presented clearly. This work builds on insights from previous analyses of DP-SGD; however, it brings new information to light. Overall, the results show that gradient alignment is a key cause of disparate impact. ",
            "summary_of_the_review": "This paper provides new insights on an important problem. The paper also demonstrates empirically improvements based on a modified DP-SGD algorithm that reduces disparate impact.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper715/Reviewer_tDQn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper715/Reviewer_tDQn"
        ]
    }
]