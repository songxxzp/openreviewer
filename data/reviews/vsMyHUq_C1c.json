[
    {
        "id": "71ew1Vil_0",
        "original": null,
        "number": 1,
        "cdate": 1666309534824,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666309534824,
        "tmdate": 1670429409904,
        "tddate": null,
        "forum": "vsMyHUq_C1c",
        "replyto": "vsMyHUq_C1c",
        "invitation": "ICLR.cc/2023/Conference/Paper5555/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper developed Neural-IVP, an ODE based IVP solver, to solve initial value PDEs. Neural-IVP is based on the local in time methods, but the authors show that local in times methods have issue of representational power and numerical stability. Neural-IVP is developed by addressing these two issues.",
            "strength_and_weaknesses": "Strengths\n- The scalability and numerical stability issues of local in time methods are analyzed.\n- New techniques are proposed to address those issues.\n\nWeaknesses\n- A few techniques are used together to improve the local in time methods. Each of these techniques is not totally new. It is also unclear how important of each technique.\n- There is only one example in this paper. Many more examples are needed.\n- Even for this example, there are not sufficient convincing results. There are no quantitative errors.\n- In the paper, it claims about \u201chigh dimensional\u201d PDEs. However, the example in Section 5 is a 3D problem, not high dimensional at all. Examples of at least 10 dim are required.\n- If time dependent 3D problems are \u201chigh dimensional\u201d, then many existing papers have solved time dependent 3D problems by deep learning methods, such as physics-informed neural networks (PINNs). A lot of relevant literature review is missing. \n- There are no comparisons with other methods (either deep learning or conventional methods) in terms of accuracy and speed.\n- In Introduction, \u201cRather than compute costs which scale exponentially in the dimension, they instead typically have error \u2026\u201d. There are no definitions of N and epsilon. This sentence is not a rigorous mathematical statement. Also, references are required.\n- In Introduction, \u201cmore that 3 dimensions\u201d. A typo here.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear.",
            "summary_of_the_review": "The paper proposed extensions of local in time method, but the experiments are not convincing.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5555/Reviewer_ZCbx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5555/Reviewer_ZCbx"
        ]
    },
    {
        "id": "Nr-MDViuJfZ",
        "original": null,
        "number": 2,
        "cdate": 1666546480831,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666546480831,
        "tmdate": 1669282013056,
        "tddate": null,
        "forum": "vsMyHUq_C1c",
        "replyto": "vsMyHUq_C1c",
        "invitation": "ICLR.cc/2023/Conference/Paper5555/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper describes a method which helps improve scalability of the local-in-time ODE solvers.\n",
            "strength_and_weaknesses": "Strengths:\n- The reviewer really enjoyed the problem statement in sections 1-3; it gives a good grasp on what the problem is and why the current (ML and non-ML based) solvers struggle to achieve good quality solutions for high dimensional problems, as well as complex initial conditions and for higher-order PDEs\n- The problem is really interesting and in many aspects understudied\n\nWeaknesses:\n- Some of the details of the descriptions are failing to give the consistent picture of what the method looks like; see comments 3, 4\n- Experimental assessment: the current experimental assessment lacks detail on why it is better than the existing solvers; see comment 5\n",
            "clarity,_quality,_novelty_and_reproducibility": "Reproducibility: see question 3 below; there are questions about reproducibility as currently the reviewer thinks the improvements are needed.\n\nNovelty and clarity: The paper seems novel, to the best of the reviewer's understanding, and the first three sections are really well written. On the description of the method and the experimental sections, the answers need to be given. The clarity of the method description needs to be improved (see comments below).\n\nQuestions on quality and clarity:\n\n1. (Minor) Dimensionality: page 1, \u201cRather than compute costs which scale exponentially in the dimension, they instead typically have error\u201d N must be defined \n\n2. (Minor) Typos should be proofread e.g. \u201cPage 2: These methods has proven successful \u201c\n Also, should local in time solvers be spelled \u2018local-in-time solvers\u2019 as it is a compound adjective (see https://proofed.co.uk/writing-tips/a-guide-to-compound-adjectives-and-hyphenation/ for a better explanation of my point)? This question is totally subjective, and the reviewer intends it as an open question, which is in no way is reflected in my score. \n3. While sections 1-3 give an excellent background,  it looks like section 4 does not give the method in one place in all its entirety; the reviewer also thinks that the method does not look reproducible from the description. Section 4.1 discusses a toy problem of a sum of two Gaussian like wave packets on which different  solvers are evaluated; is the proposed model a modified Du & Zaki (2021) architecture, or is it based on Bruna et al\u2019s architecture? What is the compete list of modifications of this architecture?  It could be presented, for example, as some sort of algorithm. What are the hypoerparameters of the model?\n4. In section 3, the description states that the computational complexity of the model is O(p^3 + p^2 n) and memory O(p^2 + pn); what is n and what is the exact architecture for which this assessment is made? \n5. For the more complicated scenario, described in section 5, there need to be a comparison of models (with Bruna et al (2022) and Du& Zaki(2021)) and ablation studies: which of the proposed improvements actually make the impact on the solution: sinusoidal embedding, head fine-tuning etc? How does it work for different parameterisations of the equation? Up to what dimensionality is the solver still able to persist with stable learning, and at what dimensionality the proposed numerical scheme collapses? Is it possible to give more examples, e.g. some second-order PDEs or problems with the complex conditions, where the standard solvers fail (see Section 3 )\n",
            "summary_of_the_review": "The reviewer thinks that while the introduction and the summary of the challenges of scalability of the local-in-time solvers are really clear and well written, the details of the proposed method and  be experimental assessment could be improved (see comments above).\n\n==\nUpdating the scores to recommend acceptance as the authors, in my view, sufficiently addressed the comments",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5555/Reviewer_X8sx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5555/Reviewer_X8sx"
        ]
    },
    {
        "id": "Nkv-tSWmyT",
        "original": null,
        "number": 3,
        "cdate": 1666571720030,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666571720030,
        "tmdate": 1669244722912,
        "tddate": null,
        "forum": "vsMyHUq_C1c",
        "replyto": "vsMyHUq_C1c",
        "invitation": "ICLR.cc/2023/Conference/Paper5555/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method, called Neural-IVP, for solving partial differential equations (PDEs) using neural networks. They use various helpful techniques to stabilize the PDE solutions, increase the scalability, and improve the representation power of the neural networks. Neural-IVP is a local in time method, meaning that the time dependency is induced by having time-variant parameters in the neural networks. They improve the representation power by using sinusoidal embedding and solving the last layer of the neural networks linearly. In order to increase the scalability and the number of parameters in the neural networks, they propose to use Jacobian-vector-products implemented using automatic differentiation, which makes the complexity of time and memory grow linearly by the number of parameters. ",
            "strength_and_weaknesses": "Strength:\n\n- Showing the deficiency of the PDE solvers.\n- Suggesting new techniques to overcome the shortcoming of the PDE solvers.\n- Increasing the scalability and conditioning of the PDE solvers.\n- Proving (via theorems) why singular solutions happen (leading to ill conditioning) due to continuous parameter symmetry.\n\nWeakness:\n\n- Limited applications and examples.\n- Lack of evaluation in high-dimensional PDE problems.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is sufficiently clear and novel.",
            "summary_of_the_review": "I believe that using neural networks to solve PDEs is an interesting and important problem to pursue. This paper has done a good job in showing the drawbacks of the previous methods for solving PDEs and has tried to address those by using various techniques. However, one main shortcoming of the paper is the lack of high-dimensional problems/examples. One of the selling points of this paper is the improved scalability. So, one expects to see its scalability to high-dimensional settings as well. In the section 5 of the paper, the title say \"high-dimensional hyperbolic PDEs\" but the paper only shows a (3+1) dimensional spacetime example. I am very curious to see if this method can work in hundreds-dimensional problems where neural ODE methods can work without problem? Or, if there is a limit in achievable dimensions, the authors should be clear about it. Also, reporting the training time versus dimension could also be helpful to see. \n\nMinor comments:\n\nThere are some typos throughout the paper. These are some of them:\n\n- be emploted to computer --> be employed to compute\n- due the challenges --> due to the challenges",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5555/Reviewer_qtnF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5555/Reviewer_qtnF"
        ]
    }
]