[
    {
        "id": "0f-qSJXgH6",
        "original": null,
        "number": 1,
        "cdate": 1666248394574,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666248394574,
        "tmdate": 1666248394574,
        "tddate": null,
        "forum": "YPKBIILy-Kt",
        "replyto": "YPKBIILy-Kt",
        "invitation": "ICLR.cc/2023/Conference/Paper6247/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "The paper targets problems with graph learning tasks containing missing node features. \nTheir key idea is to assign different pseudo-confidence to each imputed channel features. \nThe proposed imputation scheme includes two processes.\nThe first one is the feature imputation using channel-wise inter-node diffusion, and the second is the feature refinement via node-wise inter-channel propagation.",
            "strength_and_weaknesses": "Strength :\n\nThe problem is clearly described and the methods are well presented.\nThe scheme can even handle at an exceedingly high missing rate (e.g., 99.5%) and achieves state-of-the-art accuracy for both semi-supervised node classification and link prediction on various datasets containing a high rate of missing features.\n\nWeaknesses:\nI did not find notable weaknesses of this paper.",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is clearly written. \nThe quality of the methods looks sound, and the novelty is fair.",
            "summary_of_the_review": "The work motivates by an interesting and practical problem when the graph learning is conducted in presence of missing node features.\nOverall, the methods look sound and reasonable.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6247/Reviewer_tfst"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6247/Reviewer_tfst"
        ]
    },
    {
        "id": "25AhpEgXhJ",
        "original": null,
        "number": 2,
        "cdate": 1666680390422,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666680390422,
        "tmdate": 1670013136255,
        "tddate": null,
        "forum": "YPKBIILy-Kt",
        "replyto": "YPKBIILy-Kt",
        "invitation": "ICLR.cc/2023/Conference/Paper6247/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes an imputation method for missing node features in graph neural networks. There is a node-wise diffusion as well as channel-wise diffusion that is based on the \"pseudo confidence\" of a missing feature node, which is inversely proportional to the distance to the closest observed feature node. Semi-supervied learning and link prediction experiments are conducted with good results in the very low sampling regime (0.5%).",
            "strength_and_weaknesses": "Strength: The idea is simple and easy to understand. Performance on the 0.5% sampling setting is impressive. Notations are explicitly defined and derivations are explained well. There are enough implementation details to reproduce the experiments. Extensive hyperparameter search was done (reported in appendix).\n\nWeakness: The advantage compared to feature propagation (FP) is not yet convincing. \nSince some of the concepts are straightforward, some sections (e.g. section 3.4) could be simplified to make room for more experiments that go beyond the benchmark datasets. For example, an experiment with simulated data to understand the model's behavior better could have made the paper's argument stronger.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written, and provides enough detail to reproduce the experiments.",
            "summary_of_the_review": "I think the idea presented in this paper is interesting, and it is explained well. There are also extensive experiments with promising results. But it's not clear why this ~1% gain in accuracy makes this better than the very simple FP.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6247/Reviewer_NNts"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6247/Reviewer_NNts"
        ]
    },
    {
        "id": "oXekSimUF-",
        "original": null,
        "number": 3,
        "cdate": 1666741516276,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666741516276,
        "tmdate": 1669219774316,
        "tddate": null,
        "forum": "YPKBIILy-Kt",
        "replyto": "YPKBIILy-Kt",
        "invitation": "ICLR.cc/2023/Conference/Paper6247/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors tackle the problem of imputation in graphs, in which we want to predict missing node features in graph-structured data. Their approach uses a strategy involving pseudo-confidence (PC), where the PC of a given feature is proportional to alpha^S, where S is the corresponding node's nearest labeled neighbor. They combine this with a propagation strategy which shares information between features of the same node and between neighboring nodes. \n\nThe authors evaluate their method on a benchmark data set OGN. They follow (Rossi et al, 2021) in their evaluation. Their primary evaluation is on a data set from arXiv, in which nodes represent papers, edges denote citations between papers and node features are a representation of the words used in the paper's title and abstract. They hold out a subset of features of each node and impute these held-out features. They show that on these tasks their method outperforms existing methods including GCNMF and Feature Propagation. ",
            "strength_and_weaknesses": "Overall, the paper is understandable, the method is reasonable and the experimental results are good. As described below, I am not sure about the methodological novelty. The application impact seems high, although this is also hard to tell because the benchmarks used are on relatively contrived tasks. \n\nMy main concern is that I could not tell what parts of the proposed method are novel. This is partly because I am not too familiar with graph imputation. The proposed method contains many components and all components are described as though they are novel. In particular, the authors indicate that their main contribution as \"pseudoconfidence\" as alpha^S, where S is the distance in the graph.  They should explain that this is a common strategy used in random walk methods, Monte Carlo reinforcement learning, and many other methods. Similarly, they should explain and cite the inspiration for each other part of their method. It seems likely that there are novel components and novel ways in which preexisting components are combined, but I could not work out what these are. \n\nWhat real-world problems have 99% missing features?",
            "clarity,_quality,_novelty_and_reproducibility": "See above.",
            "summary_of_the_review": "See above.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6247/Reviewer_z9Q8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6247/Reviewer_z9Q8"
        ]
    }
]