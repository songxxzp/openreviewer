[
    {
        "id": "QxQQgGL8b3p",
        "original": null,
        "number": 1,
        "cdate": 1666607627121,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666607627121,
        "tmdate": 1666607627121,
        "tddate": null,
        "forum": "oqSKdRyYO1g",
        "replyto": "oqSKdRyYO1g",
        "invitation": "ICLR.cc/2023/Conference/Paper2907/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper evaluates the performance differences among accents in asr systems such as amazon, google and microsoft\u2019s asr systems. The systems have biased word error rates when evaluated by a large and global dataset of speech from the speech accent archive. \nThis is more like an investigation report, instead of a reach paper with novel methodology or technical solutions.\n",
            "strength_and_weaknesses": "Strong:\n\n1 Biases were found in existing commercial systems such as amazon, google and microsoft\u2019s asr systems for voices from different regions and different accents;\n\nWeak:\n\n1 Could not find technical novel parts and this paper is an investigation report without detailed technical solutions.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The motivations and investigation details are clear.\nThis paper is a high-quality investigation report of the bias of existing asr systems.\nCould not find much novelty parts in terms of technical part.\n\nDetailed comments and questions:\n\n1 Existing systems are bias \u2013 not by design \u2013 but by the amount of available data for training asr models.\n",
            "summary_of_the_review": "Could not find novel ideas or technical solutions. This is an investigation report.\nCan not give a high recommendation score currently.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2907/Reviewer_fz1F"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2907/Reviewer_fz1F"
        ]
    },
    {
        "id": "syVCsnqmwIp",
        "original": null,
        "number": 2,
        "cdate": 1666671569047,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666671569047,
        "tmdate": 1666671569047,
        "tddate": null,
        "forum": "oqSKdRyYO1g",
        "replyto": "oqSKdRyYO1g",
        "invitation": "ICLR.cc/2023/Conference/Paper2907/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors present a paper on biases in mainstream commercial speech recognition services from Amazon, Google and Microsoft that:\n1. shows how there are statistically significant performance differences in a word information lost (WIL) metric when the speech that is being transcribed comes from a native vs non-native speaker/age of onset of English speaking.\n2. speakers that learn English in a naturalistic environment have lower WIL than in an academic\n3. WIL is lower for speakers whose first language is a Germanic one \n4. there is a statistical significant correlation between WIL and the speaker's birth country's political alignment to the United States.\n\nThe findings that speech recognition systems do worse for non-native, academic environment and non-Germanic L1 vs Germanic L1 are all not particularly surprising and I don't believe are novel findings. Reporting WIL to demonstrate this is likely novel. The main contribution of this paper is showing a political aspect to the disparity.",
            "strength_and_weaknesses": "Strengths\n- Performs a controlled study of how various commercial recognizers perform with a fixed text that is read by speakers that have provided demographic information. \n\nWeaknesses:\n- Without samples of ASR results from the collection, cannot tell if there were systemic experimental design biases in the results due to poor text/scoring normalization choices. e.g. are numbers normalized, would a 6 vs \"six\" be penalized?\n- WER doesn't necessarily correlate with overall performance; errors on filler or hesitation words are inconsequential, errors on names very problematic. WIL likely has the same problems. Would have been useful to publish WER alongside WIL for those less familiar with WIL. \n- Does WIL actually reflect user satisfaction? for example, how do aspects of L2 English acquisition compare on completing Alexa requests or transcribing videos?\n- The lack of differences between Google and All-Google settings seems strange: it would be interesting to see a table matrix showing how each of the sub accent systems compare to the EnUs for matched cases, ie. EnIn tested on EnUs vs EnIn on EnIn, EnUk vs EnUs, etc.  why would Google offer multiple accent versions if there is no substantial difference?\n- The work uses read speech to analyze performance, however most systems expect spontaneous speech. \nhttps://www.researchgate.net/publication/221999276_Differences_between_acoustic_characteristics_of_spontaneous_and_read_speech_and_their_effects_on_speech_recognition_performance\n- the sum of these experimental issues may invalidate the findings, magnify intrinsic biases in the ASR systems, or be inconsequential\n- the work fails to explore other possible sources of the disparity / it is too quick to assign political power:\n   * is it simply a data issue? do worse performing population simply have less data available to train on? author's could try to train systems with different proportions of accented data \n    * is it technical? is modeling of accents more difficult as they deviate further linguistically from English? does the level of linguistic difference matter, e.g. grammatic verb-order vs pron differences?\n    * is it historical? do the least well performing demographics come from populations \n    * it would be useful to explore and eliminate other possible sources before solely describing power relationship between birth country and united states as the reason for disparities\n   * is this something that holds for other power relationships? would native Russian speakers of Chinese do better on Baidu's ASR systems? how about on American Chinese ASR systems?\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. Novelty of WIL and its correlation with various aspects of L2 English acquisition e.g. age, Germanic root, etc. are not particularly novel or interesting. \n\nThe hypothesis that the disparity of various commercial recognizers is related to political power isn't well researched, ie given other possible explanations that are neither suggested or explored as noted above. There are also many statements that aren't fully backed and tend to be of an opinionated nature, e.g.\n- \"assumption that ASR works for everyone\", citation?\n- \"dangerous situation\" \"particular English language accents ... unable to obtain basic services.\" - this seems rather exaggerated. in what situations would this disparity result in lack of basic service or a dangerous situation?\n- \"attempted standardization of the English language via the increasing ubiquity of ASR systems is another chapter in a long story of how movements create a standard language... have been tools to maintain power.\" - a clear link between a disparity in accented vs native ASR performance as a tool to maintain power hasn't been established, how can it be described in this manner?\n\nThe work is likely reproducible. The source data from Speech Accent Archive is available on request, but at the moment none of the resulting ASR transcripts or processing scripts are available. Having an anonymized github source would be useful in reviewing the results especially given the conclusions being drawn.",
            "summary_of_the_review": "The paper provides unsurprising results showing disparities in recognition performance given various aspects of native vs non-native speakers of English. A political hypothesis to these disparities is novel, however isn't sufficiently explored to be considered well-supported.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2907/Reviewer_D6XQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2907/Reviewer_D6XQ"
        ]
    },
    {
        "id": "oyKDeaYWFwx",
        "original": null,
        "number": 3,
        "cdate": 1666800810568,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666800810568,
        "tmdate": 1666800810568,
        "tddate": null,
        "forum": "oqSKdRyYO1g",
        "replyto": "oqSKdRyYO1g",
        "invitation": "ICLR.cc/2023/Conference/Paper2907/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this work, the authors dissect the problem of discriminatory Automatic Speech Recognition (ASR) performance on accented speech along the following three dimensions:\n1. By evaluating predominant ASR services on a large and global dataset of English speech in varying accents.\n2. By identifying speaker covariates in a linear regression model that significantly impact ASR performance.\n3. By examining the quantitative results within the larger context of the role of language in exacerbating inequality and making ASR services more exclusive.",
            "strength_and_weaknesses": "The main strength of this work is that it takes a thorough critical look at ASR accent bias. The authors evaluate three popular ASR services by Microsoft, Google and Amazon on accented English speech from The Speech Accent Archive representing 212 first languages across 171 birth countries. They find that ASR performance is significantly better for speakers whose first language was English. While such observations have been previously documented, this work also examines a number of speaker covariates like age of onset of English speaking, environment where English was learned (naturalistic vs. academic), etc. These covariates were found to have a significant effect on ASR performance across all three services.\n\nI consider the following to be the main weaknesses of this work:\n1. The covariate referring to whether the speaker's birth country is a part of NATO was found to be associated with lower WILs. Based on this observation, the authors hypothesized that how far a speaker's birth country is from United States' geopolitical power is correlated with how ASR services perform on their speech. This hypothesis appears to be a bit tenuous. It's unclear if there are other hidden variables that might also be playing a role here. For example, the number of years the speaker lived in the US, how often the speaker interacts with native speakers of English, etc.\n2. As the authors note, a majority of the speakers in the data set were residents of the United States at the time of recording. It would have made for a compelling story if the authors had created and released a more representative dataset of accented speech without the bias of US residency.\n3. The related work section completely ignores the fairly large body of work that focuses on improving ASR for accented speech. For example, please refer to \"Accented Speech Recognition: A Survey\" by Hinsvark et al., 2021 for a recent survey. Citations to some other recent works on fairness in ASR are also missing. For example, \"Model-based approach for measuring the fairness in ASR\", Liu et al., 2021 and \"Toward Fairness in Speech Recognition: Discovery and mitigation of performance disparities\", Dheram et al., 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written. The empirical analysis has been conducted on a publicly available dataset and the authors promise to release their scripts to ensure reproducibility.",
            "summary_of_the_review": "While the main thesis of this work is well-motivated and the paper is written well, in its current form, I think the paper is marginally below the acceptance threshold mainly due to the concerns I have stated above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2907/Reviewer_mfgs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2907/Reviewer_mfgs"
        ]
    }
]