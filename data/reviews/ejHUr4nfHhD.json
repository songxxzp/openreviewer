[
    {
        "id": "yU9odsdmVN",
        "original": null,
        "number": 1,
        "cdate": 1666656044549,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666656044549,
        "tmdate": 1669470821221,
        "tddate": null,
        "forum": "ejHUr4nfHhD",
        "replyto": "ejHUr4nfHhD",
        "invitation": "ICLR.cc/2023/Conference/Paper1728/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper explores self-supervised contrastive learning for long-tail data. It presents an empirical study of the impact of the temperature parameter on the head and tail categories. Based on the study, the paper proposes a simple yet effective solution to improve the imbalance pretraining which involves a dynamic temperature schedule. Compared to the vanilla contrastive learning and the SDCLR baseline, the proposed method demonstrates better performance on three long-tail benchmarks: CIFAR10-LT, CIFAR100-LT, ImageNet100-LT.",
            "strength_and_weaknesses": "Strength\n\n**[S1]** Topic: the paper investigates self-supervised learning for long-tail data. This is one of the first steps toward applying self-supervised approaches to uncurated data, which is of great interest to the community;\n\n**[S2]** Insight: the paper provides an empirical analysis of the impact of the temperature parameter on the head and tail categories;\n\n**[S3]** Technology: the proposed dynamic temperature scheduling is technically sound;\n\n**[S4]** Performance: compared to the vanilla contrastive learning and the SDCLR baseline, the proposed method demonstrates better performance on three long-tail benchmarks: CIFAR10-LT, CIFAR100-LT, ImageNet100-LT.\n\n**[S5]** Presentation: the writing is clear.\n\n---\n\nWeaknesses\n\n**[W1]** Interpretation:\n\ni) I find it difficult to interpret the results of TS. The study in Sec.3.3 and Fig. 3 seems to indicate that TS achieves a trade-off between optimizing the performances of the head or tail classes: as shown in Fig.3, TS slightly reduces the performance of the head classes but significantly improves the performance of the tail classes. On the other hand, results in table 7/8/9 show that TS consistently improves the performance of both the head and tail classes. The improvements on the head and tail classes are also comparable: +2.1%/+2.4%  kNN@1 for the head/tail classes of ImageNet100-LT (table 9). It looks like TS is more than a simple trade-off?\n\nii) it is also unclear to me why decreasing the temperature during the training is the optimal scheduling solution (table 4 and 5). It looks like TS learns the head classes better at the early stage of the training then progressively prioritizes the tail classes. I wonder if TS may hurt the performance of the head classes at the later stage of the training. I would also be curious why alternative schedules perform worse than TS.\n\nOverall, I\u2019m happy to learn about the good performance of TS but the interpretation of TS deserves more investigation than what is presented in the current paper.\n\n**[W2]** Evaluation. The results of SDCLR in table 3 look different from what were reported in the [SDCLR](https://arxiv.org/abs/2106.02990) paper. I wonder if these results are reproduced? If this is the case, I wonder if there is any difference in the experimental setting compared to the SDCLR paper. For example, the SDCLR paper reported results with 500 epochs pretraining while TS is trained with 800 epochs (Sec. 4.1), I wonder if different methods shown in table 3 share the same experimental configurations\n\n**[W3]** The analysis in Sec. 3.2 and 3.3 is limited to contrastive learning. It is not clear to me if TS could be beneficial to non-contrastive SSL methods that use a temperature parameter, e.g. SwAV, DINO, etc.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written clearly. The proposed method is not new but effective. The authors are suggested to include some clarifications on the experimental settings, as discussed in [W2].",
            "summary_of_the_review": "The paper provides an empirical analysis of the impact of the temperature parameters on self-supervised contrastive long-tail pretraining. A simple yet effective temperature scheduling solution is also proposed and demonstrates superior performance on three long-tail benchmarks. In general, I'm happy to learn about the good performance of this simple solution but would prefer some clarifications on the evaluation ([W2]). The paper could be stronger if it includes further investigations to interpret the results of TS ([W1]) and analysis of non-contrastive self-supervised methods ([W3]).\n\n***\nAfter rebuttal:\n\nMy concerns are addressed in the rebuttal. I thereby raise the score to 8.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1728/Reviewer_bPFj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1728/Reviewer_bPFj"
        ]
    },
    {
        "id": "o2frdgmrFkv",
        "original": null,
        "number": 2,
        "cdate": 1666697006779,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666697006779,
        "tmdate": 1669391974101,
        "tddate": null,
        "forum": "ejHUr4nfHhD",
        "replyto": "ejHUr4nfHhD",
        "invitation": "ICLR.cc/2023/Conference/Paper1728/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tackles the long-tailed learning problem by varying softmax temperature during the course of training. The authors argued that different magnitudes of the temperature value actually induce different learning preferences, which makes it possible to gradually switch the learning objective by carefully setting up a temperature scheduler. The proposed method has been evaluted on serveral long-tailed learning benchmarks, demonstrated its effectiveness.",
            "strength_and_weaknesses": "Strength:\n- The proposed method is interesting and is of a unique view.\n- The proposed method requires no computation overhead, which is a tempting merit.\n\nWeaknesses:\n- The evaluation is not comprehensive. Only contrastive learning based methods are compared against.\n- The improvement is quite limited compared with other long-tailed learning methods.",
            "clarity,_quality,_novelty_and_reproducibility": "The overall quality is good, which is easy to follow and clearly written. Also the proposed method is novel.",
            "summary_of_the_review": "An interesting method, yet with limited empirical improvments.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1728/Reviewer_RFLZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1728/Reviewer_RFLZ"
        ]
    },
    {
        "id": "E3-mXt8KQf",
        "original": null,
        "number": 3,
        "cdate": 1667180618704,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667180618704,
        "tmdate": 1668698633475,
        "tddate": null,
        "forum": "ejHUr4nfHhD",
        "replyto": "ejHUr4nfHhD",
        "invitation": "ICLR.cc/2023/Conference/Paper1728/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Contrastive learning objectives are a popular and effective method for self-supervised learning. Most variations of the contrastive objective have a static temperature hyperparameter $\\tau$. Previous work suggests that large values of $\\tau$ lead to improved group-wise discrimination while small values lead to improved instance-wise discrimination. The authors study the effect of varying this temperature parameter in 'long-tail' settings with imbalanced data. They posit that long-tail class performance benefits from instance-wise discrimination ability and run initial 'coarse supervision' experiments to test this claim. Since this method requires (weak) labels, the authors also propose a dynamic temperature schedule that can be used in unsupervised settings. In a series of ablation experiments, they find that a cosine schedule that gradually switches between the two phases leads to the best performance. ",
            "strength_and_weaknesses": "Strengths:\n- The topic is interesting and offers a promising direction for deepening our theoretical understanding of contrastive learning.\n- The work is clear and easy to follow with the main theoretical claim explicitly laid out and experiments set-up to test it directly.\n- The experiments are conducted with a variety of models and datasets. \n\n\nWeaknesses:\n- It is unclear to me whether the cosine schedule is actually the optimal one. While it clearly outperforms the rapidly changing schedules like the step function, how does it compare, for example, to a linear (oscillating) schedule?\n- The marginal performance gain from MoCo to MoCo+TS does not seem significantly higher in the imb 150 vs imb 50 case. It isn't entirely clear whether the results support the hypothesis posited initially by the authors, otherwise one might expect the marginal gain to be higher in the more imbalanced case. It would be useful to compare marginal performance gain on CIFAR10-LT and on CIFAR10 to confirm that the improvement from the temperature schedule is actually related to the data imbalance. \n- There have been a few recent papers studying temperature in contrastive learning. In particular, how does your dynamic temperature scaling compare to the method in 'Dynamic Temperature Scaling in Contrastive Self-supervised Learning for Sensor-based Human Activity Recognition' (Khaertdinov et al., 2022)?\n\n***Update after author response***\nThe authors have addressed these weaknesses to my satisfaction.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is clearly written. I especially appreciate that the main theoretical claim is explicitly laid out and tested. \n- I have some small concerns about novelty, as described above. \n- It seems like all relevant details are provided for reproducing the main results.",
            "summary_of_the_review": "I think the work is interesting and important, but have some concerns detailed in the Strengths and Weaknesses section. \nI would be likely to raise my score and recommend acceptance if these concerns were addressed. \n\n***Update after author response***\nThe authors have addressed these weaknesses to my satisfaction. I have raised my score accordingly.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1728/Reviewer_Fp8W"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1728/Reviewer_Fp8W"
        ]
    }
]