[
    {
        "id": "dOx_yRN4Jn0",
        "original": null,
        "number": 1,
        "cdate": 1666534635082,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666534635082,
        "tmdate": 1666534635082,
        "tddate": null,
        "forum": "QmH1_mn6SI",
        "replyto": "QmH1_mn6SI",
        "invitation": "ICLR.cc/2023/Conference/Paper4602/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method FP_AINet by using an adaptive induction network to obtain fusion prototype for addressing the issue of noisy samples in few-shot learning. Extensive experiments are conducted on multiple datasets, showing the effectiveness of the proposed method.",
            "strength_and_weaknesses": "* Strength\n\n1. The motivation of using fusion prototype is sound. \n\n2. The experimental results of the proposed method are good.\n\n\n* Weaknesses\n\n1. The writing of this paper could be improved. In addition, there are many confusions on the notations in this paper. For example, as for {Q=\\{(x_q,y_q)\\}_{q=N\\times K+1}^{N'\\times K}} in Section 3.1, N' is not defined. In Section 3.2, the {f_{\\theta_f}()} represents both the feature extractor and the feature, the variance is represented by both \\theta and \\sigma, and so on.\n\n2. The technical contribution of this paper is incremental for using the existing techniques from multiple works, such as Induction module (Geng et al., 2019) and DC (Yang et al., 2021). In fact, some works have tried the similar idea proposed in this paper, such as [1] and [2], which are recommended to be analyzed. \n\n3. Algorithm 1 seems to add transductive concatenation and self-attention to the Induction Module, but it does not explain the details clearly. For example, how x_ij and x_q are concatenated, and whether x_q is one vector or all vectors in Q. In addition, although this paper quoted the Induction Module, there is no explanation for this part, which will confuse the reader, such as the meaning of squash.\n\n4. This paper does not give the details of how to use the mixed prototype to calculate the classification results, although the paper uses a simple prototype network. In fact, this part is important for the completeness of the paper.\n\n5. What is the operation of replacing the classifier with the feature extractor in the pre-training stage mentioned in the paper? Why it is beneficial to the solution of downstream tasks.\n\n6. Some state-of-the-art methods are not compared in the experimental results. More importantly, because the proposed method is a transductive method, more transductive-based methods should be compared. Also, the inductive and transductive methods should be marked to distinguish.\n\n7. In addition, why only specific backbones are used for specific datasets? For example, why ResNet-12 is not used on miniImageNet and why WRN-28-10 is not used on tieredImageNet?\n\n\n[1] Prototype Rectification for Few-Shot Learning. ECCV 2020.\n\n[2] Prototype Completion with Primitive Knowledge for Few-Shot Learning. CVPR 2021.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "* Clarity: The writing could be improved to make this paper more clear.\n\n* Quality: The overall of this paper is good.\n\n* Novelty: The novelty is incremental and limited.\n\n* Reproducibility: It seems to be reproducible but some details are missing.\n",
            "summary_of_the_review": "In general, the contribution of this paper is limited because of the limited novelty and unclear details.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4602/Reviewer_x78M"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4602/Reviewer_x78M"
        ]
    },
    {
        "id": "WR7CXNEemED",
        "original": null,
        "number": 2,
        "cdate": 1666623277581,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666623277581,
        "tmdate": 1666623277581,
        "tddate": null,
        "forum": "QmH1_mn6SI",
        "replyto": "QmH1_mn6SI",
        "invitation": "ICLR.cc/2023/Conference/Paper4602/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "A new method based on Gaussian distribution with AINet is proposed to address the problem of noisy samples in few-shot learning. More Specifically, a novel AINet is developed to focus on query-related support samples to decrease the weight of less informative samples. In addition, Yeo-Johnson transformation is further utilized to make the feature distribution more Gaussian-like. Finally, a Gaussian-based fusion algorithm is employed to obtain more accurate prototypes.",
            "strength_and_weaknesses": "Strength:\n1. Strong empirical results.\n2. A modified Gaussian-based fusion algorithm is employed to aggregates prototypes from PN and AINet by exploring the unlabeled samples.\n\nWeakness:\n1. The novelty of the proposed methods is limited.  The proposed method makes incremental modifications  and combinations on existing methods (Geng et al. (2019) and Yang et al. (2021)).\n2. Some important details are missing. For instance, the authors should discuss more on p_m and c_i.  Why and in which way they could learn mutual affiliations with each other?",
            "clarity,_quality,_novelty_and_reproducibility": "Generally speaking, the paper is well-organized and easy to follow up. The paper should be easy to reproduce if the authors could release their implementations. ",
            "summary_of_the_review": " The paper improves existing few-shot methods by using a modified Gaussian-based fusion method. It shows strong empirical results on multiple datasets when compared with challenging baselines.  However, the proposed method makes incremental modifications  and combinations on existing methods and thus the novelty is limited.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4602/Reviewer_kAKG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4602/Reviewer_kAKG"
        ]
    },
    {
        "id": "_7aUwNPmFMY",
        "original": null,
        "number": 3,
        "cdate": 1666634282625,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666634282625,
        "tmdate": 1666634282625,
        "tddate": null,
        "forum": "QmH1_mn6SI",
        "replyto": "QmH1_mn6SI",
        "invitation": "ICLR.cc/2023/Conference/Paper4602/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes to use an adaptive induction network to rectify the prototype network for few-shot learning. The adaptive induction network is developed to address the noisy samples, while this network has degraded performance with the increase of support samples since it ignores the relative local features. Thus, the authors propose a Gaussian-based fusion to combine prototype and induction networks. The extensive experimental results demonstrate the proposed method achieves better performance than the prototype network.",
            "strength_and_weaknesses": "Strength\n\n1. Most of the paper is well-written and easy to understand.\n\n2. Fig.2 , Alg. 1 and Alg. 2 are clear and helpful in reproducing the proposed method.\n\n3. The ablation studies clearly demonstrate the effectiveness of the main components of the proposed method.\n\nWeaknesses\n\n1. The main idea is to propose a new method to rectify the classical prototype network, similar to the previous work 'Prototype Rectification for Few-Shot Learning' i.e. BD-CSPN (Liu et al. (2020)). However, the authors do not provide sufficient analysis of the differences. It is confusing for the readers to understand the advantages compared with BD-CSPN.\n\n2. The experimental results are not complete. For example, BD-CSPN provided the results on tieredImageNet. However, the authors do not make the comparison in the experimental section. This leads to a question: does the proposed method truly outperform the BD-CSPN based on the rectification prototype? \n\n3. In Fig. 2, the authors had better add the results of FP_AINet to enhance the benefits of the proposed method.\n\n4. In Alg. 1 the adaptive induction network output $c_i$, but there is no $c_i$ in Fig. 2.\n\n5. In Eq. 3, it is confusing to use $p_m$ in the numerator but use $p_c$ in the denominator. What is the reason? \n\n6. In Alg. 2, only the mean $\\mu_f$ is used for the fusion prototype. Have the authors considered adding the variance for further improvement? By the way, it is better to use $\\mu_g$ to replace $\\mu_f$, which is consistent with Eq. 2.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The whole paper is clear and easy to reproduce. However, the novelty is limited.",
            "summary_of_the_review": "The novelty is incremental since the main idea is similar to the previous work based prototype rectification. The experimental results are insufficient to demonstrate its effectiveness, especially for the comparison with BD-CSPN.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4602/Reviewer_WNef"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4602/Reviewer_WNef"
        ]
    },
    {
        "id": "CttqFsgkKHM",
        "original": null,
        "number": 4,
        "cdate": 1667487055196,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667487055196,
        "tmdate": 1667487055196,
        "tddate": null,
        "forum": "QmH1_mn6SI",
        "replyto": "QmH1_mn6SI",
        "invitation": "ICLR.cc/2023/Conference/Paper4602/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper propse a method to assign scores to support samples and use Gaussian-based fusion algorithm to aggregate prototypes, in order to imigate the effect of the noise samples. in few-shot learning.",
            "strength_and_weaknesses": "Strength:\n(1) The issue of noise labled data in the few-shot learning is very important and necessary to research further.\n(2) The method of FR_AINet which can generate a more representative prototype makes sense and achieve a higher performance.\n\nWeakness:\n(1) The similar idea has already been adopted in recent works, such as \n(2) The computation cost should be reported in the experimental results.",
            "clarity,_quality,_novelty_and_reproducibility": "The quality of the work is mediate, and the clarity of the paper is satisfied, and the originality of the work is incremental.",
            "summary_of_the_review": "Based on the limited originality of the work, I recommend to weakly reject the paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4602/Reviewer_8vWo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4602/Reviewer_8vWo"
        ]
    }
]