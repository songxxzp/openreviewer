[
    {
        "id": "D5HOxtuLgd",
        "original": null,
        "number": 1,
        "cdate": 1666649910403,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649910403,
        "tmdate": 1666649910403,
        "tddate": null,
        "forum": "k7p_YAO7yE",
        "replyto": "k7p_YAO7yE",
        "invitation": "ICLR.cc/2023/Conference/Paper214/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper describes a vectorization algorithm for map construction from surrounding views (RGB). \n\n\nIt acheives state-of-the art on the nuScenes dataset, surpasses multi-modality methods (RGB+LiDAR), for a final 58.7mAP (~ +8mAP over the previous method). A toned-down version of the algorithm (45.9mAP) reaches real time (~25FPS) on a high end GPU (RTX 3090).\n\nThe paper is essentially GKT (Chen et al., 2022b) + DETR (Carion et al., 2020) - style matching extended to point level + permutational encoding for vertex sequences. The speed gain is mostly due to GKT, the matching scheme is very similar to DETR, which leaves us with the main contribution: the permutational-equivalent encoding which adding all possible vertex sequences at training (~+6mAP gain).",
            "strength_and_weaknesses": "### Strengths:\n- state-of-the-art results on nuScenes (~58.7 mAP, +8mAP)\n- 8x more efficient processing compared to the previous contender (VectorMapNet)\n- introduces modeling map element as a point set with a group of equivalent permutations\n\n### Weaknesses:\n- the vertex-to-polygon problem has a number of modelling options available in the literature (e.g., [BoundaryFormer, 1*, 2*-- the permutation issue doe]); apart from HDMapNet / VertexMapNet, none of them have been discussed; BoundaryFormer is summarily dismissed due to different domain.\n- the speed claim can be largely attributed to GTK; given that GTK runs at 72.3 FPS on the 3090 (for the same dataset, probably no large setup differences), at least a proper timing table should be added (how much time is spent for encoder/decoder/matching)\n- the paper could use a logic check, there are a number of redundant claims / language errors (see below)\n\n\n[1*]Liang, J., Homayounfar, N., Ma, W. C., Xiong, Y., Hu, R., & Urtasun, R. (2020). Polytransform: Deep polygon transformer for instance segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 9131-9140).\n[2*]Li, W., Zhao, W., Zhong, H., He, C., & Lin, D. (2021, May). Joint semantic-geometric learning for polygonal building segmentation. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 35, No. 3, pp. 1958-1965).",
            "clarity,_quality,_novelty_and_reproducibility": "My main concerns are related to novelty and experiments. Clarity/paper issues are secondary.\n\n\n1. Novelty: the permutation-invariant encoding alone is not enough for a new paper without proper vectorization experiments, see below.\n\n2. Experiments: lacking information to determine the source of the performance gains; can you share some $\\hat{V}$? why not add semantic segmentation + vectorization for comparison? It would show the superiority of your approach and require a minimal amount of changes for the decoder (segmentation already available in the GTK code). The question is, the ~mAP gain is gained from modeling? Is the information already available in the semantic segmentation and this is just a vectorization hat trick, or the vectorization method itself is the one improving performance?\nApart/in addition to this, adding other vectorization-only methods would help (see above).\n\n3. Clarity/paper issues: again, a logic/consistency check is required. Some examples below:\n- related work before conclusion? It is generally placed after the introduction and related to what follows, should be moved\n- hollow claims - \"stabilizes the learning process\" - can you provide any graphs for that? Is it just an empirical observation?\n- curious results -- Table 1, penultimate row, why add the results @epoch 24 and why continue the result at epoch 24?\n- edge direction loss -- this one makes me think the modeling is not right; technically speaking we don't need it (since none of the polygons need ordering), it is an artifact of the proposed matching method; nevertheless, the frugal ablation study is related to weighting its loss weight ($\\beta$) and turning on or off the permutation set\n- text issues -- the E.g., \"It is of great application\nvalue in autonomous driving\" -- adds nothing to the paper, repeated less than half a page away on page 3 and once again in the abstract, \"equivalent permutations\"/\"permutation-equivalent\" occurs 22 times [11+11], \"8\u00d7 faster\" is repeated twice just in the abstract), small other issues - We adopt~s~ ResNet18, further research and application<s>\n- figure 4 - \"on board sensor data\" >> explicitly state RGB cameras. Most sensors are generally on board, including LIDAR/IMUs. :)\n\nMost of the information is available in order to reproduce the paper. The authors claim the code will be made public.",
            "summary_of_the_review": "Solid performance improvements for map vectorization on nuScenes (~+8%mAP), improved speed over predecessors, but under-investigated gains source (e.g., is it the vectorization method? is semantic segmentation still a better start, or we can drop it and just use vectorization, similar to BoundaryFormer, but keep the speed?) and frugal ablation study. This paper could have been very good; given the limited set of experiments, I cannot vouch for its future impact.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper214/Reviewer_1muv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper214/Reviewer_1muv"
        ]
    },
    {
        "id": "EN-EBbkmU8j",
        "original": null,
        "number": 2,
        "cdate": 1666676954348,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666676954348,
        "tmdate": 1666676954348,
        "tddate": null,
        "forum": "k7p_YAO7yE",
        "replyto": "k7p_YAO7yE",
        "invitation": "ICLR.cc/2023/Conference/Paper214/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a novel pipeline for HD map learning, which is an essential component of autonomous driving. Traditional methods use pre-annotated HD maps for localization and mapping, preventing autonomous driving scaling up. To address that, recent works aim to predict the HD maps on-the-fly with machine learning models. These works, however, require some hand-crafted post-processing steps. This paper proposes a fully end-to-end approach to HD map learning, based on recent DETR architecture. In addition to the architecture, this paper also studies how to effectively model map elements and introduces a permutation equivalent modeling of map elements. Under all settings, this paper shows significant improvements over baselines (HDMapNet & VectorMapNet). ",
            "strength_and_weaknesses": "Strength:\n\n1. This paper further streamlines recent learning-based map learning approaches and proposes a fully end-to-end solution to learning an online HD map from multi-camera images and point clouds. This pipeline is simple and effective.\n\n2. The proposed hierarchical modeling of map elements is technically sound. This follows a coarse-to-fine paradigm and model map elements in both instance level and point level. Such operation not only improves stability and performance of map learning as studied in this paper, but also has potentials to benefit other tasks that also use a Transformer-based architectures. \n\n3. This paper also introduced a permutation equivalent module to model map elements, which I think is novel. This permutation equivalent module removes the ambiguity introduced by primitives like polylines and polygons.\n\n4. This paper demonstrates strong empirical performance on several benchmarks, compared to existing methods. Also, this paper also shows that the proposed method can achieve real-time performance and be developed to cars. \n\nWeaknesses:\n\n1. My first concern is the reproducibility. The proposed method seems to be a complex Transformer model with several new modules. With current level of details, I am not sure if one can faithfully reproduce this work and achieve similar performance. \n\n2. It remains an open question to choose between polylines and polygons if we consider new map elements. Can this paper present some guidances of that? Can we unify the polyline representations and the polygon representations for all map elements? \n\n3. More ablation studies are needed. E.g., the choices of polylines and polygons as stated above. \n\n4. This paper (arguably) overclaims several contributions. It is *not* the first end-to-end approach as far as I know (e.g. VectorMapNet already introduced the Transformer-based end-to-end pipeline). ",
            "clarity,_quality,_novelty_and_reproducibility": "The quality of this paper is good -- it presents the key idea clearly, proposes several novel approaches to the issues of previous map learning frameworks, shows strong empirical performance. I do have some concerns about the reproducibility. So I encourage authors to add more details of the model and open-source code after the review process. ",
            "summary_of_the_review": "Overall, I like this paper and recommend weakly acceptance though with several concerns (I believe they can be addressed in the rebuttal). I think this paper proposes a simple and effective pipeline for this online map learning problem. It presents clear motivation and strong empirical performance. That said, I am looking forward to seeing authors' comments to my concerns. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper214/Reviewer_oVMw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper214/Reviewer_oVMw"
        ]
    },
    {
        "id": "hRMswm784y",
        "original": null,
        "number": 3,
        "cdate": 1666782728088,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666782728088,
        "tmdate": 1666782728088,
        "tddate": null,
        "forum": "k7p_YAO7yE",
        "replyto": "k7p_YAO7yE",
        "invitation": "ICLR.cc/2023/Conference/Paper214/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose HD map construction algorithm from multi-view cameras.  They model each map element as a point set with a group of equivalent permutations.  The hierarchical matching both for instance-level and point-level is introduced and trained based on point2point loss and edge direction loss.  The experimental study shows that MapTR achieves higher extimation accuracy than the existing methods on public nuScenes dataset.  MapTR with light backbone can infer HD map at 25fps which is required for autonous driving.",
            "strength_and_weaknesses": "Strengths\n+ The map elements are represented as a set of points with a group of equivalent permutations which is suitable for expressing various shapes with edge directions.\n+ The proposed hierarchical matching and loss functions look technically sound.\n+ The performance is evaluated on public dataset and the proposed method achieves higher accuracy than the existing methods.\n+ The transformation from 2D to BEV in map encoder could be substituted by other modules such as conventional IPM.\n\nWeaknesses\n- The experimental studies are carried out only on nuScenes and not on Argoverse2 dataset like the existing method.  Are there any reasons for this?\n- More discussion on robustness towards real application is helpful.  For example, Are multi-camera input mandatory?  Can a front camera output HDMap in front of the vehicle?  How about the sensitivity of MapTR to camera position, intrinsic parameters, extrinsic parameters?  These robustness is important.",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed idea is original. The authors concisely describe the details of the method and the improvement from the existing methods.",
            "summary_of_the_review": "The proposed method is novel and achieves definitely higher accuracy than the existing methods.  I think that this paper deserves acceptance to ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper214/Reviewer_69Fv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper214/Reviewer_69Fv"
        ]
    }
]