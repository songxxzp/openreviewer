[
    {
        "id": "7cG9V3AGUGB",
        "original": null,
        "number": 1,
        "cdate": 1666538594339,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666538594339,
        "tmdate": 1670026382014,
        "tddate": null,
        "forum": "OKfmDPNPwYF",
        "replyto": "OKfmDPNPwYF",
        "invitation": "ICLR.cc/2023/Conference/Paper1311/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This proposed a framework to evaluate fairness when ground-truth sensitive attributes are not accessible. It calibrates the noisy fairness metrics using auxiliary models only and it drops many assumptions. The auxiliary model is flexible, the auxiliary model can be used if the input features have some overlaps with targets. ",
            "strength_and_weaknesses": "Strength:\n\n+ It proves the proposed method has less error than the direct estimate model under a threshold.\n+ The proposed method is a plug-in method, it can be used as long as the auxiliary model\u2019s input features have overlap with the target features.\n\nWeakness:\n\n- This paper removes some assumptions but the common assumption on T is still very strong.\n- The proposed research is evaluated on experiments with binary classification and binary sensitive attributes.\n- This work estimates the unfairness metrics in the missing sensitive attribute setting. As a framework, it would be more convincing if the mitigation solution is also provided.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Some typos, e.g., M & K, makes it difficult to understand some key points.",
            "summary_of_the_review": "This work proposes a new method with fewer assumptions to estimate fairness metrics in the setting of missing sensitive attributes using auxiliary models. The theoretical analytics and the experimental results show the effectiveness. The proposed method is a plug-in method which means it is flexible.\n\nIt would be more complete and convincing if the estimated metrics are used for bias mitigation.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1311/Reviewer_pHkG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1311/Reviewer_pHkG"
        ]
    },
    {
        "id": "ZO3ARpb7wN",
        "original": null,
        "number": 2,
        "cdate": 1666664557869,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666664557869,
        "tmdate": 1666664557869,
        "tddate": null,
        "forum": "OKfmDPNPwYF",
        "replyto": "OKfmDPNPwYF",
        "invitation": "ICLR.cc/2023/Conference/Paper1311/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper aims to evaluate the fairness of the model without accessing sensitive group attributes. The main idea is to utilize auxiliary models of estimating group attributes by calibrating their outputs. The paper first theoretically explains why we need calibration on the auxiliary models. Then, the paper suggests a calibration-based training framework that uses the existing distribution estimation techniques. The proposed algorithm is evaluated in two datasets, COMPAS and CelebA, and achieves a more precise evaluation when the auxiliary model is accurate and the target model is highly biased.",
            "strength_and_weaknesses": "[Strength]\n\nS1: The paper tries to evaluate the fairness of the models without accessing sensitive attributes, which is an important and practical issue. \n\nS2: The theoretical analyses in the paper give several nice insights. For example, I enjoy reading Section 3, which well analyzes the factors that affect the estimation error in model fairness.\n\nS3: The proposed algorithm is effective in specific empirical scenarios, as shown in their theoretical results.\n\n[Weakness]\n\nOverall, although the paper has various interesting aspects in its theoretical discussion, the proposed framework and experimental results are relatively weak.\n\nW1: The paper uses HOC as their estimator without comparing other methods. Although the paper explains some reasons for choosing HOC (e.g., free of training), it is not clear that the proposed framework can show similar results when using other estimators. The experimental results seem to be somewhat determined by the performances of HOC, so it may be questionable whether the current experimental results are dependent on HOC or not. It would be great if the paper can clarify the robustness of the proposed framework w.r.t. the estimators. \n\nW2: As shown in Tables 1\u20133, the performances when using global T and local T_k are very different, but there is no detailed discussion on how to choose either global or local. This result makes the framework less attractive, as the estimation errors are largely dependent on a specific hyperparameter (i.e., choosing global or local).",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written, and the theoretical results are interesting. However, as explained above, the proposed framework and experimental results are relatively less novel. ",
            "summary_of_the_review": "The paper tries to solve the important issue, which evaluates model fairness in a real-world scenario where sensitive attributes are not available. As the paper gives several insights in their theoretical discussion, I vote for marginally accepting this paper if it can clarify the contribution of the proposed framework and enhance the experimental results (or discussion).\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1311/Reviewer_Za6Z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1311/Reviewer_Za6Z"
        ]
    },
    {
        "id": "caiG3J8O9R9",
        "original": null,
        "number": 3,
        "cdate": 1666807728171,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666807728171,
        "tmdate": 1666807728171,
        "tddate": null,
        "forum": "OKfmDPNPwYF",
        "replyto": "OKfmDPNPwYF",
        "invitation": "ICLR.cc/2023/Conference/Paper1311/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper focuses on learning the sensitive attributes using auxiliary models for estimating fairness metrics. Theoretical analysis is done to understand the relationship between the directly measured fairness metrics and their corresponding ground-truth metrics.",
            "strength_and_weaknesses": "An important problem is studied, motivation from real-world settings is lacking.\nClarity in writing can be improved.",
            "clarity,_quality,_novelty_and_reproducibility": "Suffers from clarity. \n\nSome novelty in reducing the dependence on assumptions for the auxiliary models.",
            "summary_of_the_review": "The paper suffers from clarity, and the writing could be improved for better understanding. \nThe problem studied is of importance but would be helpful to add motivation with some problems from real-world datasets or settings.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1311/Reviewer_vWhJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1311/Reviewer_vWhJ"
        ]
    },
    {
        "id": "NixxIT3oq5",
        "original": null,
        "number": 4,
        "cdate": 1666840765639,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666840765639,
        "tmdate": 1666840765639,
        "tddate": null,
        "forum": "OKfmDPNPwYF",
        "replyto": "OKfmDPNPwYF",
        "invitation": "ICLR.cc/2023/Conference/Paper1311/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In this paper the authors study how to compute different group fairness measures when relying on pre-trained models to predict group attributes.  The paper provides a general mathematical formulation that focuses on estimating the transition probabilities (essentially the normalized confusion matrix) between ground truth and predicted group information conditioned on main task class.  The paper then suggests multiple approaches for this estimation, including one from the noisy label literature, and empirically tests which methods work best.  They find that in some cases (some datasets and fairness goals) their method outperforms baselines.\n",
            "strength_and_weaknesses": "S1. Technically challenging and important problem.\n\nS2. The formulation provided is general and clarifies what information is needed for accurate estimation.\n\nS3. The experiments provide a useful breakdown of when different methods excel.\n\nW1. Clarity: While the formulation is general, it is hard to parse in many cases the intuition behind many terms.  Further, a core contribution of the paper seems to be about leveraging noisy label approaches most significantly the HOC algorithm, but the algorithm is not at all described in the paper.\n\nW2. One core claim of the paper is that they don't need the conditional independence assumption of past literature but the \"Global\" method (which often works best at least for COMPAS) seems to directly be enforcing the conditional independence assumption of past work.  As such, it is not clear what is the core contribution of the paper.\n\nW3. Strongly strongly suggest a discussion of the limitation and ethical fraught-ness of using classifiers for sensitive attributes (eg predicting race based on name or gender based on an image).  This research is still important but there are many caveats with predicting these attributes in practice.\n\n\nDetails while reading:\n\nNot obvious how Thm 1 would be extended to equality of odds/opportunity.\n\nFor clarity purposes overall I think the paper would be easier to read assuming binary labels and groups, with generalizations to many groups being included later.\n\nSec 4.1 - Wouldn't use T to estimate all $T_k$ be exactly the conditional independence assumption from past work as described in Sec 2 (Transition Matrix)?\n\nAlso how would $T_k$ be estimated based on $\\tilde{D}$? I thought $T_k$ needs both $A$ and $\\tilde{A}$ as it is the transition probabilities between the two.\n\nHOC seems critical to the method in this paper but is not described.  For completeness please include\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The clarity could be significantly improved. I'd suggest making the paper less dense by simplifying more often to the binary case, spend more time explaining the core intuition, clarify the insight beyond prior work, and include a description of critical dependencies like the HOC algorithm.\n\nQuality: Overall the work seems thorough and high quality.\n\nNovetly: Because one of the two core methods (Global) seems equivalent to past work (relying on the conditional indepence assumption) and the other is not well described (HOC) the novelty relative to past work seems likely there but not well articulated.\n\nReproducibility: I do not believe the code is open sourced but the work seems generally reproducible.\n",
            "summary_of_the_review": "Overall the paper is a thorough study of an important problem, but the key contributions that move the field forward are hard to extract.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "See above on including a discussion of the risks of predicting group information.\n",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1311/Reviewer_oWCf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1311/Reviewer_oWCf"
        ]
    }
]