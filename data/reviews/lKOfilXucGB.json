[
    {
        "id": "K0qD4CkLL4",
        "original": null,
        "number": 1,
        "cdate": 1666481513984,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666481513984,
        "tmdate": 1670523277627,
        "tddate": null,
        "forum": "lKOfilXucGB",
        "replyto": "lKOfilXucGB",
        "invitation": "ICLR.cc/2023/Conference/Paper3896/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Authors extend VALEN with an instance-dependent incorrect label process.",
            "strength_and_weaknesses": "Strengths:\n  * Clearly a good idea to improve an already strong baseline.\n\nWeaknesses:\n  * Clarity is lacking.\n    * In equation (1), is the generation of candidiate labels conditioned on the correct label?  or perhaps conditionally independent of the correct label given the instance?  the notation in equation (1) is not clear and the surrounding text is silent.  (later in equation (3), there's a latent variable that is jointly conditioned with the instance, but not the correct label; and strangely equation (3) apparently attempts to model the probability that the correct label is [not] in the candidate set, whereas in PLL this is assumed always in the candidate set.) \n    * I find the discussion around equation (10) completely unintelligible, but possibly related to my previous concern listed above.\n  * A theoretical correctness concern:\n    * In Lemma 1 and Theorem 1, boundedness of $\\mathcal{L}_{MAP}$ does not superficially appear to be a reasonable assumption, as it has a negative log in it, but this is presented without comment.\n  * Some experimental concerns:\n    * The transformation of classification datasets to PPL datasets uses the assumed generative model, which degrades from all the conclusions drawn from it.  Consequently, I'm not drawing any of the conclusions you are hoping for:\n      * Table 1 does not convince me the proposed approach is better.\n      * Table 3 does not convince me regularization is beneficial.\n      * Figure 1 does not convince me the technique is not overly sensitive to choice of hyperparameter, except for Figure 1b.\n      * **Note**: Table 2 *is* persuasive.\n      * **Constructive feedback**: \n        * Drop Table 1 entirely.\n        * Populate Figure 1 with 3 datasets from Table 2.\n        * Do the comparison in Table 3 on datasets from Table 2.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity issues discussed above.\n\nOriginality ... well, let's be honest, it's a obvious incremental next step given VALEN, but it's still cool.\n\nQuality issues discussed above.  ",
            "summary_of_the_review": "**Don't panic.**  This paper wants to be accepted you just have to address my concerns and my score will change.  \n\nFactors that are creating a low score right now are:\n1.  a confusing exposition in section 3.2 [have someone with strong writing skills read this section and help you edit it]\n2. an apparently disqualifying precondition in lemma 1 and theorem 1 [justify it or change it]\n3. use of your own generative model for evaluation [drop all use of these datasets and only use datasets from Table 2].\n\n\n(Updated score from 3->6)",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3896/Reviewer_bU6i"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3896/Reviewer_bU6i"
        ]
    },
    {
        "id": "TGXt4jK_a7",
        "original": null,
        "number": 2,
        "cdate": 1666512115993,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666512115993,
        "tmdate": 1666512115993,
        "tddate": null,
        "forum": "lKOfilXucGB",
        "replyto": "lKOfilXucGB",
        "invitation": "ICLR.cc/2023/Conference/Paper3896/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper investigates the problem of partial label learning (PLL) on the instance-dependent scenario, which is a more realistic and practical setting. A new generative model is proposed that decomposes the generative process into two parts related to the ground-truth labels and other candidate labels, respectively. The distribution of the correct label and the incorrect label in the candidate label set of each training example are modeled explicitly by decoupled probability distributions Categorical distribution and Bernoulli distribution. MAP estimation is employed on the PLL training dataset to deduce a risk minimizer. Experiments on benchmark and real-world datasets validate the effectiveness of the proposed method. ",
            "strength_and_weaknesses": "Strengths:\n1. This paper provides a new perspective on instance-dependent partial label learning. \n2. This paper provides a theoretical analysis for the estimation error bound of the proposed empirical risk. \n3. As far as I know, it is the first attempt to explicitly models the generation process of the correct labels and incorrect positive labels from different distributions. \n4. The theoretical justifications and empirical validations are solid.\n\nWeaknesses:\n1. The authors should give more discussion about the results on real-world PLL datasets. \n2. The authors should give more details the MAP optimization problem in Eq. (7)\n3. \u201cThen we perform Maximum A Posterior(MAP) estimation\u201d should be revised as \u201cThen we perform Maximum A Posterior (MAP) estimation\u201d.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow. The extensive empirical results on both synthetic and real-world datasets validate the effectiveness of the proposed method.  Since the approaches are not difficult, the reproducibility could be ensured.\n\n",
            "summary_of_the_review": "Overall, this is a well-written paper and proposes a novel approach for instance-dependent partial label learning.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3896/Reviewer_YnxC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3896/Reviewer_YnxC"
        ]
    },
    {
        "id": "hBZ2iVTnzVX",
        "original": null,
        "number": 3,
        "cdate": 1666579879793,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666579879793,
        "tmdate": 1666579879793,
        "tddate": null,
        "forum": "lKOfilXucGB",
        "replyto": "lKOfilXucGB",
        "invitation": "ICLR.cc/2023/Conference/Paper3896/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes an instance-dependent PLL approach by decomposing the generation process of candidate labels into two processes and explicitly modeling the processes using different probability distributions, which the risk estimator is built upon. The MAP technique is employed to create the final empirical risk estimator. Then, the generation error bound of it is proposed for it in the theoretical analysis. Finally, experiments on corrupted benchmark datasets and real-world datasets validate the effectiveness of the proposed approach.",
            "strength_and_weaknesses": "Strength:\n1.  It makes sense that the paper decomposes and models the generation process of candidate labels with two separate processes. The generation process is reasonable and interesting, and it has the potential to benefit future research.\n\n2.  This definition of the data generation process is mathematically clear. The reasoning that follows is standard and rigorous, including the derivation of the risk estimator and the statistical analysis of the generalization error bound, is standard and rigorous.  All of these contribute to the soundness of the paper.\n\n3.  The proposed approach IDGP indicates the superiority when it is compared to the existing PLL methods in benchmark and real-world datasets.\n\nWeakness:\n1. In the paper, the authors respectively utilize Categorical and Bernoulli distributions to capture these two processes. More explanations can be provided on it to further clarify why the instance-dependent partial labels could be modeled by these two distributions.\n\n2. The presentation is good, but it might be better to use visuals and figures to provide an additional explanation of the learning procedure. \n\n3. The approach in Proposed Method includes two branch models, the main branch $f$ and the auxiliary branch $g$. The manually corrupted benchmark datasets in Experiments also use two sub-models $f$ and $g$. Overall, the former corresponds to the latter. However, the former $g$ appears to output two variables, $alpha$ and $beta$, whereas the latter $g$ appears to output only one. The difference inside should be explained in detail. \n\n4. Some related works [1, 2] are suggested to be cited and discussed. \n[1] Lyu, Gengyu, Yanan Wu, and Songhe Feng. \"Deep Graph Matching for Partial Label Learning.\"\n[2] He, Shuo, et al. \"Partial Label Learning with Semantic Label Representations.\"\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is simple to read, and the results are well presented. In this paper, the idea of decomposing and modeling the generation process is novel in PLL. The optimization procedure and objective are provided, and replicating the approach appears to be simple.",
            "summary_of_the_review": "This paper is intriguing and makes good contributions to Instance-Dependent Partial Label Learning.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3896/Reviewer_XV9C"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3896/Reviewer_XV9C"
        ]
    },
    {
        "id": "fZvyRnuDSUW",
        "original": null,
        "number": 4,
        "cdate": 1666683629842,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666683629842,
        "tmdate": 1666683629842,
        "tddate": null,
        "forum": "lKOfilXucGB",
        "replyto": "lKOfilXucGB",
        "invitation": "ICLR.cc/2023/Conference/Paper3896/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper aims to address the challenging problem of Instance-Dependent Partial Label Learning, which is caused by overfitting on candidate labels, by rethinking the generation process of instance-dependent partial labels. In detail, the authors consider a two-step decomposition-based process. Categorical Distribution generates the correct label for a given instance, and Bernoulli Distribution samples the incorrect labels. In this way, they explicitly model the generation process. Then, to form their optimization objective, Maximum A Posterior (MAP) is performed, with Dirichlet Distribution and Beta Distribution introduced as prior distributions.",
            "strength_and_weaknesses": "Pros: \n1.\tThe proposed generation process is inspiring and offers a new perspective for me on Instance-Dependent Partial Label Learning. The generation process is distinct from traditional Multi-class Learning and Multi-Label Learning, but it also shares a few similarities, which is significant for understanding this problem.\n2.\tThe paper is well-organized and logical. It begins by explicitly modeling the process with decoupled probabilistic distributions, then forms the optimization objective using a MAP technique, and finally theoretically analyzes the estimation error of the optimization objective.\n3.\tThe experimental results are superior to the baselines, demonstrating the effectiveness of the proposed approach.\n\nCons and Qs:\n1. Since the optimization is based on the proposed generation model, the log-likelihood\nloss function in Eq.(4), which is derived from Eq.(1)~(3), could be more detailed. On the other hand, it is also used for ablation studies. Hence, more explanations need to be made to convince me.\n2. Could you explain whether the proposed process is adaptable to a uniform generation process of candidate labels or the relationship between them?\n3. I am curious about why Eq. (6) holds. Because the derivation is not in the appendix, a detailed explanation would be greatly appreciated.\n4. I'm not sure how to estimate the parameters $\\lambda$, $\\alpha$, $\\beta$, $\\theta$ and $z$. Eq.(8) and Eq.(9) use $\\lambda$, $\\alpha$, $\\beta$ to calculate $\\hat{\\alpha}$, $\\hat{\\beta}$, while Eq.(10) and Eq.(11) replace $\\lambda$, $\\alpha$, $\\beta$ with $\\hat{\\lambda}$, $\\hat{\\alpha}$, $\\hat{\\beta}$.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized and theoretically sound, indicating its good clarity and high quality. It is novel to decompose the generation process and explicitly model it using two probabilistic distributions. The overall proposed approach is easy to understand, so I believe that its reproducibility is assured.",
            "summary_of_the_review": "Overall, the paper proposes an insightful and novel approach to dealing with the instance-dependent PLL, and the experimental results demonstrate its effectiveness. As a result, I vote for acceptance.\n\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3896/Reviewer_Zc1G"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3896/Reviewer_Zc1G"
        ]
    }
]