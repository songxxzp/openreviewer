[
    {
        "id": "qKLtYbxe0M",
        "original": null,
        "number": 1,
        "cdate": 1666507756446,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666507756446,
        "tmdate": 1668664080913,
        "tddate": null,
        "forum": "_p6enPE4Xa",
        "replyto": "_p6enPE4Xa",
        "invitation": "ICLR.cc/2023/Conference/Paper2342/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes to use diffusion model to adapt selected layers of a trained model conditioned on an input sample. Authors conducted experiments onclassification, 3D construction, tablular data and speech separation. ",
            "strength_and_weaknesses": "Stength\nUsing diffusion model for conditional parameter generation is novel.\n\nWeakness\n1. I find the paper a bit difficult to follow, it could use some rewriting/clearer plots to emphasize the motivation and approach.\n2. I would like to see more details on the experiments: what's the cost of training and what's the overhead for inference. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and quality: A bit difficult to follow. \n\nNovelty: Fair\n\nReproducibility: High",
            "summary_of_the_review": "This paper proposes to use diffusion model to generate/adapt certain weights of a trained model given a single input. The motivation and the training/inference pipeline could be better structured and explained. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2342/Reviewer_Nu1A"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2342/Reviewer_Nu1A"
        ]
    },
    {
        "id": "w6wMc5-wOJ5",
        "original": null,
        "number": 2,
        "cdate": 1666643269851,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666643269851,
        "tmdate": 1670884344204,
        "tddate": null,
        "forum": "_p6enPE4Xa",
        "replyto": "_p6enPE4Xa",
        "invitation": "ICLR.cc/2023/Conference/Paper2342/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a diffusion model which, given a neural network input x, adapts the neural network weights to specialise the network to this single input. Doing so before evaluating on each test example (x, y) leads to better predictions of y. The diffusion model is trained to imitate an SGD procedure which overfits a pretrained model's weights to a single data point.",
            "strength_and_weaknesses": "Strengths:\n - Strong experimental results on a wide variety of problems and neural architectures (image classification, NeRF, tabular data, speech separation). State-of-the-art on some of these.\n - Well-motivated and experimentally-justified innovations include predicting the scale of the weight change separately, and changing weights for only a single network layer.\n - Apart from some minor points listed below, the writing is clear and a pleasure to read.\n\nWeaknesses:\n- There is a lack of discussion of computational cost. Relative to the baselines they consider (mostly just the same networks as for OCD, but without weight adaptation), OCD is presumably considerably more costly at both training time and test time. Since at training time, it requires both performing many \"finetuning\" SGD steps, and training the diffusion model. And the test-time weight adaptations are probably expensive relative to the cost of a single forward pass. Ideally there would be a comparison where the baselines were given larger architectures, and trained for longer, etc., to match OCD for computational cost. I appreciate that this paper can still be a valuable contribution without \"winning\" in such a comparison but this would provide very helpful context. Failing this, the differences in training time and test time should at least be made explicit and discussed. I am willing to raise my score if you address this point.\n\nMinor:\n- Section 3, \"$s$ [...] is near either a local minima or an inflection point for the training loss of finetuning with sample $s$\". I don't think this is necessarily true. E.g. in image classification the loss would be minimised when the \"correct\" output logit is driven to infinity and so it seems that the minimum may be at infinity (or more precisely, there may not be any minimum) when training on a single data point.\n- Equation 10. It is not clear what $x$ refers to here, or what the \"data distribution\" $q(x_0)$  refers to. The variable $x$ previously referred to inputs to the base model (i.e. in Eq. 1) but I think this might now be referring to a variable in the space of the network weights.\n- Section 3, \"without concrete quantization\" - probably not important, but I cannot tell what is meant by this phrase",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\nMostly clear.\n\nQuality:\nSee strengths and weaknesses.\n\nNovelty:\nAFAIK the author's claims are true that this is the first \"local learning approach that involves hypernetworks\" and the first \"diffusion-based hypernetwork\", and the authors make some well-motivated design choices.\n\nReproducibility:\nThe method is described clearly and code for OCD is attached, which together should be enough for reproducibility.",
            "summary_of_the_review": "The method is novel and clearly-presented. The results are good, but their significance is a little unclear to me because of the lack of presentation and discussion of computational cost. I will consider raising my score if this is improved.\n\n~~EDIT: Lowering my score; see \"Additional related work\" comment below.~~",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2342/Reviewer_Q7pB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2342/Reviewer_Q7pB"
        ]
    },
    {
        "id": "mo_SYHH-nm",
        "original": null,
        "number": 3,
        "cdate": 1666675622249,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666675622249,
        "tmdate": 1668893747589,
        "tddate": null,
        "forum": "_p6enPE4Xa",
        "replyto": "_p6enPE4Xa",
        "invitation": "ICLR.cc/2023/Conference/Paper2342/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a hypernetwork model where the weights are conditioned on input sample $x$ and are trained to match the model after finetuning. The hypernetwork generator is a conditional diffusion model, conditioned on $x$ (and it's features), and operates in the space of network weights $\\theta$.",
            "strength_and_weaknesses": "## strengths\n- The paper presents an interesting idea of using conditional diffusion model as a hypernetwork generator.\n- The experiments covers a wide range of applications including image classification, 3-D reconstruction, tabular data and speech separation.\n## weakness and questions\n- The paper is well-written for the most part but some parts can be improved to make the manuscript clearer. For example:\n\t- In Eq. 1, $\\theta$ is not formally defined before introduction. Is $\\theta$ the \"base network parameters\"? Does this mean the initialized weights or the pretrained weights?\n\t- What are $\\Omega$'s in Sec 4.1? Are they of the same dimensionality as $\\theta$?\n\t- The presentation of figures can be improved. For example, Figure 2 is a little hard to read, the lines are very thin and captions/ticks/legends are very tiny.\n- UNet: What's the dimensionality of $\\Omega$? If we choose a conv layer then should we use a 4-D UNet? In the case shown in Figure 1, is it true that the weight matrix is treated/reshaped as a 2-D \"image\" and we operate a 2-D UNet on it? If so, any explanation for why the inductive bias introduced by UNet is useful here?\n- The experiments on image classification are a little bit limited. It would be better to test the algorithm on larger networks and larger datasets e.g. TinyImageNet.\n- At the inference phase, do we get a single point estimate of $\\theta$? Is it possible to employ an ensemble here? With the proposed OCD formulation, it might be interesting to integrate/compare the Bayesian ensemble here.",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is well-written for the most part.\n- The presented method is novel.\n- Code is provided in Supplementary.",
            "summary_of_the_review": "I think it is an interesting paper, although the presentation is not clear enough. I am willing to amend my scores if my concerns are addressed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2342/Reviewer_A1Ss"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2342/Reviewer_A1Ss"
        ]
    },
    {
        "id": "VHK0hUzaxe",
        "original": null,
        "number": 4,
        "cdate": 1666728911530,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666728911530,
        "tmdate": 1670455470143,
        "tddate": null,
        "forum": "_p6enPE4Xa",
        "replyto": "_p6enPE4Xa",
        "invitation": "ICLR.cc/2023/Conference/Paper2342/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents an approach to use diffusion models as a manner to parameterize a meta-learning algorithm, where the network perbutation prediction by the diffusion process adapts a base model to a separate task.",
            "strength_and_weaknesses": "# Strengths\n\n**Novelty.** The problem studied by the paper is interesting and is new to my knowledge\n\n# Weaknesses\n\n**Clarity.** The paper is somewhat poorly written -- the introduction does not motivate the problem to be studied, related works are incorrectly referenced and the method section is confusing and does not adequately describe what is happening in the approach. What is the train data used for training the method? How is it obtained? How is the diffusion process used to obtain the data necessary to overfit data?\n\n**Results.** The results provided the paper are somewhat toy -- the NeRF look very poorly fit for example and the paper does not appear to be empirically rigorous. The paper does not explain why the approach only works on a single layer in the network. Also I could not completely understand the different baselines presented in each table. Why is each baseline natural?\n\n**Significance.** The results provided in the paper are not significant in its current state. The proposed approach seems to substantially underperform existing baselines -- the paper could be improved substantially by illustrating an concrete application of the approach on a real world setting that outperforms existing baselines.\n\n==============\nPost Rebuttal Update\n\nI have decided to downgrade my score (see the discussion below for some issues raised). The results for instance on TinyNeRF seem incorrect (even with 32 ray samples the results are still much sharper than those shown in the paper) and generally seem toy. This problem setup seems very similar to existing meta-learning techniques, for instance a meta-learned loss https://arxiv.org/abs/1906.05374 can be used to adapt the model (where we can not input a label y into the learned loss function). Experiments are run only with very limited data on very small architectures.",
            "clarity,_quality,_novelty_and_reproducibility": "The problem tackled by the paper seems interesting, but I think the exposition of the paper could be significantly improved to describe the exact benefits and methodology in the paper.",
            "summary_of_the_review": "I think the paper is a bit preliminary -- a lot of work needs to go into the writing to clarify the paper and results could be significantly improved.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2342/Reviewer_wwSB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2342/Reviewer_wwSB"
        ]
    }
]