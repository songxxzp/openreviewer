[
    {
        "id": "lXH4BmO2lnV",
        "original": null,
        "number": 1,
        "cdate": 1665924992148,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665924992148,
        "tmdate": 1668836342862,
        "tddate": null,
        "forum": "RiTjKoscnNd",
        "replyto": "RiTjKoscnNd",
        "invitation": "ICLR.cc/2023/Conference/Paper2887/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes Equivariant Diffusion-Hypergraph Neural Network (ED-HNN) for hypergraph structured data.\n\nED-HNN is implemented as a message-passing neural network on the star expansion of the hypergraph and can provably represent any continuous hypergraph diffusion operator.\n\nED-HNN competes with recent HNNs on hypergraph node classification datasets.\n\n___",
            "strength_and_weaknesses": "\\\n**Strengths**\n\n\\+ The paper is well-organised and relevant to the ICLR community.\n\n\\+ The theory in the paper significantly establishes connections between HNNs and hypergraph diffusion.\n\n\\+ ED-HNN works well in practice on several node classification datasets in comparison with several existing HNNs.\n\n\n\\\n**Weaknesses**  \n\n\\- The key innovation in the design of ED-HNN (i.e., Step 3 in Algorithm 1) is marginal with respect to prior art.\n\n\\- ED-HNN (and message passing on star expansion) can potentially be problematic for real-world hypergraphs in which the vast majority of hyperedges are of size two, e.g., contact networks, online forum thread networks.\n\n___",
            "clarity,_quality,_novelty_and_reproducibility": "\\\n**Clarity**\n\nWhile the paper is well-organised, the clarity of the paper can be improved.\n\nSpecifically, the authors claim that Step 3 in Algorithm 1 is a simple yet significant contribution for the hypergraph neural network community, however, it does seem marginal when viewed from a graph perspective.\n\nIn other words, the star expansion of a hypergraph can be viewed as a bipartite graph and from this perspective, Step 3 in Algorithm 1 is marginal and is well-known in the message passing community.\n\n\\\n**Quality**\n\nMost (if not all) real-world hypergraphs considered in the paper are those which contain a significant fraction of higher-order hyperedges (i.e., size >= 3).\n\nThe quality of the paper can be improved by discussing hypergraphs in which a vast majority of hyperedges are of size 1 or 2 and which contain an insignificant fraction of higher-order hyperedges, e.g., contact networks, online forum thread networks [1].\n\nThe concern here is that graph-based methods (on clique expansion) would be strong baselines on such datasets and it is unclear if equivariance will play a significant role.\n\n[1] How Do Hyperedges Overlap in Real-World Hypergraphs? -- Patterns, Measures, and Generators, In WebConf'21\n\n\n\n\\\n**Novelty**\n\nThe theory connecting equivariance, hypergraph diffusion, and hypergraph neural networks is somewhat new.\n\nHaving said that, a relevant (concurrent) work, that needs to be positioned and differentiated with, is the following:\n\nEquivariant Hypergraph Neural Networks, In ECCV'22.\n\n\n\\\n**Reproducibility**\n\nThe main part and the supplementary part include enough material, e.g., dataset details, proofs, baselines with references, hyperparameters, for an expert to replicate the results of the paper.\n\n___",
            "summary_of_the_review": "While the proposed method is theoretically grounded and effective on standard benchmarks, the paper can be improved in terms of clarity and quality.\n\n___",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2887/Reviewer_GNhA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2887/Reviewer_GNhA"
        ]
    },
    {
        "id": "scTmrFdvg47",
        "original": null,
        "number": 2,
        "cdate": 1666583829725,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666583829725,
        "tmdate": 1669982372740,
        "tddate": null,
        "forum": "RiTjKoscnNd",
        "replyto": "RiTjKoscnNd",
        "invitation": "ICLR.cc/2023/Conference/Paper2887/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed ED-HNN, a GNN for hypergraphs inspired by the algorithm for solving hypergraph diffusion (optimization problem on hypergraphs). ED-HNN approximates the gradient-based optimization algorithm for hypergraph diffusion by a message passing on a bipartite graph that is equivalent to the original hypergraph. As a theoretical analysis, this paper showed the representation theorem for equivariant functions and justified the architectural design of ED-HNN. Finally, this paper applied ED-HNN to various graph data as an empirical evaluation.",
            "strength_and_weaknesses": "Strengths\n- Numerical evaluation used various types of graph data. It demonstrates the broad applicability of the proposed model.\n\nWeaknesses\n- The parameterization of NNs somewhat hinders the relationship between the proposed method and underlying hypergraph diffusion (see the Quality section for details).\n- Similar results exist for the representation theorem for equivariant functions (Theorem 1) in existing studies.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\n\nThe paper is well-written. I had no great difficulty understanding the main points of the paper.\n\n\nQuality\n\nI want to clarify the relationship between ED-HNN and the corresponding hypergraph diffusion problem. Certainly, Proposition 3 showed that ED-HNN could approximate any hypergraph diffusion operator. However, the opposite direction is not known, i.e., whether any ED-HNN represents a hypergraph diffusion operator. If we think of ED-HNN as a hypergraph diffusion operator, there should exist functions $f$ and $g$ such that the model represents an optimization algorithm of $\\min \\sum_v f(h_v; x_v) + \\sum_e g(H_e)$. However, given ED-HNN, we do not know (at least explicitly) such functions.\nIt is true that in Section 4.4, this paper showed that ED-HNN could numerically approximate the functions (CE, TV, LEC) used for the objective function of hypergraph diffusion. However, this only demonstrates the approximation capability of ED-HNN and does not imply that ED-HNN is a hypergraph diffusion operation.\nFor these reasons, although I understand there is an analogy between hypergraph diffusion and ED-HNN, hypergraph diffusion does not work as a justification for ED-HNN.\n\n\nNovelty\n\nIf my understanding is correct, extensions of the representation theorem (Zaheer et al., 2017) for invariant functions to the equivariant case appeared in existing studies (for example, [Sannai et al., 2019, Corollary 3.2]). If that would be true, I would say the novelty of Theorem 1 is limited.\n\n[Sannai et al., 2019]: https://arxiv.org/abs/1903.01939\n\n\nReproducibility\n\nThe Appendix describes how to prepare the dataset used in the experiment and the hyperparameters of the prediction model. No code is provided, so there is no guarantee of perfect reproduction. However, I think we can implement the code to reproduce the experiments to some degree.",
            "summary_of_the_review": "The proposed method shows good prediction accuracy in numerical experiments. On the other hand, on the theoretical side, the proposed method is justified by associating it with hypergraph diffusion. However, I have questions about the validity of the arguments and would like to clarify them. Also, if I understand correctly, the representation theorem for equivariant functions, one of this paper's contributions, is known in existing studies.\n\n# Post-rebuttal comments\n\nAfter the discussion with the authors, I increase my score (5 -> 6). (Note that there is a possibility that my final evaluation could change after the further discussion with other reviewers and area chairs)\n\nI raised two weak points in the first review comment. One is that the relationship between the hypergraph diffusion problem and the proposed model is unclear. The other is that the universality result (Theorem 1) is known. The question related to the first question was solved through the discussion with the authors. I understand that the proposed model is a gradient-based optimization of a hypergraph diffusion problem for some unknown function $f$ and $g$. Also, making $m^{(t)}_{e\\to v}$ equivariant, which is inspired by the hypergraph diffusion, certainly improved the empirical performance.\nOn the other hand, my concerns about the second question were correct. However, the second point was not strong compared with the first point.\nIn conclusion, since I recognize the novelty and significance, I increase my score from 5 to 6, tending to accept.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N.A.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2887/Reviewer_n5MN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2887/Reviewer_n5MN"
        ]
    },
    {
        "id": "mC5kBFuG7mf",
        "original": null,
        "number": 3,
        "cdate": 1666666374406,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666666374406,
        "tmdate": 1666666374406,
        "tddate": null,
        "forum": "RiTjKoscnNd",
        "replyto": "RiTjKoscnNd",
        "invitation": "ICLR.cc/2023/Conference/Paper2887/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a hyper-graph neural network model, ED-HNN, that can model hypergraph diffusion process. They claimed that ED-HNN shows superiority in processing heterophilic hypergraphs and constructing deep models. ",
            "strength_and_weaknesses": "**Strength:** \n - 1. The presentation is clear. \n - 2. The overall experiments show the superiority of their proposed algorithm, ED-HNN.\n\n**Weakness:** \n\nThe main claims of the paper are not well explained or supported. In particular, section 3.3 tried to discuss the advantages of ED-HNN for the design of equivariant diffusion operators. However, I have several questions in this section. \n- 1. For the claim that \u201cInvariant diffusion by forcing the operation on hyperedge e to follow that the partial derivation to each dimension is the same\u201d, could you please refer to some reference or give proof on this? It is not obvious for a reader that is not familiar to the invariant diffusion, \n- 2. \u201cMoreover, a learnable operator is important.\u201d This conclusion is weak, since it only tells that it exists such parameters that can help but didn\u2019t say whether it is difficult to optimize to such parameters. Could you give some empirical experiments on the sensitivity of the parameters to show whether the learnable operator is difficult to optimize? \n- 3. \u201cequivariant hyperedge diffusion operators are also good at building deep models\u201d is not well supported and explained. Although Figure 2 shows an interesting result that ED-HNN successfully leverages deeper architecture to achieve higher accuracy, there is no clear trend to show that How about the performance of ED-GNN when the number of the layers go to larger than 8? Meanwhile, the claim that \u201cEquivariant operators allocating different messages across nodes helps with overcoming the oversmoothing issue.\u201d is not obvious to me. I could see those equivalent operators may reduce the risk of overfitting, but how do equivalent operators help the over-smoothing issue? Is there any insight on this point?",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation is good. \nReproducibility: N/A.\n",
            "summary_of_the_review": "Please refer to the Strength And Weaknesses. If the authors could address the problems in the weakness, I\u2019d like to raise my scores.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2887/Reviewer_z25x"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2887/Reviewer_z25x"
        ]
    },
    {
        "id": "iT_CreMfAD",
        "original": null,
        "number": 4,
        "cdate": 1666681376037,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681376037,
        "tmdate": 1668845041025,
        "tddate": null,
        "forum": "RiTjKoscnNd",
        "replyto": "RiTjKoscnNd",
        "invitation": "ICLR.cc/2023/Conference/Paper2887/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the learning on hyper graphs. Targeting the problem that existing hyper graph networks often require domain knowledge in designing the mechanism to process the higher-order relations in hyper graphs, this paper proposes a hypergraph diffusion based model that can model a wide range of higher-order relations without explicitly designing based on domain knowledge. Theoretical analysis is also provided on the proposed model. Expeiments are conducted on 9 datasets and are compared with 8 baselines.\n",
            "strength_and_weaknesses": "Strengths:\n\nThis paper has a clear motivation on the proposed model.\n\nThe proposed model is accompanie with theoretical analysis.\n\nThe experiments are comprehensive. Mltiple datasets and baselines are included. \n\nWeakness:\n\n1. The adopted datasets seem not to be hypergraph datasets. As introduced in the paper, in a hypergraph, a hyperedge connects a set of nodes. However, in datasets such as cora, citeseer, pubmed, each edge only connect two nodes, and they are just standard graph datasets. Isn't there any dataset that contain true hyper edges\uff1fIt is not convincing that the simple dataset like cora requires many higher-order relations to capture during classification.\n\n2. Since some of the adopted datasets are standard graph datasets, which were also widely adopted in works on standard GNNs, like GCN [1], the compared baselines should also include these methods. As far as I know, the performance of GCN on Cora is higher than any method shown in Table 2.\n\n[1] Kipf, Thomas N., and Max Welling. \"Semi-supervised classification with graph convolutional networks.\" arXiv preprint arXiv:1609.02907 (2016).",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity is OK, but it would be better if the high-level idea of the model can be explained more clearly. In the current version, the complex theories and formulations make it hard to gain an overview of how the model works.\n\nQuality is OK.\n\nNovelty is good.\n\nNot sure about the reproducibiliy. The model is sufficiently described in paper, but whether the results can be reproduced can only be chekced by running the code.",
            "summary_of_the_review": "Overall, this paper has a clear motivation targetng a meaningful problem, which is the good aspect. However, there is also some unlcear part regarding the experiments. Therefore, I would rate it as slightly below threshold currently",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2887/Reviewer_TN8f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2887/Reviewer_TN8f"
        ]
    }
]