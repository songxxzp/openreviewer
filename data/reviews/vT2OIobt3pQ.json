[
    {
        "id": "S6XOTgblp0",
        "original": null,
        "number": 1,
        "cdate": 1666443470878,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666443470878,
        "tmdate": 1666443470878,
        "tddate": null,
        "forum": "vT2OIobt3pQ",
        "replyto": "vT2OIobt3pQ",
        "invitation": "ICLR.cc/2023/Conference/Paper2190/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a few-shot learning with representative global prototype method. It uses selected representative and non-representative samples to optimize the representative global prototypes. It also utilizes semantic embedding to generate new samples of novel classes in order to alleviate the imbalance problem. The experimental results show that the proposed method can improve few-shot learning tasks and achieves state-of-the-art performance. ",
            "strength_and_weaknesses": "Strength:\n\n1.\tThe paper considers an interesting problem in the few-shot learning task: the data distribution of novel classes and base classes can be different. The different distributions lead to the performance degradation of few-shot learning methods. Correspondingly, the paper proposes to generate more samples for novel classes, which is reasonable.\n\n2.\tThe paper is well-written and easy to follow.\n\n3.\tThe proposed method achieves the state-of-the-art performance on miniImageNet and tieredImageNet datasets.   \n\nWeakness:\n\n1.\tThe paper claims that the data distribution of novel classes and base classes could be different, resulting in performance degradation. It seems that the proposed method is more suitable for cross-domain few-shot classification. On miniImageNet and tieredImageNet datasets, the base classes and novel classes follow a similar distribution, which can not show the effectiveness of the proposed method. The experiments on cross-domain few-shot classification tasks should be discussed and added.\n\n2.\tMore detailed discussions and experiments should be added. The paper should consider dividing novel tasks into multiple different levels based on the similarity with based classes, and verify whether the proposed method is more effective on the tasks that are more different from based classes.\n\n3.\tIn the experimental setting, the proposed method uses CLIP to extract the semantic embedding for generating new novel features. CLIP contains external information. So it is unfair to compare the proposed method  with other methods. For a fair comparison, it is better to replace CLIP with another way. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow. It considers an interesting problem in few-shot learning, and has originality. But more detailed disscussions experiments should be added. It provides detailed experimental implementation. But the proposed method contains many modules which is not easy to reproduce.",
            "summary_of_the_review": "The paper considers an interesting problem in few-shot learning, but more detailed disscussions experiments should be added.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2190/Reviewer_5Wqr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2190/Reviewer_5Wqr"
        ]
    },
    {
        "id": "2qwIZ9y3FQ",
        "original": null,
        "number": 2,
        "cdate": 1666493619179,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666493619179,
        "tmdate": 1666494062967,
        "tddate": null,
        "forum": "vT2OIobt3pQ",
        "replyto": "vT2OIobt3pQ",
        "invitation": "ICLR.cc/2023/Conference/Paper2190/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a joint training strategy for few-shot learning via representative and non-representative samples to enhance the generalization to novel classes. \nThe representative samples are used for the global prototype, and the non-representative samples are further used for classification loss. \nA sample generation method is also used to generate samples of novel classes. \nThe proposed method exhibits state-of-the-art performance on the miniImageNet and tieredImageNet datasets.  \n",
            "strength_and_weaknesses": "Strengths \n- The proposed approach, which uses based and novel classes to train and generate the samples for novel classes, seems reasonable. \n- The proposed method shows better performance than the state-of-the-art methods. \n\nWeaknesses \n- Components of the proposed method are not novel (see Novelty below). \n- The ablation study is insufficient (see Quality below )\n- The writing of this paper needs improvement. (see Clarity below)  \n",
            "clarity,_quality,_novelty_and_reproducibility": "Novelty\n\nThe proposed method combines the idea of the global prototype (Li et al., 2019) and representative samples (Xu et al., 2022). The global prototype (Li et al. 2019) uses the similarity between input and global representation, but the method is built on a meta-learning framework. (Xu et al., 2022) proposed the selection of representative samples and the CVAE sample generation model. The authors introduced the modules of (Xu et al., 2022) into the global representation (Li et al., 2019) but without meta-learning. The method seems to be good, but the components are not novel. \n\nA novel point might be the introduction of non-representative samples. But this is not highlighted. \n\nQuality \n\nThe ablation study is insufficient. \nOne contribution is the joint training with representative and non-representative samples. The effects of introducing the non-representative samples are not shown. \n Also the second contribution is to propose a sample synthesis strategy ( but this is the same as Xu et al., (2022)). The effect without using the sample synthesis is not evaluated. \n \nClarity\n\nP.1 The \u201cmetric novel class data\u201d is unclear. Also, \u201cMetric presentative sample\u201d(P2), \u201cmetric the global prototype\u201d (P4), \u201cmetric the new global prototype\u201d(P4) are not clear. \n\nP1. The third paragraph seems to describe a specific paper. The author should clarify the paper. \n\nP2. \u201cMetric representative sample and representative global prototype to generate a global loss\u201d is not a sentence. \n\nP3. \u201cthe base and novel class training the representative and non-representative samples\u201d   is a typo\n\nP4. \u201cto form a support set to form a support set\u201d  is a typo\n\nP4. S={$x_j$ | p($x_j$) | $\\mu_i$, $\\sigma_i$ > $\\epsilon$ } is a typo. \n\n\n\n \n\n\n\n",
            "summary_of_the_review": "Although the proposed method is reasonable and achieves state-of-the-art performance, the proposed method only combines existing components, and this paper does not have novel aspects for few-shot learning. The ablation study is insufficient, and the writing needs improvements.  \n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2190/Reviewer_HxLp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2190/Reviewer_HxLp"
        ]
    },
    {
        "id": "0Ia04PS8J1S",
        "original": null,
        "number": 3,
        "cdate": 1666615663749,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666615663749,
        "tmdate": 1666615663749,
        "tddate": null,
        "forum": "vT2OIobt3pQ",
        "replyto": "vT2OIobt3pQ",
        "invitation": "ICLR.cc/2023/Conference/Paper2190/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This submission introduces a new few-shot learning with representative global prototype framework. For one thing, they propose a novel jointly training strategy for few-shot learning via representative and non-representative samples. For another thing, they propose a sample generation strategy to generate samples of the novel class to solve the sample imbalance problem caused by limited data (few shots). \n\n",
            "strength_and_weaknesses": "strength: This work proposes a few-shot learning with representative global prototype method.\n\nweakness: I have some questions, described below. As stated in 3.1, there are a total of N classes of samples and the support set also has N classes. To build the support set, the authors stated that they select a representative set of training samples of the ''base class''. Do they mean base classs and novel classses? Besides, the authors select the sample using p, mean vector of class i and covariance of class i. Are the mean vector and covariance of class i being fixed for using all samples within this class i? I am confused about \"which is its covariance \u03a3i is small if \u03a3i  is fixed for a given class i\". To generate samples for novel classes, the authors combine the base class data and semantic embedding ai. How can we obtain the semantic embedding, such as one-hot vector? Could the authors provide more explaination for  semantic embedding and how the samples for novel classes are generated? More importantly, how many N way K shot tasks are used to evaluate the performance? Here, N means subset of all novel classes rather than total classes. The proposed RGP is used to train a standard N way K shot or train their mentioned support set. I think the latter includes more noval task information than former. Therefore, it may be unfair to compare standard few-shot learning methods if the authors using all novel tasks. Besides, how about the computational cost at training and testing stage? Lastly, the authors mentioned their proposed RGP can break the barrier: the sample distribution of the novel class and the base class are similar. It would be better if the authors can provide some experimental results to support this argument.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper writing is not clear enough. \nQuality\\Novelty\\Reproducibility: It woud be helpful if the authors can address my above-mentioned doubts.\n\n ",
            "summary_of_the_review": "Somewhat novel and reasonable if the method is fair when comparing with its baselines.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2190/Reviewer_pA9r"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2190/Reviewer_pA9r"
        ]
    }
]