[
    {
        "id": "_ktlvkaZP0",
        "original": null,
        "number": 1,
        "cdate": 1666112962493,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666112962493,
        "tmdate": 1666112962493,
        "tddate": null,
        "forum": "Or8rcTLo7U",
        "replyto": "Or8rcTLo7U",
        "invitation": "ICLR.cc/2023/Conference/Paper4389/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new bivariate causal inference algorithm called MC-PNL (maximal correlation with independence regularisation). The authors propose to use the randomised dependence coefficient (RDC) instead of HSIC test often used by the causal inference community. \n",
            "strength_and_weaknesses": "Strengths. The paper is in general well-written. It does a good overview of the state-of-the art methods. The proposed method is novel and worth being studied. \n\nWeaknesses. It is stated that the proposed method outperforms the state-of-the-art independence test-based methods (bivariate causal inference), however, the method is much worse than some other state-of-the-art causal discovery methods. The results of the numerical experiments are not so convincing. I see that the idea is to show that the method outperforms the test-based methods, however, the IGCI method which is also based on the same asymmetry (independence of mechanism) hypothesis performs much better. Do you have some intuition? Are the independence tests used not efficient enough? And the future work should focus on a more efficient tests?  \n\nFigure 2 is unclear. What is the true causal direction? And how the plots should be interpreted? Taking, e.g., subplot a), above and below, we clearly see that the red line is well-fitted. What is the direction? And what can be deduced from the estimated residual values? \n\nAlgorithm 2 abstains from the decision only if C = 0. It is not too strict for real (noisy) applications? Were it be not better to introduce some \\epsilon, so that if abs(C) < \\epsilon the decision can not be made? As it is done, e.g. in F. Liu and L. Chan,\u201cCausal inference on discrete data via estimating distance correlations,\u201d Neural Computation, vol. 28, 2016.  \n\nFinally, in the problem formulation (equation 13), there are two parts: the HGR correlation and RDC (instead of HSIC which is, however, seems to be used in the paper). Could you study the efficiency of each of these parts?  \n\nSection 2.2: generating process and the causalities: I guess a number of assumptions are made behind the description of the idea, and these assumptions need to be mentioned. \n\nIn the numerical experiments (Section 5.2.) did you fix C = 0 (as in the Algorithm 2)? \n\nWhile reading, I have an impression that the HSIC takes too much room in the paper, finally the HSIC is criticised and is proposed to be replaced.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written. \nThere is some novelty in the contribution. ",
            "summary_of_the_review": "Some points need to be clarified. \nI have some concerns about the numerical experiments, since the reported results outperform some existing methods but are much worse compared to some other state-of-the-art approaches. \nA number of assumptions made in the theoretical part are not mentioned explicitly. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4389/Reviewer_E1Jp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4389/Reviewer_E1Jp"
        ]
    },
    {
        "id": "NxRo9bVRCYz",
        "original": null,
        "number": 2,
        "cdate": 1666603572631,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666603572631,
        "tmdate": 1666603572631,
        "tddate": null,
        "forum": "Or8rcTLo7U",
        "replyto": "Or8rcTLo7U",
        "invitation": "ICLR.cc/2023/Conference/Paper4389/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies bivariate causal direction learning from observational data. The authors focus on the general bivariate model, i.e., the post-nonlinear model, and propose a new method to learn the model. The contributions are as follows, the authors first analyze the drawbacks of the existing estimation methods, e.g., the PNL-MLP algorithm, and the AbPNL algorithm. Then they propose a new optimized function to estimate the PNL model by using the Soft-HCR. Finally, the authors apply their methods in both synthetic and Gene datasets to verify the efficiency. ",
            "strength_and_weaknesses": "Strength\n\nThe authors focus on the challenge of causal direction inferring. This is an important but challenging problem. \n\nThe paper builds on prior work in the field of casual discovery in PNL model. The authors put some effort into mitigating the problem of time-consuming and unreliable results with finite samples. \n\nThe basic idea is interesting and useful.\n\n This paper is well-written and well-organized.\n\n\nWeakness\n\nSome results are based on simulation analysis rather than theoretical analysis.\n\n\nSome concerns or questions\n\n1. The last but one paragraph on Page 2: a biased HSIC? It may be unbiased?\n\n2. \ufeffIn Table 2, the ROC-AUCs of IGCI have better accuracy than the proposed method in the synthetic datasets. However, IGCI has worse accuracy in real-data sets. Can you explain this result?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The idea of combining the Soft-HCR and dependence measure (HSIC) is non-trivial. This paper is well-written.",
            "summary_of_the_review": "The authors make some progress on the hard problem of estimating the causal direction of interest only using the observed variables.  The proposed method is non-trivial and useful with finite samples. However, some results are based on simulation analysis rather than theoretical analysis.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4389/Reviewer_2uGF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4389/Reviewer_2uGF"
        ]
    },
    {
        "id": "_iJJXNrldKb",
        "original": null,
        "number": 3,
        "cdate": 1666656238808,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666656238808,
        "tmdate": 1666656238808,
        "tddate": null,
        "forum": "Or8rcTLo7U",
        "replyto": "Or8rcTLo7U",
        "invitation": "ICLR.cc/2023/Conference/Paper4389/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors suggest using the randomized dependence coefficient (RDC) instead of the Hilbert-Schmidt independence criterion (HSIC) for the independent test for performing bivariate causal discovery using MLPs in the post-nonlinear setting. ",
            "strength_and_weaknesses": "The practical take-aways such as the strength of RCD with finite samples could be useful. \n\nAuthors have not tested their algorithm on Tuebingen dataset, which is the baseline for bivariate causal discovery.",
            "clarity,_quality,_novelty_and_reproducibility": "Presentation is clear in my opinion. \n\nNovelty is not very high, as commented above. \n\nProposed methods seem reproducable. ",
            "summary_of_the_review": "Proposing using a different independence measure is not a sufficient contribution in my opinion. This is analogous to having a different algorithm around the PC algorithm by simply using different conditional independence testers. Please see below for some more minor comments.\n\nOn Justification of the Method:\n\"However, the state-of-the-art (SOTA) PNL-based algorithms involve highly non-convex objectives for neural network training, which are\ntime-consuming and unable to produce meaningful solutions with finite samples.\"\nCausal discovery literature does not generally rely on neural network training. So I find this justification a bit inadequate. How about fitting a function class then checking residual independence as is typically done with ANM models?\n\n\"moreover, the discovered DAG may not necessarily be causal.\"\nThis is not a fair criticism either. The experts are aware that GES would return a graph in the MEC. \n\n\"In this paper, we will focus on a more fundamental problem\"\nthe relative fundamental-ness of bivariate vs. full graph discovery is subjective. I would suggest authors refrain from such subjective comparative statements.\n\nOn Experiments:\n\nA typical benchmark used for bivariate causal discovery is the Tuebingen dataset. Did you test your algorithm on this real data? It would be nice to address why this was not added. \n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4389/Reviewer_9qg4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4389/Reviewer_9qg4"
        ]
    },
    {
        "id": "_Sf2OLxU8y",
        "original": null,
        "number": 4,
        "cdate": 1666779431400,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666779431400,
        "tmdate": 1666781223457,
        "tddate": null,
        "forum": "Or8rcTLo7U",
        "replyto": "Or8rcTLo7U",
        "invitation": "ICLR.cc/2023/Conference/Paper4389/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper focuses on the challenges of estimating post-nonlinear models (PNLs) for causal discovery in the bivariate case. Indeed, solving the practical issues of estimating PNLs is an important topic.\n\nThe problems with existing methods are that they can produce local minima which are trivial and meaningless solutions and that the misspecification of noise distributions can lead to wrong causal discovery results.\nThe paper proposes an objective that avoids relying on noise distributions (similar property as HSIC minimization methods) and enforces the independence of residual and potential direction cause. \n\nIt combines the objective function in the alternating conditional expectation (ACE) algorithm (Breiman & Friedman, 1985) with a dependency measure as the penalty term for enforcing the residual to be independent of the potential direct cause. And it determines the causal direction by using the independent tests of the residual and potential direct cause. \n\nThe main experiments in Table 2 cannot show that the proposed method is significantly better than the other methods empirically.\n",
            "strength_and_weaknesses": "## Writing \n(+) The paper is well-written in general and makes the problem that it is solving and the contributions clear. \n\n(-) However, I would also suggest spending more effort on the proposed method (Page 6 - Page 7) than illustrating the problem (Page 2 - Page 5). Because I would expect the readers can know some about the problems but not really about the proposed method. It can be not the case but then perhaps readers care more about the concerns of the proposed method.\n\n## Experiments\n(+) The work provides transparent and nice-illustrated figures. \n\n(-) But in Table 2, it cannot show the proposed method stands out compared with the others empirically. A fairer claim is that it is better than the related works based similar framework. As for real-world data, the ANM-based method performs surprisingly well and is comparable with the proposed method. \n\n(-) Moreover, in this case, it would be good to show experimental results on the typical benchmark dataset, the 100 (or more) Tuebingen cause-effect pairs. Not necessary to show superiority, but to provide a comparison with the others.\n\n## Concerns about Algorithm 2\n(-) The causal score is a single number of the difference between the dependency measures in different directions. It would be more convincing to report the numbers for the experiments, especially to which degree (or within which threshold), we can believe the number is larger than zero, smaller than zero, or equal. Moreover, I am worried that in real-world data or finite samples, how much we can trust a single number that gives us the causal relationship. And it doesn't seem to show the experiments about the independent case.\n\n\n## Proposed method\n(+) The work clearly formulates the proposed method with a discussion of optimization process. \n\n(-) Nevertheless, __my main concern__ is that the proposed objective (13) lacks a justification and theoretical guarantee from the identifiability concern. ( Note that I am not asking for an identifiability proof, but the justification and theoretical guarantee for that given the PNLs under identifiability assumptions, can the method be used for determining the causal direction?)\n\nAs actionable feedback, can the authors show that  \n(i) for objective (8), is it in any way related to maximum likelihood or minimizing mutual information?\n\n(ii) as for the model in the causal direction and the one in the reverse causal direction, can objective (8) imply that the one in the causal direction has a smaller value of the optimal objective function value than the other one? \n\nFurthermore,\n\n(iii) as for objective (13), how can the property maintain by adding the penalty term? A concern is that the penalty term is added as a \"soft\" constraint which is not necessary to be exactly the case. Then, is it possible that the optimal solution by solving (13) can be the local minima which are taken as a trade-off between the objective (8) and the penalty term? Then, will this lead to a misspecified model ? will this lead to a problem for causal discovery?\n\n\nTo further elaborate on my point:\nThe authors introduced the PNL-MLP of Zhang & Hyv\u00e4rinen (2009), which uses mutual information for estimating the model and later uses independent tests for causal discovery. And the authors point out the problem of using mutual information as the objective, which can be hard with large-scale datasets. But an important fact of using the maximum likelihood or minimizing mutual information is that they are well justified by the identifiability of PNLs as illustrated in [1], especially, the independent noise assumption. \nSimilarly, as for the regression by dependence minimization (Mooij et al., 2009), it directly minimizes the HSIC score to enforce the independent noise assumption and pick up the model with a smaller score as the causal direction. This is fine because it directly uses the assumption as objective from the perspective. But for the objective in (Uemura & Shimizu 2020) and this paper, they neither directly use the independent noise assumption nor have a theoretical guarantee of the identifiability as Thm.2 and Thm. 3 in [1]. Therefore, to fix my concerns, maybe the authors could consider my actionable feedback.\n\n[1] Zhang, K., Wang, Z., Zhang, J., & Sch\u00f6lkopf, B. (2015). On estimation of functional causal models: general results and application to the post-nonlinear causal model. ACM Transactions on Intelligent Systems and Technology (TIST), 7(2), 1-22.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The work focuses on an important problem for causal discovery. It is in general well-written. The related points can be found in the previous comments.",
            "summary_of_the_review": "The paper works on the practical issues of estimating PNLs and shows the problems of existing methods. It proposes to use the objective,  maximum correlation with a dependency measure as the penalty term. My main concern is about the theoretical guarantee and the identifiability of the results given by the proposed objective. My minor concern is about the experiments and the causal score used in Algorithm 2.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4389/Reviewer_7wPL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4389/Reviewer_7wPL"
        ]
    }
]