[
    {
        "id": "EoTffIpxBO5",
        "original": null,
        "number": 1,
        "cdate": 1666005535635,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666005535635,
        "tmdate": 1668958089298,
        "tddate": null,
        "forum": "BT4N_v7CLrk",
        "replyto": "BT4N_v7CLrk",
        "invitation": "ICLR.cc/2023/Conference/Paper5265/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces FunkNN, a continuous super resolution module for image-like data. Given a low resolution image and an image coordinate x (which may not lie on the low resolution grid), FunkNN returns the predicted RGB value at that coordinate, effectively leading to a continuous image representation, where pixel values can be probed at arbitrary coordinates in R^2. To achieve this, the authors propose to use a spatial transformer which takes as input an image and a coordinate and extracts a (linearly interpolated) patch centered on this coordinate. The patch is then passed through a small CNN which returns the predicted RGB value at the coordinate location. The authors perform various interesting experiments on image super resolution and inverse problems involving image derivatives.",
            "strength_and_weaknesses": "**Strengths**\n\n- The paper tackles an interesting and useful problem.\n- The proposed model has various interesting properties. For example, the model can be trained with very low memory since it only requires patches and the continuous nature of the model allows for easy estimation of derivatives.\n- The inverse problem applications and experiments are interesting.\n- The out of distribution experiments are interesting. It is nice to see that a model trained on CelebAHQ can generalize to LSUN bedrooms.\n- The figures are nice and help with the general understanding of the paper.\n\n\n**Weaknesses**\n\n- In general, the discussion of related work is lacking and the paper is not very well situated in the literature. In particular, the proposed model is very closely related to LIIF which is briefly mentioned as a baseline. However, from reading the FunkNN paper this is not clear. It was not until I had a look at the LIIF paper that I realised how closely related these two ideas are (using local information to upsample images at arbitrary resolutions). The differences need to be discussed in more detail and related works should be properly acknowledged. In addition, generative models of continuous images are briefly mentioned but not discussed in detail (and a reference to [1] is missing). Further, while works like Chen & Zhang 2019 and Dupont et al 2021 are mentioned as performing poorly for grid-based generative tasks, it is worth noting that these models are also much more general and can be applied easily on various data modalities.\n- As the proposed method is a super resolution module and not a generative model, I believe it makes more sense to focus on super resolution in the related work section instead of generative models (which currently takes up much more space). In general, the model does not feel very well situated in the super resolution literature.\n- There is very little quantitative evaluation of the model. For example, for the inverse problem experiments there is not a single quantitative metric (even though e.g. just measuring reconstruction error should be simple) and only a handful of quanlitative comparisons. Further, there is little discussion of what baselines could be relevant for these experiments.\n- The authors discuss generative models throughout the paper, but do not include any experiments or evaluation for this. For example, it would be interesting to see how FunkNN applied to some low res generative model would compare to other generative models of continuous images.\n- While the writing is generally clear, there are quite a few typos and some missing information. For example, in Table 1 it is not clear on which dataset the model was evaluated. Is the performance averaged across all examples on some test subset of CelebAHQ?\n\n\n**Nitpicks**\n\n- It seems like a lot of citations are missing brackets. I would recommend using `\\citep{}`.\n- The authors often refer to \"Implicit Neural Networks\". However, it seems like the two dominant terms in the literature now are \"Implicit Neural Representations\" or \"Neural Fields\", so I would go with one of these options to be consistent with the literature.\n\n[1] Adversarial Generation of Continuous Images, Skorokhodov et al, CVPR 2021",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n\nThe paper is generally quite clearly written and the figures are nice. A few details are missing in the results section.\n\n**Quality**\n\nThe paper is fairly high quality. The method and experiments are both interesting and the paper is quite well written.\n\n**Novelty**\n\nThe proposed method is reasonably novel, but is closely related to exisiting methods.\n\n**Reproducibility**\n\nThe details and explanations provided in the paper seem to be sufficient for reproducing the results in the paper.",
            "summary_of_the_review": "Overall, I think this is a fairly good paper, which may be of interest to the ICLR community. The method and experiments are interesting. However, I do not think the paper is very well situated in the literature and also lacks some experimental evaluation. I therefore believe the paper in its current state is borderline, but I am willing to update my scores if some of the concerns are addressed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethical concerns.",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5265/Reviewer_9a5t"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5265/Reviewer_9a5t"
        ]
    },
    {
        "id": "MZuP_ts-bky",
        "original": null,
        "number": 2,
        "cdate": 1666258667120,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666258667120,
        "tmdate": 1669026433990,
        "tddate": null,
        "forum": "BT4N_v7CLrk",
        "replyto": "BT4N_v7CLrk",
        "invitation": "ICLR.cc/2023/Conference/Paper5265/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces FunkNN, a super-resolution architecture built on a two-stage process to model images as a continuous function.\n\nIn order to predict the color value for a given (x, y) location, first a Spatial Transformer with a bilinear kernel is used to extract a PxP patch from the image whose coordinates are centered on the point (x, y), and then a CNN is used to predict the color value at the chosen point. In a sense, one could tell that FunkNN is built by using a CNN to sharpen an initial bilinear upscaling.\n\nThe model as a whole allows to both compute spatial gradients in the image, and back-propagate gradient information back to the low-resolution image. This makes it possible to combine FunkNN with any off-the-shelf low-resolution generative model. The paper illustrates this by using such models as a prior over in images in problems of high-resolution image reconstruction from partial data: reconstructing an image from its 20% highest intensity spatial gradients, or in the context of limited-view CT reconstruction.\n\nOn the super-resolution task, FunkNN is shown to be competitive to LIIF, a state of the art model, on x2, x4 and x8 tasks, while being a much smaller model in terms of parameter count.",
            "strength_and_weaknesses": "**Strengths:**\n\nThe paper proposes a simple and elegant model, showing the possibility to build continuous super-resolution methods with *relatively* small models. The efficiency of FunkNN is demonstrated on multiple different tasks, illustrating the various possible applications of the model. The construction of the model is well motivated.\n\nThe core idea of the paper is in my opinion the fact that it delegates the \"interpolation\" part of the problem to a spatial transformer which achieves bilinear interpolation over the whole patch, rather than trying to train a NN to do it. It does seem like a good inductive prior to give to the CNN for the final prediction.\n\n**Weaknesses:**\n\nFirst of all, I want to say that I am not deeply familiar with the problem of super-resolution, and I refined my understanding of it using the references from the paper. My attention went in particular to the LIIF model (reference Chen et al. 2021 from the paper), which seems to me to have quite a lot of similarities with the proposed FunkNN.\n\nThe models are clearly different:\n- LIIF passes the whole low-resolution image in a CNN encoder, then extracts a small patch from that encoded representation, and uses a NN to interpolate to the target pixel value from that small patch.\n- FunkNN extracts a small patch from the low-resolutions and at the same time interpolates it to align its pixel grid to the target coordinate using a spatial transformer, and then use a CNN to predict the target pixel value from that aligned patch.\n\nHowever, as far as I can tell, the main properties of FunkNN advanced by the paper (being able to compute spatial gradients of the image and being able to back-propagate gradients to the low-resolution input) are shared by LIIF. This means that for all the inverse problems described in section 4, on which the performance of FunkNN is illustrated, it would be possible to make a performance comparison with LIIF.\n\nFurthermore, FunkNN like LIIF represents the image prediction as a continuous function of pixel values. This means that, like LIIF, FunkNN could theoretically be able to generalize to scale factors different than the ones it was trained on. LIIF for example is trained on x2, x3 and x4 factors, and shown to generalize well up to x30 from that. No such attempt at generalization is made on FunkNN.\n\nThe paper points the large number of parameters of LIIF. From what I understand, it comes mostly from the large CNN encoder LIIF uses, that works on 48x48 patches. However, nothing in the structure of LIIF would prevent using a much smaller encoder working on smaller patches (for example 8x8 like FunkNN in the experiments). Doing so could probably bring LIIF to a number of parameters comparable with FunkNN.\n\nThe core of my concern is thus this: while conceptually different (interpolation done by a NN vs. done by the spatial transformer), LIIF and FunkNN are two models with very similar sets of capabilities. I thus find it a lack in the paper that the two models are not compared in a more in-depth way: the inverse problems FunkNN is evaluated on should be accessible to LIIF, and the arbitrary scaling of LIIF should be accessible to FunkNN. I find this especially lacking given that, from a conceptual point of view, it seems to me that the good inductive bias of FunkNN has the potential to make it very competitive with LIIR on all those tasks.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written presents the proposed model and test setting with all the necessary details to reproduce its experiments.\n\nThe paper take advantages of previous work (spatial transformers) and re-combines it in a novel and well-justified way for the task of super-resolution.",
            "summary_of_the_review": "I believe this is overall a decent paper. The proposed model is well-justified, simple and elegant, and experimentally shown to be applicable to several relevant tasks.\n\nHowever I think that to truly be a good paper it is lacking an in-depth comparison with other models of the literature that can be applied to the same tasks (I focused on LIIR from the references of the paper, but it's entirely possible other models could also be applicable here).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5265/Reviewer_BzrP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5265/Reviewer_BzrP"
        ]
    },
    {
        "id": "MIX2KnatPE",
        "original": null,
        "number": 3,
        "cdate": 1666383303374,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666383303374,
        "tmdate": 1666383303374,
        "tddate": null,
        "forum": "BT4N_v7CLrk",
        "replyto": "BT4N_v7CLrk",
        "invitation": "ICLR.cc/2023/Conference/Paper5265/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a method for image super-resolution that resembles an implicit function, but has strong inductive biases in the underlying architecture. To predict the super-resolved value for a particular coordinate, they interpolate a small 2D patch centered at that coordinate from the original image (reminiscent of RoI-Align from the segmentation literature), and pass this through a CNN.\nThey show competitive super-resolution results on natural image datasets, and show that their method produces plausible spatial derivatives that be used in a medical imaging applications.\nCompared to other super-resolution methods, theirs seems to be much more efficient in terms of computational complexity and parameter count.",
            "strength_and_weaknesses": "Strengths:\n1. The proposed method is well-motivated and clearly explained. \n2. The method is sensible and has a number of desirable properties.\n\nWeaknesses:\nThe main weakness is that the experimental evaluation could be more extensive. For example:\n1. In \"Related Work\", the authors discuss GAN-based super-resolution methods, but do not include any such methods as baselines in their experiments.\n2. I can imagine that the proposed method could be successfully applied to density estimation. For example, as a cascaded density model similar to what [1] does with diffusion models.\n\nI wonder if more emphasis on directions like these would make the paper more compelling to a broader audience. In contrast, the discussion about OOD generalization feels a bit weak (proposed method not substantially better than baseline), and the image derivative experiments feel a bit niche (I personally do not find these particularly exciting, and imagine that much of the generative modeling community feels similarly).\n\n\n[1] Cascaded Diffusion Models for High Fidelity Image Generation. Ho et al, https://arxiv.org/abs/2106.15282.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. The proposed approach is moderately novel and well-executed. The authors do not provide code, but I think the paper could be reproduced from the details in the text.",
            "summary_of_the_review": "I do think that this paper would be stronger if the authors focused on slightly different directions (see \"Weaknesses\" section), but overall I feel that it is a solid incremental contribution in super-resolution. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5265/Reviewer_Zsei"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5265/Reviewer_Zsei"
        ]
    },
    {
        "id": "MdnwlgT87UV",
        "original": null,
        "number": 4,
        "cdate": 1667438163844,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667438163844,
        "tmdate": 1667438163844,
        "tddate": null,
        "forum": "BT4N_v7CLrk",
        "replyto": "BT4N_v7CLrk",
        "invitation": "ICLR.cc/2023/Conference/Paper5265/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a patch-based framework for solving inverse problems. The proposed approach is able to achieve reasonable performance on several tasks.",
            "strength_and_weaknesses": "Strength:\n1. The paper is well-written. The proposed approach is simple and easy to follow.\n2. The empirical results are good. The model is able to achieve comparable performance while using fewer parameters than state-of-the-art models on several inverse problem tasks.\n\nWeakness:\n1. Section 3 is hard to follow. For instance, what does \"sample discrete images from a powerful convolutional generator\" mean? Do you mean to generate an image using the pretrained generator? What does \"discrete image\" mean? Does it have a fixed resolution?\n2. In section 3.1, it would be better to define the input of ST formally (e.g., coordinate, image) instead of just mentioning its dimension. \n3. In section 3.2, does it mean given a pretrained generative model, you apply FunkNN to the output from the generated samples of the model? Why not directly apply it to existing low-resolution images so that the quality of the results will not be bounded by the pretrained generator? \n4. The notation is section 4.1 is hard to follow. For instance, a new model IN$_\\theta$ is introduced. What is this model doing? It's better to keep the notation consistent. The parameter $j$ is also not formally defined, what are $u$ and $x$?\n5. The structure of the paper can be improved. For instance, some results are presented in section 4, but there is another section called Experimental results (section 5). \n6.  Besides the super-resolution results (table 1), there is no comparison with state-of-the-art baselines for the other tasks.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The main approach is simple and easy to follow. However, the method and experiment sections are very hard to follow, with undefined notations and unexplained experimental settings. The contribution of the paper is mainly on the empirical side, and thus more thorough comparisons with state-of-the-art approaches (both quantitatively and qualitatively) on each task are needed. The reproducibility is also unclear.",
            "summary_of_the_review": "This work proposes a simple approach to solving inversion problems. However, the presentation of the paper can be improved, and more empirical results and comparisons with state-of-the-art baselines are needed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Discrimination / bias / fairness concerns"
            ],
            "details_of_ethics_concerns": "Generated super-resolution images could introduce bias if the model is trained on a biased dataset.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5265/Reviewer_kWFU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5265/Reviewer_kWFU"
        ]
    }
]