[
    {
        "id": "vJ3yl8UQ4CD",
        "original": null,
        "number": 1,
        "cdate": 1666610639030,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666610639030,
        "tmdate": 1668731514606,
        "tddate": null,
        "forum": "P5Z-Zl9XJ7",
        "replyto": "P5Z-Zl9XJ7",
        "invitation": "ICLR.cc/2023/Conference/Paper9/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, authors propose continuous-discrete convolution (CDConv) for joint modeling of geometric and sequential protein structures. This is motivated by the observation of regular sequence structure and irregular geometry structure of proteins. The proposed instantiation of CDConv is rotational invariant, which does not require additional data augmentation and is efficient to optimize. Empirical evaluation on several benchmark datasets demonstrates the effectiveness of the proposed method.",
            "strength_and_weaknesses": "Pros:\n1. The observation of regular sequence structure and irregular geometry structure is valuable, which leads to the main motivation of this paper. Previous works indeed fail to perfectly cover both aspects of protein structures.\n2. The proposed relative spatial encoding is rotational invariant, which is critical for efficiency model optimization. In addition, such rotational-invariant implementation is more computationally efficient than spherical harmonics based ones, e.g., SE(3)-Transformer.\n\nCons:\n1. I am not sure whether the proposed method can properly deal with protein structure where some residues have missing 3D coordinates, possibly due to the difficulty in experimental determination. According to Equation (7), the construction of relative spatial encoding relies on 3D coordinates of adjacent residues\u2019 C-alpha atoms.\n2. As described in Section 4.2, the sequential kernel size is set to different values in different tasks (fold classification: 11; reaction classification: 25; Go term and EC number prediction: 15). Does this indicate that the proposed model is somehow sensitive to the choice of sequential kernel size? How should this be alleviated?\n3. In Table 3, discrete convolution for 3D geometry structures is evaluated. For discretized 3D coordinates, it would be hard to preserve the rotational equivariance/invariance, thus explicit data augmentation should be adopted for more sufficient training. Could you please provide additional details on how data augmentation is adopted here?\n4. In Table 3, it would be nice to explicitly highlight which methods are rotational invariant (thus does not require data augmentation) and which are not, so as for easier comparison.\n5. In Section 4.5.1, the voxel size for discretizing 3D coordinates is set to 0.5A. Since the geometry radius is 4A, this means that the discrete convolutional kernel is of size 8 x 8 x 8, which may have the risk of over-parameterization and under-fitting. Will this affect the performance of such baseline methods?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Well written, easy to follow.\n\nQuality: Good.\n\nNovelty: The motivation is well founded, and the proposed method is novel and well captures the dual discrete and continuous nature of protein structures.\n\nReproducibility: Authors have claimed that the code will be released.",
            "summary_of_the_review": "The motivation of joint modeling of regular sequence structure and irregular geometry structure of proteins is reasonable. The proposed CDConv achieves this goal by decomposing convolutional kernels into independent weights for different sequential displacements and continuous relative spatial encoding, which is rotational invariant and efficient to optimize. However, some comparison with alternative convolutional mechanisms is not well conducted, as the difference in rotation invariance and necessity for data augmentation may also affect these results. Additional discussion may be needed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper9/Reviewer_JFLd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper9/Reviewer_JFLd"
        ]
    },
    {
        "id": "dKS56qk9Tz",
        "original": null,
        "number": 2,
        "cdate": 1666635665038,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666635665038,
        "tmdate": 1668280312547,
        "tddate": null,
        "forum": "P5Z-Zl9XJ7",
        "replyto": "P5Z-Zl9XJ7",
        "invitation": "ICLR.cc/2023/Conference/Paper9/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Discrete convolutions have been widely used on 2D images and 1D protein sequences.  And continuous convolutions have been widely used on 3D data such as point clouds and to some extent on 3D protein structures.  The paper proposes to apply both at once and shows one can obtain improved empirical results with such an approach on protein classification tasks.\n\nHowever, attention based mechanisms e.g. as in AlphaFold and RosettaFold have been largely replacing convolutions over the past 2 years.  The authors should comment on these methods as an alternative.  E.g. why not repurpose the AlphaFold (or a relevant subset of its architecture) to combine the 1D and 3D information?",
            "strength_and_weaknesses": "Strengths:\n* The idea is a simple and practically effective melding of two widely used ideas in protein modeling with a large practical and empirical upside.\n* The empirical performance of the method is a strength.  It has state of the art performance on all classification tasks benchmarked.  Can the authors comment on situations in which they expect the approach might not perform as well?\n\n\n\nWeaknesses:\n* The authors should comment on attention-based alternative methods.  In particular the approach of constructing an NxN dimensional pair representation influenced by both 1D and 3D information, and using it to computed biases on attention weights is at this point very well recognized to be extremely effective (at least in the context of protein structure prediction).  Presumably this same mechanism /architecture could be applied to these classification tasks.  Is there a reason why the authors do not compare to this?\n* I find the terminology \u201c(3+1)D\u201d to be very off-putting and distracting since my mind collapses (3+1) into (4), which I suppose is not intended.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and original.",
            "summary_of_the_review": "I recommend accepting the paper because it clearly describes a simple and effective new architecture for protein classification problems.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper9/Reviewer_hLLm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper9/Reviewer_hLLm"
        ]
    },
    {
        "id": "-vCgBz2hl3z",
        "original": null,
        "number": 3,
        "cdate": 1666665922286,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666665922286,
        "tmdate": 1666665922286,
        "tddate": null,
        "forum": "P5Z-Zl9XJ7",
        "replyto": "P5Z-Zl9XJ7",
        "invitation": "ICLR.cc/2023/Conference/Paper9/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed a Continuous-Discrete Convolution (CDConv) for Geometry-Sequence modeling in proteins. The goal is to increase the accuracy of four tasks, protein fold classification, enzyme reaction classification, gene ontology term prediction, and enzyme commission number prediction. The paper also explained how the CDConv captures the features of protein structure.",
            "strength_and_weaknesses": "Strength:\n1. The paper address a very important problem. \n2. The paper did a good job of integrating 1D features of the peptide chain and 3D features of amino acid coordinates.\n3. The rotation invariance is guaranteed by the convolution kernel design.\n\nWeakness:\n1. There is no formal problem formulation.\n2. The description of the experiment is not clear. For example, the author did not provide details about how to mask the central amino acids in 4.4.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall easily readable. \n\nThe proposed idea lacks technical depth and the method lacks important details. See the weaknesses above.\n\nThe novelty of the proposed idea is marginal.\n\nThe reproducibility is OK.",
            "summary_of_the_review": "The paper is to unify continuous convolution and discrete convolution for modeling protein structure. They claim that the results of their method are state-of-the-art accuracy in four tasks. In addition, they explained how the CDConv capture the features of protein structure, i.e., the early layers tend to focus on the central region of the protein and the late layers can capture the whole structure.\n\nHowever, there are some issues in this paper:\na) The author did not give a formal problem formulation. \nb) The description of the experiment is not clear. In section 4.4, they did not give the details of how to mask the central area. The mask method may change the feature of the continuous features. Thus, more accuracy may be caused by the mask method rather than the importance of central amino acids.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper9/Reviewer_qyBv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper9/Reviewer_qyBv"
        ]
    },
    {
        "id": "H5E9JOo7Vr",
        "original": null,
        "number": 4,
        "cdate": 1666807303255,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666807303255,
        "tmdate": 1666807327210,
        "tddate": null,
        "forum": "P5Z-Zl9XJ7",
        "replyto": "P5Z-Zl9XJ7",
        "invitation": "ICLR.cc/2023/Conference/Paper9/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proposed a new genre of convolution, namely continuous-discrete convolution (CDConv) for protein representation learning, which is folded from 1D discrete amino acid chains into a 3D continuous space. Rather than separately aggregating 1D and 3D representation, the proposed (3+1)D CDConv unifies continuous and discrete convolutions in the 3D and 1D spaces. The proposed method was validated on a variety of protein properties prediction (classification) tasks and achieves SOTA performance on them.",
            "strength_and_weaknesses": "**Strengths:**\n\n1. The motivation is clearly explained. \n\n2. The proposed framework is original and powerful (in experiments).\n\n3. The framework suits the application of protein representation learning well, and it can potentially inspire the community for representing other complex entities. \n \n**Weaknesses:**\n\n1. It seems the embedding method can only be applied to specific tasks. As stated in Section 3.4, the convolution design satisfies rotation invariant, which is sufficient for properties prediction. However, rotation equivariance is usually required for broader scenarios of protein representation. It is questionable whether the proposed scheme can still fit in.\n\n2. The computational efficiency and the scalability of the proposed method should have been discussed. Considering the protein sequence can go more than thousands of tokens, and the current convolution scheme stack multiple layers to progressively enlarge its receptive field, it is necessary to investigate its performance (and speed) on relatively large proteins. \n\n3. As the experimental results are very impressive, revealing the program really helps back up the reliability of the reported scores.\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Minor Questions/Problems:**\n\nFigure 3: according to Figure 3(b), it seems t+1 is also a valid neighbor within the dashed ball (<r) and it is close to t in the sequence (<l/2). Why is it not considered a neighbor of t in the caption?",
            "summary_of_the_review": "The paper has proposed an interesting convolution model for protein representation learning which is of good quality.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper9/Reviewer_nEe2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper9/Reviewer_nEe2"
        ]
    }
]