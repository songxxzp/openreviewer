[
    {
        "id": "z48vzEnyIku",
        "original": null,
        "number": 1,
        "cdate": 1666623202355,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666623202355,
        "tmdate": 1666623202355,
        "tddate": null,
        "forum": "5DkfiQPy9A",
        "replyto": "5DkfiQPy9A",
        "invitation": "ICLR.cc/2023/Conference/Paper1226/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes an attention generation method for ROI detection by adversarial counterfactual without attention label. The attention map can be used to highlight useful information for disease classification and detection. The experiments show its improvements on different medical imaging tasks.  ",
            "strength_and_weaknesses": "Strengths: \n--The idea using counterfactual images for saliency map generation is interesting.\n\n--The improvement for medical imaging taks is significant. \n\nWeaknesses:\n\n--The novelty is simple and limited. \n\n--More experiments are needed, such as existing counterfactual generation.",
            "clarity,_quality,_novelty_and_reproducibility": "the originality is there, but novelty are limited. No code is provided.",
            "summary_of_the_review": "the proposed method is interesting, but the novelty is limited",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1226/Reviewer_3Yeb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1226/Reviewer_3Yeb"
        ]
    },
    {
        "id": "bdahhhf6joi",
        "original": null,
        "number": 2,
        "cdate": 1666638202919,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666638202919,
        "tmdate": 1666638202919,
        "tddate": null,
        "forum": "5DkfiQPy9A",
        "replyto": "5DkfiQPy9A",
        "invitation": "ICLR.cc/2023/Conference/Paper1226/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes Adversarial Counterfactual Attention (ACAT), which first generates regions of interest (ROI) in (medical) images with saliency (heat)map techniques, and then uses these saliency map ROIs to generate soft spatial attention masks at various scales, that are integrated into a deep learning classifier. The counterfactual images are generated using small progressive shifts in the latent space, to encourage a smooth transition from the original image to the counterfactual. ACAT is reported to increase the baseline classification accuracy of lesions and COVID-19 related findings, from CT scans.\n",
            "strength_and_weaknesses": "Strengths:\n\n1. Presents a method for improving classification performance by automatically integrating saliency map information.\n\n2. Compares against several existing saliency map fusion methods.\n\n3. Saliency maps of the various methods visualized.\n\nPossible Weaknesses/Considerations:\n\nThe paper appears to contain two main contributions: regularized latent shift to produce counterfactual images, and thus saliency maps, and the use of these saliency maps to guide classification via attention. While some ablation experiments are attempted with other saliency map methods (e.g. Grad-CAM), these experiments might not be fully complete.\n\n4. Segmentation performance with ground truth annotations is reported for the regularized latent shift method against other saliency map methods, in Section 4.3 and Appendix H. To begin with, the attribution map evaluation in the main text appears to consider only \u201cthe pixel with the greatest value in each CT scan\u201d, with the annotated region. It is not clear if the consideration of just a single pixel (albeit of greatest value) in an entire CT scan to evaluate the performance of a saliency map, is particularly meaningful.\n\n5. IOU and Dice score performances are then reported in Appendix H, but details such as how each saliency map is thresholded do not appear to be described. Moreover, the set of saliency map methods tried in Appendix H appear not entirely the same as in Section 4.3 (NoRec is missing).\n\n6. The set of saliency map methods tested does not appear very comprehensive; more recent methods such as Integrated Gradients do not appear included.\n\n7. The contribution of different saliency map methods to classification performance (as reported in Tables 1 & 2) does not appear to be evaluated directly, as Table 1 only reports performance against other frameworks.\n\n8. For classification performance, only accuracy is reported. It would be highly recommended for common metrics such as sensitivity, specificity and AUROC to be included, to better reflect the performance of the various classifiers over the full range of possible thresholds.\n\n9. The contribution of multiple attention masks at different scales (Section 3.2.1), instead of at a single scale, does not appear directly evaluated.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The counterfactual saliency map technique is clearly motivated and described, as are the datasets and experiments. The main technical novelties appear the progressive optimization of the latent shift method, and the integration of saliency map attention at multiple scales.\n",
            "summary_of_the_review": "This paper proposes an Adversarial Counterfactual Attention (ACAT) method that uses counterfactual saliency maps to guide classifiers through attention. Some uncertainty remains as to whether the proposed counterfactual saliency map method is optimal for the classification task, and as to the evaluation of the saliency maps on annotations.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A\n",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1226/Reviewer_svqR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1226/Reviewer_svqR"
        ]
    },
    {
        "id": "cSCd8aRlRJS",
        "original": null,
        "number": 3,
        "cdate": 1666969160644,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666969160644,
        "tmdate": 1666969160644,
        "tddate": null,
        "forum": "5DkfiQPy9A",
        "replyto": "5DkfiQPy9A",
        "invitation": "ICLR.cc/2023/Conference/Paper1226/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a method based on saliency maps to guide a classifier in tasks where only part of the image is relevant. The saliency maps are generated using an adversarial gradient descent on a fixed classifier and autoencoder. They are then combined with the classifier at several scales to finetune it. The method is validated on 2 datasets. ",
            "strength_and_weaknesses": "### Strengths:\n- the method is simple (no iteration on the adversarial parts)\n- the shown results are good\n- good related works\n\n### Weaknesses:\n- I think that the main weakness of the method is its novelty: in Flores et al., saliency maps where already generated using an adversarial approach with an auto-encoder and the contributions on this part seems to be the use of several smaller gradient steps instead of one \u00a8large\" step.\n- Similarly, the network architecture is similar to ones previously used to incorporate saliency maps but with a multi-scale approach. Once again, the results are better with this approach but when a proposed model is a small improvement over a previous one, I feel that more experiments are required to add value to the article: for example, is it really using a multi-scale model that helps or the fact that the smaller scale can detect small RoI? (as suggested by the drop of performance for large RoI).\n- the dropout experiment if I understand it correctly is not fully convincing. If the dropout is not spatially constrained, information from all parts of the image still go through even with p=0.5. Maybe a layer with a random cutout (or RandomErasing in torch) might be more similar to a RoI approach.\n- Maybe adding a small \u00a8Algorithm box\" with the inputs and outputs of both steps would be good (First step: pretrained model and auto encoder -> RoI detector, 2nd step: baseline + RoI detector -> final classifier) \n",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity:\nThe article is globally clear (minus a summary of the method, cf weaknesses) and the related work is good.\n\n### Novelty:\nI fell that the novelty is a bit missing\n\n### Reproducibility:\nThe method seems easy to implement and the authors indicated that code would be available.",
            "summary_of_the_review": "My initial recommendation tend towards rejecting this work: while the results are good, I feel that the novelty of the proposed method is not sufficient and that more ablations studies to fully understand the model are necessary to accept it.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1226/Reviewer_McTW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1226/Reviewer_McTW"
        ]
    }
]