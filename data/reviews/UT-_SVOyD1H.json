[
    {
        "id": "A2l-5sEb12",
        "original": null,
        "number": 1,
        "cdate": 1666476490439,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666476490439,
        "tmdate": 1666476490439,
        "tddate": null,
        "forum": "UT-_SVOyD1H",
        "replyto": "UT-_SVOyD1H",
        "invitation": "ICLR.cc/2023/Conference/Paper1720/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Authors provide the first algorithms for provably vanishing regret for Contextual Bandits with Concave Rewards.",
            "strength_and_weaknesses": "Strengths:\n  * Multi-objective criterion arise frequently in practice.\n  * Reduction-based algorithm design maximizes reuse of existing and novel componentry and overall utility of approach.\n     * e.g., the discussion mentions constraints (good: reduction to CB-knapsack algos might work).\n  * Figure 1 (right) is particularly persuasive.\n\nWeaknesses;\n  * FW-LinUCB will give you nice theorems, but composing with the infinite action linear version of square cb[2] will give you an algorithm people will actually want to deploy. \n    * We never use UCB algos in production here because they are not robust to reward feedback delay.\n    * You might also find interesting a composition with a smoothed regret variant of square cb for infinite action spaces [3].\n  * It's not clear how to elicit the trade-off function in practice.  \n    * For example, does the Lin et. al.[1] elicitation technique yield a concave tradeoff function (or, e.g., would preference elicitation be viable over a constrained model class like generalized gini)?\n\n[1] https://arxiv.org/abs/2203.11382\n\n[2] https://arxiv.org/abs/2207.05836\n\n[3] https://arxiv.org/abs/2207.05849",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity gets an A+.  Authors cover a *lot* of territory while managing to retain intelligibility and hit the page limit.  Kudos.\n\nQuality and originality also gets an A+.  This is clear improvement over Agarwal 2016.",
            "summary_of_the_review": "Exemplary work.\n\nConfidence is just a 3 because I didn't check the proofs.  If I get time I'll circle back to them.  \"Math/other details were not carefully checked.\"",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1720/Reviewer_4Gmp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1720/Reviewer_4Gmp"
        ]
    },
    {
        "id": "yJDKLlupZLI",
        "original": null,
        "number": 2,
        "cdate": 1666636543990,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666636543990,
        "tmdate": 1666636543990,
        "tddate": null,
        "forum": "UT-_SVOyD1H",
        "replyto": "UT-_SVOyD1H",
        "invitation": "ICLR.cc/2023/Conference/Paper1720/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers contextual bandits with multi-dimensional rewards, with a known concave function that transforms the cumulative multi-dimensional rewards to a one-dimensional value to be maximized. This paper proposes a method to reduce the CBCR problem to scalar-reward bandits which has been extensively studied, so that no restrictions necessary on the policy space. Also, a smoothing technique is provided in case of non-smooth concave function $f$. Then, the paper introduces an application using their reduction method, which focuses on contextual ranking bandits with fairness-aware objectives, and shows that their method is efficient with regret guarantee. Experimental evaluations are presented.",
            "strength_and_weaknesses": "Strengths:\n* This paper proposes an interesting method to reduce CBCR problem to a studied problem, being the first to remove restrictions on the policy space.\n* The reduction method has some generality to cover a class of applications that can be modeled by CBCR framework, such as the fair ranking problem mentioned in the paper.\n\nWeaknesses:\n\nOverall, I believe this is a high-quality paper, which has some solid contributions that may benefit future works. Here, I have some minor suggestions and questions:\n* In the ``setting'' paragraph in Section~2, the reward is defined as a noisy multi-dimensional reward. I would suggest authors to further declare the noise, e.g., the support of the random noise; the restrictions on the distribution; is it heavy tailed? As the distribution of the noise can heavily affect the policy design, even it may have zero mean. Or, if the only requirement of the noise is zero mean in this work, please also mention that.\n* Throughout the paper, the concave function $f$ on the reward is assumed as known by the learner, and the reduction also requires the knowledge of $f$. What if $f$ is unknown so that $f(\\sum_t r_t)$ is unknown? How much difficulty will be brought to address the CBCR problem with an unknown $f$? As I think an unknown $f$ is more commonly seen in real world. Or, what will be the case if both the reward $r_t$ and $f$ are unknown and we only know $f(\\sum_t r_t)$? Nonetheless, both alternative settings can be considered in future works.",
            "clarity,_quality,_novelty_and_reproducibility": "This work has good quality in writing and clarity. I have no problem in understanding the ideas. The novelty and contributions are decent to be published.",
            "summary_of_the_review": "Overall, I enjoyed reading this work, and I learnt interesting results from it. The idea of the reduction method is novel and general. Related literature is well-discussed in Introduction section.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1720/Reviewer_Gk2g"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1720/Reviewer_Gk2g"
        ]
    },
    {
        "id": "1V0zF0Pei3p",
        "original": null,
        "number": 3,
        "cdate": 1666871671058,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666871671058,
        "tmdate": 1666871671058,
        "tddate": null,
        "forum": "UT-_SVOyD1H",
        "replyto": "UT-_SVOyD1H",
        "invitation": "ICLR.cc/2023/Conference/Paper1720/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies a contextual bandit problem with **stationary** context and **fixed** action set. At each step, the environment randomly selects a context $x$, then the player needs to choose an action $a$ that maximizes $f(\\mu(x)a)$ where $f(\\cdot)$ is a known concave function and $\\mu$ is an unknown matrix-valued function. This paper solves this problem by nesting Frank-Wolfe algorithm with standard linear/contextual bandit algorithms.\n",
            "strength_and_weaknesses": "\n### Strength\n\nThe paper provides a new setting, designs a new algorithm, proves its theoretical guarantee, and conducts experiments on real-world data to validate its performance. The paepr is rather complete for this problem.\n\n### Weakness\n\nBy considering only the stationary context set and fixed action set, the paper is actually more restrictive than most contextual bandit literature that considers possibly adversarial context sets. In particular, the paper shall not claim at the end of Sec. 2 that it \"subsumes classical contextual bandits.\" Also, the \"reduction\" in Sec. 3.2 is not that rigorous because LinUCB and SquareCB both work for adversarial contexts, meaning that the reduction cannot be understood as that the algorithm in the paper could replace LinUCB or SquareCB. Consequently, I am concerned on the impact of this paper over the bandits learning society.\n\nThe paper does not contain much technical novelty that could possibly inspire future work, as the proof seems to be a straightforward combination of Frank-Wolfe algorithm.\n",
            "clarity,_quality,_novelty_and_reproducibility": "\nThe paper refers to $\\mu(x_t)a_t$ as \"reward\" and defines regret as the difference between $f(\\text{reward})$ and the best $f(\\text{reward})$. This is different from the classical way of defining regret as the difference of reward and may confuse some readers.\n\nApart from this, the paper is generally well-written and I did not find any apparent typos in main text. Some LaTeX errors in appendix need be fixed, e.g., Lemma ?? in page 25.\n\nThe paper appears to supplement enough details for reproduce the results, including the code. I did not run the code, though.\n",
            "summary_of_the_review": "\nThe setting does not sound interesting or important to me. Besides, I have some concerns as prescribed in \"Weakness\" section.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1720/Reviewer_joWt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1720/Reviewer_joWt"
        ]
    },
    {
        "id": "wI18rNWwKZv",
        "original": null,
        "number": 4,
        "cdate": 1667190174977,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667190174977,
        "tmdate": 1667190174977,
        "tddate": null,
        "forum": "UT-_SVOyD1H",
        "replyto": "UT-_SVOyD1H",
        "invitation": "ICLR.cc/2023/Conference/Paper1720/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers contextual bandits with concave rewards where the rewards are defined by a concave objective function with stochastic reward vectors. This setting removes the restrictions on the policy space compared to prior works. Under this setting, this paper proposes an (first) algorithm with the vanishing regret. The theoretical results and techniques could be applied to fair ranking problems. Experimental results also support the derived results. \n",
            "strength_and_weaknesses": "This paper is well written. The model (setting) in this paper is interesting, well motivated (based on the provided concrete examples) and more general compared to prior works. The geometric interpretation of CBCR (policy space spanned by a convex set) is a nice explanation and illuminates the optimization directions. This paper provides a nice and elegant reduction from CBCR regret to a scalar-reward bandit problem based on Frank-Wolfe analysis. This bypasses the core challenges in optimization in policy space. However, it is not clear  (at least to the reviewer) whether the obtained regret for CBCR (under this specific setting) is optimal or not. This paper lacks analysis and explanation in this aspect. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper talks about interesting and important topics related to the general concave bandit problem with good quality and clarity. The idea is novel as far as I know together with the techniques (not original but nice apply).  \n",
            "summary_of_the_review": "Overall, I think that the studied model in this paper is well-motivated with more general problem setting. The proposed algorithm is sound  together with the related analysis. Therefore, I recommend \u201caccept\u201d.\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1720/Reviewer_aNts"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1720/Reviewer_aNts"
        ]
    }
]