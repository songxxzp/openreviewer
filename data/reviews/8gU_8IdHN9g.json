[
    {
        "id": "D4YUlLdPPV",
        "original": null,
        "number": 1,
        "cdate": 1666533977098,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666533977098,
        "tmdate": 1666533977098,
        "tddate": null,
        "forum": "8gU_8IdHN9g",
        "replyto": "8gU_8IdHN9g",
        "invitation": "ICLR.cc/2023/Conference/Paper2018/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper discusses the problem of detecting graphs that have been generated algorithmically. The paper discusses four different types of scenarios from the simplest (where the model knows all the possible details about the generation process) to the hardest (where nothing is known in advance).\n\nThe classifier used is an end-to-end trained GNN encoder with an MLP used to output the classification outcome.\n\nThe classifier has a decent performance, although not super high making the task challenging.",
            "strength_and_weaknesses": "# Strengths\n\n1. Novel problem\n2. Method is simple enough to be easy to implement\n\n\n# Weaknesses\n\n1. The method itself could be used to detect generated graphs that cannot be detected easily and thus being used in an attack\n2. The classifiers that  authors tested on their datasets are pretty much \"standard\". I wonder wether there might be some better architecture that can be used to take specific care of this task",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and novel. It is also straightforward to replicate the experiments.",
            "summary_of_the_review": "Some questions to authors:\n\n1. When you write: \"... use Euclidean Distance to measure the 1-nearest-neighbor similarity between each generated graphs and real graph sets...\" ==> how can you make sure that euclidean in the embedding space is the right distance? Have a look at these two papers (https://www.sciencedirect.com/science/article/abs/pii/S002002551630696X ; https://arxiv.org/abs/1812.09095) is there anything that you could use to better compute the 1-nearest neightbor?\n\n2. If you have a good way to detect generated graphs, wouldn't this be useful to filter out generated graphs that are difficult to spot? How would you prevent this from happening?",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Potentially harmful insights, methodologies and applications"
            ],
            "details_of_ethics_concerns": "As I said in my review: it is possible to use this to actually devise adversarial attacks to GNN algorithms. This mighr represent a possible issue for society.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2018/Reviewer_eg3n"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2018/Reviewer_eg3n"
        ]
    },
    {
        "id": "6lN-XGwikD8",
        "original": null,
        "number": 2,
        "cdate": 1666656067701,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666656067701,
        "tmdate": 1666656067701,
        "tddate": null,
        "forum": "8gU_8IdHN9g",
        "replyto": "8gU_8IdHN9g",
        "invitation": "ICLR.cc/2023/Conference/Paper2018/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "DISCLAIMER: I reviewed this paper for NeurIPS 2022 earlier this year. As far as I can tell, not much (if anything) has changed in this manuscript. As such, I will reiterate the points in my original review.\n\nSummary:\n\nThe authors investigate the performance of existing graph neural network models to discern between real graphs and \"fake\" graphs generated synthetically, potentially for a nefarious purpose. The authors explore 4 scenarios of increasing complexity and real-world relevance, as well as 3 different approaches from the machine learning literature to learn to discern between real and fake graphs.",
            "strength_and_weaknesses": "Strengths:\n- Experimental results provide some practical insights on the performance of different ML approaches for the target task\n- Authors explore 4 scenarios of increasing complexity, which provides a valuable comparison on how the models perform under ideal circumstances vs. more realistic circumstances.\n\nWeaknesses:\n- Unclear significance and relevance of the addressed problem. The authors' argument is that they are preemptively studying a problem that may become relevant in the future. It is challenging to assess significance at this moment. It is also challenging to assess whether the performance obtained by the models would be good or not in practice for this hypothetical task. Having a case study would help justify the authors' claims of significance.\n- No novelty. The evaluation and data generation is performed using existing methods.",
            "clarity,_quality,_novelty_and_reproducibility": "Originality: The proposed methods are not novel. The main novelty in the paper is proposing the problem of discerning between real graphs and fake graphs. I argue this is not a big intellectual/technical leap from the analogous problem in image/video data.\n\nClarity: The paper is very clear. The notation, proposed problem, datasets, and evaluation are all clear to me.\n\nQuality: I believe the evaluation is of above average scientific quality. The technical quality is limited, as none of the methods are novel.",
            "summary_of_the_review": "See my comments above. My main concern with this paper is the lack of novelty. If the main contribution of the paper is a new ML task, I do not find compelling evidence in the paper to suggest that this task will have an application in the future. It may very well be the case that this task will become relevant for a certain domain at some point. But we simply do not know, and we can just \"extrapolate\" from other types of data, such as images.\n\nI am curious as to how the authors arrived to the generated graph detection problem? Was there a particular application in mind where fake graphs are indeed a concern? If so, please discuss in the paper, as it would *significantly* strengthen the contribution. Or was the thought more along the lines of \"if the task of detecting fake images is of interest to the community, why not detecting fake graphs instead\"?\n\nIf the idea of a new task is indeed the crux of the contribution, I would recommend this paper to be accepted as a short letter, an extended abstract, or a poster, not as a full research paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2018/Reviewer_4WuZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2018/Reviewer_4WuZ"
        ]
    },
    {
        "id": "Aa2jMu7qWQ",
        "original": null,
        "number": 3,
        "cdate": 1666707347470,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666707347470,
        "tmdate": 1666707347470,
        "tddate": null,
        "forum": "8gU_8IdHN9g",
        "replyto": "8gU_8IdHN9g",
        "invitation": "ICLR.cc/2023/Conference/Paper2018/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors present a new problem, how to detect real graphs and \"fake\" graphs. The authors then explore four scenarios where the detection algorithm applies, and propose three different machine-learning methods to detect fake graphs.",
            "strength_and_weaknesses": "Strengths,\n\nS1: Authors explore four scenarios, which provide both ideal circumstances and realistic circumstances.\nS2: This paper proposes a new problem.\n\nWeaknesses,\n\nW1: The motivation is not strong and seems artificial. It is not clear how the generated graphs are used in malicious misuses or misinformation broadcasts.\n\nW2: The novelty is limited. The proposed methods are based on existing works.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and well-organized. It is easy to follow the proposed ideas and technological details. \nThe novelty of this paper is limited. ",
            "summary_of_the_review": "I recommend a weak reject for this paper because of its limited novelty and the weak motivation.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2018/Reviewer_chCC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2018/Reviewer_chCC"
        ]
    }
]