[
    {
        "id": "PIDNx1-la_h",
        "original": null,
        "number": 1,
        "cdate": 1666287297976,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666287297976,
        "tmdate": 1669135980324,
        "tddate": null,
        "forum": "IA96Pn7A08h",
        "replyto": "IA96Pn7A08h",
        "invitation": "ICLR.cc/2023/Conference/Paper1387/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors focus on the problem of identifying potential generalization gaps that can be caused by selectively choosing train a test sets in supervised learning problems.  The authors propose an algorithm called Learning to Split (LS) that iteratively trains a model, uses a three part objective to train a \"splitter\" model to assign samples train and test sets, and then again retrains a model until the gap between train and test performance ceases to increase.  They show empirically that LS is able to find splits that have greater generalization gaps between train and test performance than randomly splitting the data.  Further, they show that methods that attempt to debias models work well when labels indicating subpopulations are given, but when not provided such labels, debiasing methods perform no better than standard empirical risk minimization.",
            "strength_and_weaknesses": "Strengths\n1. The problem of automatically identifying biases in data sets is clearly one of major practical importance to the use of machine learning techniques in real-world setting.\n2. Their technique is conceptually simple, and seems rather easy to implement.\n3. The results reported clearly show LS is able to split data to increase the generalization gap compared to random sampling on a large number of varied data sets.\n\nWeaknesses\n1. I think the problem as set up in the paper may lack some practical utility.  I do not see the direct connection bween intentionally biasing train and test splits and measuring the generalization gap and bias that can arise when training a model on the data set.  What is not clear is that if a normal training procedure which randomly splits train and test data results in a sufficiently accurate model on the subpopulation discovered by LS.  If so, then LS is measuring a worst case generalization performance that may not be ever realized.  I think a more compelling set up would be if a training data is representative of a standard split, and a subpopulation can be found within a test set for which a model performs poorly.  This is much more representative of how data is used to train a model.\n2. I think the experiments could benefit from other baseline lines than random splits.  For instance, in the data sets where auxiliary attributes are available (like CelebA), you could split the train/test data across attributes and measure the generalization gap.  Doing this can result in different \u201coracle\u201d baselines that better explain generalization gap relative to clear biases.  Further, I feel a conceptually much simpler and heuristic approach can be taken based on the same principle as (2).  At each outer iteration, simply choose 25% of the samples, accounting for label distributions, that the predictor performed the worst on.  This doesn\u2019t require a complex splitter model, can exactly satisfy the desired constraints, and is in the same spirit as LS.\n3. The regularization approach seems inexact for a sampling procedure, and the constraints attempted to be imposed by the regularization terms are not satisfied in the experiments (~82% of the examples are in the train set for the \u201cBeer Look\u201d experiment).  It\u2019s not clear how important this is to be exact but if it is important, then stronger enforcement of constraints needs to be considered.\n4. Overall the paper doesn\u2019t provide much of principled framing of the problem being solved nor the proposed technique.  For instance, since label distributions are controlled for in LS, it would seem the cause of generalization gap is due to either concept drift (p(y|x) changing) or covariate shift (p(x) changing).  Without identifying the underlying formal definition of bias, it is difficult to understand what is being modeled in a principled manner.  Similarly, it is difficult to reason about how much LS is guided by distributional shifts in the data or the predictive power of the predictor (i.e. Is the generalization gap found by LS a function or the data, the model, the training procedure, or all of the above?).\n5. The justification for the \\delta parameter is taken out of context from Centola et al. 2018  Their work focuses on what proportion of a subpopulation is needed to tip a majority opinion to a minority opinion.  This has little to do with the problem that is the focus of this work.\n\nMinor Points/Questions:\n1. (2) can use some further elaboration.  As I understand it, the second term is and indicator if the predictor predicts the true label. This should be mentioned \n2. There are no details on how (3) is optimized.  The free variables z_i are in {0,1}, which makes this not an direct application of gradient based methods as written.  How is it done?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity - Overall the writing is clear.  The notation, however, could use elaboration. Specifically the equations in 3.3 and 3.4 could use some elaboration about specifically is meant by their notation.\n\nQuality - Beyond the strengths and weaknesses above, I have no further notes on the quality of the work.\n\nNovelty - Much of the proposed methodology is rather straight-forward and does not introduce many novel concepts. The main source of novelty of the work is in the posing of the problem itself: The task of splitting a data set so that a model achieves high generalization gap between test and train sets.  While i have not encountered work performing this exact task, a lot of work has focused on sources of bias.  Also, there is another parallel line of work on test and evaluation of ML models that aims to uncover biases present in data collections.\n\nReproducability - Algorithm 1 lacks any level of specificity in terms of how the sampler is used to split data and what optimization procedures are used to update the sampler or predictor.  As such, I feel it is very difficult to reproduce this work. ",
            "summary_of_the_review": "Overall, I feel there are three major weaknesses of the paper that influenced my decision.\n1.  I do not believe the specific problem formulation considered in this paper has much practical significance.  I am not convinced that intentionally splitting whole data sets to maximize a generalization gap necessarily means that training a model on the data set using standard data splits and procedures will be biased.\n2. Due to lack of principled discussion and justification, I am not convinced that the generalization gap can entirely be explained by bias in the data and not biases from the specific predictor model or training procedure.\n3. The experiments are quite limited in that there are baselines that should be used to justify the proposed approach.\n\n(see rebuttal discussion below for more details on final scoring)",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1387/Reviewer_Jd9v"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1387/Reviewer_Jd9v"
        ]
    },
    {
        "id": "BhjW8RPdvvD",
        "original": null,
        "number": 2,
        "cdate": 1666484338832,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666484338832,
        "tmdate": 1668634622608,
        "tddate": null,
        "forum": "IA96Pn7A08h",
        "replyto": "IA96Pn7A08h",
        "invitation": "ICLR.cc/2023/Conference/Paper1387/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes using an adversarial bi-level optimization to find hard train/test splits of a dataset. More specifically, the inner loop corresponds to normal ERM training on that train/test split, and the outer loop learns a Splitter that changes the train/test split to make generalization in the inner loop difficult. The authors use two regularizers to avoid degeneracies: first, constraining the ratio of train/test dataset sizes, and second, constraining the label ratio in the two datasets (to avoid all labels being in the train split and all of the others being in the val split). This automatic splitting can then be used to identify biases in the dataset, like spurious correlations, and you can combine it with group DRO to get robust models.",
            "strength_and_weaknesses": "Strengths:\n- Interesting and novel idea and approach, particularly the idea of using this bi-level optimization to identify biases in datasets.\n- The paper is clearly written and provides a thorough empirical analysis of the proposed method. \n\nWeaknesses:\n- The algorithm can be computationally expensive, since it needs to retrain erm each time in the inner loop. Maybe it doesn't need to be trained to convergence? It would be interesting to see what would happen if each inner loop isn't trained fully to convergence. Another interesting experiment to see would be to alter the algorithm to just train the last layer in the inner loop (e.g. by pretraining the earlier layers with an initial ERM run), to reduce the computation requirements. \n\nNot a weakness of this paper, but I would also be curious to see if the splitting could be used in other settings, such as OOD detection. ",
            "clarity,_quality,_novelty_and_reproducibility": "I think this paper proposes a clever novel idea and method and is written clearly. ",
            "summary_of_the_review": "The proposed idea is novel and interesting, so I recommend accepting the paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1387/Reviewer_Fe8j"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1387/Reviewer_Fe8j"
        ]
    },
    {
        "id": "n1GU4KFh0C",
        "original": null,
        "number": 3,
        "cdate": 1666542927632,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666542927632,
        "tmdate": 1670519184071,
        "tddate": null,
        "forum": "IA96Pn7A08h",
        "replyto": "IA96Pn7A08h",
        "invitation": "ICLR.cc/2023/Conference/Paper1387/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper studies a very interesting and novel problem setting: how to split the data in a way that when a model is trained on one partition cannot generalize to the second partition: while this task does not make realistic sense, careful studying of it will surely reveal many other properties that are important in the machine learning community. On the other hand, I feel like the actual algorithm proposed by this paper used for this new task is still in its fairly preliminary stage, with multiple questions unanswered. ",
            "strength_and_weaknesses": "- strengths: \n   - the paper studies a very new and interesting problem\n   - figures/visualizations are stunning\n   - the writings are very clear (although might be too detailed)\n   \n- weakness:\n   - as a new study, many new questions are left unanswered for the community to follow in the later stage\n   - while the visualizations are stunning, they look more like belong to brochures instead of academic papers, many figures do not necessarily need such visualization to explain. A simple table will do the job and then save a lot of space for more detailed discussions on other aspects. ",
            "clarity,_quality,_novelty_and_reproducibility": "- clarity: good\n- novelty as a task: great\n- novelty as a technique: \n     - the algorithm to partition the data is quite limited as it is a fairly straightfoward search through the dataset. \n          - the two constraints at Eq 1 seem to be an over-complicated paraphrase of simple ideas (sufficient training samples and label balance)\n          - line 7 and line 8 at algorithm 1 are random samples (that can probably be much improved with more heuristics, e.g., whether searched dataset will update the later search strategies)\n\n- quality\n     - it seems weird that eq.3 does not involve any hyperparameters to balance the weight between the main objectives and the regularization loss. \n          - if this is a typo, then detailed discussion will be needed on the choice of the hyperparamters\n          - otherwise, then probably more discussions will be needed on why such terms are not needed\n    - the fact the group-DRO works on the new partition data seems to offer a piece of evidence that the method doesn't work that well. \n         - group-DRO works by leveraging the minority of the samples during the training, however, if the algorithm successfully achieves its goal as depicted in Figure 1, there probably do not exist any minor samples in the training set for DRO to use\n         - probably it's more convincing to test other algorithms that explicitly account for the bias, as can be useful without the usage of the minor samples. \n    - it might be better to use the performances of these more advanced algorithms to evaluate the performance of the partition algorithm (and its variants, as ablation studies), then the detailed setup of all these algorithms will become essential. \n\n- reproducibility:\n     - given the limitation of the novelty of the method, it is probably necessary to discuss computing loads in details in the main manuscript (any evidence a more efficient algorithm is not even needed?)\n\n- minor\n     - the authors offer a good summary of papers explicitly discussing about biases, there are many other relevant papers following the debiasing strategy but do not use these keywords as this main ideas fall into a greater scope of ML robustness. It's probably better to expand the literature scope to a broader scope, e.g. (each of these represents a whole branch, instead of the listed individual paper)\n          - Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering \n          - Learning robust representations by projecting superficial statistics out \n          - Invariant risk minimization",
            "summary_of_the_review": "Overall, I think this is a greatly interesting paper with a lot of potentials, but probably a bit preliminary at this moment. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1387/Reviewer_GE6C"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1387/Reviewer_GE6C"
        ]
    },
    {
        "id": "q1qjMsoQKN",
        "original": null,
        "number": 4,
        "cdate": 1666747135132,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666747135132,
        "tmdate": 1666747135132,
        "tddate": null,
        "forum": "IA96Pn7A08h",
        "replyto": "IA96Pn7A08h",
        "invitation": "ICLR.cc/2023/Conference/Paper1387/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes Learning to Split (ls), a novel algorithm that automatically detects a potential bias in datasets. More specifically, ls consists of a Splitter and a Predictor. The Splitter learns to divide the dataset into a train split and a test split. Then, the Predictor is trained using the divided train split and measures the generalization error with the test split. The Splitter is then trained in the direction in which the generalization error increases. That is, ls find a train split that cannot generalize well in the test split and then observe the bias existing in the dataset. The authors validated that ls behaves as expected on datasets with bias annotation. Finally, when ls is combined with debiasing methods that require bias annotation during training, such as GroupDRO, these models were trained successfully without bias annotation",
            "strength_and_weaknesses": "Strength\n\n1. The paper is logically well-written, including a discussion of the limitations of ls. In particular, additional experiments related to label noise further enhanced the reliability of the paper.\n\n2. Several experiments have well validated the effect and applicability of ls. In particular, the experimental results using GropuDRO with ls are impressive. It would be interesting to conduct experiments with ls applied to other methods using bias annotations in the validation phase.\n\n3. This research tackles an important question, and I believe it is a helpful research direction for the community.\n\nWeakness\n\n1. I think there should be further experiments and discussion on how the \\delta value affects the results of ls. Therefore, during the review period, I hope the authors validate that the model works robustly even with various \\delta values. Also, it would be helpful to understand ls if the authors address how the model behaves when the percentage of minority groups varies rather than 25%.\n\n2. As the authors mentioned in Section 5, ls seems to have issues with scalability. To further discuss this concern, I think the training time of other debiasing methods should be provided in Table 2 of the Appendix.\n\n3. In Table 1, the source of the results brought from the previous paper is omitted. That information should be included to determine whether the experimental settings of ls are the same as those of the baselines.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is logically well-written and easy to follow. Also, to the best of my knowledge, this is the first paper to successfully deal with detecting biases in datasets without bias annotations.",
            "summary_of_the_review": "The main contribution of this paper is that potential biases present in datasets can be detected without bias annotations. Although there are concerns regarding scalability, I believe it is valuable as the first paper that automatically detects potential biases.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1387/Reviewer_pwSX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1387/Reviewer_pwSX"
        ]
    }
]