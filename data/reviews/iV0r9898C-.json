[
    {
        "id": "crxGfRMu_t",
        "original": null,
        "number": 1,
        "cdate": 1666578349265,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666578349265,
        "tmdate": 1670258645526,
        "tddate": null,
        "forum": "iV0r9898C-",
        "replyto": "iV0r9898C-",
        "invitation": "ICLR.cc/2023/Conference/Paper2348/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper focuses on few-shot anomaly detection where only a few normal samples are available in training. The new method leverages contrastive learning to transfer pre-trained from the source domain to target domains supported by few-shot samples. In addition, the instance positive pair loss is used to tight up normal samples, while incorporating negative pair loss to separate the anomaly and normal samples (with prior and generated samples). Last, the multivariate Gaussian and density method are used for final detection.",
            "strength_and_weaknesses": "Strength:\n* One of the major strengths of this paper is the extensive experiments on six benchmarks and convincing results.\n* Another strength is the idea of adapting pre-trained networks to target domains through contrastive learning under few-shot AD.\n\nWeakness:\n* It would be helpful to provide visualization after the outputs fit the multivariate Gaussian. This may further demonstrate if positive/negative pairs are grouped/separated as expected.\n* Some experiment details are missing, e.g., how many normal images were used in Sec. 4.5. \n3* Some competitive methods such as TDG (as mentioned in the paper) could be added to the experiments on cifar10-c and cifar100-c.\n* The state-of-the-art CSI [1] can run under few-shot setting and could be evaluated here, too. Note most key steps in this paper are very similar to CSI, so it is strongly recommended to compare with CSI in few-shot tests.\n* It should be noted that in Fig. 1 after negative augmentation, the image however did not change to an anomaly, as expected.\n\n[1] Jihoon, et al; CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear in general but could be better illustrated with visualization of multivariate Gaussian for additional interpretation and insights.\n\nThe novelty of this paper is limited in the sense that most key steps are very similar to the SOTA method CSI, although using domain adaptation for few-shot setting is somehow interesting and useful in most applications.\n\nThe implementations are well-elaborated and can be reproduced.\n",
            "summary_of_the_review": "In brief, this paper presents an interesting few-shot AD method, which includes two steps: domain adaptation for pre-trained networks, and contrastive learning via building positive- and negative sample pairs. Evaluations are extensive and promising. However, the major concern is the novelty and its difference and comparison with the SOTA method such as CSI.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2348/Reviewer_n46i"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2348/Reviewer_n46i"
        ]
    },
    {
        "id": "njnu_hSan5",
        "original": null,
        "number": 2,
        "cdate": 1666653719776,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666653719776,
        "tmdate": 1666653719776,
        "tddate": null,
        "forum": "iV0r9898C-",
        "replyto": "iV0r9898C-",
        "invitation": "ICLR.cc/2023/Conference/Paper2348/-/Official_Review",
        "content": {
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.",
            "summary_of_the_paper": "The paper proposes contrastive training and transfer learning applied to the problem of industrial defect identification via \"anomaly detection\". In particular, the negative pair loss is introduced as novelty in the paper.",
            "strength_and_weaknesses": "Strenghts:\n- The approach shows good empirical results in 4 datasets\n- The ideas for tweaking the learning using across distance positive pair and the negative pair loss may be useful in some scenarios beyond anomaly detection applied to industrial defect \n- Many experiments are provided to investigate the behaviour of the method and the proposed ideas\n- Using CutPaste as a way to synthesize negative instances is a good insight.\n\nWeaknesses\n- All new ideas are somewhat already proposed before. Although the authors put together all those with success for the application at hand, that makes the paper less novel\n- The backbone may be deterrent to the final results. Maybe using a stronger backbone such as ViT-Dino could improve results of all baselines and diminish the amount of improvement claimed by the method.\n- In terms of the application the paper does not provide a lot of insight. That is, why the proposed approaches benefit the application? Why does the defects are easier to spot after the representations are learnt with constrastive learning? Why this application is a good downstream task?\n- The batchsize may play a significant role in the learning process, but this is not mentioned or studied in the paper.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and well written overall. I don't see any huge problem with reproducibility\n\nIn terms of the problem, the datasets have a large number of defects in testing: usually in inference time anomaly detection tasks have much less anomalies than \"normal\" data. It would be interesting to see how the model behaves under a more \"realistic\", unbalanced, distribution.\n\nAll new ideas are somewhat already proposed before. Although the authors put together all those with success for the application at hand, that makes the paper less novel,",
            "summary_of_the_review": "The paper is well written and has some clever ideas, but there is no significant insight on the application, no reasons or insights are provided on why the methods work in the anomaly detection setting. Also, there is not much novelty on the main proposed methods.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2348/Reviewer_gtEo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2348/Reviewer_gtEo"
        ]
    },
    {
        "id": "oB2eUQAgqiw",
        "original": null,
        "number": 3,
        "cdate": 1666750916878,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666750916878,
        "tmdate": 1666750916878,
        "tddate": null,
        "forum": "iV0r9898C-",
        "replyto": "iV0r9898C-",
        "invitation": "ICLR.cc/2023/Conference/Paper2348/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper is focused on the few-shot anomaly detection problem. It presents a method that combines contrastive learning for adapting a pre-training model to the target domain, a cross-instance positive pair loss, an option to incorporate negative pair loss, and density-based anomaly detection. They show some promising experimental results for few-shot anomaly detection on several public datasets.",
            "strength_and_weaknesses": "Strengths: \n1. The proposed idea of applying contrastive learning for adaptation seems interesting. \n2. The experimental results on 4 different datasets are reported with promising results.\n\nWeaknesses:\n1. The paper is not well written. It is difficult to understand the main idea of the paper. How is the adaptation of a pre-trained model done with contrastive learning? Why doers the proposed training method provide good model adaptation? In addition, many important delaits for the implementation are missing. They didn't provide the network architecture of the proposed model.\n\n2. The novelty proposed in this paper is limited. All the componenets used in this paper are not new. The idea of extending the contrastive training to model adaptation is not clear. \n\n3. The notations used in describing the proposed method are not always defined or explained in the paper. For example, what are online encoder and target encoder in Figure 1 and eq. 2?\n\n4. The experimental comparisons used in this paper should include comparison with more recent SOTA methods, such as \nCFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization\nvia Conditional Normalizing Flows, WACV 2022\nRegistration based Few-Shot Anomaly Detection, ECCV 2022\n\n5. The experiment protocols should follow the previous experiments published in the previous papers, such as those in Registration based Few-Shot Anomaly Detection, ECCV 2022, for a fair comparison.\n\n6. For the denisity-based anomaly score for anomaly detection given in eq. (5), the covariance matrix could be signular if there is not enough samples in the convariance matrix estimation in eq. (4). There is no discussion on how to solve the problem.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: \nAs described in the previous section, the paper is not very clear in the presentation of the proposed method, especially some idea, notations, the network architecture.\n\nQuality:\nThe paper still has some room for imprtovement interms of novelty, presentation and experimental justification.\n\nNovelty:\nLimited for the reasons given in the previous section.\n\nReproducibility:\nDiifculty very reproduce since many details are missing in the paper.",
            "summary_of_the_review": "The paper still has room for improvement in terms of paper presentation, technical novelty, and experimental justification. Please see the comments detailed in the previous sections. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2348/Reviewer_bC75"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2348/Reviewer_bC75"
        ]
    },
    {
        "id": "VViEKUfLYO",
        "original": null,
        "number": 4,
        "cdate": 1666790209214,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666790209214,
        "tmdate": 1666790209214,
        "tddate": null,
        "forum": "iV0r9898C-",
        "replyto": "iV0r9898C-",
        "invitation": "ICLR.cc/2023/Conference/Paper2348/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper considers outlier detection in a few-shot setting with a small samples size in the target domain. \n\nThey propose to combine self-supervised learning with two loss terms, one loss term to encourage larger similarities between in domain samples, and a second loss term to encourage smaller similarities between in domain samples and simulated outliers.\n\nThey use a mahalanobis distance using normalized features to score for outlierness, without using a mean term to subtract from the features.\n\nThey go ahead to demonstrate results on four industrial defect datasets and provide an ablation study on the terms used.\n",
            "strength_and_weaknesses": "Strengths:\n*Easy to read\n*evaluation on industry datasets as opposed to simplistic standard image benchmarks\n*Mostly an improvement over Cutpaste, showing as insight limited usefulness of negative examples as created by CutPaste for certain real datasets.\n*Ablation study\n\nweaknesses: \n*straightforward extension with limited novelty\n*limited usefulness of the second proposed loss term\n*improvement over cutpaste on three datasets due to omission of the NP term, effectively demonstrating the gain due to the term encouraging clustering between positive samples.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well readable. The theoretical novelty is limited, effectively showing the usefulness of the positive pair loss term. On the experimental side the use of datasets is a plus as well as the ablation study.",
            "summary_of_the_review": "Effectively the paper shows the usefulness of self-supervised finetuning with an added positive pair loss.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2348/Reviewer_LkYy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2348/Reviewer_LkYy"
        ]
    }
]