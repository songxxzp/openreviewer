[
    {
        "id": "nleOJB-axB",
        "original": null,
        "number": 1,
        "cdate": 1666588108474,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666588108474,
        "tmdate": 1666588108474,
        "tddate": null,
        "forum": "He7UIpiEq_O",
        "replyto": "He7UIpiEq_O",
        "invitation": "ICLR.cc/2023/Conference/Paper5378/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a knowledge distillation framework for link prediction, Linkless Link Prediction (LLP). Unlike simple knowledge distillation methods that match outputs or representations of models, LLP distills relational knowledge of each link to the student MLP using proposed rank-based and distribution-based matching. These two matching strategies enable the student model to learn relational knowledge about context nodes. Experiments conducted on 9 benchmarks show the effectiveness and efficiency of the proposed framework.",
            "strength_and_weaknesses": "Strengths\n\n- The proposed KD strategy for link prediction is interesting and more effective than the previously proposed KD strategy for node-level and graph-level tasks.\n\n- The proposed method shows a faster inference time and even better performance than GNNs.\n- The proposed method can be used meaningfully in a real-world scenario by showing excellent performance in cold start nodes, which have relatively few connections.\n\nWeaknesses\n\n- A lack of technical contribution. As mentioned by the author, from the perspective that link prediction is considered as a ranking task, the proposed method for knowledge distillation (margin-based ranking loss and distribution-based matching loss) were already proposed in RankDistill [1] which proposes knowledge distillation for the ranking task. \n\n- Knowledge Distillation becomes more significant as the scale of the graph increases due to the high latency of GNN, but the huge performance degradation in the largest scale graph (ogbl-citation2) raises questions about the necessity of KD. I wonder if it is a special case in ogbl-citation2 or if the performance drop of KD usually occurs in large-scale graphs.\n\n[1] Reddi, Sashank, et al. \"Rankdistil: Knowledge distillation for ranking.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation of the paper is clear and easy to follow, but the novelty is limited in terms of the technical contribution. See the above section on strengths and weaknesses.\n",
            "summary_of_the_review": "This paper presents a knowledge distillation framework for link prediction. The presentation of the paper is clear and easy to follow, and the motivation is clear, but the technical novelty is limited. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5378/Reviewer_Z2kr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5378/Reviewer_Z2kr"
        ]
    },
    {
        "id": "Qg4MWuI3gW",
        "original": null,
        "number": 2,
        "cdate": 1666629306417,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666629306417,
        "tmdate": 1669935866269,
        "tddate": null,
        "forum": "He7UIpiEq_O",
        "replyto": "He7UIpiEq_O",
        "invitation": "ICLR.cc/2023/Conference/Paper5378/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes to distill GNN knowledge for link prediction into MLPs via distribution and rank based losses as opposed to prior work which only uses logit-matching or representation matching. The authors test their method against these prior knowledge distillation methods as well as stand-alone MLPs and the original teacher GNN. The authors further observe the difficulty with regards to cold-start nodes and observe significant performance improvements compared to some scaling GNN methods.",
            "strength_and_weaknesses": "Strengths:\n - The paper is well written and clear.\n - The experiments and models are described in a reproducible manner.\n - The proposed production setting and analysis of cold-start nodes is interesting and valuable to recommender systems.\n - The proposed method seems sensible.\n\nWeaknesses:\n - The method is significantly outperformed on the only large link prediction graph provided (OGB-Citation2 Tab.1). This is problematic because the purpose of the method is to work on large-scale graphs, where GNNs might be too expensive to run. \n - The comparison against GNN methods on cold-start nodes is not fair as known GNN techniques exist that might help in this setting (see [1], where a fully adjacent layer is proposed).\n - The evaluation method leaves me with some doubt as I think it is biased (if my understanding is correct) due to no ranking against all nodes in the graph (as is standard in KG link prediction). This is an unrealistic test setting that is also biased.\n - Knowledge graph completion is an important link prediction task that deserves to be mentioned in the introduction and related work, with a brief explanation why this setting was ignored.\n - The GNN scaling method comparison is a bit weak in that some key methods have not been considered as well as only considering inference time, but not performance. There will always be a trade-off. In general, the paper is too quick to assume that knowledge distillation to MLPs is needed and cannot be dealt with by accelerating GNNs, a point that needs further evidence before it can be accepted.\n\n[1] https://arxiv.org/pdf/2006.05205.pdf",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n - Very good\n\nReproducibility:\n - Excellent\n\nQuality:\n - Good\n\nNovelty:\n - Medium",
            "summary_of_the_review": "The paper has excellent scientific communication and reproducibility. I want to highlight this as I believe papers in the field should be held to higher standards in this regard. So I would like to commend the authors on these points. The method is well motivated, but not technically sophisticated.\n\nIn my mind there is three barriers to acceptance:\n1. I understand that there is a lack of large-scale homogeneous link prediction datasets out there. However, given the purpose of the knowledge distillation is to be applied on large scale graphs the performance in Table 1 on OGB-Citation2 is problematic. For acceptance, I would need to see a convincing analysis that shows that this is not due to the size of the dataset (the method works well on smaller citation graphs,e.g. Citeseer), but rather a peculariaty of this particular dataset. For instance, currently it is not unreasonable to hypothesis that MLPs will struggle to compress the information of many node comparisons efficiently, thus harming performance as the training graph gets larger, which would be a fundamental problem.\n2. The argument that MLPs are better suited to cold-start nodes is interesting and gives this direction additional value. However, currently I  believe the comparison in table 3, needs adaption to be convincing. There are several GNN architectures that have proposed that do not only rely on the connectivity of the graph. The simplest example is [1], where a fully adjacent layer is used at the end, if the MLP can still out-perform such a GNN architecture, then I am willing to accept that KD into MLPs might be key for recommender systems, where cold-start nodes will indeed be common.\n3. The comparison against GNN scaling methods needs a bit of improvement, namely I would like to see a discussion of the trade-off of inference time on the large-scale datasets (such as OGB-Citation2) and the final performance (as we can always predict faster while doing so less accurately). As well as including some more recent methods such as [2].\n\nI appreciate that this is a lot of work for a rebuttal phase, but otherwise the paper remains too unconvincing for such a top-level conference. Should the authors be able to address the three points above, I am willing to raise my score to acceptance of the paper.\n\nEDIT: The authors rebuttal has addressed my concerns. I have thus raised my score for the paper to be accepted.\n\n[1] https://arxiv.org/pdf/2006.05205.pdf\n[2] http://proceedings.mlr.press/v139/fey21a/fey21a.pdf",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5378/Reviewer_4BGr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5378/Reviewer_4BGr"
        ]
    },
    {
        "id": "DvLWwR6BK1",
        "original": null,
        "number": 3,
        "cdate": 1667317488576,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667317488576,
        "tmdate": 1667317488576,
        "tddate": null,
        "forum": "He7UIpiEq_O",
        "replyto": "He7UIpiEq_O",
        "invitation": "ICLR.cc/2023/Conference/Paper5378/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper aims to construct an architecture for Knowledge distillation from GNN based methology to MLP for link Prediction task in specific.\nAs GNNs are more powerful and more accurate than vanilla MLP for link Prediction task primarily due to their ability to aggregate neighbot good information, these results in more model complexity and computational cost. Hence GNNs for link Prediction tasks can't be deployed directly in a production setting. Whereas MLPs had relatively less computational cost and complexity but don't take into consideration neighborhood information which is curcial for link Prediction tasks. Hence the authors propose a knowledge distillation architecture from teacher GNN to student MLP which utilises the advantages of accuracy of GNNs as well as less model complexity of MLPs for a production setting. \n",
            "strength_and_weaknesses": "Strengths:\n\n+ Good writing\n+ New application of knowledge distillation \n\nWeaknesses\n\n- Some parts of the experiments are not clear\n- A clear motivation is lacking\n- No readme file in the code--- this seriously constrains the reproducibility\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is clearly written except some parts (see below). The paper seems to apply KD method directly into link prediction problem without a very clear motivation.\n \nQuality: The paper is technically correct. Experiments are well conducted. I did not find any flaw.\n\nNovelty: As mentioned before,  the paper plugs KD into a new task, which seems a new idea--- but I am not sure about the motivation\n\nReproducibility: No readme file present in the supplementary material. \n",
            "summary_of_the_review": "Strengths\n\n+ Motivation:  The authors have clearly outlined the motivation setting for such a proposal behind knowledge distillation.\n\n+ Ablation studies confirm that their proposed model outperforms and close to GNN.\n\n+ The have showcases on 2 large scale OG datasets, thereby confirming the effectiveness of their proposed model in large graphs.\n\n+ The authors have  explains well the experimental setup in appendix. Well written. \n\n\n\nWeakness/questions for authors\n\n - Not clear in experiments what LLMatch metric is used currently.\n\n- Uses logit based matching based on a very old paper. And also doesn't showcase the motivation of proposal of logit based matching. It should be clearly substituted with recent paper evidences.\n\n- The authors have performed experiments in large OGB datasets which are typically used for link Prediction settings. But as the authors have mentioned in the start of the paper for applications in an industrial setting, did they also perform experiments in a realtime production setting like a recommendation system e.t.c. That would have been nice to have. An analysis on a large scale real production environment(rather than simulation) would tell much more about the utility of proposed method. If there are limitations, that should be clearly specified.\n\n- Inference time graphs are plotted, however very less conclusive analysis done on much of a significant time change does KD provides over GNN w.r.t accuracy.\n\n- Each of the experiment tables should also have clear notation what values they are showing. Is it showing HITs of AUC. That should specified under each table. Some tables don't have titles or caption ( example ablation study)\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5378/Reviewer_Wrjf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5378/Reviewer_Wrjf"
        ]
    }
]