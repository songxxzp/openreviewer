[
    {
        "id": "wLOl_QnA67",
        "original": null,
        "number": 1,
        "cdate": 1666637877441,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637877441,
        "tmdate": 1666637877441,
        "tddate": null,
        "forum": "WVRb98rwbv9",
        "replyto": "WVRb98rwbv9",
        "invitation": "ICLR.cc/2023/Conference/Paper1084/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Paper propose a method for multi-agent reinforcement learning in non-cooperative partially observable environments with communication. The proposed method, TSP, adds imaginary rewards using the peer prediction method by evaluating the validity of information exchanged between agents. TSP has guaranteed convergence to the global optimum and has good empirical performance. \n",
            "strength_and_weaknesses": "Strength\n- This work is novel in the sense that it is the \ufb01rst attempt to apply mechanism design to multigent evolutionary learning. \nTSP\u2019s convergence is theoretically guaranteed for arbitrary policies and environments.\n- The method seems relatively easy to implement and numerical experiments show the effectiveness of TSP. \n\nWeakness \n- The authors could add a discussion on what causes self-play + curiosity\u2019s bad performance. \n- The author should at least discuss the scalability since the experiments are on simpler and smaller environments. \n- The learning curves show that TSP is not as stable as baselines, how many random seeds are used in the evaluation? And what causes the instability issue? \n",
            "clarity,_quality,_novelty_and_reproducibility": "Quality\n- Novel idea that improves self-play through a simple modification. \n- Empirical results show the effectiveness. Experimental evaluations are extensive. \n\nClarify\n- Mostly clear. Claims are well supported. Some details missing that could be helpful for reproducibility\n",
            "summary_of_the_review": "This work considers multi-agent reinforcement learning in non-cooperative POMDP. The proposed method, TSP, generalizes self-play to non-cooperative partially observable environments via mechanism design. The method has a convergence guarantee and is shown to outperform state-of-the-art performance for various multi-agent tasks. \nHowever, there are some weaknesses that I hope the authors could address in the next version. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1084/Reviewer_nN62"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1084/Reviewer_nN62"
        ]
    },
    {
        "id": "XZmAS-2kcu",
        "original": null,
        "number": 2,
        "cdate": 1666647342464,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647342464,
        "tmdate": 1666647342464,
        "tddate": null,
        "forum": "WVRb98rwbv9",
        "replyto": "WVRb98rwbv9",
        "invitation": "ICLR.cc/2023/Conference/Paper1084/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Truth Self Play (TSP) is a method for improving SP in partially observable environments which involve communication. The motivation is well grounded adding additional reward term to evaluate the truthfulness of communication sent. This is implemented by the additional reward  p(a_j | z_ij), which is to say, force agent j to listen to the communication sent from agent i.  In a reverse way, as the listener has to care about the message, the speaker (as this is self-play) starts providing useful information.",
            "strength_and_weaknesses": "## Strengths\n* Strong theoretical grounding\n* Experiments on lots of environments\n* This is useful\n\n## Weaknesses\n* The math is kinda OOT in my opinion. Section 3 could be way shorter. The use of imaginary numbers is unnecesary - simple use R^2 and then apply a normalization over a single dimension.\n* (Figure a) Only showing the Real part of the reward signal?  Can we see how the second reward signal changes over time?\n* Experimental results are lacking. I appreciate the variety of environments applied but simply reporting numbers isn\u2019t convincing. I\u2019d like to understand how messages look with some visualisation and how they change over time.\n* I\u2019d also like to understand what optimal or desired behaviour looks like in these environments - can you get to welface 0 in PP or TJ?\n* Please info the reader more of your baselines (CommNET and IC3Net)\n* Why didn\u2019t you run CommNet w TSP\n* Why don\u2019t you have MAPPO as a baseline?\n* The proper scoring rules seems to be no different agent modelling in other agents. Could you add some of these into the related work section just to help differentiate (or explain in rebuttal if i\u2019m being slow)\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n\nFound the paper really unclear!\n* Lots of confusing terms - is evolutionary learning any different to automatic curriculum? Just trying to understand the jargon here.\n* Unclear what internal-state refers to in the introduction -> is this the internal beliefs of an agent?\n* Why is this framed as faithful state representations - the question is about the truthfulness of the communication channel which is explicitly separate to the state space!\n\nNovelty:\nI can\u2019t tell if this is Novel cause it just seems like opponent modelling and they haven\u2019t explained why its different.\n",
            "summary_of_the_review": "The paper is to a good standard and with clarity could be a very high impact paper. Theoretical justifications are great, I would like more experimental analysis and clear terminology to understand implications. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1084/Reviewer_N5E1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1084/Reviewer_N5E1"
        ]
    },
    {
        "id": "20MapgE56AK",
        "original": null,
        "number": 3,
        "cdate": 1666677406999,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666677406999,
        "tmdate": 1666677406999,
        "tddate": null,
        "forum": "WVRb98rwbv9",
        "replyto": "WVRb98rwbv9",
        "invitation": "ICLR.cc/2023/Conference/Paper1084/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a general framework named truthful self-play (TSP) which is suitable for communicative partially-observable stochastic games and analytically demonstrates convergence to the global optimum.",
            "strength_and_weaknesses": "Strength\n1. The proposed framework TSP is general and guarantees convergence to the global optimum theoretically and experimentally.\n\nWeaknesses\n1. This paper improves the self-play problem by introducing the 'truthful' reward. However, this paper lacks a full explanation of the meaning of 'truthful', in other words, we do not find relevant information about 'truthful' in the method section, and it is too farcical to use this reward as an inverse game mechanism. The contribution of this paper is too few and its innovation is general.\n2. The experiment needs improvement. \n   1) In Table 1, the effect of PP-5 and TJ-5 is not significantly improved; compared with IC3Net+SP, the value including standard deviation has some coincidence(need more experiments iteration). In TJ-20, there is no reasonable explanation for the reduction of effect variance. \n   2) In Figure 2, the description of (a) is unclear, and the existence of (c) is unnecessary. \n   3) In Table 2, whether the CommNet+TSP's performance can be further improved should be verified. \n3. Spelling problems and unclear statements.\n    1) Introduction para3 pertially -> partially\n    2) The input of function $q_{\\phi}$ is inconsistent, $\\hat{h}_{t i}$ in Section3.2 and $\\hat{h}_{t}$ in Section3.3. ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is original and reproducible, but the quality and clarity need to be improved. ",
            "summary_of_the_review": "1. The contribution of this paper is favorable to the community .\n2. The experiment needs improvement to be more convincing.\n3. The language and symbolic descriptions in this paper need to be clearer to avoid misunderstandings.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1084/Reviewer_bEm1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1084/Reviewer_bEm1"
        ]
    }
]