[
    {
        "id": "WtbBiRqN2to",
        "original": null,
        "number": 1,
        "cdate": 1666531327027,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666531327027,
        "tmdate": 1666531339192,
        "tddate": null,
        "forum": "Pt1KTsjSfRG",
        "replyto": "Pt1KTsjSfRG",
        "invitation": "ICLR.cc/2023/Conference/Paper3866/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposes the straightforward application of transfer learning for image segmentation for limb images using DeepLabV3. In addition to the standard IoU metric the authors also rendered 3D models and compared those of the automatic pipeline with manual segmentations. As expected the fine-tuned DeepLabV3 can produce similar quality segmentation and renderings as manual annotations.",
            "strength_and_weaknesses": "**Strengths**\n- The paper is easy to follow and contains nice visualisation \n- The pipeline is evaluated not only for the segmentation quality but also its downstream task: 3D rendering\n- There are some interesting qualitative descriptions of the results \n\n**Weaknesses**\n- There is little to no technical novelty, all employed methods have been previously presented and are simply applied to a new task\n- The description of the dataset and train/validation split is slightly confusing: it is stated that the \"fine- tuning dataset consisted of 806 manually labeled images\" and further \"we randomly select 80% of the images as our training data set and reserve the remaining 20% for validation\" does this mean the same subject can be part of training and validation?\n- Later on the authors state: \"Of the 24 limb scans acquired in the previous step, two scans were manually segmented via Adobe Photoshop and set aside as ground truth references. The remaining 22 scans, totaling 6312 images, were fed into the fine-tuned neural network for segmentation.\". Are those different subjects to the ones used for fine-tuning? Furthermore, since 24 scans correspond to 12 subjects with or without additional sock, again the question of whether the 22/2 split is done on a subject-level? \n- Overall the low number (2) of held-out ground truth cases makes it somewhat  hard to trust those results, since some cherry-picking might be unavoidable \n- All models converge very quickly and no data augmentation seems to be used, this could indicate some overfitting\n- an additional practical problem of the pipeline seems to be failure of image alignment that caused scans 2, 7, 8 and 14 to not render properly with the automated workflow. I wonder whether the authors have attempted to use the automatic segmentation information or some other features from the fine-tuned network to improve on this?\n- the inference times for automatic segmentation seem awfully slow (0.32 images/s), even when being restricted to Google Colab infrastructure measuring the feed-forward path of a DeepLabV3 with mixed precision (AMP) on a Tesla T4 should result in at least two orders of magnitude faster throughput    ",
            "clarity,_quality,_novelty_and_reproducibility": "As mentioned above, while the paper is overall fairly clear there are a number of important details that should be clarified. The quality of the work judged from a technical view point is too low for an ICLR submission. While there is some practical value, the authors only applied standard deep learning tools to their dataset and processed them with another 3D rendering software. There are also no clear empirical insights, e.g. does the model capacity vs image dataset size influence the outcome? are there any augmentation strategies that should be considered? etc.",
            "summary_of_the_review": "I recommend to reject the paper due to limited (or non-existing) technical novelty and low empirical insights.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Discrimination / bias / fairness concerns"
            ],
            "details_of_ethics_concerns": "There are potential issues about the data split between training and testing, which is not clearly defined to separate images from the same subjects.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3866/Reviewer_FWEb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3866/Reviewer_FWEb"
        ]
    },
    {
        "id": "PMZ3gOkVrt",
        "original": null,
        "number": 2,
        "cdate": 1666647726820,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647726820,
        "tmdate": 1666647726820,
        "tddate": null,
        "forum": "Pt1KTsjSfRG",
        "replyto": "Pt1KTsjSfRG",
        "invitation": "ICLR.cc/2023/Conference/Paper3866/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a method using deep learning with photogrammetry for scanning amputated limbs. The proposed method uses deep convolutional neural networks, DeepLabv3, and transfer learning. The ResNet-101-based Deep Labv3 model was pre-trained and then fine-tuned. The scan images were acquired by using a smartphone and subsequently segmented on a desktop. Afterward, 3D limb models were rendered from the segmented images using Agisoft Metashape.",
            "strength_and_weaknesses": "Strength\n+ An interesting work that can be very useful for telemedicine or point-of-care diagnosis\n+ A workable system that uses a set of existing methods and technologies\n+ Good validation\n\nWeaknesses\n- Technical novelty is not significant\n- Lack of technical comparisons\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written and easy to follow. The idea is interesting. Experiments are presented with details. ",
            "summary_of_the_review": "The paper presents an interesting idea and good experimental results. However, the method novelty and evaluation needs improvement.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3866/Reviewer_xaFj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3866/Reviewer_xaFj"
        ]
    },
    {
        "id": "xd51F7fA2q",
        "original": null,
        "number": 3,
        "cdate": 1666655179114,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666655179114,
        "tmdate": 1666655179114,
        "tddate": null,
        "forum": "Pt1KTsjSfRG",
        "replyto": "Pt1KTsjSfRG",
        "invitation": "ICLR.cc/2023/Conference/Paper3866/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The work proposes to improve the pipeline of amputated limbs scanning by using the deep learning-based image segmentation before rendering them with photogrammetry. In this way, the density of obtained samples can be increased to improve coverage and accuracy of 3D models with more samples. The proposed method is verified in practice in the limb scanning procedure followed by DeepLab model fine-tuning and inference and finally rendering of models from segmented images.  The discussion of achieved results is also well done.",
            "strength_and_weaknesses": "The problem statement is clearly explained and the method addresses an important problem of improving time and accuracy of healthcare procedures. A very detailed discussion of clinical impact and directions is presented at the end of the work, what helps with understanding potential applications, advantages and limitations of the method. A few ideas for improvements are also presented, showing that authors have a good understanding of the presented medical problem. \n\nUnfortunately, the novelty of the work is limited. Very similar studies using deep learning segmentation topologies for improvements of photogrammetry have already been conducted. The work is an application of a known method to another computer vision dataset, but experiments focus only on a single model, so it may be difficult to draw some conclusions for future enhancements of such methods.  \n\nAlso, the reason for selection of the specific DeepLab model hasn't been justified. It would be interesting to verify other models as well. \n\nIt's also mentioned that photo alignment led to some failure cases. There are various alignment techniques that could be used to improve this outcome. Have you tried any of them?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The work is clear, but the novelty is limited in my opinion. It's an interesting confirmation of known techniques, applied to another dataset. The reproducibility of the work may be difficult due to the use of the dataset, which hasn't been made available publicly. ",
            "summary_of_the_review": "The application is interesting, however the technical contribution is not very significant. Existing methods have been reused for processing of the different dataset, but experiments are limited to some specific configuration only. A more detailed analysis of different segmentation models and preprocessing algorithms to improve limitations such as image alignment would help to improve the quality of the work. In addition, some optimizations of the segmentation model and the rendering procedure could be done to make the entire system suitable for the mobile device. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3866/Reviewer_bNhp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3866/Reviewer_bNhp"
        ]
    }
]