[
    {
        "id": "DcQYwGpD-7",
        "original": null,
        "number": 1,
        "cdate": 1666319165874,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666319165874,
        "tmdate": 1666319165874,
        "tddate": null,
        "forum": "ZKDUlVMqG_O",
        "replyto": "ZKDUlVMqG_O",
        "invitation": "ICLR.cc/2023/Conference/Paper2784/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposed a self-supervised framework for category-level 3D object pose estimation. A novel category surface embedding module is proposed which can help establishing dense correspondences within a single instance, between two different instances of the same category, and instances in different time frames. Experiment shows that the proposed algorithm achieves impressive performance on 3D pose estimation and keypoint transfer.",
            "strength_and_weaknesses": "Strength:\n1. The proposed Categorical Surface Embedding module and the corresponding cycle-consistency loss function is interesting and novel. \n2. The experiment result on pose estimation in the wild and dense key-point transfer on CUB dataset is impressive and the ablation study clearly shows the effectiveness of suface embedding and cycle loss.\n\nWeakness:\n1. There are some hyperparameters which weight different items in the overall loss function, such as \\beta_texture, \\beta_mask, \\beta_2D-3D, etc. From Table 7 in Sec. A.3, it seems that such hyperparameters varies across Wild6D and CUB in training, does the algorithm's performance depends significantly on these hyper-parameters?\n2. In Table 2, the proposed algorithm get good performance on the 'Self-supervised' setting, but significantly lower performance than algorithms in 'Synth supervised' setting, since the labeled synthetic images can be obtained with limited effort, what is the benefit of self-supervised training on Wild6D without pose label? and is it possible to test the setting of W*+R* data settting and compare to the method of UDA-COPE (Lee et al., 2022) with C+R* data setting?\n3. In Figure 2, it is not clear whether and how the deformation \\delta_V is regularized, there should be some sentences in sec.3.1 referring to Appendix A.2 and the regularization loss should be reflected in Figure 2.",
            "clarity,_quality,_novelty_and_reproducibility": "1. In general, the paper is well written and easy to follow.\n2. The formulation of the algorithm is complete and the experiment is solid and convincing\n3. The idea of per-vertex per pixel category surface embedding is interesting\n4. The reproducibility would be good since in section 5 the author committed to open their source code once accepted ",
            "summary_of_the_review": "In summary, I recommend that the paper could be accepted if all the questions in the weakness part are addressed",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2784/Reviewer_pKTW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2784/Reviewer_pKTW"
        ]
    },
    {
        "id": "4Rg9ueUi-A",
        "original": null,
        "number": 2,
        "cdate": 1666505796666,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666505796666,
        "tmdate": 1667152325145,
        "tddate": null,
        "forum": "ZKDUlVMqG_O",
        "replyto": "ZKDUlVMqG_O",
        "invitation": "ICLR.cc/2023/Conference/Paper2784/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to learn category-level 6D object pose in an unsupervised manner. The key contribution lies in a framework to learn 2D-3D correspondences between image and a category-level canonical shape as a mesh. The correspondences are learned by regressing surface embedding on both image pixels and mesh vertices, which are then matched to obtain correspondences. The unsupervised losses mainly consist of differentiable rendering loss and various cycle-consistency losses.",
            "strength_and_weaknesses": "Strength\n+ Overall the paper is clearly written and easy to follow.\n+ The problem of 6D object pose estimation in the wild is of importance in practice, such as in robotic applications. \n+ The major strength over prior arts lies in its unsupervised nature, which does not require any human annotation of object pose. \n+ The experiments demonstrate state-of-the-art performance.\n\nWeakness:\n- Some of the technical deteils are not clear.  For example, it is not clear whether the mean shape is optimized or fixed - Sec 3.1 states that the mean shape is learnable but according to Sec. A.2 the mean shape is selected from synthetic data in ShapeNet.  \n- If the method learns both the category-level mean shape and per-instance shape deformation, the decompotion of mean shape and deformation is inherently ambiguious. Any change in the mean shape can be compansated by its inverse change in the deformation. It seems there is not any regularization to resolve such ambiguity. \n- The paper has been vague about whether the depth is required in the input. My understanding is yes, because the method estimates pose by Umeyama algorithm. It is then a limitation if RGBD is required as input rather than RGB image only. The paper also acknowledges that removing depth loss leads to a drop in performance. Without depth data, how is the absolute scale of translation determined, given the ambiguity between objece size and distance caused by perspective projection?  \n- There is no ablation study on the impact of deformation compared to just using a canonical shape.\n-  Many of the objects shown in the paper are symetric, hence it is again ambiguious to define the pose. Does this cause instabability in training and how is it handled?  \n - The backprojection from 2D to 3D in the right equation of Eq.(4) needs depth as well. It is better to point out this for clarity.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall clearly written but some important details need to be more crisp, such as requirement of depth data in input and if the mean shape is learned from scratch or taken from synthetic data.\n\nOverall the paper has some degree of the novelty due to its unsupervised learning for 6D object pose. But majority of the component such as differentiable rendering, cycle-consistency loss are not new. ",
            "summary_of_the_review": "The paper is solving a practically important problem, i.e. unsupervised learning of 6D object pose. The overall framework makes senses and works reasoablely in the experiments. That said, some important details needs further clarification as discussed above. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2784/Reviewer_SV21"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2784/Reviewer_SV21"
        ]
    },
    {
        "id": "rDPbP_93JK",
        "original": null,
        "number": 3,
        "cdate": 1666559875236,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666559875236,
        "tmdate": 1666559875236,
        "tddate": null,
        "forum": "ZKDUlVMqG_O",
        "replyto": "ZKDUlVMqG_O",
        "invitation": "ICLR.cc/2023/Conference/Paper2784/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper describes to learn a model for category-level object pose estimation. The proposed approach relies on a dataset of RGB-D images of a certain category of objects, e.g. mugs or bottles, with a template mesh of an object belonging to the category. The method does not require any pose annotation to train, however it leverages recent DINO features during training. The model can still be called self-supervised because DINO learning is self-supervised itself. The approach is evaluated on the Wild6D dataset and is shown to be on par with the current state-of-the-art.",
            "strength_and_weaknesses": "I see at least three strong points in the submitted work. First of all, the idea to formulate 2D-3D pose regression through cross-attention between the image pixel features and the mesh vertex vertices seems new, original and interesting. It is one step forward compared to the direct regression of 3D coordinates from 2D images, which became a traditional tool in dense correspondence and pose estimation models wince the Vitruvian Manifold work of 2012. As the ablation study shows, without this element, the model starts to perform significantly worse.\n\nThe second strong point is that the evaluation is done on a big real dataset of objects (1722 videos of 5 object categories). The baselines are chosen as rather recent methods, and the metrics are standard and widely used.\n\nThe third strong point is the evaluation on a keypoint correspondence task, which shows the power of the learned model beyond the primary task.\n\nHowever, while the current dataset is diverse in terms of objects, it is very constrained in terms of object categories (only 5 of them, and all are rather simple). It is unclear whether a method that performs well on these categories will generalize to arbitrarily complex categories, e.g. a vehicle, etc., and there is a very popular and recent dataset (CO3D) that can be used as well.\n\nNext, it is not well described in the paper, in my opinion, that the method needs depth data to train. It would be very interesting to see what metrics can we have if we don't use depth for training. It is often the case that the dataset of RGB images is much easier to collect. As an intermediate baseline, maybe one may use some self-supervised depth estimation models here as well. I see no problem in relying on some machine learning models for annotation if they are self-supervised as well. \n\nWhile I see that the reconstruction loss is important, probably I'd suggest explaining clearly why is it needed if we have the instance consistency loss. The problem is, the reconstruction loss enforces the colour consistency constraint between the projected vertices and the pixels. The instance consistency loss basically enforces consistency between the projected vertices and the pixels as well. It is stronger, because colours may be the same or similar, but coordinates may be very different. It is also not very clear why removing the depth loss makes things worse, because in my opinion (correct me if I'm wrong) but the depth supervision is already inside the instance consistency loss.\n\nThe experiment with keypoint transfer is interesting. But I would like to see the result of keypoint transfer by DINO features as well, to be able to compare and understand if there are any gains compared to this model.\n\nMoreover, there is one question. Why are tthe DINO features used in the cycle consistency, but not the proposed 2D features?\n\nIn the Fig. 2, the cycle losses should be shown as well.\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. There are some questions regarding the terminology used. In particular, (Umeyama 1991) algorithm is for the 3D-3D alignment problem, and it is incorrect to say that it is applied for the 2D-3D alignment problem.\n\nAlso, the authors call the competitive papers 'supervised or semi-supervised', while the authors of those papers call their approaches 'self-supervised'. It relates, for example, to the work (He et al., 2022), (Peng et al., 2022), RePoNet. Would like to understand clearly why does this happen. In my opinion, those works also fall into 'self-supervised' category.\n\n\n",
            "summary_of_the_review": "Summarising, the paper contains good and valuable ideas. The evaluation shows, that the method is the best on Wild6D in terms of IoU .25 metric as well as pose metrics. However, the situation is mixed on the REAL275 dataset, and here there are question regarding the adequate baselines, because the paper refuses to accept that the competitive methods also fall into the 'self-supervised' category, while the competitive methods are also called 'self-supervised'. This is a difficult situation. Also, the paper is evaluated on just one in-the-wild dataset with 5 simple object categories. I would suggest evaluation on a ore diverse set of object categories.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2784/Reviewer_ohWa"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2784/Reviewer_ohWa"
        ]
    },
    {
        "id": "coY69yRt4ph",
        "original": null,
        "number": 4,
        "cdate": 1666669685017,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669685017,
        "tmdate": 1666669685017,
        "tddate": null,
        "forum": "ZKDUlVMqG_O",
        "replyto": "ZKDUlVMqG_O",
        "invitation": "ICLR.cc/2023/Conference/Paper2784/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a self-supervised method for Category-level 6D Object Pose Estimation. Specifically, the paper proposes an architecture and a number of geometry-based consistency losses allowing simultaneous estimation of the shape of specific instance and its pose. The experimental sections, demonstrates improvements over SOTA.",
            "strength_and_weaknesses": "The self-supervised nature of the method is attractive and makes it more applicable due to lower costs of dataset acquisition. The results improve the SOTA. Interestingly, the paper achieves better results than some supervised methods. Ablation study validates the architecture and loss choices. The methods is validated on two domains (images and videos) and two tasks (6d pose estimation itself and key points transfer)",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written, probably reproducible, and to my knowledge is novel.",
            "summary_of_the_review": "I give positive rating because in my opinion the paper is well written and novel, and will be interesting to the community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2784/Reviewer_hRgU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2784/Reviewer_hRgU"
        ]
    }
]