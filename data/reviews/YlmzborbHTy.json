[
    {
        "id": "c8s_6iPeiO",
        "original": null,
        "number": 1,
        "cdate": 1666162746054,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666162746054,
        "tmdate": 1666162746054,
        "tddate": null,
        "forum": "YlmzborbHTy",
        "replyto": "YlmzborbHTy",
        "invitation": "ICLR.cc/2023/Conference/Paper6013/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Different from the common inpainting methods, this paper propose a novel image inpainting model tending to fill the missing region with new visual instances instead of filling in the background content. The author first use two transformer-based networks to inpaint the background segmentation map and foreground segmentation map respectively. Then, an unet network is used to hallucinate the missing area with the help of the combined segmentation map. Besides, the author adopts the CLIPScore and VGA to evaluate the context consistency between the original image and the completed image.",
            "strength_and_weaknesses": "Strength:\n\u2022\tThe novel image completion pipeline which tends to fill the missing region with new visual instances.\n\u2022\tPrevious context-aware image completion method only focuses on rectangular regions while this method are free to handle masks with arbitrary shapes.\n\u2022\tObtain high quality inpainting results and a number of quantitative results prove its effectiveness.\n\nWeakness:\n\u2022\tThis method utilize a DETR pretrained on COCO which limits the application of this method. For some common used inpainting dataset like CelebA, FFHQ, Places, Paris street View, LSUN, it is hard to acquire the corresponding segmentation map to train the DETR.\n\u2022\tThe author claims \u2018COCO-panoptic is more challenging than center-aligned datasets\u2019, but the author should prove the generalization of the proposed method on other domain datasets like face (FFHQ)\u3001buildings (Paris Street View).\n\u2022\tOne important application of inpainting is object removing while this method aims for new object generation. What about the performance of the proposed method on the object removing?\n\u2022\tI find in most figures (Fig 1, Fig 3-5, Fig 8-9), there exist an obvious color discrepancy between the ground truth and the results of this paper. Can you make an explanation?\n\u2022\tWhen processing large missing area, does the segmentation completion network still has the ability to generate new objects or just inpaint with background contents?\n\u2022\tHow is the model complexity and inference time compared to other methods?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized and clearly written. The paper appears to be technically sound and maybe it is a little difficulty to reproduce the results.",
            "summary_of_the_review": "In summary, this paper proposes a novel image completion method which shows advantage in hallucinating missing region with new visual instances. Substantial experiments prove the effectiveness of the proposed method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6013/Reviewer_HUfm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6013/Reviewer_HUfm"
        ]
    },
    {
        "id": "XGiJp3ITFK",
        "original": null,
        "number": 2,
        "cdate": 1666586228722,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666586228722,
        "tmdate": 1666586228722,
        "tddate": null,
        "forum": "YlmzborbHTy",
        "replyto": "YlmzborbHTy",
        "invitation": "ICLR.cc/2023/Conference/Paper6013/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This submission proposes an image completion method to restore the missing semantic instance while preserving the relationship with the original context. To this end, three steps are proposed to complete the inpainting process, including predicting the semantic instance, generating the instance mask, and completing the image. Two evaluation metrics are introduced to assess the completed context.",
            "strength_and_weaknesses": "Strengths\n1)\tTo predict the missing semantic instance and hallucinate it is a challenging but interesting problem.\n2)\tThe writing is easy to follow.\n3)\tThe two introduced evaluation metrics are reasonable and prove the completed context's validity.\n\nWeakness\n1)\tAs I understand, the model performance is highly dependent on the missing instance prediction module. Still, it lacks sufficient explanation and analysis to prove the effectiveness, generalization, and robustness of this module. After all, the semantic instance inference in the segmentation map, especially the corrupted segmentation map is challenging. How about the performance of real-world images?\n2)\tFrom the results, the synthesized content is not consistent in style with the original context, and the completed method needs to be improved.\n3)\tAlthough the proposed method is superior in terms of the two new metrics, it is worse in the metrics of LPIPS and FID. The (novel) application of image completion, which originally intended to complete images to generate realistic content, should be clarified more clearer.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is easy to follow and the task is interesting, but the technical contribution and experiments still need to improve.",
            "summary_of_the_review": "See above",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO.",
                "Yes, Potentially harmful insights, methodologies and applications"
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6013/Reviewer_xwWL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6013/Reviewer_xwWL"
        ]
    },
    {
        "id": "WKObMjAj2T",
        "original": null,
        "number": 3,
        "cdate": 1667489102605,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667489102605,
        "tmdate": 1667489102605,
        "tddate": null,
        "forum": "YlmzborbHTy",
        "replyto": "YlmzborbHTy",
        "invitation": "ICLR.cc/2023/Conference/Paper6013/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposed a pipeline for image completion, which fills the missing region with a hallucinated instance. It consists of four parts. 1. Object detection via DETR within the masked image. 2. Predict the missing object's category via a multi-head attention network. 3. Generate the foreground & background segmentation mask with GAN. The final segmentation mask is foreground + background. 4. Segmentation guided image completion like SPADE / OASIS.\n\nExperiments are performed on COCO-panoptic and Visual Genome dataset. Four metrics are used, including LIPIPS, FID, CLIPScore, Visual Grounding Accuracy (VGA).",
            "strength_and_weaknesses": "Strength\n1. The proposed pipeline is straightforward and effective. \n2. Improve over HVITA by eliminating the restriction of rectangular missing region.\n\n\nWeakness\n1. Heavily limited to the pretrained detector. The proposed pipeline relies on DETR to provide the objects in the image, subsequent modules is limited to the pre-defined object categories of DETR. In the experiment design, only supported objects are masked as missing. Such heavy dependency limits the real-world applications of the method.\n2. The missing region is within or around the instance bbox, and the method predicts one object regardless of the existence or the number of objects. In many inpainting scenario, the missing region doesn't does not necessarily contain an object in the middle of the region.\n3. Experimental design is biased.\n3.1 The datasets are prepared in favor of the proposed method, i.e., COCO and Visual Genome contains many objects; The missing regions are created around a carefully selected subset of objects.\n3.2 The evaluation metric is biased. The CLIPScore and VGA depends on the object in the missing region. It is obvious that any inpainting method fails as long as it doesn't predict a correct category of object in the missing region.  \n3.3 It will be more convincing to provide methods to determine whether there are objects in the missing (\"no instance\"), and how to deal with cases that half of an object is missing while the other half is not (\"instance across missing region\").\n3.4 Meanwhile, experiments should be conducted on the full (not selected by object category) COCO-panoptic and Visual Genome dataset, with random missing region instead of around object bbox.\n4. It will be interesting to show whether the predicted instance in the impainted image can be detected with DETR. If yes, is the predicted category the same as the output of the \"Missing Instance Inference Transformer\"?",
            "clarity,_quality,_novelty_and_reproducibility": "Lack of academic novelty. In terms of weakness 3, the authors may argue that predicting objects is the major contribution of the paper. However, that also means predicting a limited set of objects in limited scenarios is the only thing that the proposed method can do. Indeed it is an improvement over HVITA, but it is more like an incremental one, that follows the path of HVITA and equipped with several off-the-shelf components.",
            "summary_of_the_review": "I do not recommend acceptance of the paper because of lack of academic novelty. The paper provides an incremental improvement over HVITA, but does not solve critical problems like \"no instance\" or \"instance across missing region\".",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6013/Reviewer_675z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6013/Reviewer_675z"
        ]
    }
]