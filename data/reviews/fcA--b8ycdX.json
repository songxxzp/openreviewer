[
    {
        "id": "bxqdGB5nm1R",
        "original": null,
        "number": 1,
        "cdate": 1666558298433,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666558298433,
        "tmdate": 1666654076705,
        "tddate": null,
        "forum": "fcA--b8ycdX",
        "replyto": "fcA--b8ycdX",
        "invitation": "ICLR.cc/2023/Conference/Paper4113/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "this paper suggests to simultaneously learn state representation from images and to fit the LQR solution in this state representation (and linear latent dynamics) to the externally provided optimal control signal.  ",
            "strength_and_weaknesses": "1. I do not understand the rational of this work. If you have optimal control, u, you have a solution. Why to calculate it again via LQR?\n\n2. I do not see any connection to \"the Koopman formalism\" except for the fact that the latent dynamics is represented by matrices (linear dynamics), and the Koopman operator is a linear operator. \n\n3. What is the original objective? Eq.11 is a sample based approximation of the original objective. \n\n4.  Eq.11 combines terms with different units and scales. Are the measurement loss and control loss \non the same scale? The later is in units of actions. The former is in different unites. \n\n5. Directly relevant works (e.g,. Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images Manuel Watter, Jost Tobias Springenberg, Joschka Boedecker, Martin Riedmiller) are not mentioned.\n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "the paper is very clear written. the originality is doubtful. the numerical experiments are not conclusive. ",
            "summary_of_the_review": "The concerns in \"Strength And Weaknesses\" prevent me from recommending this paper for publication in ICLR.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4113/Reviewer_1Vdd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4113/Reviewer_1Vdd"
        ]
    },
    {
        "id": "Gw9edsl6fO4",
        "original": null,
        "number": 2,
        "cdate": 1666605235166,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666605235166,
        "tmdate": 1666605384812,
        "tddate": null,
        "forum": "fcA--b8ycdX",
        "replyto": "fcA--b8ycdX",
        "invitation": "ICLR.cc/2023/Conference/Paper4113/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents a latent dynamics learning (or system identification) scenario from very high dimensional observations (images). Inspired by the Koopman operator theory, the authors try to find a latent space where the dynamics is linear. and use this dynamics to control two simple dynamical systems (pendulum toss-up and cartpole) with LQR. Unlike other Koopman-theory inspired approaches, the authors include the (LQR) control problem inside the training scenario and show examples where not including results in failure to control the system successfully.",
            "strength_and_weaknesses": "Strengths:\n\n* The paper is well written and motivated, and the presented approach makes sense. The authors show some successful examples where their contribution leads to successful control,\n\nWeaknesses:\n\n* The paper however suffers from lack of extensive experimental support. The authors only show sample sets of images and a few plots where the method leads to an improvement. The effect on the overall test data (1000 videos of 10 seconds each on both the pendulum and the cartpole systems) is not mentioned, nor is it quantified (have I missed it???)\n\n* Some comparative discussion is missing. How much of the improvement is due to the added two cost functions coming from LQR, and how much of it is due to the choice of the network and other details? Didn't the previous Koopman-theory-inspired approaches train autoencoders that led to successful control? As pendulum is the simplest nonlinear system I assume there were successful pendulum toss-ups reported previously. What was the difference there? \n\n* Ablation studies are missing. What is the effect of the the networks chosen, and is it difficult to train? I assume looking at eq. (11) that training with it successful controllers must be quite difficult and prone to issues (local minima, poor performance, nonconvergence etc.)\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and clear up until the experiments section, but afterwards some of the notation and clarifying discussion is missing.\n\n* Is the set U a subset of R^p or R^d in eq. (1)?\n* Are there any issues in coming up with a good LQR formulation with delayed coordinates? What is the choice of h in the experiments? How did you come up with it? Are there any difficulties, or is it straightforward?\n* What is N and M in your experiments? N = 4000? M = ?\n* What is the size of the control input space (d ?) Are the controls encoded to a very high dimensional space such that control is linear there? Or is it the opposite?\n* Does the dataset generation use LQR to generate optimal examples? How can we avoid feeding optimal examples for more complex systems where it may not be feasible?\n* Section 3.3 \"real\" is misleading. The real system is not \"real\", as in \"real robot experiments\" in your case I think.\n* In order to make space for more discussion one could move section 3.3.2 to an appendix, it doesn't seem too important for the paper but is presented at the very end.\n",
            "summary_of_the_review": "In general I believe this paper could be accepted, however the experimental evidence is not extensive. I would be willing to increase my score if the authors provide more discussions and quantify their approach more.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4113/Reviewer_72mB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4113/Reviewer_72mB"
        ]
    },
    {
        "id": "t8Y4EFfbmB",
        "original": null,
        "number": 3,
        "cdate": 1666628174584,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666628174584,
        "tmdate": 1666628174584,
        "tddate": null,
        "forum": "fcA--b8ycdX",
        "replyto": "fcA--b8ycdX",
        "invitation": "ICLR.cc/2023/Conference/Paper4113/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a method of learning system dynamics from raw sensory input based on Koopman operator theory. Both state and control variables are embedded into a latent space with an encoder-decoder structure. The system dynamics in latent space are forced to be linear. Apart from loss terms measuring the encoding and prediction capabilities, the authors add two losses measuring how well the latent dynamics are controllable using an LQR controller. This is novel compared to prior work.\nThe approach is validated on two simulated systems: pendulum and cartpole. The authors compare their proposed method to a baseline without the additional control-related loss terms and show qualitatively that their method can control both environments, whereas the baseline fails.",
            "strength_and_weaknesses": "Strength:\n- The paper is clear, conscise and easy to understand.\n- The authors propose two novel changes to koopman-based learning of system dynamics: First, they couple the prediction and control task and learn a representation that has to satisfy both. Second, the authors remove the requirement of the original controls being linear in latent space. These are valuable contributions.\n\nWeaknesses:\n1.  The experimental validation seems incomplete and purely qualitative. The authors do not compare against any prior method. Even though these prior methods do not train on the control task directly, they also test the control task directly or learn an actor-critic policy on top of the learned dynamics. DCKNet for example also tests the cartpole. I am missing a quantitative comparison to prior approaches.\nThe authors also only show a simple successful control trajectory. I would like to see a success rate when randomizing the initial condition of the system. \n2. The chosen control strategy, namely LQR, seems problematic for the control problems tested against. Both the pendulum and cartpole are typically considered difficult due to their inherent underactuation. In both cases the pole cannot simply be put into the upright configuration without performing a complex swingup motion. To the best of my knowledge LQR should be incapable of solving such a control problem. In the two control trajectories the authors show in their paper the pole directly moves to the upright configuration.\nTherefore, I would like the authors to clarify if the presented pendulum is underactuated. The shown control trajectory for the cartpole starts in an initial configuration which seems to have enough energy such that a direct swingup is possible. Therefore I would like to see the experiment starting from randomized initial conditions with a success rate.\n3. The approach the authors propose requires \"expert trajectories\" because the representation is learned such that the LQR controller in latent space mimics an optimal controller. For more complex systems gathering \"expert trajectories\" is difficult. Could the authors comment on how this impacts the scalability of their approach to more complex environments.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written and the writing quality is good.\n\nThe novelty would be satisfactory if the claims were supported with a stronger experimental validation. A purely qualitative evaluation based on a single performed control trajectory for both environments is weak and the major issue I have with the paper.\n\nI rate the Reproducability as good enough. All important equations and techniques used seem to be described in the paper. An available open-source implementation would make it great. ",
            "summary_of_the_review": "Due to the weak experimental support and my concerns regarding the chosen control approach I think the paper should be rejected. However, I welcome the authors add additional quantitative evaluations to support their claims.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4113/Reviewer_kRhs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4113/Reviewer_kRhs"
        ]
    }
]