[
    {
        "id": "XK8yl109O-5",
        "original": null,
        "number": 1,
        "cdate": 1666153739926,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666153739926,
        "tmdate": 1666153739926,
        "tddate": null,
        "forum": "Rn50hCOX9XX",
        "replyto": "Rn50hCOX9XX",
        "invitation": "ICLR.cc/2023/Conference/Paper6535/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This manuscript describes a straightforward application of standard deep learning techniques to the important problem of gene finding in eukaryotic genomes.  It is actually quite surprising that something like this has not been done before, since this is a central problem in genomics that is still not well solved despite decades of work in the area.  State-of-the-art methods have used HMMs for more than two decades. This paper provides convincing evidence that a deep neural network approach to this problem has promise.",
            "strength_and_weaknesses": "The paper does a very good job of providing a concise and accessible description of the gene finding problem for an ICLR audience.\n\nNot much novelty from a machine learning perspective.\n\nThe main missing piece in this paper, in my opinion, is an investigation into the types of errors that the system makes in comparison to other methods.  I want to know whether the system is missing some exons entirely, just getting the splice sites wrong, hallucinating new genes that don't exist, etc.\n\nThe other missing piece is an evaluation of how well the system works in practice on an actual genome, rather than on snippets of a genome selected around a gene.  As is, the paper is more like a proof of principle than a full solution.\n",
            "clarity,_quality,_novelty_and_reproducibility": "I think the paragraph beginning \"The current state of the art\" should include citations.  E.g., the first sentence of this paragraph should include citations.  And the first mention of software packages such as Glimmer should be accompanied by a citation.\n\nIn Section 4.1, there are some confusing statements about how the model is set up, where we are told, for example, that random flanks were added, but not precisely how these flank lengths were selected.  The text implies that this was handled differently in different experiments.  These choices need to be clearly described, for reproducibility. Similarly, why is the gene length capped at two different values, and which experiments are these caps used for?\n\nI was confused by the organization of the results.  I thought Section 4.2 was going to provide an initial comparison of the proposed method to the current state of the art.  But that section simply lists the what those methods are, and then we skip immediately to the ablation experiments.  I think the ablation experiments should come after the results that show that the method works well across many species. This seems to be what appears in Section 4.6.\n\nMinor:\n\n\"dominated the field for more than a decade\" -> \"... more than two decades\"\n\n\"HMM model\" is redundant.\n\nThe Stanke and Wacke citation used \\cite{} rather than \\citep{}.  This happens several other places as well.\n\n\"and highlighting\" -> \"and highlights\"\n\n\"recommendation are\" -> \"recommendations are\"\n\n\"identification ... are\" -> \"identification ... is\"\n\nSection 3.1 should clarify what the output labels are.\n\nThroughout, there is no need to capitalize the name of a method, even if the associated abbreviation necessarily uses capitals.  E.g. \"Linear chain Conditional Random Field (CRF)\" -> \"linear chain conditional random field (CRF)\"\n\n\"choice ... depend\" -> \"choice ... depends\"\n\n\"takes a onehot encoded sequences\" -> \"takes a onehot encoded sequence\"\n\n\"of the CRF:\" -> \"of the CRF is used:\"\n\n\"state:\" -> \"state\"\n\n\"Figure 3.1\" -> \"Figure 1\"\n\n\"to label to unnormalised label\" -> ??\n\n\"on the either across\" -> ??\n\n\"one the hidden\" -> \"on the hidden\"\n\n\"asses\" -> \"assess\"\n\n\"inference set\" -> \"inference\"\n\nThe description of annotation sources in Section 3.1 is not clear.  Provide URLs and make clear what those citations refer to.\n\n\"A. Thaliana\" -> \"A. thaliana\"\n\nSection 4.3 should do a better job of explicitly using the labeling scheme from Table 1, so we know which line is being discussed at each step.\n\nSection 4.4 mentions the name \"GeneDecoder\" without explaining that this is the name of the proposed method.  The name is formally introduced later.  I think you should state the name in the introduction.\n\n\"both strand\" -> \"both strands\"\n\n\"genes that lay\" -> \"genes that lie\"\n\n\"of sequenced\" -> \"of the sequenced\"\n\n\"models\" -> \"model's\"\n\n\"evolutionary\" -> \"evolutionarily\"\n\n\"The benchmark limited and specific\" -> ??\n\n\"model ,\" -> \"model,\"\n\n\"but it is still has\" -> \"but it still has\"\n\n\"previous findings\" -> What previous findings? This either requires a citation or a reference to some previous result in the current paper.\n\n\"Human\" -> no italics, no capitalization\n\n\"models closely\" -> \"model closely\"\n\n\"mebeddings\" -> \"embeddings\"\n\n",
            "summary_of_the_review": "From a machine learning perspective, very little here is new or innovative, but that's OK when the task is simply to apply standard methods to solve an important problem. The writing and organization are clear, though the paper is poorly proofread, with many typos and grammatical errors.\n\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6535/Reviewer_6LHj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6535/Reviewer_6LHj"
        ]
    },
    {
        "id": "Qi1IJYq0VWd",
        "original": null,
        "number": 2,
        "cdate": 1666557130029,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666557130029,
        "tmdate": 1666557130029,
        "tddate": null,
        "forum": "Rn50hCOX9XX",
        "replyto": "Rn50hCOX9XX",
        "invitation": "ICLR.cc/2023/Conference/Paper6535/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper develops a new algorithm for gene finding which is compatible with embeddings obtained from deep and transfer learning. ",
            "strength_and_weaknesses": "The paper argues the prior models for gene prediction \u201clack the flexibility to incorporate deep learning representation learning techniques\u201d as a potential drawback. This sets the motivation of the paper to develop a deep learning compatible gene prediction model. However I do not see why deep learning compatibility, per se, is a drawback of the prior works. Thus, in my opinion, the paper is poorly motivated from both the biological and methodological perspectives. The issue becomes even more problematic, as the paper demonstrates that the proposed deep learning-compatible method does not significantly improve the performance in any tangible aspect over the baseline considered. Unfortunately, all these are on top of the fact that the paper misses a key family of baseline algorithms for gene finding, i.e., GeneMark, GeneMark-S, etc. which is discussed in the paper but never compared with. ",
            "clarity,_quality,_novelty_and_reproducibility": "The quality is not above acceptance threshold for ICLR.",
            "summary_of_the_review": "The paper can be substantially improved by 1) better motivating the need for a new gene finding algorithm, 2) discussing the proposed method more clearly without over-referring to the Appendix, which I found highly distracting, 3) including key remaining baselines, and 4) editing the grammatical errors which occasionally harms the clarity of the message. I do not thing in the current state the paper is ready for publication.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6535/Reviewer_DUdq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6535/Reviewer_DUdq"
        ]
    },
    {
        "id": "eDuE4oJ1pm",
        "original": null,
        "number": 3,
        "cdate": 1666643309943,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666643309943,
        "tmdate": 1670833879948,
        "tddate": null,
        "forum": "Rn50hCOX9XX",
        "replyto": "Rn50hCOX9XX",
        "invitation": "ICLR.cc/2023/Conference/Paper6535/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors have presented a novel method of gene finding - where the task is to label spans of text the functional labels.  The presented method uses a neural algorithm that leverages conditional random fields (CRF) over the state of the art HMM methods. They provide a way to fuse pre-trained representations of genomic sequences with their architecture for this task. The novelty is in terms of architecture, incorporating domain information in the form of allowed direction of state changes and experimentations across organisms.",
            "strength_and_weaknesses": "Strengths\n\nState of the art gene finding\n\nPioneer attempt to combine pre-trained embeddings with gene finding\n\nIncorporation of domain knowledge to improve performance\n\nExhaustive experimentation\n\nCross organism experiment verification\n\n\nWeaknesses\n\nNo clarity or intuition on why CNN + LSTM does better than pre-trained models\n\nWhile an empirical ablation has been done, it seems non-intuitive that the pre-trained embeddings do not help much, considering they are tested on similar downstream non-coding tasks. \n\nNovelty needs to be explained for architecture \n\nFor example, how does the combination of embeddings work with neural HMM based formulation work as compared to the state of the art HMM methods?\n\nThe efficiency study for these methods is missing. What do we gain by using this architecture (which takes time to compute) against others? This is relevant especially because the values of Augustus\u2019 baseline performance is quite close.\n\nNo statistical significance values reported",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity - Paper is very easy to read and follow\n\nQuality - Moderate quality work - requires more analysis to justify the findings\n\nNovelty - Moderately novel - CRFs are the mainstay of POS tagging tasks and this is the first application in the gene embedding space. Though novel, more analysis is required to ascertain the need with respect to state of the art methods.\n\n\nReproducible - The paper is easily reproducible and gives clarity.",
            "summary_of_the_review": "The authors have proposed a new neural architecture, with elegant ways of including domain knowledge, for the task of gene finding. This could potentially be a new fine tuning task for gene embedding research and help practitioners in unearthing genes among unlabelled data. The experiments have been conducted well and the problem is relevant and exciting.\n\n\nAt this point, I would recommend a weak reject because I am not convinced this neural architecture, though it incorporates domain knowledge, is significantly better than the state of the art methods in any setting, (for example, Augustus also seems to perform well in cross organism settings). \n\n===============================\nSeveral of the comments have been addressed. So increasing the score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6535/Reviewer_ggXe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6535/Reviewer_ggXe"
        ]
    },
    {
        "id": "eSust7vS9Hi",
        "original": null,
        "number": 4,
        "cdate": 1666726835142,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666726835142,
        "tmdate": 1666726835142,
        "tddate": null,
        "forum": "Rn50hCOX9XX",
        "replyto": "Rn50hCOX9XX",
        "invitation": "ICLR.cc/2023/Conference/Paper6535/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The authors tackle the problem of annotating genes in newly-sequenced genomes. They develop a model called GeneDecoder which uses a combination of a CRF, LSTM and dilated convolutional layers. The authors show that the model relearns several properties of genes, including directionality and length distribution. The model achieves similar predictive performance to existing method Augustus. ",
            "strength_and_weaknesses": "Overall, the problem of annotating genes is important, the method is reasonable and the manuscript is understandable. The methodological novelty is low, as the method is a combination of standard CRF, LSTM and dilated CNN models. The experimental setup is flawed and the results are poor. \n\nI couldn't tell what the model used by GeneDecoder is. It involves a neural network, whose architecture is described in A.4. However it also uses a Latent CRF. I think the NN outputs a representation which forms the input to the CRF? This isn't actually stated.\n\nBenchmarking gene prediction tools is challenging because many of the annotations within gene databases (e.g. GENCODE) are derived from computational predictors. Thus it can be hard to tell whether a predictor is good at discovering real biology or simply recapitulating the errors made by previous predictors. There exists a benchmark for this task, G3PO (Scalzitti et al 2020), cited by the authors.  Unfortunately, the authors did not use this benchmark and instead used an ad-hoc strategy with many issues (see below).\n\nThe authors compared to pretrained versions of existing models, so differences in performance could result from differing training sets. When the authors compared against Augustus using a training set similar to Augustus's, results were similar or worse.\n\nThe authors trained and tested on genes of the same species. This not a proper simulation of the target application, in which a new species is sequenced and its genome must be annotated from scratch. \n\nIn splitting genes into train and test sets, the authors ensure that all isoforms of the same gene are placed in the same set. However, since many genes overlap, the same sequences likely appear in both train and test sets. This pitfall is described in detail in the following paper. A better strategy would be to split train and test by chromosome (or by species; see previous note). \nhttps://pubmed.ncbi.nlm.nih.gov/34837041/",
            "clarity,_quality,_novelty_and_reproducibility": "See above.",
            "summary_of_the_review": "See above.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6535/Reviewer_rvN5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6535/Reviewer_rvN5"
        ]
    }
]