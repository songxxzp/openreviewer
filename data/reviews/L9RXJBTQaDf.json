[
    {
        "id": "m0MagZkzKX",
        "original": null,
        "number": 1,
        "cdate": 1666381038365,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666381038365,
        "tmdate": 1666381038365,
        "tddate": null,
        "forum": "L9RXJBTQaDf",
        "replyto": "L9RXJBTQaDf",
        "invitation": "ICLR.cc/2023/Conference/Paper4583/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors indicate that modern computer vision systems tend to fail under dynamic lighting conditions. This is because computer vision algorithms do not explicitly make use of adaptation mechanisms similar to the ones used in retinal ganglion cells. Because current deep learning models of the retina have no in-built notion of light level , they are unable to accurately predict RGC responses under lighting conditions that they were not trained on. The authors use a model of RGC and test it on monkey and rat retinal data. The authors argue that their algorithm can be used with computer vision algorithms to adapt to dynamic environments.",
            "strength_and_weaknesses": "Strengths:\n\nS1: the authors identify and important problem in computer vision algorithms and make some biologically motivated suggestions on how this problem could be solved.\n\nS2: the paper is extremely well written and is up to ICLR standards\n\nWeaknesses:\n\nW1: With respect to making computer vision algorithms more robust, why do they feel that such an adaptation approach is necessary? Why not simply give HDR data (high dynamic range data) as input to algorithms (ie data that is represented with more than 8 bits per channel). Wouldn't this be sufficient to deal with saturation issues in high intensity situations, and low contrast in low light situations?\n\nW2: page 1 typo: \"We focus here on retina\". Missing \"the\"\n\nW3: prior related work discussed in the paper does not go before 2015-2016. I suggest an expansion on prior work detailing the effects of sensor bias in experimental methods.\n\nW4: section 3.3. The authors do electrophysiology experiments from ex vivo macaque monkey and rat retina. It is not often that you see such experiments in machine learning/computer vision conferences. Machine learning conferences like ICLR are more focused on algorithms that improve real-world performance. The way the paper is written it seems to be focused more towards a computational neuroscience audience. While not necessarily bad, in this case this seems to be to the detriment of demonstrating whether this algorithm actually leads to improvements in accuracy, performance, speed, power of computer vision systems. The main focus of the authors should have been to show that their algorithm leads to some quantifiable improvements compared to other algorithms that are solving a certain real-world problem. The authors seem to try to touch upon this in the appendix, but not in a lot of detail. This is the paper's rather major weakness in my opinion. The appendix algorithm should be in the main paper and its evaluation on a real world problem expanded upon.\n\nW5: page 5: I suggest the authors introduce parasol and midget cells and how their behavior differs, since the typical ICLR audience will not be familiar.\n\nW6: Eq 1: Should it be T or T-1? Is it sample of population variance?\n\nW7: Eq 1: clarify how Var[y] was obtained.\n\nW8: page 5: how were the sets A, B obtained? Are there confidence intervals on these estimators? Is eq 2 an unbiased estimator? Clarify if this estimator is used in Cadena 2017. It is unclear whether the average is across time. Clarify over what the expected value is taken.\n\nW9: will source code and the data be provided to make this reproducible?\n\nW10: if you connect a live camera as input, how well would the algorithm adapt to changes in the sensor gain and shutter speed?\n\nW11: page 6: 180 frames are used. At 30fps this is 6 seconds. This means it takes 6 seconds for adaptation to happen? Could this be a drawback in computer vision algorithms?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. It is an interesting, though somewhat incomplete effort at biologically plausible computer vision. It is not clear whether data and source code will be provided to make this reproducible.",
            "summary_of_the_review": "Overall, while this is a well written paper, I feel the authors need to do a better job adapting it towards the typical ICLR audience. Currently it is addressed more towards a computational neuroscience audience. As indicated on page 6, I do not feel comfortable accepting to ICLR a paper that has only been tested with white noise input. The effort in appendix C to compare it with actual algorithmic performance is incomplete and needs more work",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Responsible research practice (e.g., human subjects, data release)"
            ],
            "details_of_ethics_concerns": "Experiments were done on macaque monkeys and rats. AC should make sure there are no conflicts with ICLR guidelines",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4583/Reviewer_Rcws"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4583/Reviewer_Rcws"
        ]
    },
    {
        "id": "XYLFOYciWf",
        "original": null,
        "number": 2,
        "cdate": 1666579832529,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666579832529,
        "tmdate": 1666579832529,
        "tddate": null,
        "forum": "L9RXJBTQaDf",
        "replyto": "L9RXJBTQaDf",
        "invitation": "ICLR.cc/2023/Conference/Paper4583/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors showed that putting a photoreceptor front-end with adaptive dynamic gain control allows a deep neural network to predict more reliably the responses of retinal ganglion cells in different lighting conditions than the STOA CNN retinal model. ",
            "strength_and_weaknesses": "Introducing an adaptive gain control mechanism as a front end to CNN is a sensible and good idea.  The fact that such an adaptive mechanism should improve a CNN's prediction of neural response in different lighting conditions is not surprising. Nevertheless,  demonstrating empirically it actually does the job is still meaningful and an accomplishment. Making the adaptive mechanism itself partially learnable is also novel. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clear enough.",
            "summary_of_the_review": "While the technical and conceptual contribution in ML and representational learning are relatively limited, this paper is acceptable for demonstrating or proving  that an adaptive gain control mechanism as a front-end of CNN can improve the prediction of RGC's responses in different lighting condition. Even though it might be proving the obvious, it is still important and might have significant technical implication for visual prothesis and vision system research in the future. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4583/Reviewer_TU1Q"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4583/Reviewer_TU1Q"
        ]
    },
    {
        "id": "Hp0mJsbt0G",
        "original": null,
        "number": 3,
        "cdate": 1666664567391,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666664567391,
        "tmdate": 1669855306215,
        "tddate": null,
        "forum": "L9RXJBTQaDf",
        "replyto": "L9RXJBTQaDf",
        "invitation": "ICLR.cc/2023/Conference/Paper4583/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper implements a photoreceptor model in Keras and uses it as a front end in training a shallow CNN model to predict retinal responses to white noise stimuli. The paper reports that the photoreceptor model allows the model to generalize better to new lighting levels. This observation is demonstrated using monkey and rat RGC data. The light levels in the rat experiments used a more dramatic range of variation (4 orders of magnitude) that required a more complex cross-validation procedure due to largely non-overlapping rod and cone activation across levels. ",
            "strength_and_weaknesses": "Strengths\n\nI found the paper clear and easy to follow. The results are simple and straightforward.\n\nThe paper provides decent evidence that the photoreceptor model improves generalization to new lighting levels, which is an important form of variation.\n\nExploiting insights from biology to improve machine learning is rare and potentially exciting contribution.\n\nWeaknesses\n\nApplications to vision and ML are preliminary and left to the appendix (Appendix C), which seems likely to limit the impact of the work to the ICLR community. The photoreceptor model is rather complex which I worry will limit its popularity and impact. The authors toy with creating a simpler, convolutional layer based on their model, but again this part of the paper is preliminary and left to the appendix. \n\nThe generalization effect in monkey RGCs is only substantial for the case when training on high light levels and testing on low light levels. No measures of statistical significance or confidence are reported.\n\nIt would be interesting to know whether the model would have difficulty generalizing to a variety of lighting conditions when trained using naturalistic variation in retinal stimulation. It would also be useful to quantify model performance using naturalistic stimulation since one of the benefits of having a DNN model is that it can potentially predict neural responses to real-world stimuli, as opposed to just white noise.\n\nIf one does use a training set with a wide range of lighting levels is there any benefit of the photoreceptor model? For example, does the model require less training time to reach a given level of accuracy? For ML applications, it\u2019s not clear whether the benefit of the photoreceptor model would be worth the added complexity, particularly if it\u2019s relatively easy to create robustness by applying a bit more diversity to the training regime. \n",
            "clarity,_quality,_novelty_and_reproducibility": "Combining a biophysical photoreceptor frontend with a standard DNN architecture is novel to my knowledge.\n\nThe writing is clear and easy to follow. \n\nAs noted above, I do not believe the paper reports any statistics or measures of confidence\u2026\n\nThe cross-validation approach used to evaluate generalization to extreme lighting conditions is convoluted but seems sound.\n\nThe authors do not report any data on whether training the photoreceptor model is important or not. How did the authors choose which parameters to optimize? The photoreceptor model has a small number of parameters compared with the DNN layers, and this mismatch might make it hard to jointly train using first-order optimization algorithms such as ADAM. \n\nIt is not clear how the L1 and L2 penalties were selected (grid search?). Were the hyper-parameters chosen using the same test data used to compute explained variance? If so, this would introduce an upward bias in prediction accuracy. It would be preferable to select hyper-parameters using validation and measure performance in a separate test data set. \n\nThe authors split the trials into 2 when estimating the noise variance. However, I believe they use all the data when estimating prediction accuracy, which produces a mismatch. This mismatch is unlikely to matter since the authors report that the responses were highly reliable, but it would be better to use the same amount of data when evaluating predictions and noise variance or to correct for the extra data in the predictions.\n\nAm I correct that the data reported is from a single rat and a single monkey?\n\nI do not have the expertise to evaluate whether the retinal model is properly implemented. \n",
            "summary_of_the_review": "The combination of a photoreceptor frontend with a DNN to predict RGC responses is novel and potentially interesting. I am overall convinced that this addition helps with generalization to novel lighting levels, at least when the differences are extreme. It is unclear to me whether this insight will in practice be useful to the ML community. There might be simple training strategies that would avoid this issue, and the photoreceptor model is complex and seems unlikely to become a mainstay of computer vision models. \n\nResponse after rebuttal:\n\nI apologize for my slow response. The authors have addressed all of my comments, which I appreciate. I think this paper provides a solid contribution to the computational neuroscience literature and seems well-suited to the Neuroscience and Cognitive Science section. I still find the generalization results in monkey RGC a little underwhelming, and my best guess is that the impact of the paper will be modest. Nonetheless, I have increased my score from 5 to 6 based on the authors' argument that their paper is appropriate for the noted section. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4583/Reviewer_b3Ty"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4583/Reviewer_b3Ty"
        ]
    }
]