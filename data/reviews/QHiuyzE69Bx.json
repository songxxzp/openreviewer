[
    {
        "id": "YkXCJvijBu",
        "original": null,
        "number": 1,
        "cdate": 1666623598639,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666623598639,
        "tmdate": 1666623598639,
        "tddate": null,
        "forum": "QHiuyzE69Bx",
        "replyto": "QHiuyzE69Bx",
        "invitation": "ICLR.cc/2023/Conference/Paper2205/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper address a representation similarity metric analysis for high-dimension features by reformulating the representation simiarity metrics such as CKA, Procrustes, and CCA-based methods. Also the authors validate the changes by ablated representation by comparing linear decoding and non-linear classification performances. They present the analysis results on two CNNs such as AlexNet and MobileNetV2 traind on ImageNet. \n",
            "strength_and_weaknesses": "### Strength\n- In-depth analysis on representation similarity is an important and fundmental topic on representation learning. It can contribute to model interpretability.\n- Representation similarity metrics for high-dimensional features is also a significant topic.\n- Experiments and analysis on ImageNet-scale data are valuable.\n\n### Weakness\n- [Major] This paper seems to be basically based on [Ding et al. 2021] and its extension to high-dimensionality by reformulating metrics and linear decoding analysis. However, the advantage of the high-dimensionality is not effectively showed. The relevant information on high-dimensionality is that the authors validate their method on AlexNet and MobileNetV2 trained with ImagNet only. It is hard to find the specific details on high-dimensionality despite the emphasis in the title.\n- [Major]  I am not sure high-dimensionality is mandatory in represenation similarity metric analysis because a feature dimension of a single layer of many Transformer-based models is from 768 to 2048. To show the efficacy, experiments on higher dimensional feature similarity might be required. For example, to emphasize the effects of high-dimensionality, the aughors can concate two layers features over several tens of dimensionality. \n- [Major]  The authors presented 10 classes results in Figures 2 and 3. It is not clear how to select 10 classes from 1k classes of ImageNet. Overall, the experiemental setup is not clear for reproducibility and understanding even if they provided the source code. \n- [Major]  Following [Ding et al. 2021], experiments on multiple seeds are required. \n- [Minor] Although the authors argue they validate their method on popular CNN models, AlexNet and MobileNetV2 are not popular nowadays. Because [Ding et al. 2021] presents the results on BERT, the authors need to consider the similar experiments. The experiments on ViT are ok. ",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity and Quality\n- This paper is not easy to follow. Overall flow of this paper seems to follow [Ding et al. 2021]. But the paper is not typical organization. For example, Conclusion looks far from highlighting the core arguments of the paper. \n- There are too many contribution summary. Indeed, some of them is hard to be considered as contributions (4th and 5th)\n\n### Novelty\n- Idea on comparing linear decoding and classification accuracy is interesting. But overall flow is based on the previous work.\n\n### Reproducibility\n- The authors submitted the source code. However, it is not easy to understand how to conduct the experiments. ",
            "summary_of_the_review": "Despite the topic importance, this paper has some room to be improved (See the weakness). However, I am not an expert in this topic, so I mainy decided my score based on paper organization. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2205/Reviewer_u5hR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2205/Reviewer_u5hR"
        ]
    },
    {
        "id": "7biI7BVNIR",
        "original": null,
        "number": 2,
        "cdate": 1666691144297,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666691144297,
        "tmdate": 1666691144297,
        "tddate": null,
        "forum": "QHiuyzE69Bx",
        "replyto": "QHiuyzE69Bx",
        "invitation": "ICLR.cc/2023/Conference/Paper2205/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper conducts a series of experiments to study how well each metric captures changes to representations. Linear decoding probes and network performance are choosen to be the measurements. Authors also propose several modification to existing metrics to make it possible to evaluate high-diemntional representations with low computational cost. Experiments are conducted on AlexNet and MobileNetV2 pre-trained with ImageNet.\n",
            "strength_and_weaknesses": "**Strength:**\n\n- The reformulation of CKA, Procrustes can be applied to high-dimentional representations.\n- Some observations are new compared to existing studies.\n\n**Weakness:**\n\n- I think this paper is a simple extension of [1] which follows the same testing protocal. The observations are also empirical without deeper explanation.\n- Apart from Image-net pretraining and classification, more experiments should be performed on different tasks to further verify the claims in this paper.\n- The organization can be improved. For example, Page 8 has so much blank areas. ",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity, Quality\uff1a The organization can be further improved. \n- Novelty: I think the novelty of this paper is a little limited. \n- Reproducibility : The paper has provided the code for reproducibility.",
            "summary_of_the_review": "- This paper has merits on reformulating existing metrics for advancing calculating high-dimentional representations and conducting experiments to observe the correlation between metric and functionality. Based on the experiments, authors find some new observations. However, I think the experiments are not sufficient to support the claims. The overall contribution is not enough for accepting this paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2205/Reviewer_ZbX5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2205/Reviewer_ZbX5"
        ]
    },
    {
        "id": "qLxiUN_ic3",
        "original": null,
        "number": 3,
        "cdate": 1667389540626,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667389540626,
        "tmdate": 1667389540626,
        "tddate": null,
        "forum": "QHiuyzE69Bx",
        "replyto": "QHiuyzE69Bx",
        "invitation": "ICLR.cc/2023/Conference/Paper2205/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper performs a comparative study of three representation similarity metrics (CKA, Procrustes and PWCCA) evaluated on representations generated by AlexNet and MobileV2Net. This work extends Ding et al. (2021) (which studies the same metrics on ResNet with CIFAR-10 test images and language models). The main contribution is the reformulation of these metrics to enable efficient computation on larger models with larger images. Further contributions include the comparison of the evaluation of these metrics on two functionality measures: linear probing accuracies and network performance deficits.",
            "strength_and_weaknesses": "Strengths\n\nThe paper is well written - the theory and results are presented clearly. The paper presents interesting insights into the performance of various similarity metrics on representations generated by CNNs with two functionality measures.\n\nWeaknesses\n\nThe novelty/originality is unclear.  The paper appears to extend the work of Ding et al. (2021) who performs similar comparisons of these metrics on ResNet with CIFAR-10 (omitting the analysis of these two functionality measures).  If the main contributions is the reformulation of the metrics and the inclusion of these two functionality measures - it would be useful to see how this compares to the work of Ding et al. (2021)  e.g. the computational resources used under the original formulations on ResNet or AlexNet vs the reformulation. ",
            "clarity,_quality,_novelty_and_reproducibility": "Some questions on clarity:\nThe CNNs are trained on ImageNet. Is ImageNet also used as a test set for evaluating the metrics?\nHow do these functionality measures compare to the study performed by Ding et al. (2021)?\n\n",
            "summary_of_the_review": "This work provides some interesting insights on representation similarity metrics evaluated on CNNs. The novelty/originality needs further clarification, especially with respect to Ding et al. (2021). ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2205/Reviewer_TGPW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2205/Reviewer_TGPW"
        ]
    }
]