[
    {
        "id": "gPCfPgtPxnx",
        "original": null,
        "number": 1,
        "cdate": 1666318111855,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666318111855,
        "tmdate": 1666546100171,
        "tddate": null,
        "forum": "dOxe6utTKC",
        "replyto": "dOxe6utTKC",
        "invitation": "ICLR.cc/2023/Conference/Paper583/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper proposed a new learning concept called ADCOL(Adversarial Collaborative Learning) for non-IID features. Instead of adopting the widely used model-averaging scheme, ADCOL conducts training in an adversarial way: the server aims to train a discriminator to distinguish the representations of the parties, while the parties aim to generate a common representation distribution.\n",
            "strength_and_weaknesses": "Strength: \nIn this paper, focusing on the Non-IID feature, the author thinks out of the model-averaging scheme used in FL, and proposes a novel learning concept called adversarial collaborative learning. Instead of averaging the local models, the author applies adversarial learning to match the representation distributions of different parties. Specifically, the server aims to train a discriminator to distinguish the local representations by the party IDs, while the parties train the base encoders such that the generated representations cannot be distinguished by the discriminator. Besides the base encoders, each party trains a predictor for local personalization and ensures that the generated representation is meaningful for the prediction task.\n\nWeakness:\nThe authors claim they used the same task as in the FedBN study. However, the experimental setup in the paper does not exactly FOLLOW the setup of FEDBN, which may give the impression that the authors are choosing the experimental setup that is more favorable to their own method. More importantly, FedBN was designed for the Non-IID Feature task, but the experimental results in this paper yielded a performance inconsistent with FedBN. In addition, while this paper proposed a novel collaborative learning approach for non-IID features based on adversarial architecture and claimed to achieve better performance than other SOTA methods. However, it is known that adversarial architectures are challenging to train, and thus may be weak in experimental deployment and replication compared to other FL methods for Non-IID features.\n",
            "clarity,_quality,_novelty_and_reproducibility": "In general, it is well-organized and written, and the experimental results are encouraging. I'm not sure if Reproducibility is possible\n",
            "summary_of_the_review": "In this paper, focusing on the Non-IID feature, the author thinks out of the model-averaging scheme used in FL, and proposes a novel learning concept called adversarial collaborative learning. \n1. The authors should explain why they did not follow the FedBN experiments completely. Of course, it would be better if the authors could give the performance of the complete follow FedBN experimental setup to demonstrate the advantages of the proposed method.\n2. In the experimental results analysis section, the authors should give more analysis of the methods designed for the Non-IID feature, especially FedBN. For example in Table 16, the effectiveness of the proposed method on Non-IID features might be better demonstrated if the authors could give the results of DP-FedBN.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper583/Reviewer_bkH5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper583/Reviewer_bkH5"
        ]
    },
    {
        "id": "bctugfPSoqm",
        "original": null,
        "number": 2,
        "cdate": 1666622128789,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666622128789,
        "tmdate": 1666622128789,
        "tddate": null,
        "forum": "dOxe6utTKC",
        "replyto": "dOxe6utTKC",
        "invitation": "ICLR.cc/2023/Conference/Paper583/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors aim to address the non-IID feature distribution in the federated learning setting. To achieve this goal, the authors propose Adversarial Collaborative Learning (ADCOL) by introducing a discriminator in the center server and encoders among parties. For the proposed ADCOL, the authors do the theoretical analysis and extensive experiments to show the effectiveness. Overall, the structure paper is well-organized, and the contribution is incremental.",
            "strength_and_weaknesses": "[Strength]\nThe problem of the paper aims to address is practical, non-iid distribution is a key factor in the real-world federated learning setting. The motivation is reasonable.\nThe structure of the paper is complete and well-organized.\nThe experiments are extensive.\n\n[Weakness]\nThe theoretical contribution of the paper is incremental. The proposed ADCOL learning framework is not novel to some extent. The similar structure also exists in many GAN-based multi-task and multi-view learning settings, i.e., the generator aims to capture the domain-invariant (task-invariant or view-invariant) knowledge, and the discriminator aims to detect which encoding comes from which domain (task, or view). Bringing this similar idea to the federated learning setting may limit the contribution of the paper.\n\nThe awareness of transferring the representation other than model parameters is good in terms of privacy leaks. But the solution is straightforward. It could be more helpful to do the in-depth analysis to enhance the paper more solid.\n\nFor the selected datasets, it is better to show the statistical distribution of the heterogeneous features. It could be more aligning the main idea of the paper and help to explain the following experimental results. For the current version, the discussion of the outperformance is limited. Just listing the numbers may not be sufficient.\n\nIn Table 2, the communication round and communication size for Per-FedAVG and FedRep are missing. The authors may want to explain why they are not reported.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper presentation is clear, and the organization is reasonable. The novelty is incremental, and the reproducibility seems ok from shown context details.",
            "summary_of_the_review": "Overall, the paper introduces a solution for addressing the non-IID feature distribution problem in the federated learning setting. The paper is complete with the proposed method, theoretical analysis, and experiments. The novelty is incremental, and some details can be enhanced.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper583/Reviewer_h9oS"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper583/Reviewer_h9oS"
        ]
    },
    {
        "id": "PaT0PVBL3b",
        "original": null,
        "number": 3,
        "cdate": 1667357598261,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667357598261,
        "tmdate": 1667357598261,
        "tddate": null,
        "forum": "dOxe6utTKC",
        "replyto": "dOxe6utTKC",
        "invitation": "ICLR.cc/2023/Conference/Paper583/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new learning method, ADCOL, for non-iid features for federated learning. Furthermore, the experiments on three tasks show that ADCOL achieves better performance than state-of-the-art FL algorithms on non-IID features.",
            "strength_and_weaknesses": "Strength. \n1. This paper is well-written and easy to follow. \n2. The method is new in the area of FL. \n\nWeakness.\n1. The novelty is limited. \n2. The experimental result is not such rigorous. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity. \nThis paper is well-written and easy to follow.  This paper explaind the ADCOL clearly and show its better performance in experiments. But the theorems are not clear enough. \n\nQuality. & Novelty. \nThe Adversarial Collaborative Learning(ADCOL) has been used in other areas and shown good performance. This paper introduces the idea in FL. The method is interesting and new. Also, the paper gives some theoretical analysis and competitive experiemental results. However, averaging results of different datasets seems meaningless. \n\nReproducibility.  \nThis paper does not provide code and data for reproducing the results. ",
            "summary_of_the_review": "This paper proposes a new learning method, ADCOL, for non-iid features for federated learning. The Adversarial Collaborative Learning(ADCOL) has been used in other areas and shown good performance. This paper first introduces the idea in FL to solve the non-iid feature problem. Furthermore, the experiments on three tasks show that ADCOL achieves better performance than state-of-the-art FL algorithms on non-IID features.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper583/Reviewer_vpMT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper583/Reviewer_vpMT"
        ]
    }
]