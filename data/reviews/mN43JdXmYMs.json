[
    {
        "id": "lHhlUG2kbC",
        "original": null,
        "number": 1,
        "cdate": 1666599014484,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666599014484,
        "tmdate": 1666599396326,
        "tddate": null,
        "forum": "mN43JdXmYMs",
        "replyto": "mN43JdXmYMs",
        "invitation": "ICLR.cc/2023/Conference/Paper6372/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper is concerned with probabilistic predictions: Instead of predicting a class, the prediction is a distribution over the label space. The paper proceeds by using a probabilistic loss functional, and consider an adversarial training approach. The proposed method is a minimax problem, with perturbations in a moment set that is specified using the feature function. The paper then provides the dual formulation and integrates this formulation into a gradient descent algorithm (Algorithm 1).",
            "strength_and_weaknesses": "The paper lacks clarity and mathematical rigor:\n1. Before Proposition 1 in the main text, the authors claim that \u201cthe ambiguity set ($\\mathcal{A}(\\mathbb{P}^{\\mathrm{emp}}$) is a compact convex set.\u201d However, no proof is provided.\n2. In the proof of Proposition 1, page 13, line 6, the authors invoke Sion\u2019s minimax theorem. However, the authors did not verify that the loss function is lower-semicontinuous in $\\mathbb{P}_{Y|X}$ and upper-semicontinuous in $\\mathbb{Q}$.\n3. Also, in the proof of Proposition 1, in the middle of page 14, the authors claimed that \u201cAgain by strong duality, we can rearrange\u2026\u201d. However, no justification for strong duality has been provided. \nFurther, I feel that the use of $I_{\\mathcal{C}}(\\cdot)$ is unnecessary. In fact, the indicator function is non-smooth, non-convex, which complicates the whole process of applying duality results.\n4. The notations of $\\min_{\\mathbb{P}}$ is really confusing in the statement of Proposition 1. The expectation is already taken with respect to $P_x^{emp}$, so what is the $\\min_{\\mathbb{P}}$ in equation (3) concerning? Shouldn't $\\mathbb{P}$ be $\\mathbb{P}_{Y|X}$?\n5. The results of this paper seem to follow from Li et al. (2022) [Proposition 1, Corollary 2 and Theorem 3], however, up to today (Oct 23), I could not find the manuscript of Li et al. (2022) on arXiv or on any public domain (openreview). At this point, it is difficult for me to judge the novelty of the manuscript.\n6. Using the setup of this paper, any distribution can be conveniently represented as a matrix because the space $\\mathcal{Y}$ is discrete and the space $\\mathcal{X}$ can be reduced to a finite set supported on the training data. From this perspective, the problem becomes uninteresting because, in the end, we are only perturbing the elements of a matrix. The problem only becomes interesting, in my opinion, when $\\mathcal{Y}$ is continuous or we allow perturbations of the marginal distribution on $X$.\n7. The numerical experiments can not demonstrate that the proposed method is superior than existing approaches. The experiments are also conducted with $\\varepsilon = 0$, which implies no moment robustness.\n8. The authors should make clear how a probabilistic prediction is made at test time, when only $x$ is given and there is no information on $y$.",
            "clarity,_quality,_novelty_and_reproducibility": "- Unclear mathematical exposition \n- Limited novelty when compared with Li et al (2022)",
            "summary_of_the_review": "- The paper lacks mathematical rigor, which severely hinders my understanding and appreciation of the results. \n- There is a significant overlap with Li et al (2022) which requires clarification.\n- The experiment does not demonstrate the benefit of the proposed method",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6372/Reviewer_ARxu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6372/Reviewer_ARxu"
        ]
    },
    {
        "id": "JW5GsSdH1d",
        "original": null,
        "number": 2,
        "cdate": 1666718677354,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666718677354,
        "tmdate": 1666718677354,
        "tddate": null,
        "forum": "mN43JdXmYMs",
        "replyto": "mN43JdXmYMs",
        "invitation": "ICLR.cc/2023/Conference/Paper6372/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers distributionally robust probabilistic supervised learning. The ambiguity set is constructed to include distributions that share the same marginal with the empirical distribution and are no more than \u03b5 away from the empirical in terms of first-order feature moment divergence. The strong duality is shown such that the primal DRO problem is equivalent to a regularized ERM problem. The authors characterize the solutions to the proposed method and present an efficient algorithm for specific losses. Moreover, neural network representations are incorporated and the DRO problem can serve as a differential layer to enable end-to-end differentiable learning. \n\n",
            "strength_and_weaknesses": "strength:\n- A DRO version of probabilistic supervised learning is proposed under first-order moment ambiguity sets. \n- The DRO problem can be incorporated into neural networks and perform end-to-end differentiable learning\n\n\nWeaknesses\n- The theoretical result is weak, and the technical contribution is not clear -- in all theorems and Propositions, the reference (Li et al., 2022) is cited, but there is no clear justification for the differences with (Li et al., 2022) \n- The empirical study on real-world data is not enough, especially the baseline methods compared are very limited, only neural network models with the softmax and the spherical softmax function.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-organized and easy to follow. I found that some references might be related to this work but seems missing in the paper:\n\nShafieezadeh Abadeh, S., Mohajerin Esfahani, P. M., & Kuhn, D. (2015). Distributionally robust logistic regression. Advances in Neural Information Processing Systems, 28.\nLee, C., & Mehrotra, S. (2015). A distributionally-robust approach for finding support vector machines. Available from Optimization Online.\nChen, R., Hao, B., & Paschalidis, I. (2021). Distributionally Robust Multiclass Classification and Applications in Deep CNN Image Classifiers. arXiv preprint arXiv:2109.12772.\nAmos, B., & Kolter, J. Z. (2017, July). Optnet: Differentiable optimization as a layer in neural networks. In International Conference on Machine Learning (pp. 136-145). PMLR.\nAgrawal, A., Amos, B., Barratt, S., Boyd, S., Diamond, S., & Kolter, J. Z. (2019). Differentiable convex optimization layers. Advances in neural information processing systems, 32.\n\n",
            "summary_of_the_review": "Overall this paper is well-written and considers a problem that can be of broad interest to the machine-learning community. The results are standard -- such as the duality with regularized ERM and the risk bounds. However, the theoretical results look weak and most importantly, the authors didn't explain their technical contribution clearly, as compared with the work (Li et al., 2022). Moreover, the result in Corollary 2 is only limited to the case epsilon=0, which is the standard ERM, not the DRO problem. \nAlso considering that the numerical results are also limited and do not compare with many baseline methods, I think this is more like a borderline paper.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6372/Reviewer_QSPn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6372/Reviewer_QSPn"
        ]
    },
    {
        "id": "7GPNFD98n5",
        "original": null,
        "number": 3,
        "cdate": 1666976058592,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666976058592,
        "tmdate": 1666976058592,
        "tddate": null,
        "forum": "mN43JdXmYMs",
        "replyto": "mN43JdXmYMs",
        "invitation": "ICLR.cc/2023/Conference/Paper6372/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors present a method for learning a model that outputs probabilities wherein the output probability is the output of an optimization over an uncertainty set rather than, say the result of a softmax. They show how to learn a model using this approach and compare the method to simple alternatives on several datasets.",
            "strength_and_weaknesses": "See below.",
            "clarity,_quality,_novelty_and_reproducibility": "See below.",
            "summary_of_the_review": "Overall, I found the technical aspects of this paper clear and well-written, and the methods and evaluations reasonable. With that said, I am still very unclear on the motivation for this method, especially given that if failed to outperform simple softmax on any of the evaluation problems. My concerns are below:\n\nMajor:\n\n1. I did not follow the motivation for this method and strongly recommend that authors work to make the intuition clearer in the introduction.    Further, the experiments did nothing to make this motivation clearer. If anything, I left the paper wondering why I would use this method when a simple softmax appears to perform nearly identically. I recommend design their experiments to highlight and provide intuition for the differences between existing approaches and the proposed method and, if no differences exist, explain why a negative result is interesting. If there are no differences and no value in a negative result then it is hard for me to see the significance of the method.\n\nMinor:\n\n2. Define \"proper\" in the intro.\n\n3. Contributions: \"Extensive\" seems strong here. Instead of saying \"we performed evaluations\", describe what your evaluations show and how that contributes to our knowledge.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6372/Reviewer_u3yA"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6372/Reviewer_u3yA"
        ]
    },
    {
        "id": "mMjwo814IT",
        "original": null,
        "number": 4,
        "cdate": 1667115507018,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667115507018,
        "tmdate": 1667116666378,
        "tddate": null,
        "forum": "mN43JdXmYMs",
        "replyto": "mN43JdXmYMs",
        "invitation": "ICLR.cc/2023/Conference/Paper6372/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes an algorithm to compute a DRO objective where the uncertainty set is defined with deviations in moments of the representation. The algorithm allows one to compute the minimax DRO loss using a primal-dual formulation and reasoning about the stationary points.",
            "strength_and_weaknesses": "The derivation in the paper is theoretically interesting.\n\nMy main concern is this:\n\nWhile the paper guarantees $\\theta$ is learned well with $\\phi$ fixed, it is unclear to me why I can learn a representation with the given objective. The reason is that changing $\\phi$ changes the uncertainty set for the setup DRO problem! Without the ability to use a fixed uncertainty set from some known restriction, what is the value of the proposed method? The experiments seem to support this concern as the authors say \"All the methods become vulnerable for large pnoise possibly because of the backbone neural network model.\"\n\n\nWeaknesses/Questions:\n1. Both corrollary 2 and theorem 3.2, along with the stated uncertainty set are from ((Li et al., 2022). Why do the authors claim \" We propose a distributionally robust probabilistic supervised learning method\"? The main contribution seems to be the algorithm.\n2. What can go wrong when let $\\beta=0$?\n3. Theoretically, it seems like when learning $\\phi$, it seems possible to end up in a minima where $\\phi=0$. Can the authors explain why this won't happen when the objective is optimized?\n4. Is mixing log-likelihood and brier score used in an application? Can the authors point to a case?\n5. The experiments in table 1 do not seem to favor the proposed method much; softmax is better or similar.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is cleanly written by the novelty seems to be the algorithm to compute the DRO alone, which I believe is a useful thing.",
            "summary_of_the_review": "While I think the ability to compute minimax loss is great, I am unclear about some details and what the value of the paper is.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6372/Reviewer_FSDY"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6372/Reviewer_FSDY"
        ]
    }
]