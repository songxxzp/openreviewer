[
    {
        "id": "BVQ_XBVtx6R",
        "original": null,
        "number": 1,
        "cdate": 1666594576954,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666594576954,
        "tmdate": 1666594576954,
        "tddate": null,
        "forum": "QjQibO3scV_",
        "replyto": "QjQibO3scV_",
        "invitation": "ICLR.cc/2023/Conference/Paper462/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduced deep reinforcement learning into the study of graph matching to tackle the ubiquitous outliers in practical application. Traditional back-end solvers generate the matching result between graphs in a single forward propagation attempting to maximize affinity score. However, the blindly pursuing higher affinity score induces to involve outliers because all elements in the affinity matrix are positive in most cases. Therefore, graph matching is modelled as a sequential selection task on the association graph in this paper, where the agent is expected to early stop when inliers are all selected instead of selecting the left outliers. In order to make their methods robust and prevent the agent from selecting superfluous vertices, the authors propose two strategies:\n1. to hardcoding an exact number of inliers at which the agent stops as soon as it achieves,\n2. to updating a regularized affinity matrix where the score of overly selection is discounted.\nAdditionally, a simple yet effective revokable action mechanism is put forward to give the agent the opportunity to \u201cregret\u201d its past suboptimal decision. \nFinally, with all the aforementioned techniques, RGM shows competitive result on both image data and pure combinatorial optimization instances.",
            "strength_and_weaknesses": "Strength:\n1. Training of Reinforcement-based method proposed in this paper does not require labelled data which is costly and time-consuming in large-scale datasets.\n2. The proposed method is a back-end solver for the most general form of GM with Lawler\u2019s QAP as the input, which means it\u2019s a plug-and-play learning-based module for multiple front-end models.\n3. Extensive experiments are conducted to proffer a comprehensive analysis.\n\nWeakness:\n1. In \u201cchr (12-25)\u201d and \u201clipa (20-60)\u201d column of Table 4, why the model SK-JA overperforms your proposed method so much?\n2. Can you provide some experimental results when the size of training set varies?\n3. As for formulae, Eq (7) has a wrong sign. And there exist several pieces that I am unable to understand. \u201cF,W \u2208 R^{n1\u00d7n2}\u201d contradicts with Eq.2 above which indicates F and W are matrices of n1*n2 rows and n1*n2 columns instead of a matrix with n1 rows and n2 columns. In Eq. 9, h1 = X\u2019 \u2022 \u03b81^T where X\u2019 is a permutation matrix which is a 0-1 matrix with a shape of (n1, n2). But h1 is of the shape (n1*n2, ). So I wonder how it can be made. Still in Eq. 9, on the RHS of the calculation of h4, W is an edge weight matrix which is ought to be a matrix in R^{n1*n2 \u00d7 n1*n2} according to the corrected  formula \u201cF,W \u2208 R^{n1\u00d7n2}\u201d. However, \u201c\u03b85 \u2208 R^d\u201d as is written in the paper. I cannot understand how these two matrices multiplied.\n4. Several grammar mistakes and typos are made in the paper, e.g., \u201clearnable features are shown more expressive\u201d (probably means \u201chave shown\u201d?), \u201ca also\u201d, \u201cthe our\u201d, \u201ctreat is as a constant\u201d, \u201cWwe\u201d, etc.",
            "clarity,_quality,_novelty_and_reproducibility": "In general, the elaboration and formulation is clear so that a broad range of readers can grasp the general idea of the paper. However, several typos are expected to be revised and some detailed formulae need to be better enunciated. This is a novel work that first utilizes reinforcement learning in the back-end solver of graph matching. By regarding GM as a sequential selection task, the model shows robustness for outliers even in the absence of label. Details in the appendix provides a promising reproducibility for this work.",
            "summary_of_the_review": "This paper proposes a deep RL-based model for robust and unlabeled graph matching. Revokable action mechanism and affinity regularization is proposed to fit with the RL schema and further boost the robustness. Exhaustive experiments have been conducted to prove the effectiveness of their method. Additionally, a fact is observed that there does not exist a constant positive correlation between our target metric, F1 score, and the optimized metric, objective score, which has a potential inspiration for other researches for further study.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper462/Reviewer_6KL8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper462/Reviewer_6KL8"
        ]
    },
    {
        "id": "vMipav0WHT",
        "original": null,
        "number": 2,
        "cdate": 1666600352481,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666600352481,
        "tmdate": 1666600352481,
        "tddate": null,
        "forum": "QjQibO3scV_",
        "replyto": "QjQibO3scV_",
        "invitation": "ICLR.cc/2023/Conference/Paper462/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper introduces a sequential node matching scheme for graph matching, via deep reinforcement learning.\n\nThe proposed scheme differs from the majority of existing works that obtain the whole matching in one shot.\n\nThe main effectiveness of the proposed method seems to lie in handling outliers.\n\nExperiments on both synthetic and real-world datasets show the effectiveness of the proposed method.\n\n",
            "strength_and_weaknesses": "[Strength]\n\n1. To the best of my knowledge, using deep reinforcement learning for graph matching is novel;\n2. Experimental results are good.\n\n[Weaknesses]\n\nI cannot find major weaknesses, and only have minor comments.\n\n1. The proposed method can only handle very small-scale graph matching problem (almost toy examples). It is very hard to extend the proposed method for large-scale graph matching (~2000 nodes for each graph).\n\nThe reason is that the number of vertices in the association graph would be 400 millions.\n\nProbably I should not blame authors for this limitation since there are some previous works on PASCAL VOC.\n\n2. It is partially true to say majority works (Zanfir et al., 2018; Wang et al., 2021a) that assume there is at most one graph\ncontaining outliers.  For example, using the sinkhorn solver with padded slack row and column would naturally solve matching when outlier s exist in both two graphs.\n\nI would expect authors to compare the proposed method with sinkhorn solver (padding slack row and column) in [Learning Feature Matching with Graph Neural Networks].\n\n3. If we remove the second order (edge) affinities, what is the performance of the proposed method?\n\n4. Please provide time comparisons of the proposed method with respect to state-of-the-art methods.\n",
            "clarity,_quality,_novelty_and_reproducibility": "[Clarity]: Neutral\n[Quality]: Good\n[Novelty ]: Good\n[Reproducibility]: Fair",
            "summary_of_the_review": "Though it is novel to introduce deep reinforcement learning, the proposed method can only work for toy-scale graph matching and the comparison with respect to sinkhorn solver (padding slack row and column) is missing.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper462/Reviewer_bTMW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper462/Reviewer_bTMW"
        ]
    },
    {
        "id": "nuM6WkZCnOt",
        "original": null,
        "number": 3,
        "cdate": 1667523905155,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667523905155,
        "tmdate": 1667523905155,
        "tddate": null,
        "forum": "QjQibO3scV_",
        "replyto": "QjQibO3scV_",
        "invitation": "ICLR.cc/2023/Conference/Paper462/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper presents an approach for solving the quadratic assignment (QAP) graph matching problem, which matches nodes across two graphs and the matching quality is measured with the affinity of both the matched nodes as well as the matched edges.  The approach is a collection of smaller things, including (1) an RL formulation of the sequential decision process that matches one pair of nodes at each step; (2) a \u201crevocable\u201d mechanism that allows each step to overwrite previously matched pairs; (3) a regularized affinity score to handle outliers and (4) an approximation scheme to convert the regularized affinity score back into a QAP formulation.\n\nExperiments on synthetic tasks, key-point matching tasks in the computer vision domain and on the standard QAP instances from QAPLIB show that the proposed approach seems to be working well.",
            "strength_and_weaknesses": "Strengths:\n* The paper is quite clear and easy to follow.\n* The \u201crevocable\u201d mechanism seems new.\n* The approximation of the non-QAP affinity score into a QAP formulation is interesting and could be a convenient and fairly general way to handle other types of optimization problems.\n* Experiment results show that the proposed approach reaches higher matching quality overall, compared to prior approaches.\n\nWeaknesses:\n* The most significant weakness is that the proposed approach and QAP formulation is very expensive, $O(n_1^2 n_2^2)$, which is $O(n^4)$ for comparable $n_1$ and $n_2$, for each step, and the proposed approach is fundamentally limited to do graph matching for very small graphs.  The largest graph considered in the experiment contains up to just 64 nodes, and I don\u2019t see a clear way to scale this up to instances of significantly larger scale.  Therefore the applicability of this approach and formulation seems to be very limited.\n* The proposed solution contains a collection of smaller bits and the entire system has a fair amount of complexity to build.\n* Structure of the paper could be improved - introduction seems to be a bit too long, while many results have to be left in the appendix.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\nI found the paper to be quite clear and easy to follow.\n\nQuality:\nIn my opinion, the proposed approach is sound and the experiment results are reasonable and supports the proposed approach.\n\nNovelty:\nAs discussed in \u201cstrengths\u201d, I think the \u201crevocable\u201d mechanism and the approximation of non-QAP affinity score into a QAP formulation are interesting and novel.  The RL formulation and the regularized QAP formulation are more standard.\n\nReproducibility:\nThe paper contains a reasonable level of details with an extensive appendix, which are good for reproducibility.  On the other hand the system contains a fair amount of complexity, which makes it harder to reproduce and apply in general.",
            "summary_of_the_review": "I have reviewed this paper twice before for another venue, and it has improved a lot since then, with many of the reviewers\u2019 suggestions incorporated in this submission.\n\nThis paper as it stands now has clear strengths and weaknesses, with a few novel ideas and experiments showing that this approach does outperform previous work quite consistently; on the other hand, scalability seems like a pressing issue that significantly affects the applicability of this approach.  Given the state of the current field of computer vision where key point matching can already handle orders of magnitude more keypoints than this proposed approach is capable of doing, I think this paper won\u2019t have an immediate impact on the field.  But once the scalability problem is alleviated, or with a better matched application where the QAP formulation is really required, this approach could have a larger impact.\n\nOverall I\u2019m neutral about the paper and wouldn\u2019t mind either accepting or rejecting it.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper462/Reviewer_QGQe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper462/Reviewer_QGQe"
        ]
    }
]