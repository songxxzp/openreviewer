[
    {
        "id": "3ObZH3YcnbZ",
        "original": null,
        "number": 1,
        "cdate": 1666860410587,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666860410587,
        "tmdate": 1666860410587,
        "tddate": null,
        "forum": "SrC-nwieGJ",
        "replyto": "SrC-nwieGJ",
        "invitation": "ICLR.cc/2023/Conference/Paper2618/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper introduces the concept and the use of relative representations for machine learning models, which consists in representing data samples in terms of their embedding distance to a fixed set of \"anchor data samples\". The motivation behind proposing this representation is that, under some regularity and symmetry assumptions, it would allow for representing data in a way that is invariant across training run, initializations and even architectures. In fact, the paper demonstrates in simulations on various datasets and tasks that this hypothesis is empirically borne out. Interestingly, data similarity in this representation is observed to be highly correlated with model performance. A tantalizing application of the invariance afforded by relative representations is that they allow for zero-shot model-stitching, i.e. \"transferring\" representations across models, possibly trained on different datasets or with differing architectures. The paper for instance demonstrates combining together encoder and decoder models that were not originally trained together, which allow for instance for things like cross-lingual stitching: combining encoders and decoders trained on different languages.",
            "strength_and_weaknesses": "Strengths:\n- Simple and at the same time very innovative idea. Its simplicity makes it extremely relevant and applicable across settings, domains, architectures and training paradigms, suggesting great potential for impact, both conceptual as well as practical.\n- Thorough examination and empirical demonstration of some of the potential of this new technique.\n \nThe paper does not have any apparent major weaknesses of relevance.\nThere are however technical details that could benefit from some clarification. For instance, the paper considers the training modality of training models with relative representation, but while doing that it is not readily clear whether this happens by also backpropagating through the anchors. It would be beneficial to clarify that, and whether and if there are any differences between doing that (backpropagating also through the anchors) vs only backpropagating through the data.",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: the paper and its experiments are very clearly motivated and presented\n- Quality: the paper is very plausibly motivated and its main hypothesis is solidly supported by thorough empirical demonstrations\n- Novelty: the proposed idea and applications are very novel\n- Reproducibility: the submission includes code and visualization scripts to reproduce the results reported in the paper",
            "summary_of_the_review": "The paper introduces the concept of relative representations, a simple idea with straightforward realization but far reaching conceptual and practical consequences. The applications that this conceptual innovation affords are wide reaching and include potential theoretical advances in the study of generalization and invariance in representation learning, and a host of practical applications such as zero-shot stitching of models.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2618/Reviewer_LWWZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2618/Reviewer_LWWZ"
        ]
    },
    {
        "id": "-OH8leuHFVY",
        "original": null,
        "number": 2,
        "cdate": 1666898147921,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666898147921,
        "tmdate": 1670117627936,
        "tddate": null,
        "forum": "SrC-nwieGJ",
        "replyto": "SrC-nwieGJ",
        "invitation": "ICLR.cc/2023/Conference/Paper2618/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper highlights the difficulty in using latent representations which were obtained by training on different data, with different architectures, or, indeed, simply as a consequence of stochasticity in the training process itself. They introduce the notion of a \"relative embedding\", which is obtained by projecting the latent representations onto a (fixed, shared) set of representations of \"anchor entities\". The authors provide empirical evidence for the validity of their approach in several settings:\n1. Aligning latent representations allows for greater preservation of similarity in a shallow word embedding setting.\n2. Using relative embeddings during training does not significantly decrease performance on a collection of image and graph node classification tasks.\n3. Relative embeddings allow for zero-shot model stitching, wherein models with different architectures and potentially trained on different tasks can be combined when using these relative embeddings.\n",
            "strength_and_weaknesses": "### Strengths\n1. The fundamental idea is pleasingly simple\n2. The authors included experiments to validate their motivation and intuition\n3. A comprehensive suite of empirical results on the ultimate task (stitching), including multiple datasets, domains, and variations (eg. differences in architecture vs. data) were included\n\n### Weaknesses\n1. For the main tasks (stitching) presented in section 5 I do not think the authors made it sufficiently clear which models were *trained* using relative embeddings, and which models used the relative embeddings purely as a post-hoc adjustment step. The emphasis on zero-shot (in the title, section header, and throughout), and the fact that earlier experiments (eg. section 4.1) were performed by creating the relative embeddings post-hoc may leave the reader with the impression that the relative embeddings can allow existing pre-trained networks to be stitched together. To my understanding, this is fundamentally impossible. At a minimum, the parts of the model downstream of the \"stiching\" must always be trained using relative embeddings, because the function which takes an absolute embedding to a relative one is not (in general) invertible. Of course, this also opens two opportunities for future work: (a) For instances where the mapping from absolute to relative embeddings is not strictly invertible, perhaps it is still essentially invertible on the data manifold. For example, a large component which contributes to the lack of invertibility is the vector normalization operation, however it has previously been argued that regularization results in embeddings which are essentially on a sphere. In such a setting, we could \"learn\" the inverse via gradient descent, and attempt to use this to stitch together networks without fine-tuning either part. (b) Can we choose the anchor nodes to improve the extent to which the transformation is essentially invertible?\n\n2. I have a few issues with Section 4.1 - Word Embeddings. First, using 300 randomly drawn parallel anchors seems very weak - if the words were drawn uniformly randomly then they are very likely all rare words, and as such would seem to serve as a very poor choice for anchors. This also may explain why the Jaccard similarity did not increase as substantially as might have been expected. I also take issue with this sentence: \"The average Jaccard distance reported in Table 1 (right), says that the neighborhoods of the relative representations are matched exactly 34% of the time in one direction, and 39% of the time in the other one.\" At least to my understanding, that is not what the average of Jaccard similarity would show. In fact, one could obtain those metrics with neighborhoods which *never* exactly match. Perhaps what was meant is that the *words* in the neighborhoods matched exactly, as the authors then go on to mention the discrepancies are likely due to semantic differences. I agree, and as such I wonder why such a course-grained evaluation was used in the first place? The setting we are in is as follows: given some embeddings A and B, find some new embeddings C and D such that the all-pairs similarities between elements of A are proportional to those between elements of C (and similarly with B and D), however the similarities between equal elements of C and D are minimized. One could simply measure and report on that metric.\n\n3. No theoretical analysis is included. It is, of course, increasingly common for papers to rely fundamentally on empirical results, however it seems possible to prove results relating the number of anchor entities, variation in the training data, and potential accuracy on the task. Even making minor preliminary theoretical statements on these aspects would strengthen the paper.\n\n4. I was not able to find details on how the 2-dimensional representation in on the left half of Table 1 was created. Presumably, some dimensionality reduction technique (eg. tSNE) is used, however that raises into question the usefulness of drawing conclusions from such a picture as the dimensionality reduction introduces a number of factors which may impact the resulting representation. (One could imagine various dimensionality reduction techniques with noise or hyperparameters which, for the same exact embedding, result in different representations.) At the very least, the authors should explain how these pictures were derived.\n\n\n### Typos / Suggestions\n1. Abstract: I would recommend including something about the anchor entities in the abstract, as (to my mind) that is essential to understanding the high-level idea. Perhaps this sentence: \"In this work, we propose to adopt pairwise similarities as an alternative data representation, that can be used to enforce the desired invariance without any additional training.\" could be changed to: \"In this work, we propose to use the similarity between each representation and a fixed set of anchor representations, and demonstrate that this can enforce the desired invariances without any additional training.\"\n2. Page 1: \"The underlying assumption is that the learned latent spaces should be the best encoding given the data distribution, the downstream task, and the network constraints. In practice, however, the learned latent spaces are subject to changes even when the above assumptions remain fixed.\" The writing here presents this as though this is contradictory, but of course it is not - the latent representation which is best for the downstream task given network constraints is not unique.\n3. Page 2: \"more in general\" -> \"more generally\"\n4. Page 7, Figure 4: I don't think this figure highlights the results as well as it could. Consider making the figure 5 rows tall, and group based on absolute vs. relative first (i.e. rows would be original, abs ae, abs vae, rel ae, rel vae). This would make it very clear that absolute struggles, while relative works well. (I would make similar suggestions for Table 3 and 5)\n5. Page 7: \"prove that representations are invariant to training stochasticity\"is a bit too strong, as I believe any mathematically rigorous interpretation of this statement would be provably false. Something like \"support our claim that relative representations are more robust to training stochasticity\" seems more accurate, given the results presented.\n6. Page 8: \"obtaine\" -> \"obtaining\"\n7. Page 9: \"allow to stitch modules\" -> \"allow stitching modules\"",
            "clarity,_quality,_novelty_and_reproducibility": "I have no concerns about clarity, quality, or reproducibility. The ideas were clearly presented, I found no mathematical errors, and the authors include a thorough appendix of specific hyperparameters used along with supplemental code.\n\nI am less confident about evaluating the novelty. The idea is straightforward and simple enough that I was surprised that it has not been tried before. In section 3.1, the authors present the idea using the more abstract notion of \"a vector of similarities\", but ultimately specialize to simply using the dot product of normalized vectors. Ultimately, as used by the authors, the idea is simply:\n\n> 1. Identify $k$ \"anchor\" elements from your inputs, and let $A$ be the normalized vector representation of these anchor elements.\n> 2. Let $P$ be a linear transformation which takes the vectors of $A$ to the standard basis.\n> 3. To form the \"relative representation\" of a given vector representation of any input, we simply normalize and apply $P$.\n\nThe authors then emphasize that this relative representation is, by construction, invariant to a variety of transformations, and can be reliably used to align the latent spaces of different models, assuming they both have latent vector representations for the anchor elements (or, as in the case of machine translation, \"parallel anchors\"). I was unable to uncover any prior work during a literature search.",
            "summary_of_the_review": "This paper presents a simple idea that seems to work very well. The practical limitation of the proposed method is that it only works if the networks were trained with these relative representations in the first place. The strongest direct outcome of this paper would be that people would start using relative representations by default, thus facilitating the \"stitching\" mentioned in section 5, however I think this would require much greater exploration (eg. heuristic methods to choose the anchor elements with theoretical bounds on the potential impact) before being widely adopted.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2618/Reviewer_hU9r"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2618/Reviewer_hU9r"
        ]
    },
    {
        "id": "5xuWMgh_bt",
        "original": null,
        "number": 3,
        "cdate": 1667058052765,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667058052765,
        "tmdate": 1667058052765,
        "tddate": null,
        "forum": "SrC-nwieGJ",
        "replyto": "SrC-nwieGJ",
        "invitation": "ICLR.cc/2023/Conference/Paper2618/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes the opinion that the relative representation, the representation of data described by a fixed set of anchor representations, is invariant among different randomized training factors like seeds, optimization strategies, training steps, and even architectures. To prove their opinion, the authors then prevent extensive studies across a broad range of domains in modern machine learning. The results are impressive and very interesting. The authors show that 1) model trained on datasets sampled from similar domains (like English language) with different distributions may share the same relative representations; 2) the similarity of the relative representations of networks has a positive correlation with their performance; 3) training with relative representations shows comparable performance against the absolute representations; 4) relative representations can be shared by networks of different architectures, training distributions, and seeds, to achieve a valid effect.",
            "strength_and_weaknesses": "Strength:\n\n1. The empirical findings in this paper are very impressive and interesting.\n\n2. The paper is extremely well-written and easy to follow.\n\n3. The experiments involve broad domains of machine learning and are of interest to a general audience.\n\n4. The experiment arguments involve rich aspects of analysis and thus are convincing and impressive.\n\n\nWeakness:\n\n1. The experiments in sec. 4.1 are somewhat weak compared with those in the remained sections; only one case is considered. Adding an extra case of computer vision task may further enhance it.\n\n2. The existence of this phenomenon is well proven, but the source and deep reason for it to happen are not presented as strongly as the former.\n\n3. In Sec.4.1 and Tab. 1, it will be better if the authors can add references and more detailed explanations for the two metrics Jaccard and Mrr. It is a bit hard for me to understand how to calculate them and their roles directly from the current context.",
            "clarity,_quality,_novelty_and_reproducibility": "See my comments above.",
            "summary_of_the_review": "Very impressive results in the general area of machine learning, combined with very extensive and strong empirical arguments. Deeper analysis of the sources and reasons of this phenomenon will be appreciated.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2618/Reviewer_LNFQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2618/Reviewer_LNFQ"
        ]
    }
]