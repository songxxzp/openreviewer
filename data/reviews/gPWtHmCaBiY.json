[
    {
        "id": "Jaf38aLVWS",
        "original": null,
        "number": 1,
        "cdate": 1666148439300,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666148439300,
        "tmdate": 1670934218806,
        "tddate": null,
        "forum": "gPWtHmCaBiY",
        "replyto": "gPWtHmCaBiY",
        "invitation": "ICLR.cc/2023/Conference/Paper412/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper conducts a series of empirical studies for continual learning about the sensitivity of different network parameters, and shows some interesting observations. Based on the observations, this paper explores a Forgetting Prioritized Fine-tuning strategy for continual learning. Empirical results demonstrate its effectiveness.",
            "strength_and_weaknesses": "Upsides:\n+ This paper analyzes the sensitivity of different network parameters in continual learning, and shows some interesting observations.\n+ The empirical studies are solid and the writing is easy to follow.\n+ A new Forgetting Prioritized Fine-tuning strategy is proposed. By lazily conducting replay, the proposed method achieves comparable performance with lower computation costs.\n\n\nDownsides:\n- How to adaptively select the task-specific parameters for fine-tuning? This paper only provides an empirical study for it, but a well-designed adaptive strategy is expected based on your empirical studies. In this case, the contribution of this paper will become more significant.\n- In Table 1, does any specific method perform the best with the proposed FPF? It seems that there is no consistently state-of-the-art method when combining FPF.\n- The colors of Figure 4&5 are too complex, making it hard to understand. It would be better to simplify this figure. \n- Many previous studies find that the higher layers are more sensitive. Please discuss more Figure 7. Why are lower BN layers more sensitive\uff1f There may be some interesting discussions.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is good.\nQuality is overall good but there are a few issues that need to be resolved.\nNovelty is fair.\nReproducibility: the authors are expected to release the source code to the public.",
            "summary_of_the_review": "Overall, I like the empirical observation of this paper which may inspire some future research. However, there are still some questions to be resolved. I expect to responses from the authors.\n\n**********Post rebuttal*************\nAfter discussion with the authors and other reviewers, I suggest the authors to improve the paper by further analyzing the found observations about their in-depth reasons and making the proposed method more adaptive regarding the selection of layers and hyper-paramters.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper412/Reviewer_pB6S"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper412/Reviewer_pB6S"
        ]
    },
    {
        "id": "Y31MHe69FM",
        "original": null,
        "number": 2,
        "cdate": 1666554940510,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666554940510,
        "tmdate": 1669306554800,
        "tddate": null,
        "forum": "gPWtHmCaBiY",
        "replyto": "gPWtHmCaBiY",
        "invitation": "ICLR.cc/2023/Conference/Paper412/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper goal is to study which part of specific neural architectures is mostly affected by catastrophic forgetting in Class Incremental (CI) and Domain Incremental (DI) continual learning, to apply specialized fine tuning to those parts with the purpose of reducing interference. The 1-norm of $l$-th layer weight change between consecutive CL tasks is used as metric to measure which layers are affected most. Two finetuning procedures are provided, with one designed to optimize computational cost of memory consolidation. The method can be hot-plugged to several CL methods in literature. ",
            "strength_and_weaknesses": "-- STRENGTHS \u2013\n(+) The empirical analysis is quite articulated both in terms of number of benchmarks being considered as well as in terms of related CL strategies being assessed. The work is mostly empirical, both in its conception and its execution, so this part is quite well-done.\n\n(+) The generality of the approach is certainly positive: the fact that it can be applied to existing CL strategies is a plus, which stems from the simplicity of the approach.\n\n(+) A careful consideration for the computational costs, in a research topic that is often motivated by the necessity of making neural training sustainable, is an added strength and well motivates a part of the work.\n\n-- WEAKNESSES \u2013\n\n(-) Despite the attempt of rooting the work on considerations about task interference and drifts, this paper is mostly based on an rule-of-thumb intuition (quite an unsurprising one) which is not backed up by convincing theoretical nor empirical motivations. The attempt at providing an empirical motivation in Section 4 is unconvincing because of there is no logical consequence between the  results of the experiments and the implementation of the FPF strategy. The hints from the empirical analysis are either trivial (i.e. fine tune only the closer-to-output-layer weights) or very architecture specific (i.e. in some cases it is best to tune the outer layers but also the early layers, but not the middle ones). This kind of insight is not actionable by the community as it is not enough general. \n\n(-) Generality and impact of the strategy are also severely limited by the choice of the CL scenarios. It is straightforward to see how a metric based on instantaneous change in weights between adjacent tasks can work in CI and DI settings, as in these cases there is a clear distinction between tasks at training time, which in the CI setting is also mirrored in task-specific components of the architecture (multi-heads). The work could gain considerable strength if it can be shown that the insights and strategies can work less ideal scenarios, such as class incremental with repetition (reoccurring tasks) and single class incremental learning (no architectural segregation between tasks).\n\n(-) The exact details of the FPF strategies are nowhere to be found. Only a vague description of the intuition is provided by the details of the strategies are not provided. For instance it is not clear (until one reaches the experiments) if a buffer is needed, and what is the strategy to populate it. One would like to know how one chooses the portions of the network to include/exclude in FPF. By reading the paper it should be possible to replicate the strategy on different problems and architectures, but this is not the case given the lack of details in the current formulation. The paper should definitely be extend to include pseudo-code and other formal description of the strategies to make everything reproducible and generalizable. \n\n(-) Linguistic quality is sometimes borderline, especially in parts of the experimental section whose writing might had been rushed. Another round of proofreading is highly advised. \n",
            "clarity,_quality,_novelty_and_reproducibility": "As anticipated in the assessment above:\n - Reproducibility: weak due to the absence of details about the implementation of the FPF strategies\n - Novelty: weak due to the proposed approach being based on an unsurprising rule-of-thumb implemented by a metric (instantaneous parameter change between tasks) which provides little novel insight into the problem and whose application hardly generalizes over simple CL scenarios.\n - Clarity and quality: weak, due to linguistic issue and lack of details about the FPF.\n",
            "summary_of_the_review": "While the paper has good motivations in abstract (finding a general and efficient procedure for parameter consolidation), it fails to deliver convincing insights, due to lack of technical detail, reduced novelty and scarce generality of the results. Overall the weaknesses quite heavily surpass the merit. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper412/Reviewer_8gaT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper412/Reviewer_8gaT"
        ]
    },
    {
        "id": "s33tmuVQzcH",
        "original": null,
        "number": 3,
        "cdate": 1666643450699,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666643450699,
        "tmdate": 1669500805424,
        "tddate": null,
        "forum": "gPWtHmCaBiY",
        "replyto": "gPWtHmCaBiY",
        "invitation": "ICLR.cc/2023/Conference/Paper412/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "\nThe paper studies the dynamics of different layers in continual learning scenarios, mainly by measuring the shift in parameters. The authors show that only a small subset of parameters (e.g., final FC layer, BN stats) are very sensitive to data drift. To exploit this observation, the authors propose forgetting prioritized finetuning (FPF), which only finetunes a small subset of parameters. In addition, they propose k-time FPF, which replaces the every-step experience replay.",
            "strength_and_weaknesses": "### Strengths\n\n\n- The paper is well-written and easy to follow.\n\n\n- The direction of understanding network dynamics in continual learning is very important.\n\n\n- The proposed method is simple and intuitive and performs well.\n\n\n\n### Weaknesses\n\n\n- First, I should say that I am not sure if the drift in parameters is the best perspective for measuring the dynamics of the layers. For instance, in [2], the authors show that small/large euclidean parameter distance does not necessarily correspond to high/low forgetting, which can depend on many other factors. In other words, you given parameters $\\theta$ at the end of task 1, you can simply find $\\theta_1$ and $\\theta_2$ where $| \\theta - \\theta_1 |  < | \\theta - \\theta_2 | $ but the performance of $\\theta_2$ is better than $\\theta_1$. \n\n\n\n- In addition, as the authors mention in Appendix A.4, some of the presented results (e.g., final blocks being more sensitive) are well-established in the literature [1]. While this work dives a little bit deeper into designing FPF and measuring the compute/performance trade-offs, still, the novelty and contribution of this work are limited.\n\n\n\n\n\n**References**:  \n[1] Ramasesh, Vinay Venkatesh et al. \u201cAnatomy of Catastrophic Forgetting: Hidden Representations and Task Semantics.\u201d ICLR 2021.  \n[2] Mirzadeh, Seyed Iman, et al. \"Linear Mode Connectivity in Multitask and Continual Learning. ICLR 2021.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is well-written and clear. In terms of novelty and quality, I believe the contributions are very limited. Finally, the authors provide details of their experimental setup and hyper-parameters used to reproduce the results.",
            "summary_of_the_review": "Overall, I believe this paper is a borderline paper. Although I believe the contributions of this work is limited, I pretty much enjoyed the direction of understanding NN dynamics in CL, which is done rarely in the literature.\n\n**Post-Rebuttal Update:**  \nI want to thank the authors for their response. Given that the authors have addressed most of my concerns, I would like to increase the score.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper412/Reviewer_hdv9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper412/Reviewer_hdv9"
        ]
    },
    {
        "id": "lLsFVb7nZNX",
        "original": null,
        "number": 4,
        "cdate": 1666693877532,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666693877532,
        "tmdate": 1666693877532,
        "tddate": null,
        "forum": "gPWtHmCaBiY",
        "replyto": "gPWtHmCaBiY",
        "invitation": "ICLR.cc/2023/Conference/Paper412/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a simple technique for preventing the catastrophic forgetting problem in continual learning (CL). By showing that there are sensitive parts in neural network model when learning a novel task, the proposed approach (FPF) just fine-tune the sensitive part of a model after learning sequence of tasks. Furthermore, the additional computation cost for performing FPF the sensitive part is somewhat marginal. In the experiments, authors show that applying FPF can drastically increase the performance of baselines.",
            "strength_and_weaknesses": "**Pros:**\n\nP1. FPF is simple and highly effective, and showing sensitive regions in the parameters of neural network in CL can be a novel finding. \n\nP2. FPF can be easily plugged-in baselines, and it increases the performance significantly. \n\n**Cons:**\n\nC1. In Section 4.1, the notation in the denominator of the metric for the change of parameters is somewhat confusing. Is it $\\theta_{\\ell,n}^{t+1}$? If it is, is it feasible to use this metric for measuring the dynamics of parameters? \n\nC2. Selecting the sensitive part of the neural network is little bit confusing. How can we select the parts when we use much larger architectures (e.g. ResNet-110)? It would be better to specify the standard for selecting the sensitive region.\n\nC3. There is no comparison between FFP and the method that fine-tune all parameters using memory buffer. I think the results are quite different from \"ER\". It would be better to show the comparison between two methods with respect to the FLOPs and the average accuracy. \n\nC4. There is no experiments on the task sequence containing totally different datasets (e.g. CIFAR-100 & MNIST). The trends that Conv & FC layers are sensitive would be different from the experiments in the paper.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is somewhat clear, but some notations are confusing. Though the methods are simple and might not be novel, showing the sensitive region of neural network in CL can be novel.",
            "summary_of_the_review": "I vote to marginally accept this paper. Though some experiments are missing, and the proposed solutions are somewhat straightforward, finding out which parts are sensitive to the distribution shift in CL has significant contribution.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper412/Reviewer_LsHP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper412/Reviewer_LsHP"
        ]
    }
]