[
    {
        "id": "2n3s747NLBM",
        "original": null,
        "number": 1,
        "cdate": 1666246553826,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666246553826,
        "tmdate": 1666246553826,
        "tddate": null,
        "forum": "Z63RvyAZ2Vh",
        "replyto": "Z63RvyAZ2Vh",
        "invitation": "ICLR.cc/2023/Conference/Paper5752/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposed a model to do multi-hop question-answering over Knowledge Graphs. The core model responsible for relevance is trained once and shared between the initial retrieval of the subgraph and the detailed reasoning phases. A key claim of the paper is that by unifying the model for the two phases, we can get better quality in the answers than doing them separately.\n\nThe proposed UniKGQA model consists of two main parts: Pretrained Language Model (PLM)-based semantic matching and the propagation of matching information through the graphs. The PLM (RoBERTa in implementation) is fine-tuned with task specific data to capture the connection between entities and relationships. Its parameters are shared between the retrieval and reasoning phases.\n\nEvaluation was done on three different datasets. The UniKGQA model was compared with recent baselines and showed on-par results on two of them and significantly better results on WebQSP. The paper included detailed ablation study and different fine-tuning setups to show the benefit of using a joint model for two phrases.\n",
            "strength_and_weaknesses": "Strength\n\n1) Evaluation results: The evaluation results on WebQSP showed clear advantages of the proposed model. Ablation study and comparison under different setup helped support the paper's claim.\n\nWeakness\n\n1) Writing can be improved. Key abbreviations are not explained at first use (PLM / PPR / topic entity etc, it's always good to reduce reader's guess work). There are typos and proof-reading misses. \n\n2) The explanation of Abstract Subgraph is not clear. What if the tail entities in the same set branch out to different 2nd-hop entities? It's not all clear to the Reviewer. An example would help.\n\n3) It's better to explain more on the key differences between the WebQSP/CWQ sets and MetaQA, as UniKGQA shows clear improvements on the former but not the latter. Giving some examples would help too. \n\nList of concrete issues that should be improved.\n1) Figure 2. the order of h_m and h_q seems reversed.\n2) Page 4, MIP section, it's better to explain \"topic entity\" when used first time.\n3) Page 4 to the bottom, \"are a learnable vector\" -> \"is a ...\"; \"of if the entities\" -> \"of the entities being\"?\n4) Page 5 to the bottom, \"Eq 4\" should be \"Eq 6\"?\n5) P7 Section 4.2 second paragraph, it's not clear if unified model is the key reason of improvement, we need more supporting evidence.\n6) P8 Table 4, Why use \"Trans\"?  ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity can be improved. The writing could be improved. Figures are too complicated. \n\nQuality of the work is ok: the paper did extensive experiments on different dataset to help understand the performance deltas.\n\nNovelty is less significant: Using the sample pre-trained model feels more incremental and the benefit is only justified by better evaluation results.\n\nReproducibility is not clear. The authors didn't mention open-source or other means to reproduce.",
            "summary_of_the_review": "The Reviewer suggest weak accept of the paper after fixing the writing issues.\n\nThe paper's main contribution is clear and justified by the evaluation result, that using a unified model does show advantages in overall and break-down comparison with other recent methods. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5752/Reviewer_Xn2s"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5752/Reviewer_Xn2s"
        ]
    },
    {
        "id": "OeTRMuvh_5Y",
        "original": null,
        "number": 2,
        "cdate": 1666603326646,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666603326646,
        "tmdate": 1670589147944,
        "tddate": null,
        "forum": "Z63RvyAZ2Vh",
        "replyto": "Z63RvyAZ2Vh",
        "invitation": "ICLR.cc/2023/Conference/Paper5752/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a novel solution which uses pretrained language models to fuse the retrieval and reasoning stages for knowledge graph question answering. The authors also conduct extensive experiments to verify the effectiveness of the proposed model. ",
            "strength_and_weaknesses": "Strength.\nThis paper proposes a novel solution which uses pretrained language models to fuse the retrieval and reasoning stages for knowledge graph question answering.\n\nWeakness.\n1.\tPlease present more implementation details about the baselines. \n\n2.\tIt seems that most of the baselines are GNN-based models, which do not include additional knowledge. Whereas the solution in this paper uses pretrained models to introduce additional knowledge, which makes the experiments less comparable and persuasive. \n\n3.\tTo render this paper more convincing, I suggest the authors present more baseline models which use similar pretrained models to do this task. To name a few:\na.\tXin Huang, Jung-Jae Kim, and Bowei Zou. 2021. Unseen Entity Handling in Complex Question Answering over Knowledge Base via Language Generation. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 547\u2013557, Punta Cana, Dominican Republic. Association for Computational Linguistics.\n\nb.\tRajarshi Das, Manzil Zaheer, Dung Thai, Ameya Godbole, Ethan Perez, Jay Yoon Lee, Lizhen Tan, Lazaros Polymenakos, and Andrew McCallum. 2021. Case-based Reasoning for Natural Language Queries over Knowledge Bases. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 9594\u20139611, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well written and the solution is somewhat novelty. ",
            "summary_of_the_review": "This paper proposes a novel solution which uses pretrained language models to fuse the retrieval and reasoning stages for knowledge graph question answering. The paper is well written and the solution is somewhat novelty. However, the experiments lack comparison with some latest work. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5752/Reviewer_Zm6y"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5752/Reviewer_Zm6y"
        ]
    },
    {
        "id": "IxP_wkudTM",
        "original": null,
        "number": 3,
        "cdate": 1666835555494,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666835555494,
        "tmdate": 1670609913407,
        "tddate": null,
        "forum": "Z63RvyAZ2Vh",
        "replyto": "Z63RvyAZ2Vh",
        "invitation": "ICLR.cc/2023/Conference/Paper5752/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed to learn a multi-hop KBQA model which contains a retrieval and reasoning model that shares the same architecture. Unifying the retrieval and reasoning module let the model share more learned knowledge. Experiments show great performance on three benchmark multi-hop reasoning datasets.",
            "strength_and_weaknesses": "The propose model is simple and effective. The results are also very impressive. It can be a go-to solution for multi-hop KBQA. I have some questions about the implementation.\n\n1. Without any of the proposed technique (w/o Pre, Trans), the model already outperforms the previous state-of-the-art. Do you know why this happen?\n2. The reasoning and retrieval module share the same input structure and same model architecture, but it seems they do not share the same parameters. This sounds weird to me, and I am not sure why this will lead to improvement in model's performance. How much improvement comes from the pretraining of question-relation matching (see also Fig 3(c))? You should consider emphasizing the pretraining strategy if it leads to a big improvement.\n3. What is the size of the KB you use for WebQSP and CWQ? Do you use the full Freebase?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Overall the paper is clear to read.\n\nThe paper should include more details about key choices in the experiments, e.g. size of KB. Also, it makes me worried why the ablated results without any of the introduced technique (in Table 4) can outperform the previous state-of-the-art.",
            "summary_of_the_review": "The paper delivered good results in their experiments and the intuition of having a shared reasoning and retrieval model is promising. However, it is hard to tell whether the biggest improvement comes from the advertised techniques. Please consider emphasize on your contributions. Having good numbers itself does not warrant an acceptance of the paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5752/Reviewer_j49Y"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5752/Reviewer_j49Y"
        ]
    }
]