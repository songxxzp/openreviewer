[
    {
        "id": "gXWWqg_0_53",
        "original": null,
        "number": 1,
        "cdate": 1665932760924,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665932760924,
        "tmdate": 1670829212435,
        "tddate": null,
        "forum": "FIrQfNSOoTr",
        "replyto": "FIrQfNSOoTr",
        "invitation": "ICLR.cc/2023/Conference/Paper1628/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents to perform instance-wise batch label restoration from only the gradient of the final layer, to extract labels from gradients. The core idea is to establish linear equations of the gradients, probabilities and labels to derive the Number of Instances (NoI) per class by the Moore-Penrose pseudoin-verse algorithm. For this purpose, this paper designs two metrics and performs empirical studies that achieve state-of-the-art performance on three benchmark datasets.",
            "strength_and_weaknesses": "Strength\uff1a\nThis paper considers the more real-world settings in gradient inversion attacking of Federated Learning (FL), where there are multiple instances of each class in a training batch. Besides, this paper derives the equation to design the algorithm.\n\nWeakness\uff1a\n- The paper is somewhat clear, but some important details are missing or unclear. For example, does the model of server share the same network architecture with the model of clients in Figure 1\uff1fMoreover\uff0cin Figure 2\uff0chow do servers and clients interact\uff1fIs the iLRG method run on the server side?\n- The authors leverage Intra-class High Similarity and Inter-class Low Entanglement. However, this may assume that the server can obtain the labels of clients, which violates the privacy setting of FL.\n- There are missing ablation experiments with the experimental part. For example, which of the intra-class high similarity and inter-class low entanglement contributes more to the result\uff1f\n\nQuestion:\nWhat judgment does the server use to determine similar or dissimilar classes in section 3.1\uff1f\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is somewhat clear, but some important details are missing or unclear.\n\nQuality: The paper appears to be technically sound. \n\nNovelty: The paper contributes some new ideas or represents incremental advances.\n\nReproducibility: Key details are sufficiently well-described for competent researchers to confidently reproduce the main results.",
            "summary_of_the_review": "Please see Q1 and Q2.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1628/Reviewer_9FpD"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1628/Reviewer_9FpD"
        ]
    },
    {
        "id": "O7PfAWNDhu",
        "original": null,
        "number": 2,
        "cdate": 1666601917929,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666601917929,
        "tmdate": 1668491312635,
        "tddate": null,
        "forum": "FIrQfNSOoTr",
        "replyto": "FIrQfNSOoTr",
        "invitation": "ICLR.cc/2023/Conference/Paper1628/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This manuscript studies the instance-level label restoration in mini-batch training under the federated learning structure. The authors proposed a strong method that is capable of restoring labels via gradient inversion attack even when batch size is as large as 4096, which was usually considered a challenging task. This is achieved by estimating the class-wise averaged embedding (to which authors improved over [1]) to estimate the class-wise averaged predicted probabilities, and then using the Moore-Penrose algorithm to solve the linear equation systems formulated by the class-wise averaged predicted probabilities and the bias gradients.\n\n[1] Sun, Jingwei, et al. \"Soteria: Provable defense against privacy leakage in federated learning from representation perspective.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.",
            "strength_and_weaknesses": "Pros:\n1. Authors studied a non-trivial research question, which is how to recover the training labels in federated learning through the gradient inversion attack when the batch size is large and the number of classes is more than two. With such information, the features of training samples could be better inferred, hence posing more server threats to the security of federated learning. \n2. Compared with existing work, this work does not need the strong assumption that the categories in the same batch must be small or equal to two.\n3. This work empirically shows that the training labels can be accurately inferred even when the training batch is 4096, to the reviewer\u2019s best knowledge, this is a new record and can without doubt boost the performances of most of the gradient inversion attacks.\n4. Authors insightfully leverage the averaged post-softmax probabilities, to link the label recovery and class-wise averaged embeddings via Equation (4) and (5). \n\nCons:\n1. Authors pointed out that existing work might fail when the activation function can yield negative values. However, I did not see how the authors' proposed method can solve this.\n2. I\u2019m interested in the situation when there is no bias for the FC layer since the absence of bias is rare - but not impossible. In that case, is the reconstructed class-wise embedding reduced to the embedding produced by [1]? Also, while the authors make the justification that leveraging bias gradients can be helpful, I recommend authors make ablation studies to compare the quality of the class-wise embedding learned by [1] and authors\u2019 method, which could make the authors\u2019 contribution more convincing. \n3. After we know the number of instances per class within a batch, how do we assign the labels to each individual instance? If we don't do so, can authors elaborate on how only knowing the count of each class within a batch can help recover features?\n4. When there are some basic defensive strategies applied (such as DP noise and gradient pruning), what are their influence on the authors' method?\n\nThe aforementioned \"Cons\" are not necessarily the limitations, but some clarifications/ablation studies that I'm interested in.\n\n[1] Sun, Jingwei, et al. \"Soteria: Provable defense against privacy leakage in federated learning from representation perspective.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.",
            "clarity,_quality,_novelty_and_reproducibility": "$\\textbf{Clarity}$: While this paper is overall well-written, authors should try to improve the clarity of the paper, some long sentences in the manuscript make the ideas behind really hard to follow. Authors are encouraged to use intuitive and simple explanations in sections that are important for the audience such as Section 2.2 and Section 3.2. \n\n$\\textbf{Quality}$: I believe this paper is of high quality, authors provide an appendix to supplement additional information, and they released their well-structured implementation code as well as a comprehensive readme and experiment log.\n\n$\\textbf{Originality}$: A large part of this work is based on the discovery made by Sun $\\textit{et. al}$ [1], however, the authors also made a non-trivial supplement to the existing work that leads to significant empirical results. Thus I believe this paper has considerable novelties.\n\n$\\textbf{Reproducibility}$: After examining the code and experiment log, this work is believed to be reproducible.\n\n\n",
            "summary_of_the_review": "Overall, this is a well-written paper which I'm leaning towards accepting. The authors' proposed method makes intuitive sense and the motivation is clear, the experiments are comprehensive. The score will be increased upon the satisfactory and convincing rebuttal regarding the questions in \u201cCons\u201d.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1628/Reviewer_CT8P"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1628/Reviewer_CT8P"
        ]
    },
    {
        "id": "vas1fJtyxjd",
        "original": null,
        "number": 3,
        "cdate": 1666701526065,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666701526065,
        "tmdate": 1669400223148,
        "tddate": null,
        "forum": "FIrQfNSOoTr",
        "replyto": "FIrQfNSOoTr",
        "invitation": "ICLR.cc/2023/Conference/Paper1628/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Gradient inversion in federated learning is often constrained by the lack of labels. Current label restoration methods are limited to class-wise label restoration, which is to infer the presence of a category. This paper introduces a new method to infer instance-wise labels in federated learning, i.e., the number of instances per class. Based on several approximations, the labels can be restored by solving a linear equation system using a pseudo-inverse algorithm. The authors then empirically explore how well this works in practice. Some results of the compatibility with model inversion attacks are also presented. ",
            "strength_and_weaknesses": "Strength:\n1. The proposed method is compatible with gradient inversion attacks and can be plugged in to enhance current optimization-based methods.\n\n2. Instead of optimization-based methods, this paper utilizes a method based on a pseudo-inverse algorithm.\n\nWeakness:\n1. Since the instance-wise label is the number of instances per class, how can this number be used with a model inversion attack? For example, IG attack assumes there is only one image per class in a batch, so it seems that with this attack, there is no large difference between previous class-wise label restoration and instance-wise label restoration.\n\n2. Continued with point 1, what is the improvement of instance-wise restoration compared with class-wise restoration? Could you please give some application scenarios where this method surpasses the class-wise one?\n\n3. I do not quite understand some of the approximations or assumptions in this paper as follows. \n  (1) In the last of the Approx 1, you mention that \"it is observed that the variance of \\|e\\| over the whole batch is so small\". Could you please provide any theoretical analysis or any empirical results to explain this?\n  (2) Approx 2 is based on the assumption that the gradients in $\\mathbb{B}_i$ is dominant in the approximation of the gradients at index $i$. But what is the influence of label distribution in a batch to the restoration results? What if the number of class $i$ is much smaller than other classes (i.e., an extremely unbalanced batch)? Are there any results for this?\n  (3) Approx 1 assumes the embeddings $e$ and the gradients of $L$ w.r.t. $z$ are similar over a certain class. The Approx 2 assumes the gradients in $\\mathbb{B}_i$ is dominant. It is easier to understand this in a well-trained model. But what is the performance in the early training stage? Or could you please figure out whether the model used in the experiments is pre-trained or randomly initialized?\n  (4) Could you please explain more about the Approx 3 of softmax? Why or when does this approximation hold?\n\nMinor comments:\n1. Superscript $j$ is used in Approx 1 without explanation, although it is explained in section 3.2.\n\n2. In section 3.2, I think $k_j$ is the same as $|B_j|$. Is it correct?",
            "clarity,_quality,_novelty_and_reproducibility": "This is an interesting work with originality. But the there are still some concerns of mine which limits the novelty. Please refer to the previous comments. ",
            "summary_of_the_review": "This is an interesting paper, but from my point of view, it relies on many assumptions to support the approximation and method proposed in this paper. There is a lack of evidence for these assumptions. Additionally, the improvement of this method compared with class-wise restoration seems limited. If the author can provide some motivation or results of the previously mentioned assumptions, I will raise my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1628/Reviewer_ngm7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1628/Reviewer_ngm7"
        ]
    }
]