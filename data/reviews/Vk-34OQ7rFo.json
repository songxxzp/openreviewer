[
    {
        "id": "n0PV7Ggvhbp",
        "original": null,
        "number": 1,
        "cdate": 1666104193859,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666104193859,
        "tmdate": 1668664333200,
        "tddate": null,
        "forum": "Vk-34OQ7rFo",
        "replyto": "Vk-34OQ7rFo",
        "invitation": "ICLR.cc/2023/Conference/Paper4247/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a new algorithm for causal Bayesian optimization for both hard and soft interventions with theoretical guarantees. The authors use a reparameterization technique to optimize the acquisition function which is a maximum over functions. They empirically show that the algorithm mostly outperforms relevant baselines.",
            "strength_and_weaknesses": "Strengths:\n1. The problem of causal BO is motivated well and explained clearly with diagrams.\n2. The algorithm's performance is empirically well-supported.\n\nWeaknesses:\n1. One concern comes from Assumption 3 not providing an explicit formula for the sequence $\\beta_t$. The authors claim that there is an \"overall sublinear regret for MCBO\". However, $\\beta_T^N$ appears in the regret bound, where $N$ is the maximum distance from a root node to the reward node. Without an explicit formula for $\\beta_t$ (as is usual in this line of work), there is no reason to believe that  $\\beta_T^N < \\mathcal O(\\sqrt{T})$. Even if we assume that the usual formula for $\\beta_t$ (Chowdhury and Gopalan, 2017) is applicable, we still have that $\\beta_t = \\mathcal O(\\sqrt{\\gamma_{t-1}})$. For the Matern kernel, $\\gamma_T = \\mathcal O(T^{d(d+1)/(2\\nu + d(d+1))} \\log T)$ (Srinivas et. al., 2010). Thus, if the Matern kernel was used, there would be some value of $N$ beyond which the regret bound is not sublinear. Assumption 3 needs to be even stronger than it currently is for the sublinearity claim to be true. Ideally, the authors could provide an explicit formula for $\\beta_t$ instead of assuming such a sequence exists, or at least discuss why constructing such a sequence would be hard.\n\n2. Each $f_i$ is a vector-valued function modelled by a vector-valued GP. However, the vector-valued GP as presented in this paper does not match with the usual understanding of a vector-valued GP. From Sec. 3 in Alvarez et. al. (2012) (https://arxiv.org/pdf/1106.6251.pdf), vector-valued GPs have matrix-valued kernel functions $\\mathbf K: \\mathcal S \\times \\mathcal S \\rightarrow \\mathbb R^{d \\times d}$. However, this paper's regularity assumptions use a vector-valued kernel function $k_i: \\mathcal S \\times \\mathcal S \\rightarrow \\mathbb R^{d_i}$. The definition of GP posterior mean and variance Equs. 7 and 8 are not well-defined as they rely on $\\mathbf K_t$ where $(\\mathbf K_t)_{ij} \\coloneqq k_i(\\mathbf z_i, \\mathbf a_i; \\mathbf z_j, \\mathbf a_j)$, but $k_i$ is vector-valued according to their definition, so $\\mathbf K_t$ is not a matrix. Can the authors clear up this confusion?\n\n3. Why is UCB not tested on ToyGraph and PSAGraph?\n\n4. Other issues:\n- For the definitions of $\\mathcal X$ and $\\mathcal Z_i$, did you mean to use Cartesian product $\\times$ instead of union $\\cup$?\n- The legends of the plots say MBCO instead of MCBO.",
            "clarity,_quality,_novelty_and_reproducibility": "Quality:\nOther than the technical issues raised in the previous section, the paper is generally well-written. The experiments section is good.\n\nClarity:\nThe paper suffers from a lack of clarity in some technical parts as raised in point 2 of the previous section. \n\nOriginality:\nThe paper is reasonably novel as it provides theoretical guarantees for a setting in which previous work did not provide such guarantees.\n",
            "summary_of_the_review": "I believe this paper has potential. Theoretical guarantees are important and the experiments show that their algorithm performs well in comparison to baselines. However, unless I am mistaken, the paper suffers from non-trivial technical issues. Assumption 3 as presented is already very strong but actually needs to be even stronger to properly achieve a sublinear regret bound. The definition of the GP posterior mean and variance is not well-defined and hinders understanding of their method. Until these issues are addressed, I am hesitant to recommend acceptance.\n\nPOST-REBUTTAL UPDATE: The authors have satisfactorily answered the main technical concerns and have improved the paper. I have improved my score to recommend acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4247/Reviewer_B1mp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4247/Reviewer_B1mp"
        ]
    },
    {
        "id": "-SCVrFkvN-i",
        "original": null,
        "number": 2,
        "cdate": 1666419620501,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666419620501,
        "tmdate": 1666419620501,
        "tddate": null,
        "forum": "Vk-34OQ7rFo",
        "replyto": "Vk-34OQ7rFo",
        "invitation": "ICLR.cc/2023/Conference/Paper4247/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper is about Bayesian Optimization (BO), and, in particular, Causal Bayesian Optimization (CBO) based on a novel model-based approach. Authors propose to extend the existing CBO using a model-based approach, along with proofs for bounding the cumulative regret and more realistic assumptions compared to current CBO approaches. The reference model is the Structural Causal Model (SCM) with known casual graph but unknown functional relations, which enables the representation of both observational and interventional distributions. Authors explore both soft and hard interventions, with and without constraints over actions. The objective is to select a sequence of actions to maximize the expected reward by minimizing the cumulative regret function with a finite horizon. Since the acquisition function cannot be evaluated in closed form, authors apply the \"kernel trick\" and leverage gradient-based optimizers. Finally, both theoretical proofs and empirical evaluations are provided.",
            "strength_and_weaknesses": "Strength points:\n    - Model-based approach over structural causal models that inherits the theoretical framework for causal inference.\n    - Guarantees in terms of bounded cumulative regret.\n    - Assumptions make sense, allowing to generalize to a wide range of settings.\n\nWeak points:\n    - No unobserved confounding could be a naive assumption. \n    - Knowing the true causal graph combined with causal sufficiency means to know the causal mechanism, even if the functions are unknown.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear both in terms of theoretical proofs and empirical guarantees. \nFurthermore, the notation is consistent while necessarily complex. \nThe assumptions on which the contributions are based are listed and discussed in a clear manner.\nThe same applies to the discussions about limitations and possible solutions to overcome them. \nFormulas, pseudocodes and images are of good quality and help the interested reader to go through the work. \nI vote for the experimental layout (setting) is bith correct and reproducible, in the light that the author/s make available the software code. However, I had not time to check it myself.\nThe examples are meaningful, in adequate quantity and increasing complexity. \nFinally, I think that the degree of novelty of the paper is good and what developed and describe is relevant for the target field.",
            "summary_of_the_review": "The paper is well structure, organized and written and I enjoyed reading it.\nTheoretical statements are presented and supported by the associated proofs .\nFurthermore, empirical achievements are well supported a rich set of numerical experiments and obviously the associated results which are presented and discussed in an effective manner. \nThe presented approach is novel for the considered research area and its results are promising also when taking into consideration the assumptions made by the author/s. \nIt is also worth to mentin that the topic of the paper is relevant and discussed in details, thus representing an added value for the venue.\nIn conclusion I think the paper deserves consideration for being presented to a restigious venue as ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4247/Reviewer_UVNu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4247/Reviewer_UVNu"
        ]
    },
    {
        "id": "Exv4P2dYDp5",
        "original": null,
        "number": 3,
        "cdate": 1666645730154,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666645730154,
        "tmdate": 1670184834313,
        "tddate": null,
        "forum": "Vk-34OQ7rFo",
        "replyto": "Vk-34OQ7rFo",
        "invitation": "ICLR.cc/2023/Conference/Paper4247/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors present a version of the CBO paper from 2020. They introduce some new minor ideas of how to fuse BO with causal inference ideas.",
            "strength_and_weaknesses": "This review proceeds section by section per your paper.\n\n# Abstract\n\n- It is confusing when you say \"downstream\" variable of interest. Certainly BO is a sequential method but you are targeting static causal diagrams wherein which \"downstream\" makes it sound as if you mean something in the future. Looking at your graphs you are targeting the root node of each CD (as per causal inference literature, not decision tree root-nodes who flip the terminology -- though I notice you are calling the outcome variable the 'sink').\n- CBO, as introduced by Aglietti et al., target a full SCM not just a set of SEMs as you infer. Unless you are introducing a new method with the same name, then you are not discussing the same model framework.\n- The original CBO paper does not assume noisless measurements. Where does it say that? The implementation of the model CBO (see here for the complete graph from the paper: https://github.com/VirgiAgl/CausalBayesianOptimization/blob/master/graphs/CompleteGraph.py) clearly has an epsilon parameter (the noise parameter for the observational samples). Your statement is either wrong or you are referring to something different.\n- BO does not come with guarantees either so I am not sure how yours is a valid point? BO is not guaranteed to converge and so by extension neither is CBO.\n\n# Introduction\n\n- You should mention that this idea was first proposed by Aglietti et al. and yours is not a new idea w.r.t. the second paragraph. Similar ideas were introduced by the Lattimore brothers in their 2016 paper on causal bandits and Bareinboim in their 2015 before them. Optimal decision making + causal knowledge is not a new idea.\n- I am curious as to why you depart from standard ideas of representing observationa and interventions in graphical form w.r.t. figure 1. It is standard to make interventional nodes V as upper-case labels and then repsent interventions as removing any incoming arcs to that node which is relabelled with small-caps label v, Hence, why have you departed from this formalism? What is the reasoning?\n\n# BACKGROUND AND PROBLEM STATEMENT\n\n- You are assuming causal sufficiency (no UCs) but the original CBO papers does not. Is that not a bit of a limiting assumption? It certainly limits the type of problems that you can deal with.\n- It would be clearer if you used more set-notation e.g. to refer to all variables bar the outcome variables write $\\mathbf{X} \\setminus \\{Y\\}$. It is clearer.\n- The same thing for graph terminology: use standard family relationships to refer to e.g. the parents of X_i i.e. pa(X_i) if you are not including also the argument and Pa(X_i) if you are. Please stick to this and don't introduce new notation.\n- Can you please provide the pagenumber for \"soft intervention with unknown effect\" in Pearl's book, I cannot seem to find it.\n- I do not follow why graph mutilation (i.e. hard interventions) is an issue w.r.t. your method? Please explain. I do not follow the logic or rather reasoning for going with soft or shift interventions.\n- Not intervening with a hard-intervention would simply be to observe the system which results in no grap mutilation which means the DAG is not modified at all. This seems to be a odds with your previous point.\n- When we cannot intervene on a node we usually call it a \"non-manipulative variable\" - this is well studied. \n- As to _what_ we should intervene on, the intervention set as it is called, is also very well studied. See Lee and Bareinboim's 2018 paper on 'where to intervene' - they prove specifically that when there are no UCs present (like you are assuming) it is always best to intervene on _all_ the parents of the target variable.\n- You ought to reference the metric that you are using as it is not novel and has been used for decades to evaluate bandits.\n- Now in equation 6 you are using hard interventions but which in your setting will not mutilate graph is what you are saying? \n- I find it strange that you have not discussed _what_ you plan to intervene on given that you'll be exploring the whole powerset space of interventions $\\mathcal{P}(\\mathbf{x} \\setminus \\{Y\\})$ and this seems like a detail worth exploring, if not this will be terribly inefficient.\n\n# ALGORITHM\n\n- Where does equation 9 come from?\n- Please explain the last sentence of this paragraph where you say: \"In the following, we set \u03b2i,t = \u03b2t for all i such that the confidence bounds are still valid.\"\n- After equation 10 then it sounds as if you are indeed exploring the whole powerset over intervention variables. That is a _very_ large set to explore particularly as you do not have UCs so the best intervention is always the parents of Y. \n- What is $\\mathcal{I}$?\n- In the hard intervention paragraph you are saying that use the MIS/POMIS ideas of Lee and Bareinboim but you're not really; you are using one of their definitions (number 1) to find the minimal intervention sets because, again, you do not have UCs, their work is barely applicable to your setting. Their ideas come into their own when there are UCs but otherwise, with chain-structured graphs you just remove intervention sets which topologically yield the same outcome expression.\n\n# THEORETICAL ANALYSIS\n\n- This is a very nice section, nicely done.\n- It would have been nice to have a few examples of the bound in theorem 1 (give it an equation number so it can be referenced) applied to a few of the examples in figure 2.\n- Why are the a's in the figures no longer bold as in figure 1(b)?\n- I think you are taking too many liberties with how you are drawing your graphs. Typically, in causal inference, we reserve dashed edges for items that regard unobserved confounders (mind you, Aglietti et al. also takes liberty with their graph drawing so mine is a general comment). \n- You should look into dynamic treatment regimes; a lot of your examples graphs have the same topological structure (and ordering). Could be interesting to see if your ideas are applicable there.\n\n# EXPERIMENTS\n\n- It would seem odd for you to call the original paper 'EICBO' and not 'CBO' - call it the latter, as they were first to publish this idea.\n- It is very strange that you do not deploy all methods on all test cases in figure 3. ",
            "clarity,_quality,_novelty_and_reproducibility": "# Clarity\n\nThe paper is well-written and mathematically rigorous.\n\n# Quality\n\nA high-quality paper.\n\n# Novelty\n\nThe novelty is low. There are sections that, if expanded, will be far more impactful and interesting.\n\n# Reproducibility\n\nThe authors have included the code. I have not gone through it.\n",
            "summary_of_the_review": "This is a twist on an earlier idea. I do not think there is enough novelty to warrant inclusion as it stands.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4247/Reviewer_wHmj"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4247/Reviewer_wHmj"
        ]
    },
    {
        "id": "_pgTXkfHgS",
        "original": null,
        "number": 4,
        "cdate": 1667012433729,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667012433729,
        "tmdate": 1669177572328,
        "tddate": null,
        "forum": "Vk-34OQ7rFo",
        "replyto": "Vk-34OQ7rFo",
        "invitation": "ICLR.cc/2023/Conference/Paper4247/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper considers Bayesian optimization over objective functions defined via a causal graph, where the nodes correspond to functions defining the relationships between nodes in the graph (including the action variables). Within this framework, a UCB-based acquisition function is proposed. This acquisition function is shown to enjoy sublinear regret. Moreover, it is shown to perform competitively with respect to several state-of-the-art methods across several test problems.",
            "strength_and_weaknesses": "Strengths:\n1. This work considers a relevant problem setting and proposes a technically sound method with good empirical performance and theoretical guarantees. \n2. This paper is very well written overall.\n3. An implementation of the code used in the empirical evaluation is publicly available.\n\nWeaknesses:\n1. Novelty: My main concern is related to this work's novelty claims. I believe the problem setting considered by this work is the same as that of Astudillo and Frazier (2021) in the sense that a function network could be written as a causal graph and vice versa. Both papers consider a directed acyclic graph where nodes in the graph take as input an action variable and the outputs of their parent nodes. I would like the authors to clarify what they mean in the following statement: \"Moreover, function networks are not causal models and do not model actions as interventions.\" Is it only the use of the causal model formalism that makes these two problem settings different? Assuming this is the case, the primary source of the novelty of this work becomes the proposed acquisition function. I believe this is enough for this work to warrant publication, but the authors should clarify this. The authors should also explain that Kusakawa et al. (2021) also developed a UCB-based acquisition function that comes with similar sublinear regret guarantees in the cascade setting. How does the acquisition function proposed in this work compare with that proposed by Kusakawa et a. (2021) for causal graphs with a cascade structure?\n2. Lack of realistic experiments: As discussed by the authors, the problem setting considered in this work arises in many critical real-world applications. However, they only considered one realistic test problem in their empirical evaluation. Moreover, this problem does not seem to be built upon a high-fidelity simulator or real-world data.\n\nOther minor comments: \n1. The authors should discuss how $\\eta$ is modeled in more detail. I wonder how the choice of the neural network architecture affects performance.\n2. This work falls within an existing line of research on grey-box Bayesian optimization (see, e.g., Astudillo and Frazier 2022). I recommend the authors discuss this literature.\n\nAstudillo, R., & Frazier, P. I. (2022). Thinking inside the box: A tutorial on grey-box Bayesian optimization.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is very well written, and the code used in the empirical evaluation is publicly available. Thus, this work performs well in terms of clarity and reproducibility. The proposed method is technically sound, thus making this paper perform well in terms of quality. As stated above, my main concern is that the discussion regarding novelty over prior work is misleading. It is also somewhat disappointing that realistic experiments were not considered in the empirical evaluation.",
            "summary_of_the_review": "This paper proposes a novel and technically sound acquisition function for causal BO. This acquisition function performs competitively in numerical experiments. My main concerns are that (1) this work's discussion regarding novelty over prior work is somewhat misleading, and (2) realistic experiments were not considered. Were these two aspects of the paper improved, I would support accepting this work.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4247/Reviewer_geFQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4247/Reviewer_geFQ"
        ]
    }
]