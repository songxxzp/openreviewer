[
    {
        "id": "ubNwdIGw2DO",
        "original": null,
        "number": 1,
        "cdate": 1666565962937,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666565962937,
        "tmdate": 1666565962937,
        "tddate": null,
        "forum": "p7Bfc_wsDtH",
        "replyto": "p7Bfc_wsDtH",
        "invitation": "ICLR.cc/2023/Conference/Paper984/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes a new pre-training technique to induce a logical prior in the language model representation. Concretely, they propose pre-training on facts, represented as knowledge base triples (source, sink, relation) (knowledge-base completion) and link prediction, alongside traditional masked language modeling objective. Their proposed method achieves some improvement over downstream tasks, including a subset of GLUE benchmark and a couple of relation prediction datasets.\n\n",
            "strength_and_weaknesses": "Unluckily for the authors, I was one of the reviewers who have reviewed the same paper when it was submitted to ICLR 2022. [Link to the ICLR 2022 forum](https://openreview.net/forum?id=1gEb_H1DEqZ&referrer=%5BReviewer%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FReviewers%23assigned-papers)), which contains the reviews on the previous version of the draft.\n\nChanges in the current submission compared to the previous version:\n\n- Minor writing improvements in abstract, introduction.\n- Addition of a few more related works\n- Addition of BERT large and Prophet large experiments\n- Addition of multi-task finetuning results\n\nI would encourage the readers to refer to the reviews from the previous forum to get an idea about this work, as this version has barely changed. I'm adding a [diff of the two versions](https://draftable.com/compare/KSXHLMKbYBxe) for comparison. \n\nI'm surprised and sad that the authors only chose to perform minor modifications in their paper, given they had a full year to make revisions and incorporate the reviewer feedback. The authors also did not respond to the questions raised by several reviewers in the initial draft. What is shocking is that many of those questions _still remain unanswered_ in the draft the authors resubmitted **one year later**. For instance, majority of the reviewers had issues and with the presentation of the paper, involving the notation abuse in the theoretical background, motivation behind the methodology, implementation details, and explanation of the results (`cXhg`, `DQM2`, `K1pp`). The preliminaries and the model description are virtually untouched in the new version (check the diff). Reviewers also had severe issues regarding the analysis, especially the cherry picking of the heatmap and case study (`DQM2`, `K1pp`, `cXHg`). Those sections remains unchanged as well. Heck, **even typos** pointed out by the reviewers remain the same!! (\"nentailment\" in Figure 5, as pointed out previously by cXHg).\n\nRegarding the addition of new results, they do indeed add more data point on the effectiveness of the approach compared to BERT large baseline. However, these results do not change the fundamental questions about the work which has been asked previously.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Same as the last version, see my comments above.\n",
            "summary_of_the_review": "Overall, I believe the paper cannot be recommended for acceptance in any form, given the authors:\n\n- Did not change their text based on copious reviewer feedback\n- Did not respond to the questions raised by the reviewers\n- Made a mockery of the open, peer review system by resubmitting a paper with minimal changes to the same conference **one year** later.\n\nThis is highly unfortunate, as the paper does have some interesting contributions which could have been useful for the community at large, had the authors engaged in the scientific discussion and updated their manuscript accordingly.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper984/Reviewer_kqSf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper984/Reviewer_kqSf"
        ]
    },
    {
        "id": "UOHQXOwsfF",
        "original": null,
        "number": 2,
        "cdate": 1666665338698,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666665338698,
        "tmdate": 1666665411588,
        "tddate": null,
        "forum": "p7Bfc_wsDtH",
        "replyto": "p7Bfc_wsDtH",
        "invitation": "ICLR.cc/2023/Conference/Paper984/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes to enhance a pre-trained language model (PrLM) by three self-supervised pre-training tasks, namely logical structure completion, logical path prediction and logical connective masking. Experimental results demonstrate that the enhanced PrLM achieve significant performance in several NLP tasks including natural language inference, relation extraction and machine reading comprehension, compared with the basic PrLM BERT.",
            "strength_and_weaknesses": "Strength:\n\n(1) The proposed three pre-training tasks for enhancing PrLMs are novel as far as I know.\n\n(2) The enhancements are shown to be effective compared with the PrLM baseline BERT.\n\nWeaknesses:\n(1) There is a lack of comparisons with other enhancements for PrLM. In particular, none of the enhanced PrLMs mentioned in Related Work, namely ERNIE, WKLM, KEPLER and K-Adapter, is compared in experiments.\n\n(2) The presentation is not good enough and can be improved, especially in clarifying notations given in paper. In the last sentence above Figure 2, $E$ is not defined in $S=(V,E)$, and $A_i$ and $P$ are not defined in the context. In Equation 1, the symbols $a$ and $p$ are not defined, nor the whole notation $D(x_i\\mid m^a, m^p)$; especially, the meaning of the symbol $\\mid$ is unclear. In Equation 2, the function symbol $\\sigma$ used in $\\sigma[v_i, v_j]$ is not defined.\n\n(3) The declaration that the enhanced PrLM improves the ability of logical reasoning is problematic. The proposed three pre-training tasks do not deal with classical logical reasoning such as deduction and abduction. What kinds of logical reasoning that benefit from the proposal should be clarify.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The quality of the paper is fine except a lack of empirical comparisons with other enhanced PrLMs. The clarity is fair as some important notations are not defined (see comments above). Meanwhile, the notion of logical reasoning used in the paper should be clarified to distinguish it from classical logical reasoning. The originality is good since the proposed three pre-training tasks are novelty to my knowledge. Source code is provided in supplemental material.",
            "summary_of_the_review": "The novelty of the paper lies in three new pre-training tasks, which are shown to be effective compared with the baseline BERT. However, the paper can still be improved by clarifying notations in method descriptions and the crucial term logical reasoning. More importantly, the comparisons with other enhanced PrLMs are probably needed by considering that all of them adding new pre-training tasks to BERT.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper984/Reviewer_X9Xi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper984/Reviewer_X9Xi"
        ]
    },
    {
        "id": "GGAZ50HFSa",
        "original": null,
        "number": 3,
        "cdate": 1666877197175,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666877197175,
        "tmdate": 1666877244799,
        "tddate": null,
        "forum": "p7Bfc_wsDtH",
        "replyto": "p7Bfc_wsDtH",
        "invitation": "ICLR.cc/2023/Conference/Paper984/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Based on the knowledge structure fact, this paper proposes a logic-aware pre-trained language model PROPHET, which can then learn logical relations more generally from larger corpus. Extract fact from a given syntax to leverage multidimensional logical information for better representation. In this paper, three new pre-training methods based on fact are introduced in detail: 1) Logical connective masking for learning sentence-level logical connections. 2) Complete the task based on logical structure, and align the extracted facts with the original context. 3) Logical path prediction, which captures the logical relationship between facts.\n\nContributions\uff1a\n(1) PROPHET takes the initial attempt to pre-train language models that leverages the conceptual knowledge unit fact to equip PrLMs with logical reasoning ability. (2)This article introduce three novel pre-training tasks for learning logic-aware \nrepresentations from texts and facts. (3) The model performs in text classification, language reasoning, semantic similarity and other tasks better than BERT, especially in logical reasoning. The model can also model the semantic relationship between sentences.\n",
            "strength_and_weaknesses": "Strength\uff1a\n(1) Compared with existing studies that inject complex knowledge like knowledge graphs, the knowledge structure based on fact is far less complicated and more general in representing events and relations in languages.\n(2) The paper performs ablation experiments that show the effect of each pre-training task.\n(3) Compared with the lack of logical supervision in the existing pre-trained models, the proposed method can capture the inherent logical structure in the text well.\n(4) The overall structure of the article is relatively clear.\n(5) The paper performs ablation experiments that show the effect of each pre-training task.\n\nWeaknesses:\n(1) The specific technical implementation of this model is largely based on existing studies. Includes criteria for some of these parameters and measures of testing.\n(2) The experimental data and parameter selection in this paper lack necessary explanations.\nThe Prophet proposed in the paper did not show a significant advantage.\n(3) No significant improvement was reported on any of the other tasks, except for the logical reasoning task.\n(4) In the third column of Figure 4, the Prophet: nentailment maybe Prophet: entailment.\n",
            "clarity,_quality,_novelty_and_reproducibility": "In this paper, the explanation is fairly clear, and the idea is interesting. ",
            "summary_of_the_review": "In this paper, by using a new pre-trained language model PROPHET to process logic, significant improvements have been made in downstream tasks involving NLP and NLU, which can well explain the internal logic structure of the context to assist the reasoning process. It has strong stability and robustness. The description of experimental details and the treatment of ablation experiments are also more detailed.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper984/Reviewer_NY6R"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper984/Reviewer_NY6R"
        ]
    },
    {
        "id": "CLW8WZcMEMe",
        "original": null,
        "number": 4,
        "cdate": 1667170459634,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667170459634,
        "tmdate": 1667170459634,
        "tddate": null,
        "forum": "p7Bfc_wsDtH",
        "replyto": "p7Bfc_wsDtH",
        "invitation": "ICLR.cc/2023/Conference/Paper984/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper provides an approach to pre-train language models by infusing them with logic information to enhance their performance on logical reasoning. They propose to use a \"fact\" which is extracted from the text itself and propose to use three pre-training tasks 1) Logical connective masking, 2) Logical structure completion, 3) Logical path prediction. Their facts are created using dependency parse information and do not require any additional Knowledge base. Their approach outperforms BERT base and BERT large on multiple datasets.",
            "strength_and_weaknesses": "Strengths:\n* The idea to use dependency parse information to pre-train a language model such that it has logical reasoning capabilities is nice. It alleviates the need to use external manually curated knowledge bases.\n* They provide a detailed analysis talking about various aspects of their approach including ablation, comparison between entity based knowledge and showing how their method is good for longer length text.\n* They show good results when compared to a BERT baseline on multiple GLUE benchmarks and DocRED, ReClor and LogiQA.\n\nWeakness and Questions:\n* Terminology of \"fact\" is certainly not novel. It is exactly the definition of a \"triple\" that is used widely in KG + graph literature. The \"logical graph\" is also exactly a knowledge graph -- just with knowledge extracted automatically using dependency parse. Many automatic KG creation techniques also extensively use dependency parse information.\n* In the abstract, it is stated: \"it enables training logic-aware models to be conducted on a more general language text\" - not sure what \"general language\" here this means. \n* In the introduction they claim that capacity to capture logic relations is necessary for logical reasoning but provide no citation / justification for the same.\n* The three pre-training tasks they claim as novel are well known tasks. \"Logical structure completion\" and \"Logical Path Prediction\" are essentially relation / entity prediction and link prediction.\n* Baseline and Benchmarks:\n  * The authors have chosen a very old baseline - There are more recent papers that use logical information (or KGs) in pretrained LMs (Eg: Methods present in A Survey of Knowledge Enhanced Pre-trained Models - Yang et al, 2021 and more recently, LogiGAN Pi et al, 2022).\n  * The paper lacks comparison with such other baselines. The authors have not compared with other more recent LMs like T5 too. The authors did compare with SemBERT on GLUE benchmark, but omitted the model for other comparisons in Table 2 and 3.\n  * Was SemBERT also further trained for 200k steps? In Table 3, why were original numbers used and not the numbers of BERT-base trained with further 200k steps?\n  * It is well known that GLUE benchmark is not ideal to compare models for logical reasoning capabilities (Gururangan et al, 2018). It is recommended to add more benchmarks to verify the reasoning capabilities like CLUTRR. It is also recommended to add standard relation prediction / link prediction benchmarks. \n* What all types of relations do you use (Number)?\n* What happens if you just pretrain with your objectives without using BERT initialized model?\n* Great job in specifying all experimental details. Can you also talk about the time it takes to pretrain according to your method? I feel extracting dependency parse + coref information is costly, and only a very significant jump in performance warrants the need to spend compute on calculating those. \n* Please provided statistical significance with the results.\n* In 5.4 results, you only talk about BERT but not SemBERT.\n* Table 3 why didn't you use BERT trained 200k more steps? Is 0.3 especially on the original BERT statistically significant?\n* Section 6.2 - How were Named entities used? Are all NEs paired with all other NEs? Or do you just filter your set of triples such that both entities are NEs?\n* The analysis of attention map is not at all convincing. Why just use one attention map? This experiment just not do justice to the claim.\n\n\nGrammar and nit picks:\n* The title in the paper doesn't match the title here in open-review (aware missing).\n* Intro para 1 - \"However they too much rely on massive\" -> \"However, they rely too much on massive\"\n* Logic reasoning -> logical reasoning\n* Figure 1 stabalized -> stabilized\n* In Equation 1- you mean conditioned on the input with masks and not just the masks right?\n* In section 6.1 you can rephrase this as currently both of your points talk about link prediction being most effective. \n* Describe what MNLI-matched and mismatched is in Section 6.4. Are the results in Table 6 for your method? What are the scores for BERT? \n* Figure 4 - nentailment -> entailment.\n* Conclusion last line - \"our model can well interpret ..... of the context to aid\" -> \"our model can interpret .... of the context well, to aid\"\n* Some equations are missing descriptions of the variables used. There's no need to define new variables if they are not used. What are the variables in Eq 2? \n* Basis -> bases",
            "clarity,_quality,_novelty_and_reproducibility": "There are minor grammatical issues in the paper as notified above. Apart from that, the paper seems well written. It's mainly lacking in terms of quality of baselines, discussion about existing tasks (relation extraction, link prediction) and possible comparison to more recent baselines + those including other KG induced techniques. The approach suggested by the authors, in my knowledge, has not been directly explored (using dependency parse to pretrain) but the terminology introduced by the authors is definitely not novel. I would suggest the authors to talk about that relevant literature too. I had a quick glance over the supplemental code and the code seems reproducible. ",
            "summary_of_the_review": "While the idea of using dependency parse to extract triplets from the text and feeding them as part of a pre-training objective seems novel, i'm not sure how practical it is since it's very costly to run dependency parse / constituency parse. There are some experiments that seem too much cherry picked and are not convincing to support the claim they make. This paper is also lacking crucial literature review of relevant tasks like relation prediction, link prediction etc. The baseline used in this paper is also old and more recent \"logic induced\" baselines have not been used properly. There are some design choices in the experiments that raise questions (like why not use Bert trained for 200k more steps for all experiments, why not pre-train using your objectives from scratch), etc. Some of the datasets chosen to evaluate their approach (GLUE) are known widely to be poor benchmarks to evaluate logical reasoning.\nIn any case, I'm willing to bump up my rating to borderline accept if the authors have a satisfactory reply to some of my questions (I'm aware it might be tough to run new baselines) but some other explanations can definitely be provided.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper984/Reviewer_i2UV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper984/Reviewer_i2UV"
        ]
    },
    {
        "id": "mYLy9soiB0",
        "original": null,
        "number": 5,
        "cdate": 1667419596653,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667419596653,
        "tmdate": 1668083402683,
        "tddate": null,
        "forum": "p7Bfc_wsDtH",
        "replyto": "p7Bfc_wsDtH",
        "invitation": "ICLR.cc/2023/Conference/Paper984/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper introduces PROPHET which is a BERT-like model but pre-trained with three new pre-training objective:\n\n(1) Logical Connective Masking: Masking but with more chance on masking connectives (discourse adverbials, subordniate conjuctions etc.). \n\n(2) Logical Structure Completion: (closer to fact-triplet completion) \"Arg1 predicate Arg2\" forms of fact triplets are recovered from dependency parses (from off-the-shelf tools) (combined with co-reference resolution edges and such). Part of it may be masked and the model has to precict it. \n\n(3) Logical Path Prediction: (closer to syntactic dependency paths) randomly select nodes from dependency parses (from off-the-shelf tools) and predict whether the nodes are connected by a path in the parsed tree or not (binary class prediction using binary cross entropy). \n\nA decent amount of empirical experiments on different tasks, and ablations show effectiveness of the components and superiority over basic MLM-based BERT. ",
            "strength_and_weaknesses": "Strength: \n\n1. The proposed modeling strategies are not too bad. They look interesting.\n\n2. Improved performance over baseline BERT trained by standard MLM in multiple tasks and settings. \n\nWeaknesses:\n\n1. While the clarity is not too bad, it seems to fall a bit flat when it concerns specific and concrete details about the implementation. There are several parts that appeared unclear to me. Particularly it's hard for me to even verify the fairness of the experiments given unclear descriptions about how PROPHET and BERT-base were pre-trained. For different confusions/concerns, see my questions in the next section of the review. (This is my primary concern. With better clarity on some key details, I think this would be an overall acceptable paper).\n\n2. Generally the scales of the loss from generation and path classification can be different. Typically in these kinds of contexts, a scalar multiplier is used as a hyperparameter to scale up/down the losses from different objectives. \n\n3. In a sense, PROPHET is still just \"another\" new pre-training objective that improves a bit over BERT on several tasks. I am not sure how much we can take from that. There are still multiple other BERT-variants (SpanBERT, StructBERT, ReasonBERT, BERT-NCE, MC-BERT etc.)with endless different objective that gets a bit better than BERT on different NLU tasks. There are also pre-training strategies introduced for LogiQA/ReClor like LogiGAN. It's not clear if empirical-performance-wise PROPHET offer something distinctly much better than those or stack with others. Authors also attempt to motivate something about prior methods being sensitive to role reversal (section 2.1); but it's not discussed too deeply and I am not sure any empirical results in this paper demonstrate that PROPHET perform distinctly better than others in some special aspect.\n\n4. Even if PROPHET may perform better than BERT under the same training steps, PROPHET can require additional computational budget for parsing. BERT may be trainable further for the same budget and provide better results. \n\n5. Minor: a single anecdote in case study doesn't reveal much. It could be more interesting to show statistically, if PROPHET is more robust to such kind of changes as considered in the case study. Similarly, there's limited conclusion we can get from a single attention heatmap. It may be better to remove those parts (or move to the appendix) and focus more on clarifying/elaborating the other sections. ",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity:** Limited when it comes to technical expositions (see questions below)\n\n**Novelty:** The pre-training methods are moderately novel. \n\n**Quality:** Fair. \n\n**Reproducibilty:** Should be reproducible if the code works. However, some experimental details in the paper are hard to parse (see questions below).\n\n\nSuggestions:\n\n* PROPHET may be a confusing name given that it doesn't seem particularly related to the techniques introduced and  that there is already ProphetNet (https://arxiv.org/abs/2001.04063) in existence. \n\n* May be formalize what \"fact\" and its syntactic structure are in the introduction.\n\n* 2.1: \"perform sensitivity to role reversal\" -- sensitively?\n\n* Probably better to write \"Argument-Predicate-?\" as \"Argument-Predicate-[MASK]\" if mask based completation is used. Also what is the concrete token structure? Are you using something like \"argument <delimeter> predicate <delimiter> [MASK]\" or what exactly? Same question for \"Argument-?-Argument\". \n\n* 5.4: \"we continual trained\": \"we continued training....\"\n\n\nQuestions:\n1. *\"Although the existing\ntechniques have shown effectiveness in capturing syntactic and semantic information after large-scale\npre-training, they perform sensitivity to role reversal and struggles with pragmatic inference and\nrole-based event knowledge (Rogers et al., 2020), which are critical to the ultimate goal of complex\nreasoning that requires to uncover logical structures.\"* - is this issue solved by PROPHET?\n\n\n2. *\"we consider verb phrases and some prepositions in the sentences as \"predicates\", and then\nwe search for their corresponding actors and actees as the \"arguments\"\"* -- which prepositions? \"search\" arguments -- how?\n\n3. *\"To speak in detail, we randomly select a specific\nproportion \u03bb of the total facts (\u03bb = 20% in this work), from a given context. For each chosen fact, we\neither ask the model to complete \"Argument-Predicate-?\" or \"Argument-?-Argument\" (the templates\nare selected based on equal probability)\"* -- can you clarify how this is connected to the overall context? Did you concatenate/prepend \"argument-Predicate-?\" structure to the original masked sentence? If so how exactly is it concatenated? Did you use a special delimiter? \n\n\n4. *\"We pre-train our model for 500k steps. We use 8 NVIDIA V100 32G GPUs, with FP16 and\ndeepspeed for training acceleration. Initialized by the pre-trained weights of BERTbase, we continue\ntraining our models for 200k steps.\"* --- I am confused about what this means. What does \"initializing by the pre-trained weights of BERT-base\" means in this context? The weights after the 500k steps? Then what's the difference in just training for 700k? I am not sure what's particularly happen after 500k. The weights will automatically be the same as the weights after 500k at the point if we just trained for 700k without breaks. Or if you initializing the original BERT weights, what was the point of previous 500K training? Some important specifications seem missing here. \n(Did you mean to say you trained BERT-base for 500K, and then branched to training PROPHET by initializing with 500K-trained-BERT, and also continued training BERT-base to 700K (extra 200K)? -- if so why not training PROPHET with the prophet objectives for the whole 700K? Was to to simplify training expenses by sharing the training of the two models for a while?)\n\n\n5. 5.2 is confusing. It's not clear what training corresponds steps to Prophet, and what exact training steps corresponds to BERT-base. By extension the \"fairness\" is also unclear in (1) 5.4. \n\n6. Why does table 3 DocRed results not present results for your implementation of BERT (getting comparable pre-training examples and steps to PROPHET, I hope) as well?\n \n\n7. 6.2: *\"If a fact is not recognized with any named entities, we just leave it out.\"* --- Why not keep both normal facts as usual, and add named-entity-augmented facts when possible? That seems like the natural progression to make. \n\n\n8. Despite the name, I find the paper had limited to do with adding logic-specific bias or deductive bias. It's closer to adding fact-triplet filling task  (based where the ground truth is generated based syntactic dependencies, co-referential relations, and such) + conjuction-like token prediction. So it's closer to adding more explicit bias for modeling syntactical relations (which can be indirectly helpful for logical reasoning of course) (may also have relation to knowledge graph completion but I am not as familiar with the area) as opposed to something distinctively logic-specific.  I am not sure what precisely \"logic\" graph have to do with \"logic\" rather than just syntactic dependencies. ",
            "summary_of_the_review": "The paper introduces PROPHET: a BERT-like model trained with three new pre-training objectives created based on connectives and syntactic dependencies. Decent performance, but issues with clarity in technical exposition. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper984/Reviewer_5kDz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper984/Reviewer_5kDz"
        ]
    }
]