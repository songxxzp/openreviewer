[
    {
        "id": "kvG4zoeGn2",
        "original": null,
        "number": 1,
        "cdate": 1666562929473,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666562929473,
        "tmdate": 1666578197839,
        "tddate": null,
        "forum": "iA8XoWjDeGK",
        "replyto": "iA8XoWjDeGK",
        "invitation": "ICLR.cc/2023/Conference/Paper2058/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studied Pruning-at-initialization (PAI). The authors show that the accuracy of CNN models pruned by a PAI method depends on the layer-wise density. They further propose a structured PAI method, PreCrop, to prune CNNs in the channel dimension.",
            "strength_and_weaknesses": "+PAI saves training costs compared to standard pruning methods.\n\n+They theoretically show that PAI only depends on the layer-wise density (in theorem 1). \n\n+Emperical results seem good across different pruning settings, such as weight level, filter level, and channel level.\n\n-The advantage of the proposed method is not always obvious compared to SynFlow.\n\n-The baseline accuracy of MobileNet-V2 and Efficientnet-B0 is much lower than the reported accuracy in their original papers. Authors should double-check their implementations. The results on top of lower baselines are less meaningful.\n\n-Soft channel pruning methods, such as SCP [1], use no or small fine-tuning epochs. It would be better if the authors could compare the proposed method with soft channel pruning methods since their overall budget is similar.\n\n[1] Kang, Minsoo, and Bohyung Han. \"Operation-aware soft channel pruning using differentiable masks.\" International Conference on Machine Learning. PMLR, 2020.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall well-written and easy to follow. The idea is novel to some extent. They presented enough details for reproducibility, but the baseline accuracy of MobileNet-V2 and Efficientnet-B0 has some problems.",
            "summary_of_the_review": "Overall speaking, the paper provides some insights into PAI, especially the results of theorem 1. However, the low baseline accuracy of MobileNet-V2 and Efficientnet-B0 makes the empirical results less meaningful. In addition, soft channel pruning methods can achieve good performance giving a similar training budget to PAI.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2058/Reviewer_kacd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2058/Reviewer_kacd"
        ]
    },
    {
        "id": "a-kEbfCvTPm",
        "original": null,
        "number": 2,
        "cdate": 1666588675856,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666588675856,
        "tmdate": 1666588675856,
        "tddate": null,
        "forum": "iA8XoWjDeGK",
        "replyto": "iA8XoWjDeGK",
        "invitation": "ICLR.cc/2023/Conference/Paper2058/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors proposed SynExp as a proxy for accuracy and format pruning at initialization as an optimization problem to maximize SynExp. Based on this, they proposed PreCrop for channel pruning and PreConfig for channel optimization, both at the initialization. Experimental results show the proposed method can further improve existing models like EfficientNet and MobileNetV2 in terms of accuracy vs. model size trade-off. ",
            "strength_and_weaknesses": "Strength:\n1. Firstly, the paper is generally well-written and easy to follow. \n2. The proposed heuristic to estimate the network's performance outperforms existing ones on the ablation benchmark.\n3. Compared to the existing PAI method SynFlow, the proposed method has a better FLOPs/params vs. accuracy trade-off at an even coarser granularity. \n\nWeakness:\n1. Apart from PAI methods, the proposed method uses a very similar setting as zero-shot neural architecture search (NAS) (e.g., [a, b, c]) when only the channel dimension is searched (zero-shot NAS also needs to estimate the performance of a model architecture before training and compare different architectures to pick out a good one). The paper should reference such literature and compare the proposed method with zero-shot NAS, especially the performance estimation function.  We can keep the search space the same (i.e., only the channel dimension) and use the model performance estimator from zero-shot NAS literature for comparison to see if the proposed method is better. \n2. Although the proposed method aims for a training-free setting, it would be better to also include a comparison with post-training pruning results to see how large the gap is.  \n3. In the paper, it says, \"The SynExp Invariance Theorem shows that the pruning granularity of PAI methods should not affect the accuracy of the pruned model\". However, in real cases, the granularity could affect the performance of pruning by a lot (e.g., fine-grained pruning can achieve a larger learning rate). How do we explain the contradiction?\n\n[a] Zhang and Jia, GradSign: Model Performance Inference with Theoretical Insights\n[b] Lin et al., Zen-NAS: A Zero-Shot NAS for High-Performance Deep Image Recognition\n[c] Mellor et al., Neural architecture search without training \n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity, quality, and reproducibility are good. \nIn terms of novelty, the proposed method is quite similar to existing PAI and zero-shot NAS methods, with only the difference in the model performance estimator (i.e., SynExp). However, there is no evidence to show SynExp can outperform existing estimators (only compared with SynFlow, which has been outperformed by recent work like [a]).\n\n[a] Zhang and Jia, GradSign: Model Performance Inference with Theoretical Insights",
            "summary_of_the_review": "Overall, the proposed method aims to solve an important problem. However, it lacks a comprehensive comparison to existing PAI/zero-shot NAS work, which makes the contribution less convincing. The core novelty also highly depends on whether SynExp is actually better than existing ones. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2058/Reviewer_seit"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2058/Reviewer_seit"
        ]
    },
    {
        "id": "RGDmPZIm8s6",
        "original": null,
        "number": 3,
        "cdate": 1666659033722,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659033722,
        "tmdate": 1666662810302,
        "tddate": null,
        "forum": "iA8XoWjDeGK",
        "replyto": "iA8XoWjDeGK",
        "invitation": "ICLR.cc/2023/Conference/Paper2058/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper firstly proposes a metric called SynExp that is an expectation of the SynFlow values over the weights and mask distributions. According to the authors, SynExp is a constant and independent of the pruning granularity so the pruning granularity may not have an influence on the trained models' accuracy. Later on, the authors propose two techniques, PreCrop and PreConfig, that prune the model structurally and adjust the models' parameters, respectively. PreCrop solves a convex optimization problem that results in an optimal structure, while PreCrop optimizes the models' structures in place. Experiments show the empirical performance of the proposed techniques. ",
            "strength_and_weaknesses": "Strengths:\n- The presentation is generally clear and easy to follow. \n- The methods are conceptually simple yet seem to be effective. \n\nWeakness:\n- Some claims are not well supported. (See below)",
            "clarity,_quality,_novelty_and_reproducibility": "Questions:\n- Equation (4) says that the expectation on the scores is the same with fixed values of $\\{p_l\\}$ and is independent of the pruning granularity. The authors then use this fact to claim that the trained CNN is expected to have similar accuracy. Say one score is associated with one trained model accuracy, then how could the mean of the scores be associated with individual models' accuracy? If the variance of the scores is small then it is somewhat arguably, however the authors do not show this point which makes me feel less convinced. \n- Then, the proposed optimization problem in (5), though somewhat empirically effective, is not theoretically justified. Problem (5) is agnostic to the initial weights of neural networks, while SynFlow (and other PAI methods) knows the initial weights, which means they do have additional information on the model training process. The proposed algorithm, however, does not have this information but achieves superior performance without twisting fundamentally the pruning algorithm (i.e., it is still using SynFlow as a scoring function after all). So, it is somehow surprising to me that the proposed algorithm can outperform SynFlow. What is the standard deviation in Table 1? Is it possible that the performance advantage is not statistically significant?\n- Following on the previous question, we can come up with an extreme distribution of initial weights to downgrade the performance. For example, the performance is likely to drop if we put $0$ in those un-pruned weights. Solving problem (5) only results in a structure that is agnostic to certain initial weights, \n- It would be better to use a smaller line size in Figure 5 as the two lines are overlapping a lot. \n",
            "summary_of_the_review": "I am open to change my score - but currently I feel there are some points make me confused in this paper, so I am giving a 5. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2058/Reviewer_Ss1f"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2058/Reviewer_Ss1f"
        ]
    },
    {
        "id": "5u3VQNUL4W",
        "original": null,
        "number": 4,
        "cdate": 1666818529710,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666818529710,
        "tmdate": 1666818529710,
        "tddate": null,
        "forum": "iA8XoWjDeGK",
        "replyto": "iA8XoWjDeGK",
        "invitation": "ICLR.cc/2023/Conference/Paper2058/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studied the problem of structured Pruning-at-initialization (PAI) on CNNs. It first introduced synaptic expectation (SynExp) as a proxy metric for accuracy. Then, this paper formulated an optimization problem to maximize SynExp for determining the layer-wise pruning ratios, which are subject to model size/FLOPs constraints. The authors observed empirically and prove theoretically that the accuracy of CNN models pruned by PAI depends on the layer-wise density. Experiments are conducted on several CNN architectures like ResNet, MobileNetV2, and EfficientNet, on CIFAR-10 and ImageNet datasets to verify their statement and proposed method.",
            "strength_and_weaknesses": "### Strengths:\n\n   - This paper is generally well-written, and the proposed method is clearly introduced.\n\n   - This paper formulated structured PAI as an optimization problem via maximizing SynExp under model size/FLOPs constraints, which seems interesting.\n\n   - Multiple CNN architectures are used, including ResNet, MobileNetV2, and EfficientNet, on CIFAR-10 and ImageNet datasets.\n\n### Weaknesses:\n\n   - The comparisons in the experimental section are insufficient. This paper stated SynFlow [1] is the current state-of-the-art approach, and this paper only compared to the baseline model and SynFlow without any other PAI methods on each individual architecture. However, SynFlow was published in 2020 which was two years ago. There must be some new PAI papers in the same field. It\u2019s better to compare with them in this paper. This is necessary to examine the advancement and advantages of the proposed method over other competitive approaches.\n\n[1] Hidenori Tanaka, Daniel Kunin, Daniel LK Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. arXiv preprint arXiv:2006.05467, 2020.\n\n   - In Figure 2, it seems the layer-wise densities of the proposed method are close to SynFlow and have no significant advantage over it. The results in Table 1 also reflect this.\n\t\n   - In the experimental part, since ResNet-50 is a more typical architecture than ResNet-34, it\u2019s better for the authors also to provide results on ResNet-50, so that we can have an intuitive and straightforward comparison with other strong pruning methods.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity and quality of this paper are acceptable. Novelty is also enough. It is encouraged for the authors to provide the source code for reproducibility.",
            "summary_of_the_review": "Overall, this paper has merits in writing, formulation, and method originality. However, the experiments and comparisons in this paper are insufficient. The results also seem not competitive.\n\nMy final rating will be based on the authors\u2019 responses to my concerns.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2058/Reviewer_CtCn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2058/Reviewer_CtCn"
        ]
    }
]