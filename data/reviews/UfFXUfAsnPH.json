[
    {
        "id": "7XdKRa533A",
        "original": null,
        "number": 1,
        "cdate": 1666260968927,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666260968927,
        "tmdate": 1666260968927,
        "tddate": null,
        "forum": "UfFXUfAsnPH",
        "replyto": "UfFXUfAsnPH",
        "invitation": "ICLR.cc/2023/Conference/Paper661/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work provides a new method named \u201cBig learning\u201d that provides a theoretical platform for analysing, justifying, and improving foundation models such as BERT. ",
            "strength_and_weaknesses": "Strength: The mathematical descriptions are well defined. Also, the proposed Big learning method has an advantage of handling incomplete data and missing values. \n\nWeakness : The abstract is poorly written, ambiguous,  and does not describe the problem. For example, the statement \u201c Recent breakthroughs based on big/foundation models reveal a vague avenue for AI, that is, big data, big/foundation models, big learning, \u00b7 \u00b7 \u00b7 .\u201d. Exactly what avenue is being explored here? Also, decide on a single term to describe the problem and not include multiple terms such as \u201cbig data, big/foundation models, big learning\u201d.  This leaves a lot of room for confusion and misinterpretation.  This happens throughout the rest of the paper as well. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper presents a novel method as it aims to improve foundation models such as BERT by providing a theoretical framework that explains the success of the foundation models. The authors do not share the code and data used in the experiments. As a result, this may be difficult to reproduce. ",
            "summary_of_the_review": "This paper presents a new method named Big Learning that attempts to improve upon popular NLP models such as BERT by exploiting the information inherent in large scale data through modelling marginal data distributions with a single universal model. \n\nOverall, although the proposed method is novel,  the paper is poorly written ambiguous as the problem is not simply and clearly defined. Several different words are used to describe the same thing which might lead to confusion and misinterpretation by the reader. Although the mathematical expressions are clearly defined, this gets lost in the unclear text. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper661/Reviewer_hoLo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper661/Reviewer_hoLo"
        ]
    },
    {
        "id": "lUG1RYQ-73B",
        "original": null,
        "number": 2,
        "cdate": 1666637034703,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637034703,
        "tmdate": 1666637034703,
        "tddate": null,
        "forum": "UfFXUfAsnPH",
        "replyto": "UfFXUfAsnPH",
        "invitation": "ICLR.cc/2023/Conference/Paper661/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposed \"big learning\", a framework for understanding and modeling complex probability distributions. Big learning is defined to be a modeling of all possible factorizations of a given probability distribution, with all conditionals, marginals, and joints fully learned. The paper shows that existing modeling frameworks fit under the umbrella of big learning as special cases. Experiments with masking show compelling conditional generation results.",
            "strength_and_weaknesses": "Strengths\n1) The paper approaches an interesting idea. Understanding learning problems as specific instantiations of modeling the complete joint distribution over data is a compelling goal, and the basic formulation of learning all P(S|T) for all subsets S,T makes intuitive sense.\n\nWeaknesses\n1) The paper ultimately fails to prove the value of its proposition. The proposed framework is never explicitly defined, and seems to have a varying definition to fit the argument being made at any point in the text. It appears to encompass \"all possible probability distrubtion modelling\", but its not clear how this generalization is valuable.\n\na) 3.2 Discussions has a lot of strong claims that are not well substantiated. \nhow exactly can you share one model? this needs to be explicit: how does p_\\theta(x_T|x_S) learned for all S,T yield all joint/conditional/marginals that are close to q(x_T|x_S) for a specific S,T? The empirical argument is fine but does not justify this new \u201cbig learning\u201d paradigm unless it provides some new theoretical advantage or insight.\n\nb) Why or how does the framework generalize past the transformer/ViT models? Because they are \u201cdata/information hungry\u201d is odd, it's not clear what the authors mean by this. Not enough evidence is provided that \u201cbig learning\u201d generalizes past the transformer/ViT/BERT models presented. \n\nc) \u201cmodel capacity likely not an issue\u201d the discussion here seems unnecessary if the assumption is that the model is \"big enough\".\n\nd) How is this different from simple masking or conditional generation? what new insight should a reader be getting?\n\ne) weighting massive data tasks:\nthe optimum is the same regardless of different weighting strategies? how? The problem is still highly nonconvex, how is it guaranteed that the optimum will be the same if the training procedure is different via different sampling?\n\nf) Eq.6 looks like it is exactly making some assumption about the factorization of the distribution. How does this fit into the model of learning all joint/conditional/marginals? If I wanted to sample from p_\\theta(X_T\u2019|y_S\u2019), how would I do that?\n\n\ng) How is this different from masking/conditional generation that already exists with different mask levels? All experiments seem to be showing various masking results with no comparison to other frameworks, and do not seem to provide much new observations that are only possible because of \u201cbig learning\u201d.\n\n\nNotes/Other\n\n1) The structure of the arguments are difficult to follow. It's hard to see what is a technical result and what is just discussion. It would benefit significantly from definition/theorem/proposition blocks.\n\n2) Figures 1 and 2 do not add much over the text, and table 1 is very vague and not well substantiated.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\nThe paper is quite readable, but the arguments presented are not clear. Many points are made without sufficient explanation or proof. Many comparative sentences just say it is \u201cmore\u201d or \u201cbetter\u201d. Better than what? Concretely, theoretically, empirically, how is it better and what is it better than? There is a lot of language but not sufficient concrete evidence to support the claims made.\n\nQuality\nThe paper has typos, and because of the poor evidence for the claims fails to meet a high quality standard.\n\nNovelty\nThe paper claims extreme novelty, but does not justify it. The current presentation does not seem novel.\n\nReproducibility\nI have not gone through the appendices in full detail, but experimental details are provided along with more discussion of some points made in the main paper.\nNo code is provided to replicate the results presented in the experiments section.",
            "summary_of_the_review": "The paper presents a new framework, but fails to demonstrate its value, both theoretically and experimentally. Many arguments are described with text, but ultimately are not proven or substantiated.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper661/Reviewer_qcrZ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper661/Reviewer_qcrZ"
        ]
    },
    {
        "id": "nX-mZieNEg",
        "original": null,
        "number": 3,
        "cdate": 1667183823152,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667183823152,
        "tmdate": 1667183823152,
        "tddate": null,
        "forum": "UfFXUfAsnPH",
        "replyto": "UfFXUfAsnPH",
        "invitation": "ICLR.cc/2023/Conference/Paper661/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper attempts to unify many different machine learning models by re-stating them as \u2018big learning\u2019. The authors claim that this paradigm is better than existing methods since it can handle incomplete data. They conduct experiments on conditional image generation.\n\n",
            "strength_and_weaknesses": "Strengths:   \n1. The paper reviews various training objectives in literature and shows how they may be restated under their \u2018big learning paradigm\u2019. \n2.  They conduct experiments on image completion that produce good images completions (though they do not provide any metrics to compare with existing results). \n\nWeakness:\n1. The main goal of the paper is unclear. Are the authors proposing a new theoretical paradigm to analyze foundation models? If yes, there are no stated proposals for how their phrasing gives us more insight into existing methods than the existing phrasing. Are they proposing a new experimental paradigm? Is yes, the authors need to clearly state what the downstream goal and use of their experimental paradigm is.  \n2. Unsubstantiated claims:   \n- The authors claim that their big learning setup gives you more downstream applications than joint modeling (table 1), but they do not state any particular way to test this claim. For example, in their conditional joint modeling experiments, they show that you can generate images from many different ratios of missing pixels, but they don\u2019t show what the downstream use of this capability is? For instance, they don\u2019t compare to joint modeling methods to show that this method learns better representations for classification.  \n- \u201cpotentially delivers all joint/conditional/marginal data capabilities after training\u201d it is not at all obvious that a model trained on many diverse datasets will be able to model all distributions and this has not been shown via experiments in their paper.  \n- The paper makes some vague claims like \u201cbig learning behavior closely resembles the fundamental unconscious mind and the vision system of human brains\u201d. \n- They claim that \u201cbig learning is what foundation models are implicitly doing\u201d but again they don\u2019t lay out any clear testable hypothesis for this claim. Which behavior exactly are they referring to, and why is big learning any more explanatory than the loss function of existing foundation models like autoregressive modeling.   \n\n\nMinor comments. \n1. Table 1 is unclear. For eg: what do authors  ean that \u2018capabilities after training\u2019 are \u2018joint\u2019? What is the basis to claim that downstream applications are limited for joint modeling vs. abundant for unsupervised big learning?   \n2. The paper does not provide any metrics for measuring the quality of results in their paper.   \n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The papers goals could be stated more clearly\nQuality: The paper does not benchmark any results or provide clear downstream applications\nNovelty: The experiments in the paper employ existing methods with some modifications ",
            "summary_of_the_review": "The contribution of this paper is unclear - while they attempt to unify existing methods under their big learning paradigm, they do not demonstrate concrete theoretical or practical benefits of doing so. The paper also contains many unsubstantiated claims.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper661/Reviewer_ZM7W"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper661/Reviewer_ZM7W"
        ]
    }
]