[
    {
        "id": "3Lh45iRfYNg",
        "original": null,
        "number": 1,
        "cdate": 1666578192767,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666578192767,
        "tmdate": 1666578230821,
        "tddate": null,
        "forum": "P45P8xfL_n",
        "replyto": "P45P8xfL_n",
        "invitation": "ICLR.cc/2023/Conference/Paper30/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "A multi-scale structure-preserving heterologous image transformation method based on conditional adversarial network learning is proposed in this paper. The experimental results show that the proposed algorithm can better suppress the local structural distortion and has significant advantages in evaluation indicators such as RMSE, LPIPS, PSNR, and SSIM.",
            "strength_and_weaknesses": "Strengths:\n1.\tThe proposed loos function is capable to consider the correlation constraint between pixels.\n2.\tTotal variation of difference (TVD) is proposed to make the image smooth and keep the edge structure of the image better.\n\nWeaknesses:\n1.\tThe novelty is limited. As a major contribution to the author's summary, what are the advantages of multi-scale feature extraction over existing methods? It looks similar to most multi-scale feature extraction methods.\n\n2.\tIt will be better if the results of more state-of-the-art methods proposed in 2021 and 2022 are provided.\n\n3.\tMore descriptions should be given in the titles of the figures and tables.\n\n4.\tThe layout of the subfigures should be improved, e.g., Fig.6 and Fig.8. \n\n5.\tThe results of runtime should be added in the paper.\n\n6.\tThe number of references is too small. References can be further improved.\n\n7.\tThe format of the tables should be revised. These tables should contain three lines.\n\n8.\tIt will be better if the results of some non-reference metrics are provided.\n\n9.\tThere are some grammar mistakes, e.g., \u201cthe state-of-the-art algorithm\u201d in Conclusion should be \u201cthe state-of-the-art algorithms\u201d.\n\n10.\tSome results of the proposed loss functions on other image transformation methods should be added to validate the effectiveness.\n\n11.\tThe selection of hyperparameters used in the combination of loss functions should be analyzed.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is basically clear. The technical content of the paper is correct, but some details should be added. The present paper is reproducible. The novelty of the paper is limited. The multi-scale strategy looks similar to most multi-scale feature extraction methods. The effectiveness of the proposed loss functions is not validated on other image transformation methods.",
            "summary_of_the_review": "See the above",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper30/Reviewer_o1H8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper30/Reviewer_o1H8"
        ]
    },
    {
        "id": "mXrrAUkBlT",
        "original": null,
        "number": 2,
        "cdate": 1666614645395,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666614645395,
        "tmdate": 1666614645395,
        "tddate": null,
        "forum": "P45P8xfL_n",
        "replyto": "P45P8xfL_n",
        "invitation": "ICLR.cc/2023/Conference/Paper30/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work solves the problem of transforming images from infrared to real visual spectrum that too solely focuses on the KAIST-MPD dataset. To this end, the authors propose to use a multi-scale generator architecture and new loss functions such as cosine loss and total variation loss of the differences. ",
            "strength_and_weaknesses": "Strengths\n \n1. Though I have seen the use of cosine loss in the literature associated with the classification or metric learning, I haven\u2019t encountered using the same for image transformation. This can be an exciting proposal to look at.\n \n \nWeaknesses\n \n1. Poor writing standard: The paper is poorly written. Below are some examples\n\n- Input the image into the generator, the generator firstly down-samples the image three times in a row to obtain three images of smaller size, and then starts from the image of the smallest size, the generator extracts the features and encodes them. => poorly framed sentence, written as if one is talking to another in-person\n\n- Both GAN loss and CGAN loss adopt the dual form in pix2pixHD, that is, when training the generator, the generated image is True, and when training the discriminator, the real image is True, and the optimization goal is to reduce the loss at any time. The GAN loss is recorded as LGAN G when training the generator and LGAN D when training the discriminator\n- Table 1 seems to be redundant. \n- Poorly showcased results. It is extremely difficult to compare and understand the differences among the results shown in Figs. 5-7\n \n2. Lack of novelty: Multi-scale-based network architectures are very common in image transformation and restoration. Some of these works are cited by the authors themself. Some other works, for example, includes: {Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution CVPR 2017, Scale-recurrent network for deep image deblurring CVPR 2018, Msg-gan: Multi-scale gradients for generative adversarial networks, CVPR 2020} I do not see any novelty in terms of the design of the generator as such.\n \n3. The paper's objective doesn\u2019t have too much of an impact: This work aims to improve the image transformation performance specifically for the KASIT-MPD dataset. As such, the advantages of the proposed method for general image transformations are unclear. \n \n4. Experiments can be biased: Though authors have compared with some state-of-the-art methods, there is no clear description indicating if authors have used pre-trained networks or newly trained (on the dataset under consideration) versions of these state-of-the-art methods. \n \nMinor issue:\n\nSection 2: Babu[11] - erroneous citation",
            "clarity,_quality,_novelty_and_reproducibility": "Poor writing, poor quality, not much novelty.",
            "summary_of_the_review": "The work suffers from poor writing quality, lack of novelty, and too narrow scope keeping it well below the acceptance level.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper30/Reviewer_5dFs"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper30/Reviewer_5dFs"
        ]
    },
    {
        "id": "KnsecoBiLl",
        "original": null,
        "number": 3,
        "cdate": 1666752649386,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666752649386,
        "tmdate": 1666752649386,
        "tddate": null,
        "forum": "P45P8xfL_n",
        "replyto": "P45P8xfL_n",
        "invitation": "ICLR.cc/2023/Conference/Paper30/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper is interesting. It summarizes varios image processing tasks as image transformation trained on adversersial networks.",
            "strength_and_weaknesses": "Strength:\n1. SOTAs on the KASIT-MPD dataset\n\nWeaknesses:\n1. Only one dataset and infrared-rgb task is evaluated.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Good to follow and easy to understand\nQuality: Good. Can be accepted if more experiments are evaluated.\nNovelty: Seems ad-hoc combination of existing GAN networks and losses.\nReproducibility: Seems can be reproduced. ",
            "summary_of_the_review": "This paper can be accepted if more experiments are evaluated.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper30/Reviewer_KAPg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper30/Reviewer_KAPg"
        ]
    }
]