[
    {
        "id": "yMrHZYVjyF",
        "original": null,
        "number": 1,
        "cdate": 1666229274352,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666229274352,
        "tmdate": 1669995926308,
        "tddate": null,
        "forum": "U2g8OGONA_V",
        "replyto": "U2g8OGONA_V",
        "invitation": "ICLR.cc/2023/Conference/Paper1305/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper leverages recent theoretical developments in nonlinear ICA to introduce a novel model for multi-domain image generation and show that its joint distribution is identifiable from the marginal distributions. Motivated by this result, two practical algorithms are suggested, one for multi-domain image generation, which corresponds to sampling from the joint over domains, and one for image-to-image translation, which corresponds to sampling from a conditional. Both of these approaches are based on the assumptions that only a few latent variables are influenced by the domain label, which is implemented in the learned model via learned masks and regularization. Extensive experiments are performed, comparing multiple baselines on multiple datasets, which all point in the direction of improved matching between samples from the joint and better image-to-image generation.",
            "strength_and_weaknesses": "Strengths:\n- I very much like the overall direction of this work. I believe leveraging recent identifiability results from the nonlinear ICA literature for the problem of multi-domain image generation and image-to-image translation is a very good idea, given how important the question of identifiability is to these problems. Bringing this more theory-driven mindset to this literature should benefit the community.\n- The experimental section appears fairly complete, to the eye of a non-expert in multi-domain image generation.\n\nWeaknesses:\n- Overall, some theoretical statements lack clarity. One finds many undefined notation which makes some of the statements impossible to understand. Also some mathematical statements lack precision. I expand on this in the \"Clarity\" section later in my review.\n- The connections between some sections could be improved, especially between the theoretical results and the suggested algorithms. For example, in Section 3.2, I believe there is a mismatch between equation (6) and how the ground-truth model (4) was specified: in the model (6) z_s = \\epsilon + f_u (\\epsilon), whereas in the ground-truth model, z_s = f_u(\\epsilon). This could be fixed in the model by doing z_s = (1 - m) * \\epsilon + m * f_u(\\epsilon). Is there a specific reason for not doing that? \n- Section 3.3 is very hard to understand. A lot of new notation is introduced such as H, E, F and D without proper explanations. The function F is called the \u201cshared generator\u201d and then called the \u201cmapping function\u201d, this makes everything hard to follow. Also, it is not so clear to me exactly what approximates p_\\theta(x^{(u_1)} | x^{(u_0)}). Overall, the connection with the theory from the previous section is not so clear to me.\n- The motivation for using the masking mechanisms instead of just treating n_s as an hyperparameter is weak. An experiment attempts to show that the penalty coefficient associated to the mask is easier to tune than n_s. But I found this experiment unconvincing, since a priori, it\u2019s unclear what the range of \\lambda we should search over\u2026 The left top plot of Figure 4 shows a flat curve, but the curve would not look so flat had the range been different. How does one choose the proper range? All main experiments in the paper are performed with \\lambda = 0.1 and yields very good results. What happens when these experiments are run without this masking mechanism and with n_s = 16 or 32 (which were the best dimensionality found in the ablation study)? Do we see similar performance? \n- I couldn\u2019t find information in the main text about how the mask m is learned, nor a reference to appendix. Is m = sigmoid(parameter) ? Or is it a Gumbel-Sigmoid?\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:\n- What is \\mathcal{Z} ? Undefined?\n- Lemma 3.1: \n    - Isn\u2019t A1 a consequence of (4)?\n    - A2 is also a consequence of (4). Indeed, if you apply an element-wise transformation to a vector of mutually independent random \n    variables (which in this case is a Normal(0,I)), the resulting vector remains mutually independent.\n    - In A2, what is said in words corresponds to pairwise conditional independence while what is written mathematically corresponds to mutual conditional independence, which are not the same.\n    - A3. q is not defined.\n    - A4. What are B_{z_c}, B_{z^*_c} ? What is Z_s? Both are undefined, thus I can\u2019t understand this assumptions. \n    - The conclusion of the theorem refers to \u201ccomponent-wise identifiability\u201d and \u201cblock-wise identifiability\u201d, but both terms were defined after the statement of the lemma, the author might want to consider introducing their definition before the lemma. \n- Section 3.2\n    - I do not understand the following statement: \u201cIf we feed the domain label into the generator directly, the generator may over-utilize the information of domain label u in order to confuse the conditional discriminator D\u201d. What does over-utilize mean? What does it mean to confuse the conditional discriminator?\n    - If we set n_s = n and n_c = 0, is it equivalent to feeding the domain label u in f_u ?\n- Section 4.1\n    - Caption of figure 3: \u201cWe observe that there are unnecessary changes between the images (e.g., the added sun-glasses in the first row, the different poses of animals of StyleGAN2-ADA in second row) without regularization.\u201d I agree that this is indeed observed in the samples provided in Figure 3, but is it an observation that generalizes across samples? \n    - The MNIST samples in Figure 3 for the baseline methods look a bit weak to me. Why is that? The baselines should give good sample quality, no? (Although we expect weaker pairing quality in the baselines)\n    - I cannot really assess the relevance of the metrics used.\n\nNovelty/originality: \n- As far as I know, this is the first work proposing an identifiability result for this setting, which I think is a significant contribution.\n\nMinor:\n- The model p(z_s | u) defined in equation (4) factorises over the components of z_s, i.e. this is the usual conditional independence assumptions of the latents made in previous ICA work, this should be mentioned explicitly when introduced.\n- In first paragraph of second page: set of marginals from 1 to n, but should it be from 1 to d?\n- Equation (1) also has n instead of d.\n- Extra parenthesis in (4) ",
            "summary_of_the_review": "Even though I very much like the overall direction of this paper, (i) the overall lack of clarity, (ii) the lack of cohesion between the theory and the proposed methods and (iii) the lack of evidence for the usefulness of the masking mechanism prevent me from recommending acceptance. I am open to increase my  score if the authors address the main points I raised in my review (see Weaknesses section).",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1305/Reviewer_1JgB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1305/Reviewer_1JgB"
        ]
    },
    {
        "id": "vTuxeeMRBk",
        "original": null,
        "number": 2,
        "cdate": 1666593598239,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666593598239,
        "tmdate": 1666593598239,
        "tddate": null,
        "forum": "U2g8OGONA_V",
        "replyto": "U2g8OGONA_V",
        "invitation": "ICLR.cc/2023/Conference/Paper1305/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on conditional image generation and image-to-image translation. Although current methods enable both tasks work well, they fail  to formulate suitable constraints for the joint distribution, since there can be infinitely many joint distributions that can derive the same marginals. Inspired by Independent Component Analysis (ICA) theory, authors propose a new regularization by enforcing a specific type of minimal changes across domains. The quantitative and qualitative results demonstrate the effectiveness of the proposed method.   ",
            "strength_and_weaknesses": "Although there are a few outstanding methods proposed to explore conditional image generation, this paper explores a new view, which is effective to remove unwanted joint distributions. \n\nThis looks solid which give strong theory support about how to guarantee the true joint distribution. \n\nThe paper is well-written, and easy to follow.\n\nAuthors provides  conditional image generation and image-to-image translation results, which sounds interesting.",
            "clarity,_quality,_novelty_and_reproducibility": "I have a few concerns about this paper.\n\n1) The motivation to use ICA is not really clear. Is it to build the true joint distribution? Also I am wondering whether the diversity are reduces with ICA regulation? Could authors show the precision/recall?, such as StyleGAN and the proposed method, and starganv2 and the proposed one?\n\n2) As reported in Table 1, on mnist dataset the baseline (stylegan) has 95.9 FID, while the proposed method is 1.43. I am wondering how author perform the comparison experiment. \n\n3) The proposed method is easily influenced by hyper-parameters.\n\n4)  In this introduction, authors mentions current methods fail to remove the unwanted joint distributions, which means this paper can achieve it. could authors give some examples? For example, the age or does not change when changing hair color. I fail to find some kinds of figures like this. ",
            "summary_of_the_review": "This paper sounds interesting, which first considers ICA into the training of both conditional image generation and image-to-image translation.  The main experiment  shows the effectiveness of the proposed method. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1305/Reviewer_spME"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1305/Reviewer_spME"
        ]
    },
    {
        "id": "IZ_bIhpl-gW",
        "original": null,
        "number": 3,
        "cdate": 1666625677856,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666625677856,
        "tmdate": 1666625677856,
        "tddate": null,
        "forum": "U2g8OGONA_V",
        "replyto": "U2g8OGONA_V",
        "invitation": "ICLR.cc/2023/Conference/Paper1305/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper provides an in-depth study of estimating the joint distribution of multi-domain image generation and unpaired image-to-image translation. To mitigate the highly ill-posed issues of mapping from marginal distributions to joint distribution, the authors provide an in-depth analysis for the distribution modeling, while their theory is based on some tight assumptions. Besides, the paper implements this theory in a cheap way. Specifically, the paper empirically demonstrates the disentangled content and style controllable generator through a simple framework and loss function. Then, based on this architecture and new regularization, the paper improves the performance of multi-domain image generation and unpaired image-to-image translation on multiple datasets. ",
            "strength_and_weaknesses": "#### **Strengths**\n- There are many works using the StyleGAN or StarGAN architectures to perform the image generation and translation tasks but without in-depth analyses. This paper provides an in-depth study of the joint distribution for multi-domain generation and translation, which provdes some insights for the following researchers.\n- The implementation way is easily achieved, and the loss function is interesting. The corresponding impressive results are good enough to support the contribution claimed by the authors.\n- The paper is well organized and is easy to follow. Several observations are studied with quantitative and visual analyses, followed by the corresponding ablation study, making the paper easy to follow and concrete. \n\n#### **Weaknesses**\nWhile the proposed method is interesting and the experimental analyses are comprehensive, I believe some parts need more clarification (even after considering the supplementary material and code).\n- The joint distribution is the key motivation and novelty in the paper. However, the experiments just demonstrate the much better performance and the effectiveness of the provided framework. It will be better to visualize the distribution of the original dataset as well the generated results of different methods through the t-SNE, especially for MINIST7, which contains obvious domain and class category.\n-  The domain $u$ is predefined. As claimed by the authors, \"collecting corresponding data across domains can be prohibitively expensive\". Then, how could the authors define the domain numbers in a dataset?\n- More generally, for the CELEBA-HQ, the authors split it as female and male faces domains. Could we also add other domains, such as sad and happy, young and old and others? Does different domain numbers affect the performance?",
            "clarity,_quality,_novelty_and_reproducibility": "#### **Clarity**\n- The paper is well written and easy to follow. \n- The key motivation and overall idea toward addressing the task is clearly explained.\n- The implementation way is simple and reasonable.\n- The code is well organized. \n\n#### **Quality**\n- The model reaches better performance than the state-of-the-art methods.\n- The effectiveness of the theory and model is clearly demonstrated in the experiments.\n\n#### **Novelty**\n- The cheap normalization is novel and interesting. \n- The implementation for the join distribution through a simple domain-specific component-wise monotonic transformation is reasonable. \n\n#### **Reproducibility**\n- The code is well organized. I believe the experimental results can be reproduced using the provided code. ",
            "summary_of_the_review": "This paper investigates an important topic of unified multi-domain image generation and unpaired image-to-image translation task. Despite the experimental part could be further enriched to clearly demonstrated the better joint distribution learned by the proposed method, the easily achieved implement and thorough analyses on the properties provides many insights and might arouse following researchers. Therefore, my rating for this submission is positive.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1305/Reviewer_h5sT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1305/Reviewer_h5sT"
        ]
    },
    {
        "id": "g9efhQYbJMf",
        "original": null,
        "number": 4,
        "cdate": 1667019995827,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667019995827,
        "tmdate": 1667019995827,
        "tddate": null,
        "forum": "U2g8OGONA_V",
        "replyto": "U2g8OGONA_V",
        "invitation": "ICLR.cc/2023/Conference/Paper1305/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This method proposes a method for multi-domain image generation and unpaired image-to-image translation. The main challenge in these problems is learning a joint distribution from multiple marginal distributions is ill-posed, since there can be infinitely many joint distributions that can derive the same marginals.  Utilizing recent advances in nonlinear Independent Component Analysis (ICA) theory, the authors propose a new method to learn the joint distribution from the marginals. With the assumption that the influence of domain information is minimal in the data generation process, the method introduces the domain information through a component-wise monotonic transformation. Further, by assuming that the number of the underlying components affected by the domain information is minimal, the authors show that the true joint distribution can be recovered from the marginal distributions. Then the learned joint distribution can be used to sample meaningful tuples and translate input images to another domain without content distortion. First, the authors test the method on five multi-domain image generation datasets and evaluate using FID and domain-invariant perceptual distance (DIPD) metrics (for datasets with unpaired data.) On this dataset, the method obtains some improvement over baseline approaches, and especially shows good results on MNIST7, where other methods fail due to mode collapse. On the application of image-to-image translation, the method also obtains good results, outperforming baseline methods in both latent-based and reference-based settings. \n",
            "strength_and_weaknesses": "Strengths:\n1. The proposed approach shows pretty good improvement over the baseline methods, especially on the task of image-to-image translation. \n\n2. The ablation studies show the effect of different design choices, such as reducing the dimension of the style dimension or the effect of the number of style dimensions on generation quality. These are informative in understanding the effect of design choices on generation quality. \n\nWeaknesses/questions:\n1. The quality of writing in the paper is uneven, with some parts not written clearly, which makes the paper difficult to understand in parts. \n\n2. As the authors also allude to in the last section, the proposed method is not as effective when the content across domains is not aligned, such as the case of the ArtPhoto dataset (where the method shows the least improvement in FID). Can the authors comment the general applicability of the method in the light of this limitation, beyond standard constrained facial image and digit datasets? \n",
            "clarity,_quality,_novelty_and_reproducibility": "See above",
            "summary_of_the_review": "The paper proposes a method for multi-domain image generation and unpaired image-to-image translation, using an ICA-based method to learn the joint distribution from the marginals. The proposed method obtains decent improvement over baselines on standard datasets, however, performance gains are limited on complex images where the content across domains may not be aligned. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1305/Reviewer_6m6y"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1305/Reviewer_6m6y"
        ]
    }
]