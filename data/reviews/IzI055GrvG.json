[
    {
        "id": "ukZoP46B2M",
        "original": null,
        "number": 1,
        "cdate": 1665760897131,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665760897131,
        "tmdate": 1665760897131,
        "tddate": null,
        "forum": "IzI055GrvG",
        "replyto": "IzI055GrvG",
        "invitation": "ICLR.cc/2023/Conference/Paper24/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposed modification for multiple object tracking framework based on GTR[Zhou et.al 2022]. Instead of use the feature representation from detection bounding boxes. This paper proposed to use split bounding boxes and surrounding image patch if there are other objects located close to the current object, which aims to tackle occlusion and avoid identity switch cases.\n\nThe proposed methods performs comparable with state-of-the-art methods on MOT17, MOT20 and DanckTrack benchmark. ",
            "strength_and_weaknesses": "Transformer based tracking framework demonstrated promising performance. Research effort to improve those framework should be encouraged. This paper tried to explicitly guide the model to learn local object patches and surrounding object patches to improve performance. Experiments demonstrated the proposed part-whole attention improves tracking performance, both in the ablation study and on MOT17 and DanceTrack comparing to GTR.\n\n- How was the structure in part-whole attention module designed? Did the author try other designs? Any insights?\n- Given this paper is based on GTR, experiments should conduct on TAO dataset.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The overall structure is based on GTR but the context was not clear. The author should add add clear statement to acknowledge work by GTR paper. The proposed part-whole attention is well described. The discussion regarding L_feat should be expanded, especially alpha.\n\nExperiments are conducted on different hardware setup and reported similar performance, which indicates certain level of reproducibility. But code is publicly available.\n\nModified a previous work to introduce more feature representation prior. Novelty is fair.",
            "summary_of_the_review": "This paper proposed Part-Whole Attention module for GTR framework for multiple object tracking task. The proposed module are clearly described and experiments demonstrated the effectiveness. \n\nMore experiments on TAO dataset should be included to compare with its baseline method GTR. Discussions of the structure design for Part-Whole Attention module should be added",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper24/Reviewer_rS4y"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper24/Reviewer_rS4y"
        ]
    },
    {
        "id": "oEccdgVEckS",
        "original": null,
        "number": 2,
        "cdate": 1666746532405,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666746532405,
        "tmdate": 1666746532405,
        "tddate": null,
        "forum": "IzI055GrvG",
        "replyto": "IzI055GrvG",
        "invitation": "ICLR.cc/2023/Conference/Paper24/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a hierarchical representation of objects for multi-object tracking. The hierarchical representation consists of 3 levels: part, whole and union of overlapped objects. The proposed approach demonstrated good performance on multiple pedestrian/dance public datasets. ",
            "strength_and_weaknesses": "The strength of the paper is the fusing of the three levels of representation for multi-object tracking associations. The weaknesses of the paper are some of the notations and areas are not clearly presented.\n1. The notations of M and N in section 3.1 are not defined when appearing in the first and second part. This causes confusion when reading the paper.\n2. N should be T in 1<=i<=N in the third page.\n3. In page 4, \"we can tract the CNN features from them\", what is the CNN architect to extract the features?\n4. In page 6 Inference section, \"whose negative value serves as the entries in the cost matrix\". The cost value should not be some negative values. \n\nAnother weakness of the approach is the lack of motion feature in the association. In the association, only appearance features are considered. This can lead to association errors when two objects have similar appearances (similar color of clothes) even they are farther apart in the space. In the Detection and Feature Extraction section, detection features are extracted from a video clip of T frames and then the detection from each one of the T frames is associated with the trajectories. There can be significant motions in the T frames and appearance would be hard to handle the discriminability of the objects.",
            "clarity,_quality,_novelty_and_reproducibility": "The combination of 3 levels of representation especially the union of overlap using attention is somewhat creative. ",
            "summary_of_the_review": "Overall, this work shows somewhat creativity, but only considers the appearance features can be insufficient to solve challenging tracking cases.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper24/Reviewer_YxoG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper24/Reviewer_YxoG"
        ]
    },
    {
        "id": "77jvaCc_1F",
        "original": null,
        "number": 3,
        "cdate": 1666921859676,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666921859676,
        "tmdate": 1666921859676,
        "tddate": null,
        "forum": "IzI055GrvG",
        "replyto": "IzI055GrvG",
        "invitation": "ICLR.cc/2023/Conference/Paper24/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes an interesting 'Hierarchical Part-Whole Attention' for multi-object tracking. The proposed module is integrated with transformer network and achieves good performance (comparable or even better results than SOTA mot trackers). The overall training efficiency is also good, i.e., 4 hours on 4*v100 GPUs, while other Transformer based trackers may need days. This paper is well-written and organized, and I believe it will be a good baseline for future works to compare and in-depth development on this framework. ",
            "strength_and_weaknesses": "strength: \n1. the idea of Hierarchical Part-Whole representation of target object in MOT seems interesting; \n2. the combination of Hierarchical Part-Whole Attention and Transformer works well on existing benchmark datasets; \n3. the paper is easy to follow and understand. \n\n\nweakness: \n1. the source code will be released or not is unclear. it is an interesting idea, but the implementation is also complicated. If the code is not available, maybe it is hard for other researchers to follow. \n2. the running efficiency is not real-time. i.e., not fast enough for practical applications. ",
            "clarity,_quality,_novelty_and_reproducibility": "this paper is clearly written and the information is enough to reproduce the experiments. ",
            "summary_of_the_review": "the idea is reasonable, \nthe framework is not very complicated for MOT. \nthe training time is acceptable, but the inference is fast; \nthis paper is well-written and easy to follow. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper24/Reviewer_hWAz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper24/Reviewer_hWAz"
        ]
    }
]