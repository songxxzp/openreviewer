[
    {
        "id": "j4x55jGMPU0",
        "original": null,
        "number": 1,
        "cdate": 1666536686084,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666536686084,
        "tmdate": 1666536686084,
        "tddate": null,
        "forum": "ABqIh51jNQm",
        "replyto": "ABqIh51jNQm",
        "invitation": "ICLR.cc/2023/Conference/Paper5429/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focus on a generative problem of Constrained Scene Generation (CSG) under the condition of zero-shot and object-aware. Inspired by psychophysiological studies, author propose a Spatial Reasoning Network (SPREN) to imitate the multiple systems of reasoning and memory in human beings. Specifically, the framework integrated the state-of-the-art image generation network with the proposed spatial reasoning module to generate image satisfying complex spatial constraints. Besides, they design a forward-checking strategy to ensure the model could handle the zero-shot and object-aware CSG without any fine-tuning. Experiments indicate that SPREN could generate images specifying constrained conditions and also verify the effectiveness in zero-shot and object-aware variants of this task.",
            "strength_and_weaknesses": "Strength\n1)The greatest strength of this paper is that author propose a plug and play module to enhance the off-the-shelf image generation networks with spatial reasoning ability. Meanwhile, it also could handle zero-shot and object-aware CSG without any fine-tuning, which cost little to increase the quality of generated images. Thus, this work has well practicability and worth to generalize.\n2)Besides, author refer to the psychophysiological studies and provide a theoretical explanation that why the cognition needs to combine the spatial constraints, which represented in propositional logic to perform the iterative decision. In this case, the model could explicitly show the reasoning process, which has good interpretability.\n3)In experiments, author also verified the effectiveness of spatial reasoning module to stepwise discriminant analysis and evaluated the quality of generated constrained scenes.\n\nWeaknesses\n1)Although the proposed spatial reasoning network is effective alone, the quality of generated images still relies heavily on the image generation network, which is implemented by off-the-shelf framework GLIDE. To verity the generalization of spatial reasoning network, I think author should further explore different frameworks of image generation.\n2)According to my understanding, the visual element generation module needs to be sequentially called on each box from the blueprint. When the spatial reasoning module provide all the blueprint, image generation network could also directly inpaints all the masked area while keep the global semantic and spatial information. So, I think this sequential manner maybe a little redundant.\n3)In section 3.3, author choose 20% as the stop time, but it is not discussed in the experiment. I suggest to add relevant comparative experiments.\n4)In practical application, some large-scale pre-trained models could directly realize the similar function for the task of CSG, even under the condition of zero-shot. I think the quality of generated images maybe better than the cases you present in experiments. Meanwhile, the propositional logic mentioned in this paper also requires additional manage. So, how do you view this problem? ",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-organized and clearly introduce the motivation of proposed method. Author focus on the task of Constrained Scene Generation, as well as the zero-shot and object-aware variants. They design a Spatial Reasoning Network to combine with the off-the-shelf image generation model for enhancing the ability of high-level spatial reasoning, which could be easy to make reproduction. Though with a good motivation and framework, the number of experiments are far from satisfaction, which are lack of detailed analysis for some hyper-parameters and generalization.",
            "summary_of_the_review": "As mentioned above, the highlight of this paper is that author proposed a a plug and play module to enhance the off-the-shelf image generation networks with spatial reasoning ability, which meanwhile equipped with a good interpretation from the view of psychophysiological studies. But this work pointed out the key challenge of the spatial reasoning in CSG is vital for future studies. The whole framework is easy to implement and has well practicability, but the experiments is not enough to support its generalizability. Some experiments result still need further analysis. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5429/Reviewer_4LXR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5429/Reviewer_4LXR"
        ]
    },
    {
        "id": "qph2dcdCRne",
        "original": null,
        "number": 2,
        "cdate": 1666638115662,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666638115662,
        "tmdate": 1666638115662,
        "tddate": null,
        "forum": "ABqIh51jNQm",
        "replyto": "ABqIh51jNQm",
        "invitation": "ICLR.cc/2023/Conference/Paper5429/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This work proposes a model for spatial reasoning using RNNs for constrained image generation. They compare their method to two baselines and show improved performance on some metrics.",
            "strength_and_weaknesses": "Strengths:\n1. The paper is well motivated.\n2. The idea of constrained image generation with spatial reasoning is interesting.\n3. The paper is easy to follow.\n\nWeaknesses:\n1. The experiments are very limited and use uncommon metrics to measure the image generation quality (there is no FID, Inception Score, Precision and Recall, or user study).\n\n2. The literature review is very limited and mostly covers the earlier works on the topic and very few recent works.\n\n3. The novelty is limited. The paper re-introduces existing concepts without referring to them. The proposed blueprints are the same as scene layouts commonly used in image generation literature. Also, the bounding box prediction network is not new. There are a lot of works on the topic of image generation and manipulation using scene graphs and semantic scene generation that are not covered in this work. E.g. sg2im [1] already predicts bounding boxes from a scene graph (similar to the constraints in this work), constructs a scene layout (blueprints), and generates an image conditioned on this. The image manipulation part, which performs addition / deletion / changes to the objects has been explored in SIMSG [2]. [3,4] already learn spatial reasoning based on scene graphs. [5] generates images from scene layouts.\n\n[1] Johnson et al. \"Image generation from scene graphs.\" CVPR 2018.\n[2] Dhamo et al. \"Semantic image manipulation using scene graphs.\" CVPR 2020.\n[3] Zareian, Alireza, et al. \"Learning visual commonsense for robust scene graph generation.\" ECCV 2020.\n[4] Garg et al. \"Unconditional scene graph generation.\" ICCV 2021.\n[5] Zhao et al. \"Image generation from layout.\" CVPR 2019.\n\n4. The paper needs better organization. There is too much repetition of text in introduction and methodology that leaves a small space to the experiments which are an essential part of a research paper.\n\n5. The evaluation metrics are not explained. What are pref score, constraint sat, obj sat, pos sat?",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and easy to understand. The quality and organization of the writing need to be improved. The novelty is limited (please refer to weaknesses).\n\nIt is possible to reproduce the paper.",
            "summary_of_the_review": "Overall, the paper is low on standards such as evaluation and novelty.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5429/Reviewer_wJp9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5429/Reviewer_wJp9"
        ]
    },
    {
        "id": "Biru_8BreF",
        "original": null,
        "number": 3,
        "cdate": 1666682588238,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666682588238,
        "tmdate": 1666682588238,
        "tddate": null,
        "forum": "ABqIh51jNQm",
        "replyto": "ABqIh51jNQm",
        "invitation": "ICLR.cc/2023/Conference/Paper5429/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a method that composites objects onto a background image in a way that satisfies a set of spatial constraints. A neurally-guided search approach is taken, where a recurrent neural network predicts, via binary space partition, a distribution over possible locations of objects, which is used to guide the solution of a constraint satisfaction problem via backtracking. It is shown that the generated composite matches the constraints better than other general purpose image editing methods. No evaluation on image quality/realism is conducted.",
            "strength_and_weaknesses": "# Strength:\n- Using neural nets to guide the solution of CSP is an appropriate solution for this task.\n- Output satisfy the constraints well.\n\n# Weaknesses:\n### Design choices\nIn general, there is very little justification for the design choices, to list a few:\n- What's the motivation for using this binary partitioning scheme to infer the spatial location of objects. What's the advantage of this over, say, predicting a mixture of gaussians / a distribution over discretized coordinates / etc.?\n- Is it reasonable to predict x and y separately? I assume they are highly correlated.\n- Is it sufficient to condition the the spatial reasoning module on the \"object identifier\"? Does this identifier provide enough information to determine the location of objects?\n- How is the visual element generation module implemented and how to ensure the generated image patch blends well into the background image?\n### Evaluation & Quality of results\nThe evaluation performed in this submission is largely insufficient:\n- Evaluation focused on the amount of constraints satisfied. However, amount of constraints satisfied is not the only thing one cares about when evaluating these images. As the authors acknowledge themselves, visual quality is also very important. No evaluation on the visual quality of the outputs is provided, and, judging from the few qualitative examples provided, these image look appear to be very unrealistic , with a lot of problem with perspectives, illumination, and plausibility of layout in general.\n- The comparison conducted is not fair. The proposed method is designed solely around constraint satisfaction and has access to constraint formulations which are not available to the baseline. The baseline is a general purpose framework that accounts for much more than spatial constraints. I expect to see baselines that specifically focuses on constraints, this can be simple baselines such as a pure CSP-based algorithm without the neural guide part.\n- I think it's probably more appropriate to evaluate the proposed method on datasets that focused more on object relations and layouts, since the focus of this work does not seem to be image realism anyways. Datasets that target compositionality e.g. CLEVR, or more real-world scene datasets e.g. 3D-FRONT, 3DSSG, can be more appropriate here.\n- No ablations at all, which leaves me unsure about a lot of things e.g. how much does the RNN help with solving the CSP? Do the RNN really learn proper location priors e.g. lambs are never placed in the sky?",
            "clarity,_quality,_novelty_and_reproducibility": "### Quality\nOK, but can be improved. Both the justifications of design choices and the quality of results are lacking.\n\n### Clarify\nMostly clear, but many missing details, some wrong terms (e.g. looks like its a recurrent NN not a recursive one), and some descriptions that are unnecessarily convoluted (e.g. S1/S2 cognition, Problem 1/2).\n\n### Originality\nThe neurally-guided CSP is a nice idea for image generation, but other than that, there isn't much novelty in this submission, with most modules being largely borrowed from existing works.",
            "summary_of_the_review": "While I find the idea of the paper interesting and that there can be some potentials down this direction, ultimately I am underwhelmed by the justification of the design choices, and more importantly, but the low quality of the results and the lack of appropriate evaluations, particularly on image realism.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5429/Reviewer_9XhE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5429/Reviewer_9XhE"
        ]
    }
]