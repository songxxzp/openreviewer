[
    {
        "id": "wyk_N_GDen",
        "original": null,
        "number": 1,
        "cdate": 1666527189180,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666527189180,
        "tmdate": 1666527189180,
        "tddate": null,
        "forum": "G1H4NSATlr",
        "replyto": "G1H4NSATlr",
        "invitation": "ICLR.cc/2023/Conference/Paper2297/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper argues that the PAWS is not robust to unlabeled real-world data. This paper tries to tackle this problem by suggesting the RoPAWS. RoPAWS uses in-domain prior to prevent a model from overconfidently predicting unseen class data by adopting regularization utilizing similarity between labeled and unlabeled data. Thereby RoPAWS shows better performance in various settings. RoPAWS especially excels in uncurated settings with fewer labels.\nAlso, this paper gives a novel probabilistic view of PAWS. \n\n",
            "strength_and_weaknesses": "Strengths\n\n- Probabilistic explanation of PAWS that it works as generative classifier and extension to RoPAWS make sense and interesting.\n- The problem definition and formulation were clear.\n- Straightforward solution for the given limitation (overconfident prediction).\n- It obtains SOTA results with moderate additional time cost.\n- Fig. 4 shows apparently how RoPAWS works effectively compared to PAWS\n\nWeaknesses \n\n- The performances of the proposed RoPAWS as well as PAWS will be highly dependent on the choice of data augmentation methods for creating different views. The details are missing.\n- This is rather a question: I wonder if the self-supervisory signals between the two views of the labeled data gives better performance.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and easy to follow. It appears to be technically sound and gives adequate theoretical explanation and experiments. \n",
            "summary_of_the_review": "The motivation of RoPAWS is well supported. I believe that sufficient advances in the performance on uncurated settings shows the effectiveness of RoPAWS. Also the analysis using t-SNE demonstrates that RoPAWS works as the authors intended.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2297/Reviewer_oxEy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2297/Reviewer_oxEy"
        ]
    },
    {
        "id": "TNTUpcz_ue",
        "original": null,
        "number": 2,
        "cdate": 1666597603861,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666597603861,
        "tmdate": 1668669784266,
        "tddate": null,
        "forum": "G1H4NSATlr",
        "replyto": "G1H4NSATlr",
        "invitation": "ICLR.cc/2023/Conference/Paper2297/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper aims to make semi-supervised learning robust when unlabeled data contains out-of-class data. This is a practical problem. The authors improve the semi-supervised learning algorithm PAWS by calibrating the prediction of PAWS based on the data densities. Experimental results show the proposal achieves better performance compared with the PAWS algorithm.",
            "strength_and_weaknesses": "Strength:\n1) This paper focuses on the robust semi-supervised learning problem with out-of-class unlabeled data. This is an important problem.\n2) The proposal achieves better performance compared with PAWS.\n\nWeakness:\n1) This paper only gives a minor improvement on the PAWS algorithm. The contribution and novelty are quite limited. Can the proposal be applied to the general semi-supervised learning algorithms?\n2) There are also some other robust SSL algorithms that consider the out-of-class unlabeled data. More related methods should be compared in the experiments.\n\n\n---------Update-------\nI notice that the authors compared with some robust SSL algorithms on CIFAR-10 datasets. I recommend the authors conduct experiments on more settings, such as different datasets, various labels, various extents of OOD unlabeled data, etc.\n",
            "clarity,_quality,_novelty_and_reproducibility": "1) The paper is clear and easy to understand.\n2) The proposal is a minor revision of the existing PAWS algorithm. The novelty is limited.",
            "summary_of_the_review": "Overall, the contribution and novelty of this paper is limited, the experimental results are also not convincing.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2297/Reviewer_NjZV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2297/Reviewer_NjZV"
        ]
    },
    {
        "id": "zAPGPHFZClP",
        "original": null,
        "number": 3,
        "cdate": 1666637057400,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637057400,
        "tmdate": 1666637057400,
        "tddate": null,
        "forum": "G1H4NSATlr",
        "replyto": "G1H4NSATlr",
        "invitation": "ICLR.cc/2023/Conference/Paper2297/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper at hand prososes an extension of a recent proposed semi-supervised representation learning approach PAWS. The extension focuses in robustness, hence, RoPAWS, concerning uncurated data from, e.g., out-of-distribution data. This is a relevant problem in many real world applications.",
            "strength_and_weaknesses": "+ Quite simple extensions to pave the way for real world problems.\n+ Experiments a thoughtful and support the main aim of the approach.\n",
            "clarity,_quality,_novelty_and_reproducibility": "+ The paper is well written, good motivated and quite easy to follow.",
            "summary_of_the_review": "The paper addresses a relevant problem and proposes an extension to \"fix\" limitations of the recently proposed PAWS method. The extensions seems incremental but I'm still in favor for the paper and think its worth publishing.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2297/Reviewer_Q9GX"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2297/Reviewer_Q9GX"
        ]
    },
    {
        "id": "pDYTuqhAkHq",
        "original": null,
        "number": 4,
        "cdate": 1666678528829,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666678528829,
        "tmdate": 1666678528829,
        "tddate": null,
        "forum": "G1H4NSATlr",
        "replyto": "G1H4NSATlr",
        "invitation": "ICLR.cc/2023/Conference/Paper2297/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper extends the semi-supervised image classifier PAWS (Assran et al., 2021) by using unlabeled data in addition to the labeled data to inform the representation. Using the unlabeled data in this way allows the model to learn from out-of-distribution classes rather than assuming unlabeled data is curated to contain the same classes seen in labeled data. Experimental results show that the proposed RoPAWS method performs roughly on-par with baseline PAWS method on curated datasets and improves on PAWS in uncurated (OOD) settings.",
            "strength_and_weaknesses": "Strengths: \n*  The work reframes the PAWS method as a generative classifier and uses this probabilistic interpretation to clearly introduce the calibration using the unlabeled data in this setting.\n* The method prevents over-confident class predictions for OOD data in the unlabeled set, unlike PAWS, which yields better representations for classification.\n* Ablation study is provided to provide a careful study of the components of the method\n* Sensitivity of hyper parameters are empirically investigated and show improvements over baseline PAWS for a range of hyperparameter settings.\n\n\nWeaknesses:\n* In the original PAWS, class-balanced sampling plays an important role to avoid collapse of representations. By introducing the unlabeled data, it is not clear if this trivial collapse is now a problem in RoPAWS. Can this point be clarified in the exposition of the method? \n\n* When applying this method to curated data, it is not clear any improvements in performance should be expected. The model will be learning from more data, but the labels inferred for unlabeled data may not be accurate and therefore hurt performance. Indeed the experiments show only minor, perhaps negligible, improvement over PAWS.  The text does claim superiority in these cases as well but the numbers do not generally support the claim. The performance seems generally equal. An interesting point to investigate is the exception to this pattern where RoPAWS conclusively improves on PAWS in the curated CIFAR-10 dataset with only 25 labels per class. Here RoPAWS does benefit from using the (in-distribution) unlabeled data. This could be a strength of the proposed method if investigated further.\n\n* Likewise, the results on ImageNet (Table 2) show similarly small improvements in performance of RoPAWS over PAWS at both 1% and 10% of labels.  Some discussion of this could improve the empirical analysis.",
            "clarity,_quality,_novelty_and_reproducibility": "The text is well written and related works are well contextualized. The experiments are fairly complete and clearly explained. \n\nThe method does provide novelty in the re-framing and modification of an existing method to allow for better utilizing uncurated unlabeled data.\n\nThe text provides enough detail for reproducibility and authors provide their code.",
            "summary_of_the_review": "This is a good paper overall. The method provides an improvement over an existing method that makes is more applicable in real-world settings where OOD data is common. The text is well written and experiments are clearly laid out. Empirical results are mixed, in some settings performing on-par with existing methods and in some improving on them.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2297/Reviewer_R1Ae"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2297/Reviewer_R1Ae"
        ]
    },
    {
        "id": "0L-UmKsPDp",
        "original": null,
        "number": 5,
        "cdate": 1667020304218,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667020304218,
        "tmdate": 1667020304218,
        "tddate": null,
        "forum": "G1H4NSATlr",
        "replyto": "G1H4NSATlr",
        "invitation": "ICLR.cc/2023/Conference/Paper2297/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper deals with the problem of semi-supervised representation learning and proposes a method based on the specific previous method called PAWS. More specifically, the previous method PAWS can be regarded as kernel density estimation (KDE) for modeling the distribution of latent variables, and the proposed method called RoPAWS extends it in a semi-supervised way. The proposed method also introduces data-dependent in-domain priors assuming that an example is likely to have the same label if it is close to some labeled example.",
            "strength_and_weaknesses": "[Strength]\n\nS1. Representation learning is one of the hot topics at this conference. Technically solid methods for this topic will draw attention from a broad range of researchers and engineers.\n\nS2. The current manuscript is basically well-written and easy to follow.\n\n[Weakness]\n\nW1. I am afraid that the main idea of the proposed method is similar to semi-supervised kernel density estimation (SSKDE) presented in the following paper.\nWang, Hua, Mei, Hong, Qi, Song, Dai, \"Semi-supervised kernel density estimation for video annotation,\" Computer Vision and Image Understanding, Volume 113, Issue 3, 2009. https://doi.org/10.1016/j.cviu.2008.08.003.\nI understand that the specific implementation of the proposed method is different from that of the above paper; however, the advantages of the proposed method against SSKDE should be clearly presented both literally and experimentally.",
            "clarity,_quality,_novelty_and_reproducibility": "[Clarity]\nThe current manuscript is no problem in terms of clarity.\n\n[Quality]\nI am unsure which kind of quality should be discussed here; however, the current manuscript does not have sufficient quality for acceptance due to the lack of novelty justifications against the previous methods.\n\n[Novelty]\nAs presented in the Weakness section, the current manuscript fails to justify the novelty of the proposed method against the previous method SSKDE.\n\n[Reproduciblity]\nI think that it is no problem for reproducibility.",
            "summary_of_the_review": "I have to recommend this paper be rejected since it requires major revisions to justify the novelty of the proposed method. It should conduct detailed bibliographical surveys and experimental comparisons with previous related methods.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2297/Reviewer_yYAe"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2297/Reviewer_yYAe"
        ]
    }
]