[
    {
        "id": "h4q-N7OgJF",
        "original": null,
        "number": 1,
        "cdate": 1666318468598,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666318468598,
        "tmdate": 1666318468598,
        "tddate": null,
        "forum": "lLu1Xel2qfh",
        "replyto": "lLu1Xel2qfh",
        "invitation": "ICLR.cc/2023/Conference/Paper5095/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper studies the problem of differentially private federated learning. More specifically, in order to improve the utility of the differentially private model in federated learning, the authors propose to combine secure multiparty computation (MPC) with differential privacy (DP) when solving the regularized logistic regression. The main contribution of the paper is a new framework that allows private training for vertically distributed data.",
            "strength_and_weaknesses": "The strength of the paper:\n1. The proposed method enables private training for vertically distributed data, which is an important setting in federated learning.\n2. The authors propose a new method for secure sampling of a vector from a Gaussian distribution inside MPC.\n3. Empirical results validate the advantage of the proposed method.\n\nThe Weaknesses of the paper:\n1. It seems that the proposed method requires communication between computing parties at each iteration, which could be the key bottleneck in federated learning. Compared with the output perturbation-based method, which only requires one communication at the end, the proposed method suffers from high communication complexity.\n2. There are no theoretical guarantees of the proposed method.\n3. The presentation is not clear. For example, the learning problem is not defined. There are lots of undefined notations. More importantly, the random noise magnitudes for several baselines are unclear.\n4. It seems to miss an important baseline, i.e., Gu et al. (2021), in the experiments.",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation of the current paper is not clear:\n1. It is unclear how to get the update rule in line 8 in Protocol 4. If we choose $C$ and $\\Lambda$ to be zero, should it recover the original update rule?\n2. There is no formal privacy guarantee of the proposed method.\n3. For the baseline methods in Table 1 and Table 5, what are their noise magnitudes to achieve DP? For example, how does the variance of BASELINE-DPSGD in Table 5 scale with the number of samples and computing parties?\n4. Why the accuracy of nonprivate method can be worse than the private method with privacy budget 1 in Table 4?\n5. It is unclear how to get the hyperparameters of the proposed method.\n\nThe main contribution of the proposed method is to use secure computing parties, which enables the training of vertically distributed data. However, such a method seems to be very easy to implement in existing methods and thus allows them to handle the vertically distributed data. Furthermore, what is the advantage of the proposed noise generation method inside MPC compared with existing methods?\n\n",
            "summary_of_the_review": "The proposed method seems to be interesting since it can deal with vertically distributed data in federated learning. However, there are some problems that need to be addressed in the current paper (see weaknesses and clarity sections).",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5095/Reviewer_d2J7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5095/Reviewer_d2J7"
        ]
    },
    {
        "id": "h4NeTKtjCu",
        "original": null,
        "number": 2,
        "cdate": 1666573182885,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666573182885,
        "tmdate": 1666573182885,
        "tddate": null,
        "forum": "lLu1Xel2qfh",
        "replyto": "lLu1Xel2qfh",
        "invitation": "ICLR.cc/2023/Conference/Paper5095/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "the paper studies a method which combines MPC with DP that bypasses utility challenges of federated learning with local DP (with small datasets). authors show that the method achieves good performance by reporting their submission entry being 1st place for an iDASH 2021 challenge, at the cost of substantially more compute time. ",
            "strength_and_weaknesses": "strength: the paper is well-written and the empirical results are solid. \n\nweaknesses: \n- the main method in the paper is a combination of existing protocols in MPC and differentially private statistics release, and thus the paper lacks methodological novelty. but this perhaps isn't a super serious issue, given that authors demonstrated their point and showed good performance. \n- the paper only considers a single dataset / benchmark on which results are reported. this makes understanding the robustness of the method and results a bit difficult. \n- the method is likely so far most practical for small (to perhaps moderate) size problems, given the large compute overhead. ",
            "clarity,_quality,_novelty_and_reproducibility": "quality: the paper has good technical and empirical quality. \nclarity: the paper is well-written. \noriginality: the paper lacks a bit of methodological novelty, but the fact that it got the different components together working well together is new. \nreproducibility: the results are likely reproducible, given the authors attach a link to their code.",
            "summary_of_the_review": "the paper studies a method which combines MPC with DP that bypasses utility challenges of federated learning with local DP (with small datasets). authors show that the method achieves good performance by reporting their submission entry being 1st place for an iDASH 2021 challenge, at the cost of substantially more compute time. the paper is well-written, is of high quality, but lacks a little in methodological novelty. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5095/Reviewer_vZqr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5095/Reviewer_vZqr"
        ]
    },
    {
        "id": "SNSZFjIzJe",
        "original": null,
        "number": 3,
        "cdate": 1666603210217,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666603210217,
        "tmdate": 1666603242532,
        "tddate": null,
        "forum": "lLu1Xel2qfh",
        "replyto": "lLu1Xel2qfh",
        "invitation": "ICLR.cc/2023/Conference/Paper5095/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper investigates the problem of training a logistic regression (LR) model with differential privacy over distributed data. In order to improve over local DP approaches, it relies on multiparty computation to train a pooled-equivalent model on secret shares, adding differential privacy on the final model thanks to the output perturbation method of Chaudhuri et al. Experiments are performed on several datasets and demonstrate the improved performance, at the expense of a large communication cost (which can be mitigated depending on the protocol used and the threat model)\n\nTo sum up, the main contributions of the paper are:\n1) Proposing an MPC protocol to run the output perturbation of Chaudhuri et al. for logistic regression, working for both horizontal and vertical FL\n2) Extending MP-SPDZ for logistic regression training with L2 regularization\n3) Empirical study of the benefits of the proposed approach in terms of performance (for a given privacy budget) and communication, mainly on the iDASH 2021 track III competition dataset but also on TCGA and GSE2034 in the supplementary",
            "strength_and_weaknesses": "# Strengths\n\n1. The paper is very well written, which was not a given given the very technical nature of the topics tackled (MPC *and* DP). I really thank the authors for their writing efforts\n2. The idea proposed is general enough to be applied to any model amenable to the output perturbation method of Chaudhuri et al., which includes e.g. SVMs\n3. The method seems to reach the best performance on the current benchmark\n4. The method should yield results equivalent to centralized training (up to discretization issues), which is great for healthcare applications where there is high heterogeneity and little data per center\n\n# Weaknesses\n\n5. The paper is still limited to the output perturbation method, and only covers the logistic regression\n  - In particular, I think the abstract is misleading and should reflect more the focus on logistic regression\n6. The structure of the paper is unbalanced between the main paper and the supplementary material. The supplementary material addresses many points that are lacking in the main paper, including extension to other datasets, more interesting baselines, issues with finite precision. Several appendices are not even referred to in the main paper.\n7. The choice of baselines (even after the extension in the appendix) is not entirely fair:\n  - DP-SGD is performed with a batch size of 1, which is a worst-case approach.\n  - Further, DP-SGD is only used with local trainings followed by ensembling. The authors do not consider a FedAvg + DP-SGD approach which would be natural in this setting. Such an approach was already used e.g. in the iDASH 2020 competition (Beguier et al. Differentially Private Federated Learning for Cancer Prediction)\n  - For the method of Jayaraman et al. 2018 in table 6, the variant with output perturbation is used, although this paper shows that the gradient perturbation yields better results\n8. Regarding the experimental setup :\n  - It would be better to add error bars (where applicable) to understand the significance of the results. In particular, this could be possible for the cross-validation results of Table 2 and Table 6\n9. For vertical FL, one of the main challenges is to align record across parties. Which method do the authors use to tackle this question?\n\n\nMinor comments:\n- How do you explain the fact that in Table 7, central learning yields a better performance than the proposed MPC method? Is it due to finite precision?\n- how much does the initial secret sharing transfer (encrypted data points) weigh with respect to the total communication cost?\n- For L2 data normalization, for horizontal FL, it is probably simpler to apply it prior to creating shared secrets. When computing the total runtime, is it contained in it?",
            "clarity,_quality,_novelty_and_reproducibility": "# Clarity\n\nThe paper is very well written and clear.\n\n# Quality\n\nI think the paper and its appendices contain material for a good paper, up to some restructuring and maybe adding a few more baselines (cf above)\n\n# Novelty\n\nThe contributions of the paper, although limited in scope, are novel to the best of my knowledge\n\n# Reproducibility\n\nCode is provided by the authors. I have not checked it exactly to understand how easy it would be to reproduce it.",
            "summary_of_the_review": "This paper proposes a novel protocol for logistic regression with differential privacy in a distributed setting, which seems to reach good results. Although I think the paper would benefit from a restructuring and adding some baselines, I am bending in favor of acceptance, hence the current score.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5095/Reviewer_DC85"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5095/Reviewer_DC85"
        ]
    },
    {
        "id": "7LE6ImAvRk",
        "original": null,
        "number": 4,
        "cdate": 1666729666310,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666729666310,
        "tmdate": 1666729666310,
        "tddate": null,
        "forum": "lLu1Xel2qfh",
        "replyto": "lLu1Xel2qfh",
        "invitation": "ICLR.cc/2023/Conference/Paper5095/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper considers the problem of secure and privacy-preserving distributed ML training (specifically logistic regression model). It does so by combining MPC and DP. The approach by normalizing the data and then adding the noise to the parameters proportional to sensitivity of how this data would change the parameters. The protocol is completely distributed and does not require a trusted party.\nThe paper seems to describe the method that was used in iDash competition last year.",
            "strength_and_weaknesses": "Strengths:\n- a really well-written paper, extremely easy to follow\n- the problem of cross-silo learning is addressed completely by considering security, privacy and integrity\n- related work is very well-explained (recommendations on expanding are below)\n\nWeaknesses:\n- the novelty of the work compared to existing MPC+DP approaches is not clear\n- DP guarantees need further investigation (e.g., why delta is missing and why not use Gaussian discrete noise)\n- the method seem to work only on LR models\n- baselines method (no DP and no MPC is missing)\n- comparison with other MPC+DP approaches is missing\n- how parties combine their data in vertical setting is not explained",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The authors explain the method extremely well.\nQuality:\n- DP mechanism needs to be explained more thoroughly. For example: (1) why not use discrete Gaussian [1] (2) Does your method provide DP guarantees even if it is using Box-Muller on not real values that have been shown to be vulnerable to floating point attacks (3) does the method provide epsilon or epsilon, delta guarantees.\n- how do parties match their features when data is vertically split? would not they need to run an MPC protocol for that as well?\n- what is the baseline of an approach without DP and MPC and use of fixed point arithmetic? Please also consider reporting communication overhead.\nNovelty:\nThere is a bit of work in this space and it seems that this paper combines existing techniques. Is it the performance that is the main contribution? If so how does it compare with other works (SecureML, [2]) or with trusted-execution based works?\n\nRelated work:\n[1] The Discrete Gaussian for Differential Privacy by Canonne et al.\n[2] CaPC Learning: Confidential and Private Collaborative Learning by Choquette-Choo et al.\nSecureML by Mohassel and Zhang.\n",
            "summary_of_the_review": "This is a really nicely written paper. However contributions seem minor theoretically. Many details that need to be in main body (e.g., other datasets, generalisability, communication overhead appear in appendix) and it is hard to determine what is the generalizability of the methods.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5095/Reviewer_QAdF"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5095/Reviewer_QAdF"
        ]
    }
]