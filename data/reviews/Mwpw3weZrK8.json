[
    {
        "id": "Lil-9ugZcD",
        "original": null,
        "number": 1,
        "cdate": 1666491862637,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666491862637,
        "tmdate": 1668570591836,
        "tddate": null,
        "forum": "Mwpw3weZrK8",
        "replyto": "Mwpw3weZrK8",
        "invitation": "ICLR.cc/2023/Conference/Paper540/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper provides a comprehensive study on the Byzantine robustness of federated learning under the non-IID setting. The authors show that existing robust aggregation rules fail to defend against Byzantine attacks under the non-IID setting, and explain the root reasons by proposing two novel concepts: identification failure and integrity failure. Then, the authors propose a novel gradient decomposition scheme (GAIN) that can address both failures. Under standard assumptions, the authors derive that GAIN can mitigate the deviation of aggregated gradient, thus improving the performance. Experiments show the benefits of the proposed GAIN.",
            "strength_and_weaknesses": "Strength\n\n1. This paper tries to tackle Byzantine attacks in FL under non-IID setting. The topic is interesting and useful since data distribution is mostly non-IID in the real world. \n2. The authors point out the root reasons from a new lens, in order to explain why the existing aggregation rules fail under the non-IID setting. Then they propose a novel gradient decomposition scheme (GAIN) to mitigate the gradient deviation and improve the performance. The method is novel and easy to follow. \n3. Empirical results are sound. Extensive experiments under three different types of attacks can well support the effectiveness of GAIN.\n\nWeaknesses\n\n1. There are various types of non-IID. Does the proposed method apply to all these types of non-IID settings? More discussion is expected.\n2. In the proof for Proposition 1: the illustration for inequality (32) is confusing, more explanation is expected; the illustration for inequality (33) is missing.\n3. What is $\\delta_b$ in equation (51)?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Code is provided to reproduce all experiments. The idea of gradient decomposition is novel. The writing is clear and easy to follow.",
            "summary_of_the_review": "While there are some weaknesses, I think this work is above the threshold given the novelty and sound results in tackling the challenge of Byzantine robustness under the non-IID setting.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper540/Reviewer_TG9e"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper540/Reviewer_TG9e"
        ]
    },
    {
        "id": "9wM-18BU-8m",
        "original": null,
        "number": 3,
        "cdate": 1666494748234,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666494748234,
        "tmdate": 1666494748234,
        "tddate": null,
        "forum": "Mwpw3weZrK8",
        "replyto": "Mwpw3weZrK8",
        "invitation": "ICLR.cc/2023/Conference/Paper540/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on byzantine robustness of FL. Typically, the server uses robust aggregation rules to ensure that byzantine clients do not hinder learning. However, the performance of most aggregation rules is degraded when data is non-IID across different clients. The authors reveal the root causes of the performance degradation -- identification failure and integrity failure. Then they propose a novel gradient decomposition scheme that can address the above failures and adapt existing aggregation rules to non-IID data. Theoretical analysis and numerical experiments validate the efficacy of the proposed method.",
            "strength_and_weaknesses": "Strength:\n\n\u2022\tThe investigated problem, byzantine-robust FL over non-IID data, is important. The failure mechanism of existing aggregation rules over non-IID data is well investigated.\n\n\u2022\tThe proposed method is novel and can adequately address the failures of existing aggregation rules over non-IID data.\n\n\u2022\tThe authors theoretically justify the efficacy of the proposed gradient decomposition technique.\n\nWeaknesses:\n\n\u2022\tSeems that Eq. (8) should belong to the identification phase?\n\n\u2022\tPlease explain why computing identification score is put in the aggregation phase. It would be better to reorganize Sec. 5.\n\n\u2022\tThe paper mentioned \"We consider six representative attacks covering the three attack types described in Sec. 3\". It would be clearer to explicitly define three attack types in Sec. 3. \n\n\u2022\tIt would be better if the authors can test on 1-2 additional larger datasets, e.g., cifar100. This could make the results more convincing.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is novel and technically sound with adequate reproducibility. The structure of the paper can be further polished.",
            "summary_of_the_review": "This paper provides an interesting insight on byzantine-robust FL over non-IID data. The proposed gradient decomposition method is well motivated. The authors also theoretically analyze the efficacy of the proposed method. Further experiments on larger datasets are expected. In general, this paper has publication merits, but some issues need to be addressed.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper540/Reviewer_Fwja"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper540/Reviewer_Fwja"
        ]
    },
    {
        "id": "7UFlmGidWJF",
        "original": null,
        "number": 4,
        "cdate": 1666524522303,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666524522303,
        "tmdate": 1666524522303,
        "tddate": null,
        "forum": "Mwpw3weZrK8",
        "replyto": "Mwpw3weZrK8",
        "invitation": "ICLR.cc/2023/Conference/Paper540/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "In this paper, the authors try to solve the identification failure and integrity failure in federated learning for non-iid setting. In order to address\nboth failures, they propose GAIN, a gradient decomposition scheme that can help adapt existing robust algorithms to heterogeneous datasets. In theory, they show that integrating exisiting robust AGRs into GAIN can mitigate the deviation of aggregated gradient, thus improve the performance. Experiments on various real-world datasets verify the efficacy of proposed GAIN.",
            "strength_and_weaknesses": "Weaknesses: \n1. The writing is not clear, where partition of set {1,...,d}, which may be very critical?\n\n2. The word \"decomposition\" may not fit.\n\n3. The method is very simple. They stack other's method except set partition?\n\n ",
            "clarity,_quality,_novelty_and_reproducibility": "Maybe it is not novel.",
            "summary_of_the_review": "Maybe it is not suitable for this top conference",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper540/Reviewer_Bimn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper540/Reviewer_Bimn"
        ]
    },
    {
        "id": "J766FCwVfr",
        "original": null,
        "number": 5,
        "cdate": 1666668322808,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666668322808,
        "tmdate": 1666668322808,
        "tddate": null,
        "forum": "Mwpw3weZrK8",
        "replyto": "Mwpw3weZrK8",
        "invitation": "ICLR.cc/2023/Conference/Paper540/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors discuss Byzantine robustness in federated learning when the data is non-iid. In the non-iid setting, the gradient decomposition scheme (GAIN) is used to address the identification and integrity failures of existing defences. GAIN can be combined with a variety of robust aggregation rules to help them adapt to heterogeneous datasets. The authors theoretically demonstrate that GAIN can reduce aggregated gradient deviation, thereby improving performance. The authors provide sufficient experimental results to support GAIN's superiority.",
            "strength_and_weaknesses": "Strength:\n\n1) This paper begins a pilot study on the root causes of current robust AGR performance degradation in non-IID settings by proposing two new concepts: integrity failure and identification failure. To the best of my knowledge, this is a groundbreaking study.\n2) Following that, the authors propose a novel gradient decomposition scheme (GAIN) to reduce gradient deviation and improve performance. The method is novel and observationally supported.\n3) The entire paper is simple to understand. The authors thoroughly review all related work and summarise its benefits and drawbacks.\n4) The gradient decomposition technique proposed here is simple but effective, and it works well with existing methods.\n\n\nWeaknesses:\n\n1) Which of the six defences discussed in Section 7 is conservative and which is radical? GAIN appears to be more appropriate for conservative methods. This phenomenon can be explained further in more detail.\n2) According to the paper, the proposed method can reduce the deviation of the aggregated gradient. It is better to provide experiments to prove this.",
            "clarity,_quality,_novelty_and_reproducibility": "The quality, clarity and originality of the work are good.\n\nClarity: The majority of the paper is written clearly; however, some parts require more elaboration; see the weakness section.\nQuality: Exploiting the root causes of current robust AGR performance degradation in non-IID settings is an intriguing and important problem. This paper did an excellent job of summarising and explaining why current robust AGRs fail. The proposed gradient decomposition scheme works well, and the paper as a whole is excellent.\nNovelty: To my knowledge, the proposed gradient decomposition scheme (GAIN) is novel.\nReplicability: The provided code is clear and simple to replicate.\n",
            "summary_of_the_review": "This paper begins a pilot investigation into the root causes of current robust AGR performance degradation in non-IID settings by proposing two new concepts: integrity failure and identification failure. The authors then propose a novel way to defend against Byzantines in FL. Sufficient theoretical analysis and extensive experiments can well support their proposed method's superiority. I believe that this paper will have an impact on the community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper540/Reviewer_bm6A"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper540/Reviewer_bm6A"
        ]
    }
]