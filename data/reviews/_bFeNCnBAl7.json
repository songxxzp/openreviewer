[
    {
        "id": "F7WWRZj-s",
        "original": null,
        "number": 1,
        "cdate": 1666630504060,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666630504060,
        "tmdate": 1666630504060,
        "tddate": null,
        "forum": "_bFeNCnBAl7",
        "replyto": "_bFeNCnBAl7",
        "invitation": "ICLR.cc/2023/Conference/Paper3843/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work carries out an empirical study of the role of data manifold curvature in neural networks. The measure of curvature used is the principle curvature per sample, an algorithm for which is given by prior work. This measure is evaluated layer-wise throughout a network for several common CNNs architectures. It is observed that data evaluated with trained networks has a characteristic pattern: curvature increases, plateaus, then increases again. Furthermore it is found the gap between initial and final curvatures predicts generalization. Empirical evaluations of weight decay, regularization, and mixup training are also made.\n",
            "strength_and_weaknesses": "[+] Convincing empirical support for the characteristic trend of layer-wise curvature (Figure 1).\n\n[+] Good evidence and discussion of the relationship between ID and curvature (Section 4.3), clarifying a potential misunderstanding in the literature.\n\n[+] Reasonable choice of \"relatively\" efficient curvature measure (CAML, Li 2018)\n\n[-] More discussion of how this work's results are consistent with prior theoretical studies (Cohen et al. 2020) is desired.\n\n[-] Very limited conclusion given (single sentence). Please include a concluding section in the next revision.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "This work is clear and carefully written. The results appear to me novel and of good-quality. I did not find any code submitted to check the reproducibility of the work. I noted the author's comment of releasing the code upon publication and encourage them to do so.\n",
            "summary_of_the_review": "Overall this work offers a thorough empirical investigation of the role of curvature in deep networks, similar in spirit to Ansuini et al (2019). This work offers a number of interesting insights and helps clarify some issues in the literature. Overall I recommend acceptance.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3843/Reviewer_iQQx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3843/Reviewer_iQQx"
        ]
    },
    {
        "id": "7agfSW1gyDF",
        "original": null,
        "number": 2,
        "cdate": 1666674734001,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666674734001,
        "tmdate": 1666900967280,
        "tddate": null,
        "forum": "_bFeNCnBAl7",
        "replyto": "_bFeNCnBAl7",
        "invitation": "ICLR.cc/2023/Conference/Paper3843/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors study the curvature profile of latent representations through the layers of deep convolutional neural networks, similar to prior works on the intrinsic dimensions pioneered by Ansuini et al. (2019). The authors propose a plausible approach to densely sample the neighborhood around each input image, as needed for the numerical computation of second derivatives.",
            "strength_and_weaknesses": "- Strengths\n  - Well-formulated and presented study of the curvature profile of intermediate latent representations\n  - Empirical characterization of a common curvature profile for trained CNNs, with comparisons against untrained networks and using different regularizations\n- Weaknesses\n  - The work stays at a descriptive level. I appreciate the authors including the additional study in Appendix D, though more work is definitely needed.\n    - The impact of the loss functions is not sufficiently studied. Perhaps the authors could consider a larger family of loss functions and regularizers, or include additional measures such as the ID, to help distinguish the behavior of different training strategies.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and quality of the presentation are very good. So is reproducibility as the authors promise to release their codes.\n\n- Section 3\n  - Please include an explicit explanation as to how the work of Yu et al. (2018) relates to this discussion on density.\n  - The intrinsic dimension can vary from one point to another in stratified manifolds; see, e.g., [Whitney conditions](https://en.wikipedia.org/wiki/Whitney_conditions).\n  - I strongly recommend you tune down the claim in \"yields a well-defined local patch of the manifold.\" The sampling approach is plausible, but it's unclear how it relates to the actual manifold.\n  - Please define the \"natural orthonormal coordinate frame\"\n\n- Section 4\n  - $4.1: Please include an explicit explanation of how the theoretical studies of (Cohen et al., 2020), and empirical explorations on neural networks with random weights (Poole et al., 2016) are consistent with your empirical observations.\n  - $4.6: the histograms confirm the increase in MAPC of the last layer, but does it explain it?\n\n- Questions\n  - What happens if you train using the augmented dataset, with a densely sampled neighborhood around each image? Could the initial increase in curvature be related to data density?\n  - If I'm not mistaken, the paper only studies supervised learning. What would be the case for unsupervised learning?",
            "summary_of_the_review": "The paper presents initiates the study of curvature profiles of latent representations through the layers of deep CNNs. Main findings uncover a common pattern of the curvature profiles for trained vs. untrained networks, that seems to persist using different regularizers. The paper is well-written which would help continue the research, especially with the release of the code.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3843/Reviewer_KXuv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3843/Reviewer_KXuv"
        ]
    },
    {
        "id": "Z2Tb0Zm5FzE",
        "original": null,
        "number": 3,
        "cdate": 1666675805728,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666675805728,
        "tmdate": 1666675805728,
        "tddate": null,
        "forum": "_bFeNCnBAl7",
        "replyto": "_bFeNCnBAl7",
        "invitation": "ICLR.cc/2023/Conference/Paper3843/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper is about understanding the functionality of layers in a deep neural network by examining the curvature of the low-dimensional manifold associated with the feature maps at different layers. To evaluate the curvature, one has to have sufficiently dense samples on the manifold and this is achieved by adding small perturbations to the natural images. The paper makes the following observations. 1) curvature along layers increases drastically from the first to the second layers, and from the second last to the last layer, while stays stable for all other layers, 2) curvature gap on final layer predicts generalization performance, 3) curvature and intrinsic dimension don't necessarily correlates, 4) the effect of regularization on curvature profile. ",
            "strength_and_weaknesses": "# Strength\n\nManifold modeling provides an interesting perspective towards deciphering the role of multiple layers in a deep neural network. Previous work of Ansuini et al. NeurIPS'19 provides such an analysis using the intrinsic dimension of the manifold. This submission provides a similar study to that of Ansuini but with the manifold curvature instead of dimension. Hence, the result provides a more comprehensive understanding of the role of layers from a low-dimensional modeling perspective.\n\nThe paper is generally well-written though I find it hard to understand the technical part of it (on estimating curvature).\n\n# Weakness\n\n**Validity of the method for obtaining data density.** Part of the difficulty in evaluating curvature compared to dimension is that the former may require a much denser sampling of the manifold (intuitively). The paper addresses this challenge by a special kind of data augmentation described in Sec. 3, where (roughly) each image is performed a PCA and selected trailing components are dropped. \n\nI am not sure if this is a valid way of increasing data density and some more explanation or study seems needed. Specifically, for manifold of natural images, curvature may be caused by many things such as translation, rotation, illumination, etc, but by the proposed method for data augmentation, only curvature caused by this specific way of augmentation is studied. In fact, the effect of such a data augmentation is a bit unclear in terms of what it does to the data manifold. It may be interpreted as adding some small noise to some selected directions in the ambient image space, but it appears that this will actually generate images that are outside of the image manifold, hence it is unclear what curvature means for them.\n\nQuestion: What if one simply calculates curvature using only the original images without using any other augmentation for increasing density? \n\n**Clarity.** I find the explanation on *Curvature estimation* in Section 3 to be quite confusing, that I was not able to follow it. E.g.,\n\n- the embedding map f: what is it? it is used in eq. (1) but seems not explained at all.\n- x_i: this is used in both eq. (1) and 7 lines below eq. (1). Are they the same?\n- K: is this taken to be 1024?\n- partial / partial x^1 (6 lines below Eq. (1)): Is this the partial gradient? of what? also what is x^1?\n\n**So, deep network is not flattening the manifold?** One of the main conclusions is that the curvature increases from the first to the last layer of a deep neural network. This appears to be very surprising and what one may have expected is that the deep network flattens the manifold gradually so that the curvature should be a decreasing function. Do I miss anything here or is there an explanation for this?\n\n**Negative curvature.** I am not entirely understanding results in Fig. 5 in that the curvature here can be negative while in all previous plots, curvature is always positive. How should I understand why negative curvature may appear here?\n\n# Other comments / suggestions / questions\n\n**Toy data.** It may be interesting to perform the analysis using some toy dataset with nonlinear manifold distribution. Then, one may examine how e.g. an MLP flattens the manifold and whether the observation aligns with what is observed with natural images.\n\n**untrained network exhibit a different curvature profile**: here the experiment is only conducted on VGG. I am wondering what would happen for ResNets? In particular, because ResNet has a shortcut, if the residual branch is initailized to be small enough, then all layers should have very similar features hence curvature. Is this what is observed in practice?\n\n**Some missing references.**\n\n- Manifold-aware learning: Work on designing objectives and architectures for learning low-dimensional structures, e.g.\n\nChan, Kwan Ho Ryan, et al. \"Redunet: A white-box deep network from the principle of maximizing rate reduction.\" J Mach Learn Res 23.114 (2022): 1-103.\n\n- Manifold-aware analysis: \n\nBuchanan, Sam, Dar Gilboa, and John Wright. \"Deep networks and the multiple manifold problem.\" arXiv preprint arXiv:2008.11245 (2020).\n\n**Small issues**\n\n- Sec. 4.1: MAPC is coming out of nowhere as it is never explained before.\n- Sec. 4.1, \"we observe that MAPC is ...\": not clear what I should be looking at.\n- Sec. 4.1, \"during the transition between first and second layers\": does this mean from the output of the first layer to the output of the second layer? \n\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Overall it is quite good but I find the part on curvature estimation (in Sec. 3) to be quite confusing.\n\nQuality: I am not entirely convinced that the paper is measuring the right curvature. Also the conclusion that curvature increases from input to output seems counter-intuitive.\n\nNovelty: An analysis of curvature profile in deep networks is novel to the best of my knowledge.",
            "summary_of_the_review": "The paper provides an interesting study of deep neural networks from the perspective of manifold curvature, but I am not entirely convinced that their method is measuring the right curvature by their data sampling via PCA. I also find one of the main conclusions to be counter-intuitive and there is a lack of discussion. Finally, there is a clarity issue with the discussion of curvature estimation.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3843/Reviewer_8GhN"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3843/Reviewer_8GhN"
        ]
    },
    {
        "id": "YEAOj3xGMwd",
        "original": null,
        "number": 4,
        "cdate": 1667549386072,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667549386072,
        "tmdate": 1667549386072,
        "tddate": null,
        "forum": "_bFeNCnBAl7",
        "replyto": "_bFeNCnBAl7",
        "invitation": "ICLR.cc/2023/Conference/Paper3843/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper studies how the curvature of the data manifold changes across different layers of the trained networks. It proposes the mean absolute principle curvature (MAPC) that characterizes the averaged curvature of the data representations, and shows that there is a three-stage behavior of the MAPC along layers: an initial increase, a long phase of a plateau, and another final increase. This observation is consistent among different network and training setups and is not observed for untrained networks. The authors further show that the curvature gap between the last two layers is correlated with the performance of the network, and can be used to predict the generalization ability of the networks. ",
            "strength_and_weaknesses": "Strength\n\n1. The question this paper study is an interesting and important one. The geometric properties of the data will affect the trainability of the network. Studying how these geometric properties change across layers can help us understand what types of features are learned or preferred. Previous literature focuses more on the intrinsic dimensionality of the data manifold, and this paper investigates how the curvature behaves for convolution neural networks, which definitely worth studying. \n\n2. The paper proposes a single measure MAPC that captures the overall curvature of the data manifold, and provides empirical observations of a three-stage change of the MAPC across layers: an initial increase, followed by a stable phase in the middle, and another final increase. The observation is stable across different network and training setups and datasets so are quite convincing. The authors also relate the normalized MAPC gap to the model accuracy which can have further implications. \n\n\nWeakness: \n\nAlthough the paper provides many nice experiments and observations, the authors do not put them into a coherent picture and provide further justification for the observed phenomena, making it hard to grasp the contribution of the paper and how one should build understanding upon all the figures. \n\n1. Missing justification of the MAPC. As the authors have pointed out, there is a difference between the curvature of the decision boundary and the curvature of the data manifold. MAPC is a metric of the latter and the authors failed to provide a justification over why the curvature of the whole manifold is preferred and why MAPC is a good measurement for it. The authors do discuss the choice of curvature metrics in appendix A, saying all metrics exhibit similar behaviors and claim using MAPC \"due to the lack of a canonical metric\". and MAPC is a metric for the latter. This arbitrary choice of curvature measures fails to convince readers why MAPC is able to capture key geometric information of the data. \n\n2. The main message of the paper is unclear. There are many experimental observations but the authors fail to put them into a complete picture. Two important findings in the paper are that there is a three-stage change of the curvature along layers and that the normalized MAPC gap is correlated with the model accuracy. However, the authors use most space describing the figures without providing enough explanations of where the phenomena come from. The three-stage phenomenon is actually counterintuitive. It is more natural to consider the network \"flattening\" features through layers instead of making them curvier. One explanation that one can come up with is that the network flattens data along decision boundaries, and compress data elsewhere, resulting in the increase of MAPC due to the compression and averaging effect. The arguments in the paper would be much stronger if the observations can be supported by detailed reasoning and further empirical justifications. \n\n3. The missing explanation also makes it hard to utilize the findings in the paper. For example, the authors argue that the normalized MAPC gap is correlated with model accuracy, but does that mean we would like to learn networks that explicitly encourage a large curvature gap between the last two layers? This unclarity of future direction also compromises the importance of the findings. \n\nOther than the contribution of the paper, I also have questions about the computation of MAPC\n\n4. The data lies in a high-dimension space, making the estimation of the data manifold hard. In the paper, the authors propose a data augmentation method to get enough local data by blurring (removing information in some of the small singular value spaces). This process is done for each image separately and thus it may not preserve the manifold information. The curvature information based on this data augmentation regime is more likely to capture how robust the network is towards the small singular value spaces. \n\n5. To compute the curvature or MAPC, one needs to fix a dimensionality. In the paper, the dimensionality is computed through the TwoNN algorithm for each layer. On the other hand, one can imagine that the curvature information is highly correlated with dimensionality. By allowing a larger dimensionality, one can fit the data with a much smaller curvature. The discussion about this relationship between dimensionality and curvature is missing in the paper. \nIn the discussion session, the authors mention that \"as computation proceeds, samples concentrate near their same-class samples in highly-curved peaks, facilitating separation between clusters\". Will this indicates that even though the data is highly curved, as it is concentrated, if one views it in a higher dimensional space, the curvature can actually be small? \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. The authors have made the experimental approach explicit and easy to understand. The authors explain all the figures in good detail. On the other hand, the writing focuses too much on what is plotted in the figures and misses the connection between the experiments and how they contribute to the larger picture. As a result, it reads more like a few separate experiments without having a coherent message. ",
            "summary_of_the_review": "The paper studies a fairly interesting problem that is worth further efforts to investigate. The authors provide interesting experiments showing a three-stage behavior of the measurements of the MAPC and the relationship between the normalized MAPC gap and the performance of the network. However, the authors fail to provide enough explanation of either the importance of the MAPC or the reasoning for the three-stage behavior. The reviewer considers the paper to be below the quality of acceptance. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3843/Reviewer_revH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3843/Reviewer_revH"
        ]
    }
]