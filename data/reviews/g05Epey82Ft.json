[
    {
        "id": "LC5m2PCa70",
        "original": null,
        "number": 1,
        "cdate": 1666670251020,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670251020,
        "tmdate": 1666670251020,
        "tddate": null,
        "forum": "g05Epey82Ft",
        "replyto": "g05Epey82Ft",
        "invitation": "ICLR.cc/2023/Conference/Paper3179/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper embeds a learnable recurrent network based on Laplacian transformation into a reinforcement learning agent and claims that the Laplacian based recurrent network outperforms the others.",
            "strength_and_weaknesses": "It seems to be novel to use Laplacian transformation to derive a neural representation of evidence or numerosity. I believe this framework may suggest some general principle of neural coding. Nevertheless, I feel some parts of the paper are not well written and can be improved further.\n\n### Major concerns\n\n- Based on the text it is unclear to me that how the authors embed the Laplacian transformation into a recurrent network, even if I read the manuscript several times. Do authors firstly perform a Laplacian transformation on the input, and then feed the transformed inputs to a recurrent net? Or do authors use the Laplacian transformation to propose or constrain the recurrent net structure? \n\n- The connection between Eqs. 3 and 7 implicitly suggests that the firing rate of neurons represents the Laplacian transformation of an input. It is better to have more detailed explanations at here.\n\n### Minor concerns\n\n- If I understood correctly, Eq. 3 is wrong because it is inconsistent with Eq. 2, while Eq. 4 is correct. There must be some typos.\n\n- It is not clear of the meaning of n* in Eq. 5. Is it the preferred evidence of a neuron? Also, is $\\tilde{f}(n*, n)$ the reconstruction of $f(t)$ by only using a Laplacian basis?\n\n- $\\alpha(t_i)$ is not defined and I need to guess. Is it the instantaneous change of numerosity as mentioned right above Eq. 3? Besides, is the modulatory input $(\\alpha=1)$ also the change of numerosity? If so, I don't understand why $\\alpha=1$ represents no modulatory input.\n\n- The definition of $W_L$ right below Eq. 7 is contradictory with each other and quite confusing.\n\n- The math definition in Eq. 8 is no problem but I don't understand why author call the cross-correlation as subtraction between functions.\n\n- The 4th line to the 7th line below Eq. 8 is repetitive.\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The current paper presents a novel idea of using Laplacian transformation to develop/inspire a recurrent network. However, the writing is not very clear (see my comments above) and some typo exists. It is unclear how technically the Laplacian transformation is embedded into the recurrent network. Since this is a small network model and I believe the paper can be reproduced without too much effort.",
            "summary_of_the_review": "I have gone through the math derivations and read the manuscript for several times and I believe I try my best to understand the paper but there are still some places which are not clear.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3179/Reviewer_BAao"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3179/Reviewer_BAao"
        ]
    },
    {
        "id": "5MlTjpmJVD",
        "original": null,
        "number": 2,
        "cdate": 1666746297554,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666746297554,
        "tmdate": 1670554205359,
        "tddate": null,
        "forum": "g05Epey82Ft",
        "replyto": "g05Epey82Ft",
        "invitation": "ICLR.cc/2023/Conference/Paper3179/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper describes a network that combines a Laplace framework into a reinforcement learning architecture achieve superior performance over GRU and RNN in an evidence accumulation task both in terms of reward gain and generalization. Moreover, the activity of units in the proposed architecture resembles map-like neural activity in the brain for accumulated evidence. ",
            "strength_and_weaknesses": "Strength: The paper looks into an interesting and commonly used task in decision making and RL experiments in the field of Neuroscience. \nThe paper is clearly written and different components are very well explained step by step. It also provides a virtual environment, useful for the community to simulate evidence accumulation experiments. \n\nWeakness: This work only covers one specific task from one family of experiments (Evidence accumulation). The paper can be significantly improved if the method is tested on broader range of tasks in the face of uncertainty (e.g. see \"Recurrent Model-Free RL Can Be a Strong Baseline for Many POMDPs\" by Ni et al, ICML 2022), and/or works on hippocampus and cognitive maps (many references  presented in the paper) and/or different evidence accumulation tasks in neuroscience (e.g. see works of Michael Shadlen lab for human and monkey, and Carlos Brody lab for rodent). In terms of architecture, comparison of an architecture with a Bayes filter (e.g. see implementations of \"End-to-end learnable histogram filters\", by Bonschkowski & Brock, NeurIPS deep RL workshop 2016, or \"QMDP-Net: Deep Learning for Planning under Partial Observability\" by Karkus et al, NeurIPS 2017) instead of Laplace framework could be illuminating. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and very easy to follow. I also appreciate its reproducibility particularly because of the provided supplementary material. The modelling/theoretical contribution as well as experiments/results however is limited.  ",
            "summary_of_the_review": "I think because of lack of significant modeling/theory contribution as well lack of test-domains this paper is not ready to be presented in the ICLR venue yet. \n\nUpdate after rebuttal: \nI appreciate the authors' response and adding more experiments. The added experiments, however, are very much in the same domain of previous one and only a threshold has been changed (the accumulation mechanism is the same). In the evidence accumulation task (e.g. in mentioned labs), a sufficiently task has either 1) different number of options (e.g. more than 2) 2) different decision time criterion (reaction time v.s. fixed) or 3) dynamic weigh of evidence through the task. Moreover, even if the proposed approach is new, we do not know whether it is works better than a simple Bayesian update, which is in fact shown to be able to solve evidence accumulation task.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3179/Reviewer_ojuW"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3179/Reviewer_ojuW"
        ]
    },
    {
        "id": "M8oNgLB-t_3",
        "original": null,
        "number": 3,
        "cdate": 1667508604733,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667508604733,
        "tmdate": 1667508604733,
        "tddate": null,
        "forum": "g05Epey82Ft",
        "replyto": "g05Epey82Ft",
        "invitation": "ICLR.cc/2023/Conference/Paper3179/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper presents a novel framework for reinforcement learning, specifically for evidence accumulation tasks that involve counting quantities and deciding which is greater. The general approach is to use cognitive models as inductive biases by learning a function representing the evidence and giving the resulting representations to an RL algorithm. The paper includes a discretized version of the Laplace transform-based framework to use with a neural network.\n\nThe framework is as follows: the Laplace transform is rewritten as a differential equation in terms of the numerosity of the stimulus and discretized; an inverse is also derived. This is meant to enable learning of a counted quantity. To subtract one quantity from another and determine which one is higher, the paper presents a cross-correlation mechanism. \n\nThis framework integrates into an RL algorithm (here A2C) by having environment inputs go into a recurrent layer, have that layer learn a direct representation of the count of the objects and their difference (in theory), and then pass the output of this layer to the actor and critic networks. \n\nExperiments are done on an \"accumulating towers\" task. There are several ablations removing various parts of the Laplace framework, as well as RNN and GRU layers as baselines. Task reward statistics show that the Laplace and inverse Laplace transforms with subtraction do very well, as does GRU. Other ablations have mid-range performance, and RNN does quite poorly. Frozen versions of RNN and GRU are unsurprisingly very poor.\n\nWhen evaluating on harder versions of the task, Laplace with subtraction continues to do well, as does GRU. The paper attributes this to the gating mechanisms present in both methods.\n\nFinally, there is some analysis of neural activity and its connections to human cognitive maps. Results show that Laplace with subtraction appears to activate sequentially as a function of evidence. GRU and other versions of the Laplace framework also shows some tuning to \"magnitude\"/\"amount of evidence\".",
            "strength_and_weaknesses": "**Strengths**\n- Introduction is strong and motivates the paper well. The idea of cognitive models providing inductive biases is not novel but this is a very interesting instantiation of it\n- The connections to human cognitive maps are more convincing than a lot of \"human cognitive construct + our cool new method\" connections that ML papers attempt to make, especially because of follow-up evidence in the paper such as the logarithmic representation. While even this one is ultimately conceptual (and the logarithmic representation appears to be a design choice rather than an emergent property, if I understand correctly), I find it compelling.\n- The paper is well-packaged - it makes several claims and demonstrates them, and the methods solve exactly the problem motivated and outlined. To some degree, the final contribution about gating could use more expansion, but I realize it's more a validation of prior work and I appreciate the acknowledgement of the similarities/power of existing work\n\n**Weaknesses**\n- The Laplace framework presented here seems very tuned to this specific task, or at least counting-based tasks. The paper acknowledges in \"Future Work\" that this is by no means the only type of latent variable and encourages work on others, but as of right now the framework is engineered in terms of counting - or at least, that's the sense I get reading it. It's still an interesting method, but GRUs and RNNs are much more general modules; it would be helpful to have (brief!) discussion of either 1) the domain limitations of these equations or 2) the potential to easily adapt this method to other tasks. I see how this formulation may extend to some other quantities, but I don't know for sure. \n- The discussion I described above would make the comparisons in this paper make more sense, but for actual acceptance I'm not sure that would be enough. This is an interesting idea and novel to my knowledge, but without seeing experiments in other domains, it's not clear how much value it adds. A more general approach covering a larger domain (potentially through multiple frameworks like this one), and experimental results on those, would be more convincing.\n- From a pure utility perspective, it's unclear how much value this method provides over GRU (not to mention, it has a narrower domain if I understand correctly). Because the performances are so similar, some statistics differentiating them would help.\n- The word \"deep\" is used in the title and throughout the paper, but the version of A2C experimented on uses single-layer FCNs for actor and critic. The paper isn't making claims about scale or ability to handle large real-world tasks or complicated environments, so this claim seems not only false but unnecessary to the story.",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\n- Section 2 is quite clear given the math in it; while it did take a couple reads to build intuition for the Laplace framework, it wasn't overly daunting or impossible\n- Results section could use better claims-based signposting, rather than topic-based, or just a general info dump as most of it is now (which is not to say that long section doesn't read well; it does). Three of the four contributions are claims that will be demonstrated, so the results section may benefit from section headings based on those claims. \n\n**Quality**\n- Experiment section is carefully considered. The experiments designed to support each claim in the contributions are intuitive and convincingly designed\n- The paper doesn't leave any loose ends or unanswered questions. It feels like a finished piece of work.\n\n**Originality**\n- The high-level concept of cognitive models as inductive biases (or some such integration) is familiar, but I believe this particular approach for evidence accumulation is novel. I think the contribution list is quite an accurate and complete summary of the parts of this paper that are novel.\n\nNits:\n- \"Amount of evidence\" is strange phrasing here. It seems from the rest of the paper and the place cell example that this means *n* itself, but the phrase sounds like it means, how much evidence we have that the value is *n* as opposed to other values. ",
            "summary_of_the_review": "I am recommending a weak acceptance for this paper. It is a good paper and I enjoyed reading it, but I am not convinced of its significance from a general modeling perspective given the limitations I think I see in its domain. I also am not totally sure I understood all the math, so I may be missing limitations; I may also be missing strengths. \n\nAll that said, the quality of idea and execution is far above a workshop paper and it is a very compelling read, so I wouldn't consider it fair to recommend rejection just because it's an interesting and well-demonstrated idea rather than the next big SOTA system like a lot of papers. I would raise my score if I were convinced that this opens a lot of future work directly (not just in high-level concept) or enables improvement on new tasks out of the box, and if I were convinced that it provides meaningful improvement over existing methods.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3179/Reviewer_tPG3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3179/Reviewer_tPG3"
        ]
    }
]