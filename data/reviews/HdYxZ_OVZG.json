[
    {
        "id": "sJhRiUlMvf",
        "original": null,
        "number": 1,
        "cdate": 1666508850830,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666508850830,
        "tmdate": 1666508850830,
        "tddate": null,
        "forum": "HdYxZ_OVZG",
        "replyto": "HdYxZ_OVZG",
        "invitation": "ICLR.cc/2023/Conference/Paper139/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper describes a 2-stage approach to perform reasoning in large language models (LLMs). The main idea is to decouple the fast thinking process of generating text for a prompt and the slower process of reasoning such as iteratively generating related sequences of text, etc.\n\nThe main motivation is to make LLMs more robust to prompt design by decoupling the step to answer prompts and the step to perform the actual reasoning over a complex task. To perform reasoning, the approach proposes to use probabilistic inference. Specifically, GPT-2 XL is used to generate sets of associations and probabilistic inference sums over these associations.\n\nThe paper seems to propose a simple idea but one that seems to work very well on a complex suite of tasks in Big-bench. In particular, it is shown that the approach achieves state-of-the-art results on 8 of the ten tasks. For each of the taks, three variants of GPT are used for prompting and the type of probabilistic inference performed is more specific to the task.",
            "strength_and_weaknesses": "Strengths\nSimple and intuitive idea but produces excellent results in a challenging domain\nSeems to be more scalable since it can help us achieve state-of-the-art results with simpler models\nThe experiments seems quite detailed and impactful since they show in most of the tasks the proposed approach yields state-of-the-art results\n\nWeaknesses\nOne general issue may be how does the model scale up as the sets produced by the prompts to LLMs become large. In general, probabilistic inference may tend to become less reliable in this case so does that have a major influence on the SUM process.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper uses standard benchmark problems and is quite clear in terms of the description and setup and therefore to me it seems like the results should be reproducible,\nThe novelty may not be as high since it mainly is an integration of methods but the impact of the approach seems significant. The writing is clear, given that they have addressed a large number of different problems with their approach.",
            "summary_of_the_review": "Overall seems like an impactful paper with strong empirical results. They show that with their two-step approach, it is possible to achieve state-of-the-art results with much smaller models and thus should have an impact on scalability in future applications.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper139/Reviewer_2TCH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper139/Reviewer_2TCH"
        ]
    },
    {
        "id": "adNDwEulvnl",
        "original": null,
        "number": 2,
        "cdate": 1666746314023,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666746314023,
        "tmdate": 1666746314023,
        "tddate": null,
        "forum": "HdYxZ_OVZG",
        "replyto": "HdYxZ_OVZG",
        "invitation": "ICLR.cc/2023/Conference/Paper139/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes ThinkSum: a two-stage paradigm for performing inference with large language models (LLMs) with no gradient update. The authors distinguish ThinkSum from chain-of-though like prompting methods by claiming that ThinkSum performs probabilistic inference instead of using LLMs to directly generate answers. The authors demonstrate the ThinkSum approach on some selected datasets from the BIG-bench and show that it outperforms vanilla few-shot learning with GPT-3.",
            "strength_and_weaknesses": "Though the authors present ThinkSum as a general framework for LLM inference in Section 2, the definitions for \"Think\" and \"Sum\" are very vague and do not well relate to the example shown in Figure 1. Then the rest of the paper is devoted to explain how ThinkSum can be used to tackle different tasks selected from BIG-bench in a case-by-case sense: each subsection covers one (class of) task, but it remains somewhat unclear how each example relates to the definition of ThinkSum presented in Section 2 and the connection between the individual tasks is unclear. Many new terminologies (in different colors) are introduced: some are completely unnecessary (e.g. product aggregation) and some do not have any clear explanations. The only baseline that the authors compare against to is the few-shot learning with GPT-3; the authors might want to include other prompt-based approaches as baselines. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is not well-written and hard to follow; even the definition of the ThinkSum paradigm is not clearly presented.\n",
            "summary_of_the_review": "Despite the extensive demonstrations performed in this study, the authors need to present the ThinkSum paradigm in a more organized and clear way: even the core idea of ThinkSum is not clearly explained the examples throughout the paper do not help much explaining ThinkSum paradigm. The experiments demonstrate the effectiveness of the approach in some sense but need comparisons against more baselines. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper139/Reviewer_Xf9p"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper139/Reviewer_Xf9p"
        ]
    },
    {
        "id": "xTt6FYBx4n",
        "original": null,
        "number": 3,
        "cdate": 1666830307817,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666830307817,
        "tmdate": 1666830307817,
        "tddate": null,
        "forum": "HdYxZ_OVZG",
        "replyto": "HdYxZ_OVZG",
        "invitation": "ICLR.cc/2023/Conference/Paper139/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposed a reasoning framework, ThinkSum, which includes a fast think module and a slow sum module. The authors argued that this framework is good at performing many reasoning tasks with simple operations.",
            "strength_and_weaknesses": "The performance of the proposed model is strong in their experiments. However, I am not sure if the improvement can be applied to other tasks. For example, the task in Figure 1 requires evaluating every possible combinations of the choices. This is doable for 5 choices, but not so much for 100 choices or more (in SQuAD-type QA, the output could be any combinations of tokens) which is extremely expensive. Prompting LMs to score all possible candidates is also not accurate if the number of candidates is large, because the union of errors.\n\nThe ThinkSum framework, however, is too general such that almost all existing methods fall into this framework, if you think scoring is the Think step, and argmax is the sum step.\n\nAlso, tasks experimented in this paper are classification tasks. You may consider running some regression tasks as well.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is easy to read. Though, I may have missed some important parts of this paper.",
            "summary_of_the_review": "The scope of the proposed ThinkSum framework for LLMs is not well defined. Please consider narrowing it down to a subset of tasks. The authors may also consider running some more challenging tasks to show the efficacy of the proposed framework.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper139/Reviewer_KxRo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper139/Reviewer_KxRo"
        ]
    },
    {
        "id": "EVzKhXaA-nj",
        "original": null,
        "number": 4,
        "cdate": 1666900955811,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666900955811,
        "tmdate": 1666900955811,
        "tddate": null,
        "forum": "HdYxZ_OVZG",
        "replyto": "HdYxZ_OVZG",
        "invitation": "ICLR.cc/2023/Conference/Paper139/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "1. This paper proposed a two-stage method that reasons over sets of objects or statements.\n2. The paper performs empirical evaluation on the BIG-bench benchmark and shows improvements over fewshot GPT3",
            "strength_and_weaknesses": "Strengths:\n1) Experimental results suggest the proposed method has an improvement over few-shot GPT.\n\nWeaknesses:\n1) The paper should reduce the usage of color in the main text\n2) The paper should reduce the amount of branding and focus on the actual technique.  I don't see how this has much to do with thinking fast and slow\n3) Figure 1 is confusing.  The think step involves manipulating the inputs to get new sequences instead of just generating a set of relevant words?  Then, the second step is the actual summing over the sequences generated in the first step.\n4) There is a lack of technical details.  In particular, it is not exactly clear how the sum step is performed.  If this follows a probabilistic framework, please write down the steps formally.\n5) This paper first contrasts to chain of thought prompting, but it doesn't compare to that in experiments.\n6) Table 1 is confusing.  What's the difference between GPT-3 175B (davinci) and InstructGPT?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity, Quality and Reproducibility need to be improved.\nWithout clear writing, it is hard to evaluate novelty.",
            "summary_of_the_review": "The writing is not clear, making it hard to evaluate the contribution of this paper.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper139/Reviewer_nmJR"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper139/Reviewer_nmJR"
        ]
    }
]