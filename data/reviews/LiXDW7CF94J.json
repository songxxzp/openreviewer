[
    {
        "id": "oyIWxTZxM6Y",
        "original": null,
        "number": 1,
        "cdate": 1666213839606,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666213839606,
        "tmdate": 1669767015813,
        "tddate": null,
        "forum": "LiXDW7CF94J",
        "replyto": "LiXDW7CF94J",
        "invitation": "ICLR.cc/2023/Conference/Paper4423/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Studying the robustness of learned representations in unsupervised learning such as self-supervised learning or auto encoders as opposed to the traditional supervised learning settings when there exists distribution shifts in data.\n\n",
            "strength_and_weaknesses": "# Pros:\n\n- The paper is well-written, easy to understand and follow along.\n\n- The explorations to identify the significance of representations with unsupervised learning in a distribution shift are interesting.\n\n- Literature is covered adequately.\n\n# Cons:\n\n\n- Significance of the following contributions highlighted is questionable:\n  - Systematically evaluate SSL and AE on distribution shift tasks.\n  - The proposed solution in the paper is what everyone uses and is a standard practice, how is it different from what already exists or known to the community\n  - Controllable-Shift (CS) datasets, are they used only during evaluation or they used in training also?\n  - OOD linear head. Again, fine-tuning the pre-trained model on a small set of left out data is also a known practice then what is your contribution here to highlight this as a stand out contribution?\n\n- Figure 2 is referenced first and Figure 2 later, better move Figure 1 to the end of page 3 or page 4.\n\n- Figure 1 also warrants focussed attention of the reader to understand forcing the reader to spend a few extra minutes. Not an ideal presentation style.\n\n- The subsampling used to prepare the CS datasets is not entirely clear. How can you guarantee that the samples picked result in spurious correlations? Are the real world sets by default contains spurious correlations in the entire dataset so that you can pick any subsample of images randomly to mimic this behavior? A small algorithm on CS dataset prep in appendix also could be of value.\n\n- How did you train CNN back bone? No details on hyper params used, network architecture, number of epochs. As per the loss functions used, those eight SL, AE and SSL have the standard ones so that is fine. Also, how long did you fine-tune the pre-trained backbone (f) on the held-out OOD data?\n\n- Another question, why a simple CNN why not the state-of-the-art SSL methods such as contrastive learning or the more recent CNNs architectures such as ResNets, etc.? Will the results hold true with more advanced networks? This question remains more true given the performance of the unsupervised methods on real world datasets, the results in 3.2.1\n\n\n ### Minor comments: \n - \u201cThis is becaues, \u2026\u201d should be \u201cThis is because,...\u201d\n - \u201cunder distribution shif, \u2026\u201d should be \u201cunder distribution shift, \u2026\u201d\n\n  - Too many forward references, this is not a thesis introduction chapter, but a research paper, please minimize the number of forward references.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and Quality: The presented approach or the presentation can be further improved but is reasonable as it is.\n\nNovelty: The novelty side of this paper is weak as most of the work is existing in the literature rather it is astudy on the effectiveness of the existing approach(s) \n\nReproducibility: The results can be reproduced.",
            "summary_of_the_review": "Please refer to the strengths and weaknesses. IMO, the weaknesses out-weight the strengths in this paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4423/Reviewer_ekJ8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4423/Reviewer_ekJ8"
        ]
    },
    {
        "id": "NRfKSzIPvJq",
        "original": null,
        "number": 2,
        "cdate": 1666681349361,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666681349361,
        "tmdate": 1666685069326,
        "tddate": null,
        "forum": "LiXDW7CF94J",
        "replyto": "LiXDW7CF94J",
        "invitation": "ICLR.cc/2023/Conference/Paper4423/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper benchmarks self-supervised learning (SSL) techniques and auto-encoder (AE) techniques under synthetic and realistic distribution shifts. The main conclusion is that the SSL and AE methods are less sensitive to distribution shifts. Also, the linear classification head is the main source of the spurious bias. Finally, the paper also develops ways to create different levels of shifts in real-world shifts datasets.",
            "strength_and_weaknesses": "Strength:\n\nThe empirical contribution should be appreciated by the community, as it is something people have been discussing for a long time. It is good to see a concrete evaluation paper.\n\nThis paper is very clearly written. \n\nWeakness:\n\nThe fact that this paper only discusses image data may limit its impact. To be honest, I think the conclusion is sort of known to the community already. Pretraining in the source domain and fine-tuning the linear layers in the target domain has been shown to be an effective transfer learning method. So I feel what is more interesting in the direction is the large language models or vision-transformers. \n\nOn the other hand, I think the elephant in the room is still unknown: To what extent can we really rely on the pretrained representations to do the transfer and adaptation? What is the limit?\n\nThe way we set up the problem may also have some impact on the results. For example, the way we \"control\" the shift in the images may not be generalizable to real-world shifts in, for example, fairness problems/subpopulation shifts, where we cannot easily create shifts in a meaningful way. So, I also suggest adding discussions on the limitations of the work. \n\nIn table 4, why the SL accuracy is much higher?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. The analysis is relatively sound. I do not find a code repository but appendix includes enough details for reproducibility.\n\nAs mentioned, I think the contribution is mainly about conducting rigorous benchmarking research in this domain, which is valuable. The conclusion, though, is relatively known to the community.",
            "summary_of_the_review": "It will be nice if the scale of the research is a bit larger than the current one. By scale, I mean the coverage of different SSL methods and AE methods, the scale of the dataset, and the architecture. Because what is still unknown to the community is the limit of scaling up in using SSL or AE in domain adaptation/generalization/distribution shifts. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4423/Reviewer_JB4R"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4423/Reviewer_JB4R"
        ]
    },
    {
        "id": "6S3h8zQuP7",
        "original": null,
        "number": 3,
        "cdate": 1666830911484,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666830911484,
        "tmdate": 1666830911484,
        "tddate": null,
        "forum": "LiXDW7CF94J",
        "replyto": "LiXDW7CF94J",
        "invitation": "ICLR.cc/2023/Conference/Paper4423/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The submission provides an extensive empirical study on supervised (SL), unsupervised (autoencoder, AE), and self-supervised (SSL) representation learning algorithms in a distribution shift scenario. The key contribution is comparing these algorithms when the representation is learned on the source task while the classifier is learned on the target task. The findings are that (1) SL is more sensitive to distribution shift than SSL and AE, and (2) there is a remarkable difference between the performance of classifier heads trained on source and target distributions.",
            "strength_and_weaknesses": "The consideration of training the classifier head on the target distribution is reasonable and important in my opinion. In domain shift tasks the source domain is generally of a much larger scale than the target task. It is then reasonable to assume that the representation is trained on the source domain and the classifier (which needs less data if it is given a high quality representation) is trained on the smaller target domain dataset.\n\nThe set of algorithms and tasks are sufficiently diverse. There is ample evidence for all the claims in the paper. The only exception is the \"Findings\" paragraph in Section 3.2.2. Figure 3 is supposed to back this claim but the plots show high levels of noise and mixed patterns. For example, in fig 3 (a, top) the error bars mostly overlap and in Fig 3 (b, bottom) SL shows a drop in sensitivity. I suggest adding more runs, more levels of r_id, and clarifying the number of runs and what error bars represent.\n\nI would also like to see a detailed discussion on the augmentation methods used for SSL as this is critical to the performance of the representation learning method. What augmentation methods are used? For each pair of images concatenated together, is the same augmentation method used for both images? Are the two images modified exactly the same way (e.g. if both are rotated, are both images rotated in the same direction and by the same angle)?\n\nMinor comment: The first sentences of the first two bullet points at the end of the introduction are worded too close to each other. I understand that the first point refers to accuracy and the second point refers to shift sensitivity but this is not what those two sentences convey.",
            "clarity,_quality,_novelty_and_reproducibility": "This study is novel to the best of my knowledge although, given its importance, it is possible that previous has conducted similar experiments. The setting where the classifier is trained on the target domain is close to the feature transfer setting in transfer learning. I think the difference here is the types of datasets that are used and the controllable degree of shift between the source and target domain. If previous work has compared SSL, AE, and SL representation learning in a feature transfer setting and showed that SSL learns more transferrable features then the findings of this paper are less surprising.",
            "summary_of_the_review": "I'm voting for accept as the claims in the paper are clearly stated and well motivated and supported. I elaborated on these points in the Strengths/Weaknesses section and provide a few suggestions.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4423/Reviewer_xV8K"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4423/Reviewer_xV8K"
        ]
    },
    {
        "id": "2ETSppH_4w",
        "original": null,
        "number": 4,
        "cdate": 1667456257475,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667456257475,
        "tmdate": 1667456257475,
        "tddate": null,
        "forum": "LiXDW7CF94J",
        "replyto": "LiXDW7CF94J",
        "invitation": "ICLR.cc/2023/Conference/Paper4423/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides a comprehensive empirical study of the OOD generalization performance of SSL, AE and SL. In addition to testing standard algorithms on standard distribution shift datasets, the paper proposes a new controllable realistic distribution shift task, and also consider a setting where the linear head is retrained on the OOD data. Results suggest that SSL and AE are more robust to distribution shift than SL.",
            "strength_and_weaknesses": "Strength:\n- The experiments are very comprehensive and implementation details are provided.\n- The construction of the controllable distribution shift dataset is novel.\n- As far as I know, this is the first work that explicitly takes retraining the linear head into consideration, and compare its performance side by side with using the ID linear head. This could be an important point that is worth highlighting to the community.\n\nWeakness\n- There's limited explanation about why SSL/AE works better than SL on shifted distribution beyond what people already know in the literature.\n- To some extent, I feel there's nothing surprising about the findings in this paper. Although it's always nice to have more comprehensive experiments, it's unclear what's the conceptual insight that a reader can gain from this paper. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and the writing is of good quality.",
            "summary_of_the_review": "I think this paper provides a reasonably good empirical comparison between SSL/AE and SL in various settings with different datasets. Although the result doesn't sound surprising, it's good to have this as an addition to the community, hence I would love to recommend for its acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4423/Reviewer_Bhk8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4423/Reviewer_Bhk8"
        ]
    }
]