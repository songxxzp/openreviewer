[
    {
        "id": "MIeOFBCZ6d",
        "original": null,
        "number": 1,
        "cdate": 1666669145811,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669145811,
        "tmdate": 1670367208599,
        "tddate": null,
        "forum": "K8oz8DyuJD",
        "replyto": "K8oz8DyuJD",
        "invitation": "ICLR.cc/2023/Conference/Paper2185/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies supernet training in the federated setting. Compared to standard supernet training algorithms, various twists have been made to accommodate the constraints in federated learning systems. The experiments have verified the performance of the proposed method. ",
            "strength_and_weaknesses": "Strength: \n- Supernet training in federated learning is an interesting topic. \n- This work can potentially have practical value as it explains the detailed steps of the method. \n\nWeaknesses:\n- The paper describes a lot of the details in the approach. The high level picture is somewhat missing, so it is hard to identify a core novel contribution in this work. It seems the contribution is mainly in the detailed tuning of the centralized supernet training algorithm to the federated setting. I think such a work can be useful, but not very interesting from a scientific point of view. \n- It would be nice if non-obvious findings, both in the algorithm design and empirical results, can be highlighted and discussed in the paper. \n- It is not clear what Dirichlet parameter $\\beta$ is used to obtain the results shown in the main paper. \n- I wonder why the personalized model gives much better performance than the initial model, and why the initial model's accuracy is so low. Is there an explanation for this?\n- There are only a few plots that compares the proposed FedSup algorithm with baselines. To conclude that FedSup performs uniformly better than baseline algorithms, comparisons with baselines need to be made with multiple datasets. I wonder why the appendix does not include such comparisons for the other datasets. \n- What does O and X mean in Table 4?",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Some parts need clarification as mentioned above. \n\nQuality: The paper has weaknesses as mentioned above.\n\nNovelty: The novelty is somewhat limited as most contributions are in the detailed steps that appear to be more like tricks instead of something fundamentally new. \n\nReproducibility: The code has been provided which is good, although I didn't try to run it. ",
            "summary_of_the_review": "The topic is interesting, but the novelty is somewhat limited, and overall the paper should have more insightful discussions on both the technical contributions and empirical results.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2185/Reviewer_zfru"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2185/Reviewer_zfru"
        ]
    },
    {
        "id": "C_IIeu62unH",
        "original": null,
        "number": 2,
        "cdate": 1666740747179,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666740747179,
        "tmdate": 1666740747179,
        "tddate": null,
        "forum": "K8oz8DyuJD",
        "replyto": "K8oz8DyuJD",
        "invitation": "ICLR.cc/2023/Conference/Paper2185/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "While federated learning has become a popular paradigm for collaborative machine learning, it suffers from data heterogeneity and system heterogeneity. This work proposes FedSup, a federation framework of supernet training to address both heterogeneities. The key idea is to directly train the subnetworks on the device and introduce parametric normalization and self-distillation to improve the training. Experiments show that FedSup improves global and personalized client model accuracies with better communication efficiency.",
            "strength_and_weaknesses": "Strength:\n+ this work provides an interesting analysis of similarities and differences between federated learning and supernet training in NAS.\n+ extensive experiments evaluate both FedSup and E-FedSup performance compared to conventional approaches (FedAvg etc).\n\nWeakness:\n- the analysis of the compounding effect in E-FedSup is weak. In E-FedSup, the system heterogeneity and data heterogeneity are entangled since sub-architecture sampling is biased. It would be better if this work could provide more experiments on the generalizability of the trained supernetworks under E-FedAvg.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-organized and easy to follow.",
            "summary_of_the_review": "This paper proposes an interesting question on training the supernet of neural architecture search in the context of federated learning. However,  In general, I think this paper is marginally above the acceptance threshold.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2185/Reviewer_jbFv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2185/Reviewer_jbFv"
        ]
    },
    {
        "id": "c8PO3WyIO1",
        "original": null,
        "number": 3,
        "cdate": 1667182770077,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667182770077,
        "tmdate": 1667182770077,
        "tddate": null,
        "forum": "K8oz8DyuJD",
        "replyto": "K8oz8DyuJD",
        "invitation": "ICLR.cc/2023/Conference/Paper2185/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper empirically studies the federated learning setting on super-net training.\nThis paper considers both directions simultaneously to overcome the data privacy issue and data heterogeneous issue in parallel.",
            "strength_and_weaknesses": "Pros:\n\n1. The problem is well-motivated. Existing methods either \"train a single global model but keeping each local heterogeneous training data decentralized\" or \"train an overarching network that supports diverse architectural settings to address heterogeneous systems equipped with different computational capabilities\". This paper considers both directions simultaneously to overcome the data privacy issue and data heterogeneous issue in parallel.\n\n2. The paper is well written. The challenges of super-net training are well listed and solutions are provided in Section 3.\n\n\n\nCons:\n\n1. This paper is mainly focusing on the empirical part of federated learning and supernet training. However, it would be great if the authors could provide theoretical evidence on why \"parametric normalization\"  and \"in-place distillation\" could help alleviate the data heterogeneity issue from either optimization (e.g., convergence analysis) or generalization (e.g., the generalization analysis in [1]). \n\n\n[1] Personalized Federated Learning: A Meta-Learning Approach https://arxiv.org/abs/2002.07948\n\n2. Although sampling based on FLOPs is interesting, I am having doubts about whether this will exaggerate the data heterogeneity issue. For example, lower complexity models are more likely to be trained on devices with less computation ability, and the data will be loss similar on these devices.   \n\n3. For experiments, I think the authors also need to compare with single machine supernet training, i.e., all heterogeneous data are gathered onto a single device and used for training. This experiment could be used as a baseline to show the trade-off between efficiency and accuracy.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written. \n\nAlthough a number of training techniques (e.g., parametric normalization, in-place distillation) are proposed for better training, the backbone of the method sounds to me like a combination of FedAvg and NAS (neural architecture search), which is mostly an incremental engineering effort. \n\nCode is not provided, not sure about the Reproducibility.",
            "summary_of_the_review": "This paper studies a well-motivated interesting problem, paper is well-written and easy to follow. \n\nThis paper mainly focused on the engineering part of federated learning, however for papers that are working on federated learning, some theoretical analysis on either convergence or generalization is usually expected. \n\nThe proposed complexity-based sampling method might exaggerate the data heterogeneously issue and hurt model performance. \n\nThe authors are also expected to compare with centralized training to demonstrate the trade-off between efficiency and accuracy.\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2185/Reviewer_Zkr8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2185/Reviewer_Zkr8"
        ]
    }
]