[
    {
        "id": "JshwyitRvM",
        "original": null,
        "number": 1,
        "cdate": 1666496520793,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666496520793,
        "tmdate": 1666496898370,
        "tddate": null,
        "forum": "YnVpYUjzVHC",
        "replyto": "YnVpYUjzVHC",
        "invitation": "ICLR.cc/2023/Conference/Paper546/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Focus on the consistent of ML interpretations, this paper introduces a new objective of consistency based on a notion called truthful interpretation by applying Fourier analysis of Boolean functions. Experimental results show that the method achieves higher consistency compared with other methods.",
            "strength_and_weaknesses": "\nStrong Points:\n[1]This paper produced a novel method of Fourier analysis of Boolean function to get consistency guarantees.\n\n\nWeak Points:\n[1]It is suggested that the author need to highlight the contributions of this paper, especially the part of technique improvements.\n[2]This paper lacks an understanding of where the paper's going, the authors, for example, fail to focus on the consistency of interpretability and the improvements of truth interpretation.\n[3]As above, it needs to review the works of about ML inconsistent rather than the different types of interpretable models in Related Work.\n[4]For any model  and  especially with different structure, the weight distribution which is defined to evaluate the inconsistency by Equation (1) is lack of some evidence. It might be needed to provide some demonstrations.\n[5]It is better here to supplement more clear and plain explanations about algorithm 1 and 2.\n[6]How to evaluate that a function can faithfully interprets the readable part of the network or not in section 3.2?\n[7]Although the experiment results based on SST-2 and IMDb datasets is impressive compared with other baselines, it is needed more clear and sufficient analysis about that. And the experimental hardware environment is not reported.\n[8]Many of the reference should be further improved. For example, few references miss page, and the format of references is not uniform and either AAAI or its full name. In addition, the authors may try to discuss the existing work in published papers (rather than a number of preprinted references from arxiv).",
            "clarity,_quality,_novelty_and_reproducibility": "Presentation quality should be improved. For reproducibility, experimental details need further description.",
            "summary_of_the_review": "Contributions, especailly technique improvement need to be cleary addressed.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper546/Reviewer_BSNn"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper546/Reviewer_BSNn"
        ]
    },
    {
        "id": "O6kEUV3sqA",
        "original": null,
        "number": 2,
        "cdate": 1666506647755,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666506647755,
        "tmdate": 1666506647755,
        "tddate": null,
        "forum": "YnVpYUjzVHC",
        "replyto": "YnVpYUjzVHC",
        "invitation": "ICLR.cc/2023/Conference/Paper546/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes an explanation method to provide consistent and truthful explanations of black-box models. Experimental results verify the effectiveness of the proposed method.",
            "strength_and_weaknesses": "[Strengths]\n1. This paper focused on an important topic, i.e., learning consistent and truthful explanations.\n2. This paper is well written. It is easy to follow the authors\u2019 ideas.\n\n[Weaknesses]\n\n1. There exists a significant theoretical defect in the algorithm. Algorithm 1 and Algorithm 2 aim to learn the polynomial $g(x)=\\sum_{S,\\chi_S\\in C} \\alpha_S \\chi_S(x)$ as the explanation model. However, such an explanation model cannot provide universal explanations because it does not consider the dimension alignment issue. For example, given two sentences, \u201cHow are you.\u201d and \u201cHello, how are you.\u201d, $\\chi_{\\\\{x_1, x_2, x_3\\\\}}$ and $\\chi_{\\\\{x_2, x_3, x_4\\\\}}$ both correspond to the sub-sentence \u201chow are you\u201d of these two sentences. Therefore, the network is supposed to predict the same score for the input of these two sub-sentences, but the explanation model provides different explanations, i.e., $\\alpha_1\\chi_{\\\\{x_1, x_2, x_3\\\\}}$ and $\\alpha_2\\chi_{\\\\{x_2, x_3, x_4\\\\}}$. Such explanations do not make any sense. It seems that such explanation models are only suitable for data where each dimension has a fixed meaning. This is our main concern.\n\n2. The authors do not provide explanation results of the proposed method. Therefore, it is difficult for us to make any comment on the interpretability of the proposed method.\n\n3. The metric of consistency is unable to strictly measure the consistency between normal samples and masked samples. It is because the masked sample is an out-of-distribution (OOD) sample. The explainable model is supposed to provide different explanations for normal samples and OOD samples. For example, a normal sentence contains ten words, and the masked sentence only contains two words, whose explanations are almost absolutely inconsistent. In this way, even the supposed optimal explanation is unlikely to get the inconsistency of zero, i.e., $I_D(f,g)\\ne 0$. The authors are supposed to prove that your definition of inconsistency can correctly reflect the absolute inconsistency of the explanation method.\n\n4. The authors\u2019 three claims about \u201cinterpretability, consistency, and efficiency\u201d lack clear definition and proof, i.e., \u201c(a) Attribution methods are interpretable and efficient, but not consistent. (b) The original network is consistent and efficient but not interpretable. (c) If one model is interpretable and consistent, it cannot be efficient.\u201d I find that it is very difficult for me to provide any comments on these unprecise claims. The authors are supposed to provide a clear definition of \u201cinterpretability, consistency, and efficiency,\u201d and provide proofs of these three claims.\n\n5. Concern about the correctness of the input space of functions $f$ and $g$. In some Definitions, e.g., Definition 3.2 and Definition 3.3, $f,g\\in\\\\{-1,1\\\\}^n$, but in other Definitions, e.g., Definition 3.4 and Definition 3.6, $f,g\\in\\\\{0,1\\\\}^n$. If they are all correct, then the authors are supposed to explain the reason why the input space is different.\n\n6. Definition 3.8 gives the lower bound of the fitting error of the explanation model. Why do you focus on the lower bound of the fitting error, instead of the upper bound?\n\n7. The experimental comparisons of the proposed explanation method and other explanation methods in Section 5.1 are unfair. It is because the majority function contains the product relation $x_1x_2x_3$, which naturally prefers the explanation method proposed in this paper, where $\\chi_S$ is also defined on the product relation $\\prod_{i\\in S} x_i$. The authors are supposed to conduct experimental comparisons on other functions that do not depend on the product relation of input variables.\n\n8. Ask for more experiments. (1) The authors are supposed to compare the inconsistency between the proposed method and the Faith-SHAP [cite1], which is also an efficient explanation method. (2) The authors are supposed to conduct experimental comparisons with more models, such as LSTMs or Transformers. (3) The authors are supposed to conduct experiments to verify the effectiveness of Algorithm 2.\n\n[cite1] Tsai et al. \u201cFAITH-SHAP: THE FAITHFUL SHAPLEY INTERACTION INDEX\u201d in arXiv:2203.00870 \n\n9. In Figure 3, results show that the proposed method did not exhibit significantly lower readable inconsistency than other methods. This makes me question the effectiveness of the proposed method.\n\nMinor.\n- Which convolutional neural network is the authors use for experiments in Section 6.1?\n\n- Please provide the actual radius in Figures 2, 3, and 4, instead of $\\infty$\n\n- In Definition 3.1, I think it should be $\\chi_S(x)$ instead of $\\chi_S$ in the left-hand side of the equation.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The idea of this paper is clear and the paper is well written. However, the theoretical novelty is limited and experimental settings are unclear.",
            "summary_of_the_review": "There exists a significant theoretical defect of the proposed method and the authors do not provide explanation results of the proposed method. Besides, experimental settings are unclear.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper546/Reviewer_hMRo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper546/Reviewer_hMRo"
        ]
    },
    {
        "id": "1dsHy02plb",
        "original": null,
        "number": 3,
        "cdate": 1666719824498,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666719824498,
        "tmdate": 1666719824498,
        "tddate": null,
        "forum": "YnVpYUjzVHC",
        "replyto": "YnVpYUjzVHC",
        "invitation": "ICLR.cc/2023/Conference/Paper546/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper investigates the tension between consistency and simplicity in interpretability. The goal is to find a model from a restricted function class (e.g. of simple functions) that matches the network on as much of the input space as possible. The paper focuses on Boolean functions, takes the function space to be functions that are space in the Fourier basis, and investigates approaches to find the sparse function that best approximates a given function. They investigate the performance of (slightly modified versions of) the Harmonica algorithm (Hazan et al., 2017) and Low-degree (Linial et al., 1993). The paper then evaluates these algorithms and compares them to existing approaches\u2014including LIME and SHAP\u2014on datasets for sentiment analysis and movie review classification. ",
            "strength_and_weaknesses": "Strengths\n- The paper illustrates that existing tools from learning sparse approximations to Boolean functions could be related to interpretability. \n\nWeaknesses\n- The analysis in the paper is entirely restricted to Boolean functions, and the restricted function class is assumed to be sparse functions in the Fourier basis. The algorithms studied in this paper rely heavily on these assumptions. \n- The algorithms investigated by the paper are standard in the learning Boolean functions literature (as the paper does acknowledge). For example, Section 4 is entirely devoted to analyzing existing algorithms (with minor modifications). \n- The empirical evaluation is restricted to small-scale setups: a convolutional network achieving ~80% accuracy on the SST-2 dataset and a convolutional network achieving trained on the IMDb dataset. It would be useful to more extensively empirical evaluate their methods on larger-scale setups with modern networks. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is fairly well-written. \n\nThe goal of the paper seems to be to examine the tension between consistency and simplicity in the context of interpretability. However, the insights provided by this paper are limited to Boolean functions where the set of interpretable functions is taken to be functions that are sparse in Fourier basis. As a result, it is not clear whether the insights are applicable to practical settings. Moreover, the algorithmic and empirical contribution of the paper are both limited.  \n\n",
            "summary_of_the_review": "The paper investigates the tensions between consistency and simplicity in the context of interpretability, with a focus on interpreting Boolean functions with functions that are sparse in Fourier basis: however, the setup is quite restrictive, and furthermore, both the algorithmic and empirical contributions are limited. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper546/Reviewer_dqjk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper546/Reviewer_dqjk"
        ]
    }
]