[
    {
        "id": "YWpWM_SFO_x",
        "original": null,
        "number": 1,
        "cdate": 1666659719417,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666659719417,
        "tmdate": 1666659719417,
        "tddate": null,
        "forum": "TLx9diIRJVj",
        "replyto": "TLx9diIRJVj",
        "invitation": "ICLR.cc/2023/Conference/Paper4300/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a task-agnostic framework to measure the quality of pretrained representations.  This approach uses generated data from a conditional Gaussian mixture to evaluate the learned representation.  The usefulness of this metric is evaluated by comparing to results from linear probing on CIFAR 10/10-c",
            "strength_and_weaknesses": "Strengths:\nDetermining a robust and straightforward measure of the quality of learned representations (whether pretrained or otherwise) is an important endeavor.  Current approaches use linear-probing, but this is naturally task specific.  Having a task-agnostic measure of representation quality would be valuable.  The author's state the main tradeoff is between accuracy and adversarial robustness.\n\nWeakness:\nIt's not clear whether a task-agnostic representation is meaningful or valuable.  Is the best representation the one that transfers to the most tasks, transfers the best to a specific task, is most extensible to an expanse of the domain, etc?  The authors have clearly stated what they deem as \"good\", but it's not clear that this is a general definition of a \"good\" representation.   \n\nThe theoretical results derived all assume a balanced dataset, which is uncommon in real wold data.\n\nThe evaluation is only done on image classification (CIFAR 10/10-c).  While it is true that this dataset is used, it doesn't seem to be a good test dataset alone for this.  Vision transformers and large scale pretraining are most beneficial on massive datasets (both in the number of samples and when the images themselves are larger than CIFAR-10).  Therefore it's unclear how these results would hold on real world scenarios where such approaches would be actually used.  It's fine to start with CIFAR-10, but demonstration on a larger dataset (even Imagenet) and especially on a dataset where such approaches are more appropriate (e.g. medical imaging) would be much more powerful.\n\nTo demonstrate the usefulness of this approach, I believe the authors would need to more systematically demonstrate how the scores obtained from different pretraining procedure (e.g. MOCO, DINO, SimCLR, etc.), pretraining dataset (e.g. Imagenet, COCO, something entirely different like medical or remote sensing), downstream task (e.g. classification, segmentation, surface normals), and downstream dataset change and how that corresponds to the final downstream task performance (both fine tuning and linear probing).  The authors are implying that this metric is more general and therefore more useful than something like linear probing, but they have not demonstrated it over a wide enough range of representations and tasks, in my opinion.",
            "clarity,_quality,_novelty_and_reproducibility": "Over the paper is clear and easy to read.  Some of the captions could be slightly clearer.  While the reader can find alpha, epsilon in the text, it is helpful to restate that in the caption if possible.",
            "summary_of_the_review": "Creation of a task-agnostic measure of a learned pretrained representation has significant value.  \n\nHowever, by evaluating this metric only on a single task and dataset (classification for CIFAR 10/10-c), the impact of the paper is strongly limited.  How this would hold on other tasks (e.g. segmentation, surface normals, etc.) as well as larger, real world datasets where such approaches are needed, is not explored.  The assertion is that this metric is more useful than linear probing because it can be examined at the time of pretraining (not downstream task formulation) to anticipate how well that representation will perform across a number of tasks.  With that logic, this metric should enable the user to select the \"best\" representation from a set of representations which have been learned.  This needs to be demonstrated over a wide range of pretraining datasets, pretraining methodologies, downstream tasks, donwstream datasets, etc.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4300/Reviewer_Lj97"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4300/Reviewer_Lj97"
        ]
    },
    {
        "id": "kVBsiwZ17BA",
        "original": null,
        "number": 2,
        "cdate": 1666801162393,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666801162393,
        "tmdate": 1666801293068,
        "tddate": null,
        "forum": "TLx9diIRJVj",
        "replyto": "TLx9diIRJVj",
        "invitation": "ICLR.cc/2023/Conference/Paper4300/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a novel way to evaluate the quality of a pre-trained representation. It requires no real data and downstream tasks for the evaluation. In the evaluation, it utilizes synthetic data generated from the mixture of two Gaussian distributions. The authors prove the soundness of the method using the assumption of Gaussian.\nThe synthetic data is used to evaluate the trade-off between accuracy and robustness.\nThe evaluation is done on ViT architecture with different sizes. The experiment shows the SynBench score can be used to predict the model performance on downstream tasks.\n ",
            "strength_and_weaknesses": "Strength: \n- The idea of evaluating a presentation without using a real dataset and downstream tasks is interesting. The idea is novel and the theory seems to be well proved under the Gaussian assumption.\n\nWeakness: \n- The theory's assumption is too strong and unclear whether the result can be transferred to more complex real-world scenarios.\n- The experiment can be an effective way to validate whether the assumption holds true for more challenging scenarios. The experiment done in the paper is insufficient to get a conclusion. The comparison is done using variants of ViT and does not include other architectures. Since the evaluation method is a universal approach, it is important to see whether it is effective for other models.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-organized and easy to follow. The writing can be improved. For example, it is difficult to get an intuitive understanding of what area A and area B means without checking the equation details. \n\nThe idea is novel and interesting. But whether it is effective is uncertain given the result presented in the paper.",
            "summary_of_the_review": "The paper presents an interesting idea to evaluate pre-trained representation. The idea is conducted with Gaussian synthetic data. It is unclear to me whether this way of evaluation can really transfer to a meaningful metric for downstream tasks. The experiment in the paper is somewhat limited to support the claim of the authors. If authors can apply this evaluation strategy to more model architectures and show the same discovery, it will be very impressive. I think its current status is below the threshold of ICLR.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethics concerns.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4300/Reviewer_xsCU"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4300/Reviewer_xsCU"
        ]
    },
    {
        "id": "ntydbJixGC5",
        "original": null,
        "number": 3,
        "cdate": 1667419788019,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667419788019,
        "tmdate": 1667419788019,
        "tddate": null,
        "forum": "TLx9diIRJVj",
        "replyto": "TLx9diIRJVj",
        "invitation": "ICLR.cc/2023/Conference/Paper4300/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper aims at finding a *task-agnostic* and *model-agnostic* way of evaluating the quality of any pretrained model's extracted features. Specifically, authors develop a score that measures the accuracy-robustness tradeoff of a model's representation on a synthetic binary classification task. Authors asses the relevance of such score by studying how well it correlates with ViT model's ability to obtain a good in-distribution (CIFAR) / out-of-distribution (CIFAR-10C) accuracy tradeoff.",
            "strength_and_weaknesses": "### Strengths\n\n**Interesting problem.** The problem of evaluating the quality of a pretrained model's representations in a *task-agnostic* fashion appears as an ambitious (perhaps a bit ill-posed?)/important problem in a context where pretrained/foundations models are becoming de-facto starting points for most existing specific applications.\n\n**Exhaustive related work section.** The related works part covers relevant lines of works, including most recent works on pretrained models benchmarking.\n\n### Weaknesses\n\n**Motivation.**\n\n*Use of synthetic data.* I'm having hard time wrapping my head around how the model's behavior on images synthetized from a Gaussian mixture (i.e probably very far away in the input space from both the source and target distributions) could inform the model's behavior on real-world images. Could authors provide additional motivation ?\n\n  *Adversarial perspective: * (See below for a more detailed comment) I'd suggest authors provide more motivation on why they chose to address the general problem of \"representation quality\" through the lens of adversarial robustness, as the link between adversarial robustness and generalization is not trivial (although I concede it is not unreasonable either).\n\n**Lack of comparisons.** Authors do not really compare to any other line of work. Although I could concede that other works have never tried to address this exact setting (i.e completly task-agnostic evaluation of representations), authors do not seem to have put any effort into adapting any technique to their setting, which makes the relevance of their score (on top of my next comment) hard to evaluate. For instance, cited lines of work that use unsupervised criterions (e.g. mutual information or Minimum Description Length) could be adaptated to the synthetic binary classification task that authors propose (e.g. comparing the mutual information between representations and labels in the input space vs in the representation space), and provide at least some point of comparison.\n\n**Hardly falsifiable hypothesis.** The contribution section claims that the score evaluates the quality of the representations. On the other hand, authors do not find any strong positive correlation between their score and actual tradeoff performances of models in Table 3. (e.g. standard probing for ViT-L, corresponding to $\\epsilon=0$, has smaller score but significantly higher OOD generalization). Authors comment on that part that \"although SyncBench-score may share trends with empricial real-life tasks, it is meant to characterize a general behavior of the pretrained representations.\" This feel a bit hand-wavy to me, in the sense that the definition of \"general behavior\" can mean everything and anything. I believe the paper would benefit from clearly defining what the score is meant to act as a proxy of, and explictly show positive correlation between their score and this metric. \n\n**Lack of experiments.** Echoing to my previous point, even if strongly positive correlation had actually been found, more experiments would be needed to support the initial goal/claims of producing a score that *applies to a wide range of pretrained models* and informs downstream accuracy. In particular, more architectures should be tried (at least 1 ConvNet), more datasets (CIFAR is a relatively outdated choice considering the myriad of more recent vision datasets), and at least one additional task (e.g. segmentation/detection ? or even anything in another modality?) to support the *task-agnosticity* part.",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity \n\nBelow, I've tried to explicit the points that were confusing to me.\n\n*Abstract*. I would suggest removing some technical details and focus on the important message. In particular, the sentence \"we set up a reference ... to infer the quality\" is quite unclear. On one hand, introducing the use of gaussian mixtures feels unecessary at this stage. On the other hand, focusing on explicting what \"accuracy-robustness\" tradeoff means for a score that claims to be task-agnostic would be more insightful. Regarding that point, I'd suggest authors state explicitly that they create a synthetic binary classification proxy task to estimate the model's accuracy-robustness (hard to understand before page 4 of the current manuscript).\n\n*Gap in argumentation.* Introduction starts by motivating the surge in usage of large pretrained models, and the need for a way to assess the quality of representations in a \"task-agnostic\" fashion, which I completly hear. With almost no transition, the argument jumps to a discussion on how a potential lack adversarial robustness from the network could impede the model's performance on downstream tasks. I had a hard time following the rest of the introduction from that point on, i.e. from \"however, if the underlying ... standard accuracy and adversarial robustness to input perturbations...\". I may be missing context, but I still suggest authors elaborate/provide references to bridge the gap between a model's adversarial robustness and its potential of better transfering to new tasks.\n\n*Mathematical notations.*: I found mathematical expressions unadequately verbose. \n  My high-level suggestions would be to defer as much as possible to Appendix (including at least 2 out of 4 lines of Eq (2)), and revise/simplify notations. Here are more specific points:\n\n- I guessed by elimination that $y^*$ corresponded to the optimal $\\epsilon$-robust classifier. However, classifiers were referred to as $f$ \n       in the section before. If my understanding is correct, I would suggest something like $f_{\\epsilon}^{*}$.\n- Unless I missed it: $\\theta$ is not defined. I tried to assume that represented the network's parameters, but still does not make sense, since at the stage this is introduced, we're still referring the input space (in other words, there is no dependence upon the networks at all). Please clarify this.\n- Adding $\\mu=..., \\sigma=...$ at each line makes Eq (2) unecesarrily bulky. Unless I'm missing something, the dependency upon $s$ would be better carried by $a$, such as $a(s_i, \\epsilon) > a_t$. That would also allow $\\epsilon$ to also appear as a dependency and ease reading.\n- Results 3.1 to 3.4: After re-reading those 4 results, it appears to me there is a lot of repetition which could presumably be factorized into a single result giving both the expected $||\\delta||$ and standard accuracy in the case of a general gaussian mixture, and subsequently instantiated with more assumptions (e.g. $\\Sigma=\\sigma I$).\n\n",
            "summary_of_the_review": "The current manuscript does not appear ready for publication due to (i) lacking motivation on the important directions of the work, (ii) lacking experiments/evidence to properly support author's claims and (iii) lacking clarity and conciness in writing. Therefore, I cannot recommend acceptance at this stage.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4300/Reviewer_REYd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4300/Reviewer_REYd"
        ]
    }
]