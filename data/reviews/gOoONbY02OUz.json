[
    {
        "id": "bfS7mi60hI",
        "original": null,
        "number": 1,
        "cdate": 1666697952234,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666697952234,
        "tmdate": 1666697952234,
        "tddate": null,
        "forum": "gOoONbY02OUz",
        "replyto": "gOoONbY02OUz",
        "invitation": "ICLR.cc/2023/Conference/Paper4850/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper aims to explore the problem of data set imbalance in face identification systems. They specifically focus on imbalance with respect to gender presentation. Aiming at the imbalances(both in terms of identities or images per identity) in the train set and the test set, the author conducted several experiments on the Celeb A dataset and got some conclusions.",
            "strength_and_weaknesses": "Strength:\n1. The problem of data imbalance is a good direction and deserves further study.\n2. The authors have carried out experiments on the problem of data imbalance in different situations and draw conclusions according to the experimental results.\n\nWeaknesses:\n1. The author carried out experiments (session 4 and session 5) respectively under the condition that the training set and the test set are not balanced, but the conclusion obtained is relatively shallow. At the same time, in the case of imbalanced training set images, the abnormal occurrence is caused by resampling, that is, the bias is partly caused by human factors and the result is not rigorous enough.\n2. The authors conclude in session 7.1 that females are generally more difficult to identify than males, but the authors only conducted experiments on the Celeb A dataset.  There are differences in the difficulty of different data sets.  If the experiment can be carried out in more datasets, the conclusion will be more convincing.\n3. In session 7.2, the author argues that there are reasons for bias in humans and machines are different. But the author does not analyze what reason is and why they are different. I think this conclusion is meaningless.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: This paper is clear and easy to understand\nQuality: This paper is of average quality and has some loopholes\nNovelty: The direction of this paper is innovative\nReproducibility: This paper is reproducible",
            "summary_of_the_review": "The authors have carried out various experiments, but the conclusion is relatively simple. The authors reveal many common errors in bias calculation in face recognition tasks, but do not provide effective strategies to avoid these problems",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4850/Reviewer_vAAf"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4850/Reviewer_vAAf"
        ]
    },
    {
        "id": "KoSdK3QG1Nv",
        "original": null,
        "number": 2,
        "cdate": 1666702318487,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666702318487,
        "tmdate": 1666702318487,
        "tddate": null,
        "forum": "gOoONbY02OUz",
        "replyto": "gOoONbY02OUz",
        "invitation": "ICLR.cc/2023/Conference/Paper4850/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper can be categorized into an \"analysis type\" paper, which doesn't propose anything new; instead, it demonstrates that standard image classification modeles, such as RestNet, MobileNet etc., can lead to biased predictions on face recognition tasks and datasets.\n",
            "strength_and_weaknesses": "Strengths:\n\n1. Fair number of experiments done on a standard dataset.\n2. Multiple models investigated.\n3. Extensive analysis conducted\n\nWeaknesses:\n1. Limited novelty in the sense that this is purely an analysis paper, and that too this type of analysis has been done before if not on the same dataset.\n2. Paper not well-written, e.g., even the task isn't clearly described (see the summary).\n3. No insights is provided into what exactly is the (likely) reason for the observations.\n4. No attempt to alleviate the bias is made.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty is limited (see the summary).\n\nClarity is not good in terms of precisely defining the task and the protected attributes. ",
            "summary_of_the_review": "The paper can be categorized into an \"analysis type\" paper, which doesn't propose anything new; instead, it demonstrates that standard image classification modeles, such as RestNet, MobileNet etc., can lead to biased predictions on face recognition tasks and datasets.\n\nThe paper is poorly written. It's not even clear after reading Section 3 (Face Identification Setup) that what the task actually is. Is the model trained to predict a particular class (ot of say p ones), i.e., $\\theta: \\vec{x} \\mapsto \\mathbb{Z}_p$ or is the task that of metric learning, i.e., $\\theta: \\vec{x} \\times \\vec{z} \\mapsto \\mathbb{R}$?\n\nIn addition to gender, there're plenty of other attributes in the CelebA dataset that can be considered for stereotypical biases (checking for parity in the posteriors), e.g., \"attractiveness\" is one such feature, and there could be easily be biases discovered by a combination of more than one attribute, e.g., \"females wearing glasses are less attractive\" etc.\n\nThe paper reports the biases but doesn't propose a method to alleviate them, which in my opinion, severly limits its contributions in terms of novelty.\n\nThe paper lacks any kind of analysis. What's presented as actionable insights, such as \"overrepresenting the target demographic group can sometimes hurt that group...\", an academic paper should provide insights into why is that the case? What's the difference between the performance from different models? Is MobileNet more biased than ResNet? If so, why, if not then why not?",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4850/Reviewer_qe6A"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4850/Reviewer_qe6A"
        ]
    },
    {
        "id": "CE-IPlyjr1",
        "original": null,
        "number": 3,
        "cdate": 1667430999876,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667430999876,
        "tmdate": 1667430999876,
        "tddate": null,
        "forum": "gOoONbY02OUz",
        "replyto": "gOoONbY02OUz",
        "invitation": "ICLR.cc/2023/Conference/Paper4850/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper unravelled the complex effects that dataset imbalance can have on the model bias for face identification systems. \n\nThis paper separately considered imbalance in terms of identities and images per identity in both the train set and the test set.\n\nThis paper thoroughly explored the effects of each kind of imbalance possible in face identification, and discuss factors which may impact bias.",
            "strength_and_weaknesses": "Strength:\n\nBias in face recognition is a timely topic.\n\nThis paper provided comprehensive statistics regarding bias in the training set and test set.\n\nWeakness:\n\nIn Section 7.1, 'We observe that both models have higher male performance when the test set is perfectly balanced'. This observation is not explored in depth. Is it because female images usually contain make-up?\n\nIn Fig 6, there is no black line in the figure. The legends (identity, image)  are confusing. It is better to show male identity, male image and so on.\n\nThere is no reference to MobileFaceNet, CosFace and ArcFace.\n\nThe technical contribution of this paper is limited as only sampling strategy is used with some simple statistics on the results.\n\nThere are some useful conclusions in Section 8, but it is not very insightful for training unbiased face recognition models",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is clear and straightforward. But the technical contribution of this paper is limited. This paper is easy to reproduce the statistics reported in the paper.",
            "summary_of_the_review": "Bias in face recognition is a timely topic. This paper employed data sampling techniques on different dimensions, such as training data, test data, identity and image. Extensive results supported some conclusions on the bias problem of face recognition. However, the technical contribution of this paper is limited and some observations are not in-depth.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethics concerns.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4850/Reviewer_AVTo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4850/Reviewer_AVTo"
        ]
    }
]