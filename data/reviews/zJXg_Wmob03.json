[
    {
        "id": "c1BQmrwv4Ci",
        "original": null,
        "number": 1,
        "cdate": 1666441751944,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666441751944,
        "tmdate": 1666442008176,
        "tddate": null,
        "forum": "zJXg_Wmob03",
        "replyto": "zJXg_Wmob03",
        "invitation": "ICLR.cc/2023/Conference/Paper2149/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies class incremental learning and proposes several approaches based on Voronoi Diagrams called iVoro. In particular, the paper contributes four approaches: iVoro, iVoro-D, iVoro-AC/AI, and iVoro-L. The introduced approaches are validated on three datasets (CIFAR-100, Tiny ImageNet and ImageNet-Subset) reporting large improvements over previous non exemplar class incremental methods.",
            "strength_and_weaknesses": "Strengths:\nNice idea of using Voronoi Diagrams in class incremental learning\nRather extensive validation\n\nWeaknesses (details see section below):\nClarity of presentation could be improved\nMight be hard to reproduce the models from the current writing of the methodology section\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: \nThe introduction is rather verbose and could be shortened and improved. It does a good job motivating the need of class incremental learning however it misses some important information, e.g.:\n\n\u2022\tIn general, the structure of the introduction is a bit confusing. Prior to getting to the contributions part, there is little information about the introduced iVoro models \u2013 adding a diagram/Figure of an over iVoro system would make it easier to understand. The details about the models are presented as a part of the contributions\u2019 enumeration \u2013 which makes the contribution summary rather lengthy. In general, it might be worth to consider presenting one iVoro system in the introduction as the introduced approach and outline other three in the experimental section as baselines or ablations.\n\n\u2022\tOverall, the reviewer finds the contributions rather unclear \u2013 consider rewriting the enumerate part of the intro.\n\n\u2022\tIt might be worth to add a note about the anticipated impact of the introduced model. The authors highlight the strong performance that is nice but adding a few comments on what these results/models change for the research community would strengthen the paper.\n\n\u2022\tThe authors study \u201c\u2026 the challenging data-free CIL problem under the strictest memory and privacy constraints \u2013 no stored exemplars and fixed model capacity.\u201d \u2013 form the current text it is unclear to the reviewer why this aspect of CIL is worth studying. Adding some motivation would improve the manuscript.\n\n\u2022\tThe captions of the figures should be self-explanatory and contain all the details required to understand the figures.\n\n\u2022\tIn Fig. 2 all the scenarios start with different placing of points in the plane \u2013 see the left most figure in all scenarios. It would be easier to do across methods comparison if all would start with the same point placings.\n\n\u2022\tMethodology section is also hard to follow, it is math heavy and contrails little intuitions on why particular design decisions have been made. Rewriting the methodology part with a focus on presentation simplicity and reproducibility would strengthen the paper.\n\nQuality:\nPutting aside the presentation clarity part, the quality of the paper looks good overall. The paper has fair number of experiments and ablations. The reported results show large gains over prior art. Adding standard deviations to reported values would strengthen the quality of the presentation. \n\nNovelty:\nThe reviewer has not seen before the use of Voronoi Diagram in the context of DNN for class incremental learning, thus there seem to be some edge of novelty. Note, that the reviewer is not actively working on class incremental learning thus might be unaware of some prior art.\n\nReproducibility:\nThe authors motion they will release the code on github. However, based on current presentation of the methodology section it might be hard to code up the methods and reproduce the reported results. The reviewer would encourage the authors to rework the methodology section focusing on reproducibility ease.\n\n",
            "summary_of_the_review": "The introduced ideas are interesting and show good performance in the task of class incremental learning. The paper is well validated and contains significant number of ablations. Overall, the reviewer would lean towards acceptance, assuming that the authors could improve the presentation clarity with a focus on the introduction and methodology sections.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2149/Reviewer_uHig"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2149/Reviewer_uHig"
        ]
    },
    {
        "id": "xPdHONz4nU",
        "original": null,
        "number": 2,
        "cdate": 1666663105785,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666663105785,
        "tmdate": 1666663105785,
        "tddate": null,
        "forum": "zJXg_Wmob03",
        "replyto": "zJXg_Wmob03",
        "invitation": "ICLR.cc/2023/Conference/Paper2149/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper constructs a Voronoi Diagram in an incremental manner to perform Data-free Class-Incremental Learning (CIL). The proposed method is shown to be a flexible, scalable and robust with theoretical insights and experiments, and it promotes the performance of CIL. ",
            "strength_and_weaknesses": "Strength:\n- The paper is clearly written and easy to understand. \n- The paper deals with class incremental learning in a new perspective. \n- The paper investigates fundamental problem in machine learning.\n\nWeakness:\n- I am not quite sure how the method will perform when the distribution of class labels is (highly) skewed. \n- The proposed method and theory will work when separation between classes in the feature space is sufficiently clear. The authors mention this as a challenge in the introduction, but I am not quite sure how they alleviated this problem.  ",
            "clarity,_quality,_novelty_and_reproducibility": "The text is clear and this work can be reproduced if one has sufficient knowledge in basic machine learning. ",
            "summary_of_the_review": "I am not an expert in this field so I may be wrong, but based on the papers of my expertise that I have read before, I think this is a good paper in general. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2149/Reviewer_K7j8"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2149/Reviewer_K7j8"
        ]
    },
    {
        "id": "YaLlc5qiK7",
        "original": null,
        "number": 3,
        "cdate": 1667218838286,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667218838286,
        "tmdate": 1667218838286,
        "tddate": null,
        "forum": "zJXg_Wmob03",
        "replyto": "zJXg_Wmob03",
        "invitation": "ICLR.cc/2023/Conference/Paper2149/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a method for class-incremental learning, i.e. learning a classification task while during training the model has no access to already used data and new samples can contain new classes. Dividing the classification network in feature extractor and classification head, the authors start with the substitution of the classification head by a 1-nearest-neighbour decision landscape (Voronoi diagram) and derive refined methods from there.  \nThe model is tested on the three established datasets CIFAR-100, TinyImageNet and ImageNet-Subset. \nSpecifically, the authors develop four components that enhance their baseline model: parametrised normalisation, a divide-and-conquer strategy for iterative construction of decision landscapes, augmentation consensus and integration and multilayer compatibility. \nThe authors test different combinations of these components to test their respective effects as well as conducting comparison to several benchmark models. The method outperforms all benchmark models in terms of common performance measures on the three datasets by far. ",
            "strength_and_weaknesses": "**Positive:**\n- the paper is structured well and the ideas are presented in a intuitive way\n- Illustrations support the main text well \n- Extensive citation of the literature\n- Code will be made available \n- The method shows improvement compared to benchmark methods for CIL\n\n**Negative:**\n\n- (Major) The experimental results show strong two-digit improvement compared to the best baseline (cf. Tab. 1). I missed a section where the authors provide an intuition and reasoning why the method works so much better than everything that has been done before. There is neither a discussion nor a conclusion in \u201c4 Discussion and Conclusion\u201d, more a summary. \n\n- (Minor) It is easy to loose track of the different versions and reading flow suffers from looking up in the text what the different iVoro-x models actually are. \n\n**Questions:**\n- It seems the baseline method already shows major improvements. You write *\u201cWe suspect that this is because the features generated by the frozen feature extractor can be satisfactorily separable by linear bisectors (Fig. 2). As we can see, the features for other methods are all dramatically changing during the phases, but those for iVoro are all fixed, making incremental VD construction possible. \u201c* \u2028Can you provide a line of argumentation why this could be beyond the above sentence?\u2028\n- 2.1 - C_t once is the dataset at time step t and once is the set of classes at phase t. If those are different letters I could not distinguish them. The sentence, that C_i are pairwise disjoint irritates because this is not clear. ",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity:**\nThe paper is structured well and the methods are introduced in a clear way. However, the paper suffers in my opinion from the nomenclature of the method itself. \n\n**Quality:**\nLiterature is quoted in a generous way and experiments are extensive. There is additional experiments and results in the appendix. \n\n**Reproducibility:**\nThe code will be made available, so the results should be reproducible. \n\n",
            "summary_of_the_review": "The work at hand is well structured and written. The presented methods are to the best of my knowledge novel in the context of CIL. While the experiments and results stress superiority to other methods, the paper does not discuss its findings sufficiently. An attempt to explain why the method outperforms benchmark models to such a great extent would strengthen the work. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2149/Reviewer_zQrg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2149/Reviewer_zQrg"
        ]
    }
]