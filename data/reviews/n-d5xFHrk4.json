[
    {
        "id": "quB826BhZm8",
        "original": null,
        "number": 1,
        "cdate": 1666559561439,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666559561439,
        "tmdate": 1666559561439,
        "tddate": null,
        "forum": "n-d5xFHrk4",
        "replyto": "n-d5xFHrk4",
        "invitation": "ICLR.cc/2023/Conference/Paper3976/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors propose a method based on the Past Motion Dropout hyperparameter from ChaufferNet, the behavioral cloning approach to autonomous vehicle motion planning. With the same motivation as ChaufferNet authors, they suggest to set the dropout parameter to 100%, such that neural network policy does not have access to past ego states. Similarly to ChaufferNet, they implement initial state perturbations as well. To compensate for the lack of temporal smoothness, the authors add a linear quadratic regulator. The authors also adopt a common Transformer-based architecture.",
            "strength_and_weaknesses": "Strengths:\n- the paper is well written and is easy to follow\n\n- it is great that the approach is evaluated on a publicly available planning benchmark\n\nWeaknesses:\n- there is no statistical significance evaluation of both the main comparison table and the ablation table. Planning benchmarks are known to have high variance, and it is not clear how training and evaluation randomness affect the results. I suggest the authors follow reinforcement learning experiments best practices, e.g. [1]\n\n- baseline selection: it is explained how the model architectures differ and how many parameters they have. Would be great to add a column with numbers of parameters for every model in Table 1, for example:\n\n|Benchmark|Model | Num params | Comment |\n|:--|:--|:--:|:---:|\n|Lyft|Raster-perturb | 25M | based on ResNet-50 |\n|Lyft |BC-perturb | 2M | based on github colab |\n|Lyft | UrbanDriver | 2M | or 3.5M in the paper, not clear |\n|Lyft | CCIL | ? | ? |\n|nuPlan|Raster | 25M | based on ResNet-50 |\n| nuPlan |Vector-perturb | ? | |\n| nuPlan |LaneGCN-perturb | ? | |\n| nuPlan | CCIL | ? |  |\n\nBased on the open-source code of UrbanDriver, it looks like BC-perturb and UrbanDriver models are small compared to ResNet-50 based Raster-perturb. Depending on the number of parameters in the proposed method, these approaches could be not directly comparable.\n\n[1] Deep Reinforcement Learning at the Edge of the Statistical Precipice, NeurIPS 2021",
            "clarity,_quality,_novelty_and_reproducibility": "The novelty as limited as Past Motion Dropout was proposed in ChaufferNet.\n\nThe empirical evaluation is done in closed loop simulation only, and is not convincing. ChaufferNet showed that models trained with Past Motion Dropout are able to be deployed both in simulation and in real world. The proposed approach suggests that ChaufferNet policies could be trained without ego history, but only offers a limited evaluation in simulation.\n\nThe novelty of the Transformer architecture used for planning is also questionable, as it has been adopted in both motion forecasting and motion planning tasks.\n\nQuestion to the authors: I did not understand what happens with the future ego trajectory after an initial state perturbation is applied. Is it updated as proposed in ChaufferNet?",
            "summary_of_the_review": "My suggestion is borderline due to minor novelty compared to ChaufferNet and the lack of real world testing. It is not clear how many parameters the proposed approach and selected baselines have, and if the results are statistically significant.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3976/Reviewer_oTYL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3976/Reviewer_oTYL"
        ]
    },
    {
        "id": "w1Vy11EIe6K",
        "original": null,
        "number": 2,
        "cdate": 1666665291790,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666665291790,
        "tmdate": 1666665291790,
        "tddate": null,
        "forum": "n-d5xFHrk4",
        "replyto": "n-d5xFHrk4",
        "invitation": "ICLR.cc/2023/Conference/Paper3976/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposed an offline method to overcome the covariate shift issue in imitation learning. A context-conditioned imitation learning method was proposed, which learns a policy to map context state into  ego vehicle's state without any history ego vehicle's information. To apply the method to urban driving, an ego-perturbed goal-oriented coordinate system was implemented, which helps to reduce the implicit ego information. Finally, model performance was tested on Lyft and nuPlan datasets with several baselines, which demonstrates proposed method can outperform all baselines. ",
            "strength_and_weaknesses": "Strength:\nThis paper proposes a novel offline learning method and a new coordinate system representation, which aims to mitigate the covariate shift problem. The proposed model outperforms the state of the arts in both Lyft and  nuPlan datasets in multiple matrics including collision, off-road, discomfort and L2 position errors with ground truth. In addition, the video and code are released, which will benefit the research of imitation learning. Besides, the paper is well written and has clear framework. In summary, the strength are novelty, performance and opensource.\n\nWeaknesses:\n1. Figure\nFigure1:\nFigure1 is not elegant, impressive or fresh. The authors really need to pay more attention to Figure1 and spend much more time on it.\n\nFigure2:\nI do not understand which method the authors choosed as \"BC\" method in figure2. The authors should explain more about Figure2 in details.\nI do not understand why only one \"BC\" method was selected as comparison with proposed method in toy experiment either.\nIn Performance Evaluation the authors compared with three methods including Raster-perturb, BC-perturb and UrbanDriver. At least it is required to show the closed-loop trajectories of all these models.\n\n2. Benchmark\nBenchmark should take the state of the art offline reinforcement learning algorithms such as Conservative Q-Learning(CQL) into consideration, which makes the result more convincing.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well written and well organized. The idea that removes all history ego vehicle's information from input to overcome covariate shift problem is full of novelty. I believe there will be more applications of this idea in the future.",
            "summary_of_the_review": "Though there exist some problems in Figure and Benchmark, this paper is still considered as full of novelty and beneficial to the field. The paper is marginally above the acceptance threshold.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3976/Reviewer_VSrE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3976/Reviewer_VSrE"
        ]
    },
    {
        "id": "u-Htavhq1Bk",
        "original": null,
        "number": 3,
        "cdate": 1666670890419,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670890419,
        "tmdate": 1666670890419,
        "tddate": null,
        "forum": "n-d5xFHrk4",
        "replyto": "n-d5xFHrk4",
        "invitation": "ICLR.cc/2023/Conference/Paper3976/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents CCIL, a novel behavior cloning approach that learns a driving policy from human demonstrations. It adopts an ego-centric scene representation with a transformer-based architecture. The network predicts a sequence of future ego SDV states, which are converted to control actuations by a LQR. CCIL is evaluated in closed-loop planning driving benchmarks Lyft and nuPlan and attains state-of-the-art performances on both benchmarks.\n",
            "strength_and_weaknesses": "### Strengths\n- The paper is well written and the presentation is clear.\n- The proposed method is effective and achieves state-of-the-art performance. This is the strongest aspect of this paper in my opinion.\n\n### Weaknesses\n- I am not sure how helpful the theoretical analysis is. The assumptions in equation 3 and 6 which linearizes the state and policy does not match the real world or actual implementation of methods. I am also curious why the example at the end of section 3 particularly chooses the formulation of \u201cu_t=s_t + K_bc s_t\u201d.\n- I am afraid that the proposed method has limited novelty. Using an ego oriented coordinate space for observation and predicting future states has been explored in behavior cloning for driving policy learning before [1,2] and is largely a standard practice in motion forecasting [3,4] (although the latter also contains ego state information as opposed to CCIL). \n- I would like to see a latency analysis of the whole system as well as individual components of the methods, and how it compares with the baseline methods.\n- I would like to see an ablation where the causal transformer encoder is trained to predict only the current step\u2019s state predictions instead of all H steps.\n\n[1] ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst, Bansal et al.\n\n[2] TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving, Chitta et al.\n\n[3] MultiPath: Multiple Probabilistic Anchor Trajectory Hypotheses for Behavior Prediction, Chai et al.\n\n[4] Diverse Multi-Future Prediction and Planning for Self-Driving, Cui et al.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: great, the paper is well written and the presentation is clear\n\nQuality:good, attains SOTA numbers\n\nOriginality: not too great as mentioned in the above section\n",
            "summary_of_the_review": "The paper presents CCIL, a behavior cloning approach for driving policy learning. Although the presented approach is effective and attains state-of-the-art performance on both the Lyft and nuPlan benchmarks, aspects/main claims of the paper are not novel and heavily explored in driving policy learning/autonomous driving. Hence I do not recommend acceptance of the paper at the moment.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3976/Reviewer_cGNi"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3976/Reviewer_cGNi"
        ]
    },
    {
        "id": "Ds6YNj6tpo",
        "original": null,
        "number": 4,
        "cdate": 1666765522448,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666765522448,
        "tmdate": 1666765522448,
        "tddate": null,
        "forum": "n-d5xFHrk4",
        "replyto": "n-d5xFHrk4",
        "invitation": "ICLR.cc/2023/Conference/Paper3976/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work builds a pipeline for closed-loop planning via behavior cloning.\nTheir propose to use only past local context (as opposed to SDV state and context in prior work), and use a transformer to predict future states, which is then turned to actions via LQR controller.\nThey show significant improvements over prior methods on the nuPlan and Lyft closed loop planning benchmark. ",
            "strength_and_weaknesses": "### Strengths\n\n* Experiments show clear improvements over IDM, FLOW, COPO\n* Overall mathematical notion is for the most part clear and well-motivated\n\n### Weaknesses\n\n* The main motivation seems quite counter-intuitive at first glance. Taking out ego-state seems like it would harm performance.\n* Overall writing could be improved - several sections read off like lists.\n* Figures could use some polish and better descriptions.\n* nuPlan baselines are **extremely** weak which raises some concern.\n\n### Minor Issues / Questions\n\n* In table 2: it looks like w/o regularization is quite strong.\n* How does the method perform without the LQR controller?",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity, Quality:** the results look great but the contributions are not completely clear\n**Novelty:** novel in terms of theoretical analysis of closed-loop planning\n**Reproducibility:** code is provided and I believe it is reproducible",
            "summary_of_the_review": "This work introduces a fairly counter-intuitive but effective approach and show significant improvements on closed-loop planning. However, I believe the paper does not have the appropriate amount of polish for the venue.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3976/Reviewer_oLbQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3976/Reviewer_oLbQ"
        ]
    }
]