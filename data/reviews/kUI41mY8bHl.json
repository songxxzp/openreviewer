[
    {
        "id": "qC236SH3Yrg",
        "original": null,
        "number": 1,
        "cdate": 1666280753988,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666280753988,
        "tmdate": 1670933707202,
        "tddate": null,
        "forum": "kUI41mY8bHl",
        "replyto": "kUI41mY8bHl",
        "invitation": "ICLR.cc/2023/Conference/Paper939/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes ShiftMatch \u2013 a transformation of the training data that represents likelihood in Bayesian neural networks. This data-dependent likelihood helps dealing with corruptions of the data at test time. It can perfectly remove certain types of corruptions. Interestingly, it does not change the training data, so this transformation can be applied on pre-trained networks. Moreover, it can be applied to normal neural networks, not only Bayesian neural networks.",
            "strength_and_weaknesses": "**update after rebuttal** I have read the authors\u2019 response and other reviews. The authors did clarify mostly my concerns so I am increasing the score.\n=======================\n\n\n\nStrengths:\n* The paper proposes an interesting way to deal with test time data corruptions without the need to touch the training time. This allows a user to use any of the pretrained networks and apply ShiftMatch only at test time. With the caveat that one would need an access to training data to compute statistics required for transformation. \n* This transformation is neatly incorporated into Bayesian formulation. \n* The paper provides rather extensive empirical evaluation on the method, though check the weaknesses on experiments. \n* The paper is well written mostly and easy to follow.\n\nWeaknesses:\n* Experiments are missing comparison with other methods that deal with corruptions or covariate shift. The only baseline that directly addresses the same problem is EmpCov, but there are other works, e.g., Trinh et al. 2022. Tackling covariate shift with node-based Bayesian neural networks. ICML.\n* (not major) I am missing a bit more discussion how ShiftMatch fits into the Bayesian deep learning. For example, does it help/hurt with cold posterior effect? (Wenzel et al., 2020. How Good is the Bayes Posterior in Deep Neural Networks Really? ICML). Also, there is a discussion on effect (non-decremental as one might think) on OOD detection, but it would be great to see more discussion and experiments on effect of ShiftMatch on uncertainty quantification provided by BNNs.\n* (not major) A bit more discussion and experiments on approximations for covariance estimates would be beneficial. I find results from Appendix C are rather surprising and interesting, but lacking more explanation here. It is unclear for me why \u201c\u201cw/I Kronecker factored covariance\u201d compromises the ability to obtain accurate covariance estimates. \n* Test time runtime discussion is missing. The paper rightly so emphasises that training time is unaffected by ShiftMatch, but how slower does the test time become with ShiftMatch? There is a brief mentioning of runtime for spatial batchnorm (a potential implementation of ShiftMatch).\n* (not major) It would be interesting to see the comparison not only to batchnorm but with decorrelated batchnorm cited in the paper.\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**: The paper is mostly well written and very easy to follow. Some minor comments are listed below.\n\n**Quality**: The paper appears to be technically sound. The method is theoretically justified and rather extensively tested empirically with the exception that recent other methods dealing with covariate shift are missing for comparison.\n\n**Novelty**: The ShiftMatch method appears to be novel.\n\n**Reproducibility**: It seems some small details might be missing for reproducibility. For example, learning rate for SGD in the experiments is not specified, or how the outputs for deep ensembles were averaged.\n\nOther comments/suggestions (these don\u2019t impact the score):\n\n1. Acronyms such as SGD and FRN and HMC are not defined in the text\n\n2. Introduction, first paragraph. \u201cimages\u201d \u2013 the text prior to that was not limited to images only\n\n3. Figure 1 caption. \u201cHMC, SGD, Deep Ensemble, SGLD, mean-field VI\u201d \u2013 missing references\n\n4. After eq.(3): \u201cC is the number of features, \u2026 from the inputs to a single feature in the first hidden layer\u201d. If I understand correctly C is the number of features in the input layer, which should be emphasised to distinguish from that single feature in the first hidden layer\n\n5. Page 3, last paragraph. \u201cincluding for robustness\u201d \u2013 weird wording\n\n6. Page 3, last paragraph. \u201cC is the number of channels\u201d \u2013 first, channels were not properly introduced here and C has been used before to denote the number of features\n\n7. Around eq. (12)-(13). It is probably worth mentioning that priors are assumed to be the same in the \u201cstandard BNN\u201d and in the BNN with ShiftMatch\n\n8. Eq. (14). C has been used already to denote the number of features and the number of channels\n\n9. Figure 3 caption. Ensembles are not mentioned\n\n10. Page 7, bottom. It would be interesting to see a discussion on why on some corruptions the ensemble works better and on some worse than ShiftMatch.\n\n11. Figure 5 caption. ImageNet-C is missing a reference.\n\n12. Appendix B. Which data has been used here? \u201cTab.3 gives performance differences with and without ShiftMatch\u201d \u2013 was it meant to be \u201cbatchnorm\u201d here?\n\nMinor:\n\n1. Eq. (10) \u201c.\u201d -> \u201c,\u201d   \n\n2. Sec. 4.6. First sentence. \u201cShiftMatch retains all useful the theoretical properties\u201d -> \u201cShiftMatch retains all the useful theoretical properties\u201d\n\n3. Conclusion. Second sentence. \u201cShiftmatch\u201d -> \u201cShiftMatch\u201d\n\n4. Appendix A. last line. S -> Sigma\n",
            "summary_of_the_review": "I suggest acceptance of the paper as I believe the strengths outweigh the weaknesses. The only real big weakness is the absence of comparison to other methods other than EmpCov dealing with covariate shift. \n\nI would be interested to know the authors thoughts on the two weaknesses I mentioned: absences of other baselines and runtime discussion \u2013 during the rebuttal\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper939/Reviewer_NoHk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper939/Reviewer_NoHk"
        ]
    },
    {
        "id": "ezD-7K2se3",
        "original": null,
        "number": 2,
        "cdate": 1666679687613,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666679687613,
        "tmdate": 1668735262050,
        "tddate": null,
        "forum": "kUI41mY8bHl",
        "replyto": "kUI41mY8bHl",
        "invitation": "ICLR.cc/2023/Conference/Paper939/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes ShiftMatch, a new training-data-dependent likelihood for robustness to corruption in  pre-trained Bayesian neural network. ShiftMatch allows it to use publicly available samples from pre-trained BNNs (Although it needs train data on test phase).",
            "strength_and_weaknesses": "Strengths :\n\n- It's ingenious to try to see a change in the prior as a change in the likelihood.\n\n- The performance is good compared to the comparison methods (BatchNorm, EmpCov).\n\nWeaknesses :\n\n- Chapter 4.1, which is the motivation of this paper, is hard to follow. More specific, authors claim that\n\n$w \\sim N(0, \\frac{1}{C N_{\\text{train}}}( X_{\\text{train}}^{\\top} X_{\\text{train}}) )$,\n\n$X_{\\text{test}} w \\sim N(0, \\frac{1}{C N_{\\text{train}}} X_{\\text{test}} ( X_{\\text{train}}^{\\top} X_{\\text{train}}) X_{\\text{test}}^{\\top})$\n\ncan be seen as\n\n$\\operatorname{ShiftEmpCov}(X_{\\text{test}} ; X_{\\text{train}}) = X_{\\text{test}} ( X_{\\text{train}}^{\\top} X_{\\text{train}})^{1/2}$,\n\n$w^{\\prime} \\sim N(0, I)$,\n\n$\\operatorname{ShiftEmpCov}(X_{\\text{test}} ; X_{\\text{train}})\nw^{\\prime} \\sim N(0, \\frac{1}{C N_{\\text{train}}} X_{\\text{test}} ( X_{\\text{train}}^{\\top} X_{\\text{train}}) X_{\\text{test}}^{\\top} )$.\n\nThis statement is obviously true, but however, I think these statement is related to prior distribution of $X_{\\text{test}} w$. \nIf we change prior like above, then what can you say about the posterior and predictive distribution? I think more detailed explanation is needed.\n\n- Proposed method can be summarized as follows : Match the first and second moments of the test data distribution with the those of the train data distribution. In other words, the algorithm compares test dataset with train dataset, and make test dataset distribution similar to train dataset distribution by covariate shift. I wonder if it will work well even if half of images are corruption-free and the other half are corrupted by intensity 5. Considering the idea of proposed method, I'm worried that it works well only for one unified corruption intensity.\n\n- Is it much more effective to match the distribution in all layers than to match only the distribution of input data? I wonder what it means to consider all the layers.\n\n- It would have been nice to measure the \u2018Expected Calibration Error\u2019, which is commonly used to evaluate Bayesian models on classification problem.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "See the strengths and weaknesses written above.",
            "summary_of_the_review": "While the subject of this paper is interesting and novel, I believe the authors' claims are not adequately supported due to a series of weaknesses. I am more than willing to increase my score if the authors address the aforementioned limitations.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper939/Reviewer_BEej"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper939/Reviewer_BEej"
        ]
    },
    {
        "id": "YiXfYkk7XMH",
        "original": null,
        "number": 3,
        "cdate": 1666708818138,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666708818138,
        "tmdate": 1670342627672,
        "tddate": null,
        "forum": "kUI41mY8bHl",
        "replyto": "kUI41mY8bHl",
        "invitation": "ICLR.cc/2023/Conference/Paper939/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents ShiftMatch, a simple method based on a data-dependent likelihood, enhancing the robustness of Bayesian neural networks to corrupted data. Given a (pre)trained BNN, ShiftMatch computes the training data statistics (mean, variances) and uses them to construct a transformation matrix for each layer. The prediction for a test input is then done with the transformation matrix computed from the training statistics. The prediction with the training data-dependent transformation alters the likelihood, but this transformation leaves the likelihood evaluated with the training data invariant; that is, even though the likelihood was changed, it remains the same for the training data, so one can just reuse pretrained BNNs trained with typical data-independent categorical likelihoods. For high-dimensional data with spatial structures, the authors further propose structural covariance estimation schemes that could improve the scalability of the method. The benefit of the proposed method is demonstrated via various image classification benchmarks with corruptions.",
            "strength_and_weaknesses": "Strength\n- The paper is well-written and easy to follow. \n- The problem of interest is indeed an important topic in the literature, so the motivation is clear.\n- I find the idea of the data-dependent likelihood that does not alter the training procedure interesting and novel. I think the design of the ShiftMatch likelihood and its interpretation as a data-dependent likelihood is clever.\n- The experiments are thorough, and the results are convincing. Including the additional experiments in the appendix, the authors provide various ablations and alternatives that can further strengthen the arguments made in the paper.\n\nWeakness\n- If I have to be picky, the method can be considered incremental since it is largely inspired by existing methods including EmpCov and test-time batchnorm. Still, I think the proposed method is valuable, especially the design of ShiftMatch likelihood leaving the training procedure unchanged.\n- As already discussed in the paper, the method requires storing or recovering training data for prediction. However, the arguments in section 4.5 to defend against this is also reasonable, so I won't think this is a critical problem.\n\nHere are some questions and minor comments:\n- EmpCov seems to transform only the input layers, but ShiftMatch seems to be applied for all the intermediate layers. Can you comment on this difference? For instance, would the performance of ShiftMatch be degraded if only applied to the input layers?\n- In page 7, the paper explains the reason why ShiftMatch performs poorly for \"Translate\" corruption. It seems that ShiftMatch also underperforms baselines for \"Scale\", and slightly underperforms deep ensembles for \"Gauss blur\". The latter is quite disappointing since section 4.6 explains how ShiftMatch can \"perfectly\" removes stationary linear corruptions. Can you comment on this?\n- I don't expect the size of the training data to stably estimate the statistics to be large. Having said that, one could think of a bagging-like procedure where multiple subsets of training data are sampled, corresponding statistics are computed, and multiple predictions are computed from the multiple statistics to be ensembled. This may make the interpretation of the data-dependent likelihood more cumbersome, but may enhance the robustness of the method.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity and quality: the paper is generally well-written. Motivations, reviews of the existing works, and the design principle of the methods are clearly described. The experimental results are well displayed with easy-to-interpret graphs and figures.\n- Novelty: as far as I know, the ShiftMatch likelihood is novel, even though it may have been inspired by some of the existing works.\n- Reproducibility: the authors describe details of the experimental settings. Also, all the codes including scripts that can reproduce the results are provided.",
            "summary_of_the_review": "In summary, I enjoyed reading the paper, and find it to be a novel contribution with promising results.\n\npost-rebuttal: I have read the authors' response which resolved my concerns. I keep my original score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper939/Reviewer_MwDb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper939/Reviewer_MwDb"
        ]
    }
]