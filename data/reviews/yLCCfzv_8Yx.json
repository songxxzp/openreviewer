[
    {
        "id": "VKppiOjxH3",
        "original": null,
        "number": 1,
        "cdate": 1665995802611,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665995802611,
        "tmdate": 1665998301940,
        "tddate": null,
        "forum": "yLCCfzv_8Yx",
        "replyto": "yLCCfzv_8Yx",
        "invitation": "ICLR.cc/2023/Conference/Paper4899/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper considers a human-algorithm collaborative framework in bandit problems. In this framework, the algorithm will first pick several candidate arms based on its picking rule, and then the human will choose one arm in this candidates to pull, based on his/her choosing rule. In this paper, the authors mainly consider the case that both the human and the algorithm are running UCB-type algorithms, i.e., their decisions are made based on the upper confidence bounds of all the arms (with different parameter $\\alpha_h$ and $\\alpha_a$). In this case, they show that when both $\\alpha_a$ and $\\alpha_h$ are large enough (e.g., larger than 1), then the regret of the system is at most the same as the worse one (either the human or the algorithm). On the other hand, if $\\alpha_h = 0$ (i.e., the human is totally greedy), then the regret of this system is linear with $T$, as long as the algorithm must provide at least 2 candidate arms to the human. Finally, the authors use some experimental results to demonstrate their theoretical findings. ",
            "strength_and_weaknesses": "Strength\n\n1. The human-algorithm collaborative framework plays an important role in machine learning researches.\n\nWeakness\n\n1. The algorithm seems to be useless in the system.\n\nWhen $\\alpha_h = 0$, it is showed that the regret is linear with $T$, even if there is an algorithm that controls the candidate arms. Though this regret can be better than the only-human case, we do not want to regard it as an efficient framework.\n\nWhen $\\alpha_h \\ge 1$, according to Theorem 1, the algorithm can only make the regret upper bound worse (or at least the improvement is limited).\n\nThen my question is, why we must use such a human-algorithm collaborative framework is these examples? Why not get rid of the algorithm and only let the human make decisions?\n\n2. The theoretical contribution of this paper is limited.\n\nThe theorems and lemmas in this paper seem trivial. I read the full proofs, but I do not see any new techniques or novel insights within them. They are just tranditional UCB-based analysis and there seem to be no technical challenges.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Some concerns about the proof of Theorem 2.\n\nWhat do you mean by the last inequality in Page 6? I can understand that when the first pull of arm 0 is less than that threshold, then the regret can be linear with $T$. But what if the first pull of arm 0 is larger than that threshold, while the second pull of arm 0 is bad enough so that the empirical mean is then smaller than that threshold?\n\nI think you may need to define $p_{i,\\epsilon}$ as the probability of \"the empirical mean of arm 0 is less than that threshold in some time step\".",
            "summary_of_the_review": "Overall, I do not think the contribution of this paper is enough for an ICLR submission. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4899/Reviewer_c8Yy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4899/Reviewer_c8Yy"
        ]
    },
    {
        "id": "9pj9FlgISPT",
        "original": null,
        "number": 2,
        "cdate": 1666632965674,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666632965674,
        "tmdate": 1666632965674,
        "tddate": null,
        "forum": "yLCCfzv_8Yx",
        "replyto": "yLCCfzv_8Yx",
        "invitation": "ICLR.cc/2023/Conference/Paper4899/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper is about a model of sequential decision-making in which the algorithm is only allowed to select a subset of the possible options, and a human user is then required to choose one among them. The authors analysed theoretically the case in which both the agents (algorithm and human) are both relying on a Hoeffding-like bound to select the options. Finally, they present some synthetically generated experiments to evaluate the performance of the UCB-like algorithm when different numbers of arms are shown to the user.",
            "strength_and_weaknesses": "I think that the motivating example provides an interesting setting in which the research is still somehow missing a deeper analysis. However, the arguments and analysis of the authors do not seem to be complete enough yet for publication at ICLR. In my opinion, the author should focus more on the setting, for instance analysing the lower bound on the regret before proposing algorithms.\n\nMoreover, I think that the regret defined by the authors does not reflect the fact that the user might have different goals. I think that the modeling in this aspect may be revised and improved.\n\nFinally, the experimental results are not convincing at all. Indeed, they are on a too narrow set of settings, and statistical significance is not provided in most of the cases.\n\nLemma 1: Increasing in K is a bit generic. What is the dependence on this parameter?\n\n\n\nMinor:\nRemove all the contractions like isn't and doesn't\n\nI think that in the literature review, you should also mention and discuss the corrupted bandit setting. For instance,\n\nGajane, Pratik, Tanguy Urvoy, and Emilie Kaufmann. \"Corrupt bandits.\" EWRL (2016).\n\nZhao, Heyang, Dongruo Zhou, and Quanquan Gu. \"Linear contextual bandits with adversarial corruptions.\" arXiv preprint arXiv:2110.12615 (2021).\n\nand literature therein cited.\n\nDefine a symbol for regret.\n\nPlease provide the comments on Theorem 1 after it has been stated.\n\nTheorem 1: It is not clear to me where did you use the fact that \\alpha_h > 1 and \\alpha_a > 1\n\nTheorem 2: Does this regret match the theoretical lower bound? Is it possible to show that this is the best one might do in this setting?\n\nAssuming the shaded areas are the confidence intervals for the analysed mean regret (it is not clearly stated in the text), I think that the results provided are not statistically significant.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear, and the novelty in terms of the setting is evident.\nThe authors did not provide the code for the experiments, even if they are described in detail.",
            "summary_of_the_review": "The paper presents a novel setting, but the authors did not succeed in providing a deep analysis of it.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4899/Reviewer_DhuT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4899/Reviewer_DhuT"
        ]
    },
    {
        "id": "Fa0SPiVlz_",
        "original": null,
        "number": 3,
        "cdate": 1666650441822,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666650441822,
        "tmdate": 1666651037505,
        "tddate": null,
        "forum": "yLCCfzv_8Yx",
        "replyto": "yLCCfzv_8Yx",
        "invitation": "ICLR.cc/2023/Conference/Paper4899/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper considers the problem of reward maximization in human-algorithm coorperation situation. The paper provides a policy and theoretical analysis. Then the paper shows some experiment results.",
            "strength_and_weaknesses": "Strength:\n* The problem of human-algorithm coorperation is interesting. The authors provide sufficient literature on such problem.\n\nWeaknesses:\n* The problem formulation is quite standard, which provides narrow space to make contributions.\n* Section~3.2 only introduces the part of a policy for \"human\", and I don't see the other part for \"algorithm\" (or assumptions on how the \"algorithm\" will behave). So I don't understand what the theoretical analysis and the regret results are for.",
            "clarity,_quality,_novelty_and_reproducibility": "Both the writing and the content of this paper is questionable.",
            "summary_of_the_review": "This paper is not ready to be published.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4899/Reviewer_PnxP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4899/Reviewer_PnxP"
        ]
    },
    {
        "id": "meQA4aPja9g",
        "original": null,
        "number": 4,
        "cdate": 1666670330963,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666670330963,
        "tmdate": 1669131177917,
        "tddate": null,
        "forum": "yLCCfzv_8Yx",
        "replyto": "yLCCfzv_8Yx",
        "invitation": "ICLR.cc/2023/Conference/Paper4899/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper considers joint human-algorithm system in multi-armed bandits. The authors explore multiple possible frameworks for human objectives and provide theoretical regret bounds. They also give experimental results which show how regret varies with the human decision-maker\u2019s objective and the number of arms.",
            "strength_and_weaknesses": "Strengths:\n\n1. The considered joint human-algorithm system in multi-armed bandits is very interesting and well-motivated.\n\nWeaknesses:\n\n1. While the considered joint human-algorithm system in multi-armed bandits is a very interesting and well-motivated problem, the formulation for this human-algorithm system in this paper is too simple. Specifically, the formulation just considers a simple combination of selecting the empirical best arm and selecting the optimistic best arm (according to the classic UCB algorithm). Under this simple formulation, the joint human-algorithm system does not bring too many challenges to the original multi-armed bandit problem. \n\n2. The theoretical analysis and results in this paper are similar to those in the classic multi-armed bandit works, e.g., the upper confidence bound-based analysis and the empirical myopic analysis. It is unclear to me what unique challenges the joint human-algorithm system impose on the theoretical analysis in this paper.\n\n3. The writing of this paper seems causal. There are several blanks and typos.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The considered joint human-algorithm system in multi-armed bandits is a very interesting and novel problem. But the theoretical analysis and techniques in this paper are similar to those in classic bandit works. The authors present experimental results, and do not provide the code.",
            "summary_of_the_review": "This paper considers a very interesting and well-motivated problem, i.e., a joint human-algorithm system in multi-armed bandits. But the formulation considered in this paper is too simple, which makes the theoretical analysis in this paper too standard (very similar to classic UCB analysis). The unique challenge of joint human-algorithm system is not well captured and analyzed in this paper. The writing of this paper looks causal, and needs to be improved. For these reasons, I give rejection.\n\n=========\n\nThank the authors for their response. I think this problem is well-motivated and worth a deeper analysis. The current formulation and analysis is too simple to fully capture the interesting insights and unique challenges of human-algorithm decision making. I think this work can be significantly improved by using theoretically deeper formulation and analysis. Therefore, I keep my score.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4899/Reviewer_Skb5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4899/Reviewer_Skb5"
        ]
    }
]