[
    {
        "id": "Du3ZGCDjH83",
        "original": null,
        "number": 1,
        "cdate": 1666689604842,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666689604842,
        "tmdate": 1666689604842,
        "tddate": null,
        "forum": "9D5FH6LFbRu",
        "replyto": "9D5FH6LFbRu",
        "invitation": "ICLR.cc/2023/Conference/Paper6526/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a general framework Functional Risk Minimization (FRM), a general framework for scalable training objectives which results in better performance in small experiments in regression and reinforcement learning. FRM model each data point (x_i, y_i) as coming from its own function f_\\theta_i. The authors also show that FRM can be regraded as finding the simplest model that memorizes the training data, providing an avenue towards understanding generalization in the over-parameterized regime.\n\n",
            "strength_and_weaknesses": "Pro: The paper rethink the common assumption in machine learning community and proposes a new comprehensive model that can subsumes classic Emipirical Risk Minimization for many common loss functions. \nCons: 1) The computation cost of FRM in its current form is high. 2) Maybe the authors can discuss more why the FRM is really crucial and why we could not just modify the classic ERM for instance and get similar performance. ",
            "clarity,_quality,_novelty_and_reproducibility": "It is well-written article with high quality and novelty. I do not check the reproducibility of this paper. ",
            "summary_of_the_review": "The paper is marginally above the acceptance line. I would suggest to accept this paper. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6526/Reviewer_EeLk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6526/Reviewer_EeLk"
        ]
    },
    {
        "id": "JCWrLInMCJ",
        "original": null,
        "number": 2,
        "cdate": 1666741160844,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666741160844,
        "tmdate": 1666741160844,
        "tddate": null,
        "forum": "9D5FH6LFbRu",
        "replyto": "9D5FH6LFbRu",
        "invitation": "ICLR.cc/2023/Conference/Paper6526/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a new basic data generation framework where each data point is associated with a function and the `noises' are assumed to be from the variation of its function rather than its output used in classical ERM.  Two corresponding models are proposed for unsupervised learning (generative model) and supervised learning.  ",
            "strength_and_weaknesses": "Strength\n\n1. the idea of associating each data point with a function is interesting.\n2. the paper is well-written and examples are given to show the motivation and clear some concepts.\n3. the functional risk minimization may extend the existing ERM to a new era.\n\nWeakness\n\n1.  Even the authors claims there are some difference between the proposed FRM to the Bayesian learning on page 2, it is still confusing to me that the proposed model, at least the functional generative model, is just a kind of hierarchal Bayesian model as illustrated in Fig 1. The authors claim that 'FRM only use a single parameter at test-time'. It looks weird because FRM believes every data point is associated with its own function f_{\\theta_i} then why and how you use single \\theta at test time? like generate new data? \n\n2. The similar thing happens to FSM for supervised learning. When training using (1) and predicting using single \\theta^*, the objective function for training and test will be different which implies that the assumptions behind training and test are different. Is that OK? Note that this is not happened in ERM where the assumptions behind training and test are consistent. Is there any effect from such property? \n\n3. There is no experimental evaluation on the proposed functional generative model in section 5. \n\n\n ",
            "clarity,_quality,_novelty_and_reproducibility": "Overall, the paper is clear and the idea is interesting, but there are some parts need more discussions or explanations.  ",
            "summary_of_the_review": "This paper proposes an interesting and valuable idea to extend the classical ERM to FRM. The benefits are well introduced. However, there are sill some confusions of the concepts, like the relation with hierarchal Bayesian. Please see Strength and Weakness for more details. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6526/Reviewer_6yNo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6526/Reviewer_6yNo"
        ]
    },
    {
        "id": "-oFAPwV8CQA",
        "original": null,
        "number": 3,
        "cdate": 1667486757676,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667486757676,
        "tmdate": 1667493283373,
        "tddate": null,
        "forum": "9D5FH6LFbRu",
        "replyto": "9D5FH6LFbRu",
        "invitation": "ICLR.cc/2023/Conference/Paper6526/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents a novel framework for supervised learning problems. First, it introduces functional generative models which represent $ P(x,y)$ in terms of a latent variable $ \\theta$ that is sampled independently of $ x $ and then determines $ y $ as a function $ f_\\theta(x)$. This is contrasted to a standard additive noise model, where $ y = f_\\theta(x) + \\epsilon$. Using this noise model, the paper proposes functional risk minimization (FRM) as an objective to find the maximum likelihood parameter $ \\theta^*$ and proposes an approximate algorithm that relies on approximating an integral over all parameters by a local Laplace approximation.  ",
            "strength_and_weaknesses": "### Strengths\n\n1. This paper presents a very interesting and (to my knowledge) novel take on representing noise in a learning framework. This could be highly impactful as it may allow for more easily dealing with the variation in real datasets than standard MLE in additive noise models. \n\n2. The empirical results on linear regression with non-uniform noise seem to be strong, demonstrating that as the noise distribution changes, FRM begins to outperform ERM. \n\n### Weaknesses\n\n1. It is not clear how closely the implementable algorithm relates to the theoretical presentation and derivations. Equations 7 and 8 seem to be the core algorithmic contribution of the paper, but they are never formally derived and it is highly unclear under what conditions they will actually relate to the population objective. \n\n2. The implementable algorithm as proposed does not seem to be scalable. In particular, it requires both a significant approximation to integrate over parameters and then uses Hessian information that could be difficult to get for large models. This is born out by the fact that all the experiments, while interesting, are quite small in scale. \n\n3. There is no formal argument made as to why or when FRM will outperform ERM. In fact, there are no arguments at all showing that (a) the FRM minimizer will achieve low loss, (b) the finite-sample version of FRM approximates the population variant, or (c) the finite-sample FRM minimizer will achieve low loss.    \n\n4. The presentation is confusing.\n\n    a. The use of \"ERM\" is non-standard and confusing. ERM, as used in foundational work like [1], simply refers to minimizing an empirical loss as a proxy for an expected loss. There is no mention of any particular assumption about additive noise in the ERM principle. Moreover, the entire reason to use the ERM term is to contrast it with learning objectives like structural risk minimization. This paper instead uses ERM to refer to the noise model induced by ERM with particular loss functions by viewing them as MLE. It would perhaps be more clear to frame the novelty of the approach as replacing MLE under an additive noise model with a novel MLE under the functional latent variable noise model.  \n\n    b. Similarly, FRM is often used to refer to the noise model, which is in fact the FGM under the nomenclature introduced in the paper. The paper would be much improved by being more clear about the difference between the FGM modeling assumption and the FRM learning objective.\n\n    c. The FRM learning objective is never clearly and explicitly layed out. When the authors say FRM, what implementable algorithm are they explicitly referring to? This needs to be more clear.\n\n\n[1] Vapnik, V. (1991). Principles of risk minimization for learning theory. Advances in neural information processing systems, 4.\n\n\nMinor: There are a few typos throughout the paper. For example, in the abstract \"regraded\" should be \"regarded\". In the \"FGMs encode...\" paragraph on page 4, many spaces are missing after periods. In the Table 1 caption \"Furthermoe\" should be \"furthermore\". ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity is poor, as explained above.\n\nThe novelty and potential significance are high.\n\nThe code is provided in the supplement for reproducibility purposes, but I have not checked it.",
            "summary_of_the_review": "I think this paper clearly has some interesting and promising ideas. However, as currently presented I cannot support acceptance because of the significant issues connecting the actual algorithm to the motivation, lack of basic theory, and general lack of clarity.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper6526/Reviewer_vBxE"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper6526/Reviewer_vBxE"
        ]
    }
]