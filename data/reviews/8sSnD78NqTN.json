[
    {
        "id": "hnbmQDCOO8",
        "original": null,
        "number": 1,
        "cdate": 1666326039343,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666326039343,
        "tmdate": 1668623244832,
        "tddate": null,
        "forum": "8sSnD78NqTN",
        "replyto": "8sSnD78NqTN",
        "invitation": "ICLR.cc/2023/Conference/Paper2052/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper addresses the problem of inverse constraint learning, whose goal is to learn the unknown (soft) constraints that the expert demonstrations obey in a given expert dataset, assuming that the reward function is known. The authors propose a novel method named ICL, which learns a constraint function in a way that the total constraint is bounded for the expert demonstrations but maximized for agent behaviors. They demonstrate that their proposed method outperforms two baselines on three environments.",
            "strength_and_weaknesses": "**[Strengths]**\n- The paper is well-written and easy to understand.\n- The proposed approach is theoretically well-motivated and sensible.\n- The experiments include ablation studies.\n\n**[Weakness]**\n- The main weakness of the paper is its limited empirical evaluation. The authors tested their method only on two toy environments (GridWorld and CartPole) and the HighD environment, which also seems relatively simple as it has a 1D action space (and presumably a 2D state space). Given the complexity of the method, it would be desirable to include more extensive comparisons on diverse, more challenging domains (e.g., constrained MuJoCo environments as in the ICRL paper).\n\n**[Questions]**\n- Is the constraint function $c$ in the paper a per-step function (i.e., $c(s_t, a_t)$) or a per-trajectory function ($c(\\tau)$)? If the former is the case, there should be infinitely many ways to assign per-step constraints to the expert trajectories because the only constraint is that their sum should be bounded by $\\beta$. How does the method deal with this?\n- I didn't understand the CartPole figures in Fig. 10. What do the \"a=0\" and \"a=1\" lines mean? What are the axes?\n- How is the state space defined in the HighD environment? How does the agent observe the cars in front of it? How are the expert data collected?",
            "clarity,_quality,_novelty_and_reproducibility": "**[Clarity & Quality]**\n- The paper is mostly well-written and easy to understand.\n- Detailed descriptions of the expert demonstrations used for their experiments are lacking.\n- It would be better to include the experimental details (in Appendix C.1) in the main paper.\n\n**[Novelty]**\n- The proposed method is novel to my knowledge.\n\n**[Reproducibility]**\n- The authors have released their code.",
            "summary_of_the_review": "While their proposed method is well-motivated and sensible, I cannot recommend acceptance in its current form due to its limited experimental evaluation. I would be happy to raise my score if the authors address my concerns above.\n\n-------------(11/16 Update)-------------\n\nI raised my score from 5 to 6 as the response addressed my initial concerns.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2052/Reviewer_5hKt"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2052/Reviewer_5hKt"
        ]
    },
    {
        "id": "2yqgnCWAtkf",
        "original": null,
        "number": 2,
        "cdate": 1666484534672,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666484534672,
        "tmdate": 1669011109238,
        "tddate": null,
        "forum": "8sSnD78NqTN",
        "replyto": "8sSnD78NqTN",
        "invitation": "ICLR.cc/2023/Conference/Paper2052/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposed an inverse RL algorithm for recovering soft constraints from expert trajectories. The algorithm takes a nominal reward function, and expert trajectories as input, and outputs a recovered constraint function that best matches the behavior of the expert trajectories. The proposed algorithm interleaves between two steps: 1) solving a constrained RL problem with the latest constraint function, and 2) adjusting the constraint function to maximize the constraint value among all the previously obtained policies, subject to that expert trajectories satisfying the constraint. A theorem is provided to prove the convergence to the expert policy and a practical algorithm is provided that shows empirically successful results on three constraint learning tasks. The proposed method shows better performance in terms of constraint satisfaction as well as similarity to expert trajectories than baseline methods on the selected tasks.",
            "strength_and_weaknesses": "Strengths:\nThe problem of learning constraints is an important one and a solution to this problem can be impactful\nThe theoretical framework is helpful in gaining insight of the algorithm as well as providing theoretical justifications for the proposed algorithm\nThe proposed method shows decent performance on the selected tasks\n\nWeaknesses:\nThe requirement of known reward function and single constraint is understandable but could limit the applicability of the algorithm to real-world problems.\nThe tasks used in the work are relatively simple.\nThe proposed computational algorithm seems quite complex with various tricks, such as the reweighting scheme, the two-stage constrained optimization with different weights, etc. This makes it potentially difficult to be applied to a wider variety of tasks, especially ones that are notably more complex.\n",
            "clarity,_quality,_novelty_and_reproducibility": "good",
            "summary_of_the_review": "My high-level concerns can be seen in the weaknesses section. One more detailed comment: the baseline method ICRL was applied to several more difficult continuous control tasks. It would more convincing if the proposed method was compared on similar tasks with the baselines.\n\nAlso, it is mentioned that the proposed method requires more training time than the baseline methods but I didn't find any numbers (I might have missed it). Could you provide some more details about how much slower it is?\n\nIn general the proposed method seems reasonable and attempts to solve an important problem. If the concerns above could be addressed it can be a good contribution to the ML community.\n\n\n==============\npost rebuttal: I have updated the score from 5 to 6 after reading other reviews and the authors' rebuttal.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2052/Reviewer_3D7X"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2052/Reviewer_3D7X"
        ]
    },
    {
        "id": "DgAhthx-qU",
        "original": null,
        "number": 3,
        "cdate": 1666555264389,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666555264389,
        "tmdate": 1666555264389,
        "tddate": null,
        "forum": "8sSnD78NqTN",
        "replyto": "8sSnD78NqTN",
        "invitation": "ICLR.cc/2023/Conference/Paper2052/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a novel framework to learn soft constraints for ICL. The paper gives a theoretical formulation with proof of convergence, and then provides a practical algorithm with relaxation on the theoretical formulation and several techniques. Experiments on synthetic and real-world environments show improvements of the proposed method compared to baselines. Some ablation studies are provided to verify the design choices of the algorithm.",
            "strength_and_weaknesses": "Strength:\nThe paper provides a novel framework with a theoretical formulation and a practical algorithm with reasonable relaxations. It also provides empirical results to show the improvements.\n\nWeaknesses:\n1. For the definition of 'soft' constraint, as described in future work, I also feel that the constraint through expectation is not as useful as constraint through probability for stochastic environments. Can the author give more explanation of where the current setting could be applied in real life?\n\n2. It would be great if the author could explain more about how this 'soft' constraint is guiding the algorithm design. \n\n2. The experiment results seems not strong enough to me. There is only one real-work environment and the setting is also relatively simple. It would be good to provide more complex experiment setups (e.g. robotics manipulations).",
            "clarity,_quality,_novelty_and_reproducibility": "The overall clarity, quality, and novelty are good. Can't comment on the reproducibility.",
            "summary_of_the_review": "I think the paper provides an interesting framework with a practical algorithm. Each part of the paper is 'good' but not 'great' with the weaknesses mentioned above. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2052/Reviewer_8Rs7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2052/Reviewer_8Rs7"
        ]
    },
    {
        "id": "o5rkADQXJ3",
        "original": null,
        "number": 4,
        "cdate": 1666655506616,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666655506616,
        "tmdate": 1666655506616,
        "tddate": null,
        "forum": "8sSnD78NqTN",
        "replyto": "8sSnD78NqTN",
        "invitation": "ICLR.cc/2023/Conference/Paper2052/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes a method for learning soft constraints in sequential decision making problems that can be modeled as MDPs, under the assumption that the entire MDP model is known (both transition probabilities and the reward function), but a constraint on the state-action space exists that is known only to a decision maker who can provide optimal decisions that respect this constraint, and the objective is to recover the constraint from the observed decisions of the expert. Empirical evaluation on several domains demonstrates that the proposed method is far superior to estimating the constraint than two existing methods. ",
            "strength_and_weaknesses": "The paper proposes a principled way of addressing the problem, borrowing from the computational principle and machinery of inverse reinforcement learning (IRL) methods, and the empirical evaluation appears to be convincing. The limitation that there is only one constraint is probably not significant, as this constraint could potentially be an arbitrarily complex function on state/action pairs. (Unlike many IRL algorithms, where the learned reward function is linear in the vector of parameters.) It appears that the chosen parametric form of the constraint function is a neural net with two hidden layers of 64 units each, ReLU activations, and final output with a sigmoid activation function (Table 5). Why this form, and is it really sufficient to represent arbitrary functions? What about the constraints in the chosen experimental environments, how well does it represent its constraints? Maybe learning the constraints directly from the known functions by means of supervised learning could answer this question, and also effectively provide a lower bound on the MSE that this method can provide?  \n\nAnother thing I was not clear about is the effect of the initial form of the constraint (that is, c in Equation 3 on the very first iteration of the algorithm). Was it completely random in the computational experiments, and does its value matter? In other words, does the algorithm always converge to a global minimum, or there are local minima?\n\nSome minor typos:\nP.1: \"are therefore are\" -> \"therefore are\"\nP.3: \"in an other line of work\" -> \"in another line of work\"\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed method appears to be novel, and very different from the few previous methods known for solving this class of problems. The paper is written very well and is largely self-contained. I would suggest, though, to explain in plain text the logic behind the constraints in the experimental environments. For example, what is the meaning of the constraints on the cart pole systems in Fig. 10, and what is the optimal policy under them? It is difficult to figure it out just by looking at the plots of the constraint function. (And, it does not help that the coordinate axes do not have labels or dimensions.)",
            "summary_of_the_review": "The paper proposes a novel method for recovering soft constraints in sequential decision problems, where the MDP model is known, and expert demonstrations are available under the unknown constraint. The empirical evaluation demonstrates that the method has much lower MSE in recovering the unknown constraint that two existing baseline methods.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2052/Reviewer_EuC1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2052/Reviewer_EuC1"
        ]
    }
]