[
    {
        "id": "LzxdgUztQsH",
        "original": null,
        "number": 1,
        "cdate": 1666253595450,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666253595450,
        "tmdate": 1669278098784,
        "tddate": null,
        "forum": "JTGimap_-F",
        "replyto": "JTGimap_-F",
        "invitation": "ICLR.cc/2023/Conference/Paper2371/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes rarity score, a new evaluation metric for generative models, in order to measure the \u201crarity\u201d or \u201cuniqueness\u201d of images. The metric builds on prior work such as precision/recall, coverage/density and realism scores that use nearest neighbor manifolds in pretrained VGG-like space to evaluate generative models. The rarity metric of a given image is the radius of the smallest nearest-neighbor manifold that contains the image, provided there exists such a neighborhood. The paper further proposes an extension of rarity score called RS-p to evaluate the rarity of a given generative model. \n\nQuantitative Experiments show that StyleGan2 scores the highest rarity amongst the considered generative models. The authors also perform a number of experiments to qualitatively show rare images. On training datasets, they show that diverse and uncurated datasets like Celeb-A HQ and FFHQ, have a higher proportion of rare images. Amongst generated samples, rare images consist of colorful faces and oil paintings. The rare images obtained also are dependent on the type of feature extractor considered (CLIP, VGG and DINO)\n",
            "strength_and_weaknesses": "**Strengths**\n* While current work on generative model evaluation focuses on sample fidelity and diversity, this paper explores an interesting aspect that is the ability of a model to focus on modeling \u201cniche\u201d images of a dataset.\n* The paper is easy to read, is self-contained in the sense that it provides all the required background for the related metrics. The qualitative experiments are extensive and interesting.\n\n**Weaknesses**\n\nMy main comment is that the quantitative experiments showcasing the benefits of the \u201crarity score\u201d can be more rigorous. See below for detailed feedback.\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Quality**\n\nI think the quality of experiments can be improved. \n\n**Major: Comparisons between negative realism score**\n\nFrom Fig 5), one can see that the realism score is inversely correlated with the RS-1 metric, suggesting that the negative realism score may also be used as a \u201crarity\u201d metric. It would be nice if authors could conduct user studies that show that the \u201crarity score\u201d is a better measure of rarity as compared to the \u201cnegative realism score\u201d.\n\nAs a suggestion, the authors can repeat the \u201cuser study\u201d done in Section 4.1, but with the \u201cnegative realism score\u201d as a baseline. Alternatively, the authors could also take the top x% rare images as given by both the \u201crarity score\u201d and \u201cnegative realism score\u201d and conduct a 2AFC test.\n\n**Major: Handling of Out of manifold**\n\nIf for a given sample, a nearest neighborhood manifold cannot be found, then the sample is given an undefined score. How is this handled in the computation of RS-1 score, are the out-of-manifold samples ignored in the cardinality? \nDoes it make sense to clip it to a lower bound that is defined? (for example, 0.0). In that case, one could just use the mean rarity score of the generated samples. In any case, more details on this are required.\n\n**Major: User studies across models**\n\nThe authors perform user studies for one specific GAN, StyleGAN-FFHQ. I think it is also necessary to show that for a given pair of GAN models (A, B), if rarity(A) >rarity(B), the human preference is in accordance with the proposed rarity score.\n\n**Major**\n\n* How does sample quality across different generative models correlate with the rarity metric? Do the authors observe emprically that GAN models with better fidelity also get better rarity scores? It would be nice to show quantitative experiments comparing the relationship between precision/recall, FID and rarity scores for diffferent GAN models.\n* \"Group 10 (the highest group) and Group 5 (middle group), the alignment is lesser than that of Group 10 and Group 1 (the lowest group) and the portion of answer\". These terms are introduced in the main section without any proper defintions. Given that this a paper focusing on a new metrics, I would expect the user studies to be in the main section.\n* In Section 4.4, the authors qualitatively show that on using different feature extractors, different images can be considered rare. Quantitatively, for example in Figure 7, does the ranking of GANS also change depending on the feature extractor?\n* In Figure 3, 30% real samples are assigned to be out-of-manifold seems pretty high. Can the authors rationalize why this is a good choice? Which dataset was this done on?\n* In Figure 5, RS-1 score increases monotonically with the truncation parameter. At which truncation parameter on the x-axis does the correlation breaks?\n\n**Not necessary but nice to have**\n\n* The authors can consider moving the choice of k to the experimental section\n* It would be nice to keep the y-axis scale fixed across all three subplots in Figure 5b)\n* It would be nice to have some experiments on samples from diffusion models.\n\n**Clarity**\n\n* Page 2, paragraph 2: and helps generative models synthesize rare samples without significantly losing fidelity. I think this is an oversell. The metric is used just to evaluate the samples.\n* on top of the various feature spaces with different points of view. What does \u201cfeature space with different points of view mean?\u201d. Please modify this sentence.\n* LPIPS(Zhang et al, 2018) can be done both instance wise and sample-wise by just aggregating.\n* Why is theta is introduced in RS-p, since Phi_g itself refers to samples from that of a generative model in Eq 9.\n\n**Reproducibility**\nCode has been promised but it would be nice if authors can provide code snippets or pseudocode.\n\n**Typos**\n\nI spotted some typos. It did not affect my rating but I urge the authors to fix these:\n\n* the effect of the radius is depressed by the effect of the distance between the real and the fake sample. -> Maybe depressed is not the right word here?\n* it will be helpful to use rarity score along with the fidelity metric, for selecting images or models in a broader aspect -> I think you can remove broader aspect here.\n* Within and outside because the training dataset contains a lot of noisy images for even human to accept. -> i think you can remove even human to accept.\n* But also it is -> but also because it is\n* alleviates the open challenge problem -> alleviates the open problem\n* Generation model performance -> generative model performance\n* we can think the sample is extraordinary -> the sample is rare\n* is involved in -> is within\n* allows us to maintain  -> ensures\n* Pg 4, towards the end, real manifold manifoldk(\u03a6r) -> mainfoldk should be bolded\n* 30k of real images to approximate the real manifold and calculate the rarity of 10k fake images ->  no of\n* answered to -> answered\n* generates images more conservatively -> ",
            "summary_of_the_review": "Overall, I think this line of work is promising and interesting. I have some concerns with the experiments and details of the paper. I will consider changing if the authors address the concerns and update the draft.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2371/Reviewer_tiDM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2371/Reviewer_tiDM"
        ]
    },
    {
        "id": "iTFbktXgy6",
        "original": null,
        "number": 2,
        "cdate": 1666587423329,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666587423329,
        "tmdate": 1666587709306,
        "tddate": null,
        "forum": "JTGimap_-F",
        "replyto": "JTGimap_-F",
        "invitation": "ICLR.cc/2023/Conference/Paper2371/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper targets on a fundamental problem in assessing the diversity or rarity of images, especially generated images. The authors first propose a novel evaluation metric, called Rarity Score (RS) to measure image-wise uncommonness, and based on RS, they further propose a model-wise rarity metric RS-p(\\theta). The authors show the effectiveness of the proposed metrics through various experiments including a user study.",
            "strength_and_weaknesses": "strength:\na)\tThe problem studied in this paper is of high value. There are not many works addressing this problem in current literature. A precise diversity metric is of high demand.\nb)\tThe proposed concept is new, and the implementation is not very complex.\nc)\tThe experiments can mostly support the effectiveness of the proposed metrics.\nd)\tThe organization of the paper is well, and the writing is good.\n\nWeakness & Questions\na)\tThe proposed metrics do not consider the quality of the generated images. The rarity score is trivially high when the generated images are of low quality. The results of CelebA-HQ with Top 8 in Figure 6 can reflect it. Therefore, the proposed metrics may be biased in this situation.\nb)\tThe density of the real images is not considered in the proposed method. Consider there are two real images, i1 and i2, where the feature-space radius r1 of i1 is much larger than r2 of i2, that is to say, i1 is more rare than i2. Assume that a fake image j which has similar semantics to i1 is in both the spheres of i1 and i2. The rarity score of j is equal to r2 as r2 < r1. The fake image j is then considered as a non-rare image by the proposed metric, which is not consistent with the rarity of real image i1. This may hint the author to consider weighing samples by the density of the related real images.\nc)\tThe hypothesis that \u201cordinary samples would be closer to each other whereas unique and rare samples would be sparsely located in the feature space\u201d, may need some numerical statistics to support.\nd)\tAre the proposed metrics robust to the shifts in the input images? (noise, blur, resolution, fidelity, etc.) \ne)\tI think the results of \u201cMiddle\u201d rarity score in AFHQ-Wild in Figure 6 are the most diverse.\nf)\tFrom the result of Figure 24, FID seems more accurate regarding correlation (despite negative).\ng)\tWhat does the user-preferred backbone reflect? VGG is better than CLIP? Why?\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is clearly written with good quality. Reproducibility is good, more can refer to above comments. \n",
            "summary_of_the_review": "The studied problem in this paper is important for the vision field. The concept of \u201crarity score\u201d is interesting. The proposed metric may be impactful if it has more large-scale empirical studies to verify it. Although there are some issues in current version, this is an interesting paper.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2371/Reviewer_vLSP"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2371/Reviewer_vLSP"
        ]
    },
    {
        "id": "rBJko0c5h5J",
        "original": null,
        "number": 3,
        "cdate": 1666684023906,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666684023906,
        "tmdate": 1666684023906,
        "tddate": null,
        "forum": "JTGimap_-F",
        "replyto": "JTGimap_-F",
        "invitation": "ICLR.cc/2023/Conference/Paper2371/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper pays attention to the vital problem in image generation --- the lack of evaluation metrics. Fidelity and diversity are two common metrics to evaluate synthetic images, while this paper considers another aspect, proposing a metric to evaluate the rarity of synthetic images. Specifically, two metrics are considered --- instance-wise rarity and model-wise rarity. Also, extensive experiments are conducted to show that the proposed metrics are reasonable. Moreover, human studies are conducted, which is more convincing.",
            "strength_and_weaknesses": "Strength:\n\nS1: This paper considers an important problem in image generation, proposing a metric to evaluate the rarity of synthetic images.\n\nS2: Extensive experiments are conducted, showing that the proposed metric is reasonable. In addition, user studies make it more convincing.\n\nWeaknesses:\n\nThe author only considers the images generated by StyleGAN2, some more advanced models should be considered, in particular the models that employ texts to control image generation. Also, rarity is similar to the outlier, so I think the auth should talk about the relationships between them. Plus, can out-of-distribution or novelty detection approaches be used to evaluate instance-wise rarity?",
            "clarity,_quality,_novelty_and_reproducibility": "Basically, the paper is clear and we can easily follow the idea. Also, the proposed metric is reasonable and novel to me. I think we can easily reproduce it.",
            "summary_of_the_review": "The paper considers an important problem in image generation, proposing a metric to evaluate the rarity, which is novel to me.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2371/Reviewer_3DoB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2371/Reviewer_3DoB"
        ]
    },
    {
        "id": "5OEWQuW8Cj",
        "original": null,
        "number": 4,
        "cdate": 1666698968534,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666698968534,
        "tmdate": 1666698968534,
        "tddate": null,
        "forum": "JTGimap_-F",
        "replyto": "JTGimap_-F",
        "invitation": "ICLR.cc/2023/Conference/Paper2371/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a new evaluation metric for image generation using generative and diffusion models: rarity score. The model evaluates how rare (uncommon) the generated images are judging from the standard distribution. The instance-wise rarity score is based on k-NN and the model-wise rarity score is based on CDF. The experiments show its novelty as compared to the previous metrics and the scores are shown to align with the human perception.",
            "strength_and_weaknesses": "[Strength]\n+ The proposed metric, rarity score, is a novel concept.\n+ The validity of the proposed metric is quantitatively and qualitatively demonstrated.\n+ The metric has multiple applications such as rarity specification when generating images or evaluation of the generation models.\n+ The source will be shared.\n\n[Weaknesses]\n- Although it is already shown how the proposed model is different from FID and Realism scores, I still suspect the rarity score is counter correlated with the realism score. The authors might want to discuss the difference from it with facts.\n- Limitation is not discussed well. Are there any specific cases that have high rarity score but seems common to humans and vice versa? In other words, the authors might want to discuss unsuccessful cases of the proposed model.\n- Some discussions on the difference from the previous models are already given, but the motivation why a new metrics is still needed is not clear yet. Can the authors show the cases where the previous metrices do not work well but the proposed one does?\n- The experiments include humans. It was not clear whether the authors got permission of the IRB of their intuition.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Very clear. Very carefully written, organized, and discussed. No concerns on novelty and reproducibility.",
            "summary_of_the_review": "Please see my comments above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Responsible research practice (e.g., human subjects, data release)"
            ],
            "details_of_ethics_concerns": "It was not clear whether the authors got permission of the IRB of their intuition.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2371/Reviewer_8Kcg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2371/Reviewer_8Kcg"
        ]
    }
]