[
    {
        "id": "UB89y9TcA_",
        "original": null,
        "number": 1,
        "cdate": 1666585412691,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666585412691,
        "tmdate": 1666649973685,
        "tddate": null,
        "forum": "UMERaIHMwB3",
        "replyto": "UMERaIHMwB3",
        "invitation": "ICLR.cc/2023/Conference/Paper1258/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposed a framework to perform weight sharing and pruning across two transformer backbones and within the same transformer backbone. The framework is evaluated on vision and language tasks, including Referring Expression Comprehension (REC), Visual Question Answering (VQA), and Object Detection. The results show that the proposed framework achieves a prominent trade-off between number of parameters and accuracy.",
            "strength_and_weaknesses": "Strength\n- The paper is well organized and convincing\n- The paper proposes a novel framework for weight sharing and pruning of transformer backbones\n- The method achieves a prominent trade-off between the number of parameters and the accuracy\n- The method is tested on various vision and language grounding tasks, including Referring Expression Comprehension, Visual Question Answering, and Object Detection\n\nWeakness\n- The paper does not provide a detailed analysis of the proposed method\n- Also, they only share part of hyper-parameters which makes the result hard to reproduce\n- Lack of justification for experimental setup, hyper-parameter selection for model and baseline.",
            "clarity,_quality,_novelty_and_reproducibility": "This paper shows  a clear description of the proposed framework and the evaluation of the method on several vision and language tasks and the framework is evaluated on several vision and language tasks.\nFor reproducibility, it seems hard to reproduce the method without public code.\n",
            "summary_of_the_review": "The paper is well written and easy to follow and the proposed method is clear and well motivated. \nThe experiments are well designed and the results are convincing, but the paper could provide a more detailed analysis of the proposed method.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1258/Reviewer_p7Rq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1258/Reviewer_p7Rq"
        ]
    },
    {
        "id": "cDBJ7Ol8AL",
        "original": null,
        "number": 2,
        "cdate": 1666607083906,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666607083906,
        "tmdate": 1666607121272,
        "tddate": null,
        "forum": "UMERaIHMwB3",
        "replyto": "UMERaIHMwB3",
        "invitation": "ICLR.cc/2023/Conference/Paper1258/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper introduces a novel compression algorithm for transformer-based vision and language models. It trains a hypernetwork to identify whether a network weight is able to share across multimodal backbones and across layers within one backbone or is able to be pruned off the original networks. Experiments show that the proposed model compression algorithm can reduce up to 40% of parameters without significant loss of accuracy in several downstream tasks.",
            "strength_and_weaknesses": "1. Strengths:\n\n+ The paper addresses an important topic and the proposed algorithm is well motivated. The paper is well written making it easy to follow.\n+ Experiments are done carefully and the results are convincing. \n\n2. Weaknesses:\n\n+ Some details are missing in the current version. In page 4, the authors divide a backbone into several blocks to identify whether network weights in those different blocks can be shared. By what criteria did you divide into these blocks? What is the optimal number of blocks? There is no justification by experiments or intuition for this in the paper. \n\n+ In page 4, after Eq. 5, the final W_q^vl is a combination of only two elements since s^l and s_{t_l} are binary. This makes the statement inaccurate.\n\n+ In page 6, the authors mentioned that they only used a subset of training data to train HN. How does this affect the compression performance? What proportion of the subset is sufficient? Again, there are no justifications for why the authors do this.\n+ The experiments conducted on the much smaller image size (224x224) compared to the original baselines, which raises doubts about the baselines' results.\n\n+ Have the authors tried methods such as grid search to find the best hyperparameters of the backbone for that small image input?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and the proposed method is clearly explained.",
            "summary_of_the_review": "The paper is well written and the proposed method is clearly explained.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1258/Reviewer_U8mM"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1258/Reviewer_U8mM"
        ]
    },
    {
        "id": "zclfXDZ23A9",
        "original": null,
        "number": 3,
        "cdate": 1666662058065,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666662058065,
        "tmdate": 1666662058065,
        "tddate": null,
        "forum": "UMERaIHMwB3",
        "replyto": "UMERaIHMwB3",
        "invitation": "ICLR.cc/2023/Conference/Paper1258/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper studies the weight pruning and weight sharing for image-text retrieval model. Contrary to previous works that applies the pruning and sharing on the layer level, the main idea of this paper is to apply weight sharing and weight pruning on the weight level. Therefore, the pruned model could achieve better compression rate and performance. The pruning and sharing is controlled by a hyper network, which is trained jointly with the image-text retrieval model. The proposed approach achieves better performance and better compression rate than the previous state-of-the=art.",
            "strength_and_weaknesses": "The paper is interesting to read and the proposed idea is novel.\nI just have several quick questions and comments.\n1. The proposed approach seems could be apply not only on the image-text retrieval model, but also on single modal models (e.g. image only model and text only model). I wonder why would the author choose the image-text retrieval model?\n2. Just curious, as the ConvNet models also shares unified structure across the model, would the proposed approach work on the ConvNet models?\n3. How to set the base layers? Is it set heuristically?\n4. I might miss some details, but what is the 'z' in Eq.8 in implementation?\n5. Just curious, how to enforce the Eq.6 and Eq.7 during training?\n6. I wonder did the author observe any training instabilities for image-text retrieval model pre-training? ",
            "clarity,_quality,_novelty_and_reproducibility": "Although I am not the expert in model pruning, I think this paper is novel and should attract multiple readers in model pruning and vision+language communities.\nAs I didn't have experience in implementing the model pruning approach, I cannot judge the reproducibility of this paper.",
            "summary_of_the_review": "Given the improved performance and the novelty, I would recommend the rating of 8.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1258/Reviewer_FNmr"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1258/Reviewer_FNmr"
        ]
    }
]