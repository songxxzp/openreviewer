[
    {
        "id": "x20tWAkXjtS",
        "original": null,
        "number": 1,
        "cdate": 1666725250170,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666725250170,
        "tmdate": 1669837375323,
        "tddate": null,
        "forum": "99RpBVpLiX",
        "replyto": "99RpBVpLiX",
        "invitation": "ICLR.cc/2023/Conference/Paper2092/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes an automatic method to look for hard subpopulations and spurious correlations in datasets,  by training SVMs in CLIP space to predict whether the original model will predict the data point correctly. Experiments show their method identified hard examples.\n",
            "strength_and_weaknesses": "Strengths:\nThe paper proposes an automatic method to look for hard subpopulations and spurious correlations in datasets.\nThey performed extensive experiments to show their method identified the hard subpopulations and spurious correlations.\n\nWeaknesses:\nThe captions and the images in result figures do not seem to match well:\nIn figure 1 easy exemplars, the man in the third image has a beard but the caption is \"a photo of a old man who has no beard\" \nIn figure 7 dog easy exemplars, the caption is \"a photo of a white dog on the grass\u201d but the images do not match\nIf the CLIP model is pretrained, based on the observation above, linear SVM seems not to be strong enough to separate the \u201ceasy\u201d and \u201chard\u201d examples for the original model\nThe writing of this paper prevents readers from understanding the paper:\nThe motivation is unclear, whether their ultimate goal is to look for error patterns or to improve the original model is unknown\nThe terms appearing in the abstract, such as \u201cisolating hard subpopulations\u201d, \u201cspurious correlations \u201d, \u201cdistilling a model\u2019s failure modes \u201d, \u201ddirections within the feature space\u201d \u2026should be clearly defined early on.\nIn the main paper how to generate the captions is not mentioned. Although it appeared in the supplement but at least a brief description should be included in the main paper.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The writing is unclear as the motivation is unknown and the terms are undefined. \nTraining a SVM to predict whether the original model will classify a datapoint correctly has some limited novelty.\n",
            "summary_of_the_review": "The writing prevents readers from understanding the paper and the novelty is somewhat limited. \n\n----------------------------------------------\nPost rebuttal comment:\n\nAfter reading the other reviews and the rebuttal. We raise the score to 6.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2092/Reviewer_ySph"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2092/Reviewer_ySph"
        ]
    },
    {
        "id": "hA84PaLBDM",
        "original": null,
        "number": 2,
        "cdate": 1666747236031,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666747236031,
        "tmdate": 1668239748038,
        "tddate": null,
        "forum": "99RpBVpLiX",
        "replyto": "99RpBVpLiX",
        "invitation": "ICLR.cc/2023/Conference/Paper2092/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a simple, yet effective method for identifying hard subpopulations in datasets. In addition, by utilizing the pre-trained CLIP and generative models, the underlying error patterns for identifying hard subpopulations become human-understandable. Based on such interpretations, appropriate data augmentations are applied to hard subpopulations, enhancing the performance of downstream tasks. Finally, the effects of the proposed method are validated for both cases where spurious correlation and the underrepresentation problem exist in the datasets.",
            "strength_and_weaknesses": "Strength\n1. The proposed method is novel. It is highly impressive 1) to utilize CLIP embeddings to make the proposed method interpretable and 2) to demonstrate the effect of data augmentation for the downstream tasks using pre-trained generative models based on the results of the proposed method.\n\n2. The paper is well-written and easy to follow. Also, the appendix and figures help to understand the proposed method and experimental results easily. Especially, Figures 2 and 7-(b) enhance the reliability of the proposed method.\n\nWeakness\n1. My main concern is about the scalability of the proposed method. I think the experimental settings of Section 3 and Section 4.1 seem to be limited. Moreover, based on the results for ImageNet in Section 4.2 and Figure 27 in the appendix, it seems that the proposed method does not perform well with this dataset. Specifically, I think that the results of Figure 10-(a) and Figure 27 do not match well with the SVM caption. Also, in Figure 10-(b), the gap between the positive and negative samples decreases too quickly, unlike Figure 7-(b). Could the authors provide more evident results for the claim that the proposed methods are scalable?\n\n2. In the Detection part of Section 2.1, the authors claim that the cross-validation score can be used as a measure of the failure model's strength in datasets. However, it seems that there is no experiment to validate its practicality. Could the authors verify the practicality of this score rather than the result of the correlation in Figure 4?\n",
            "clarity,_quality,_novelty_and_reproducibility": "This paper is well-written in detail and easy to understand. Moreover, the proposed method has clear novelty and originality.",
            "summary_of_the_review": "The proposed method is novel and interesting. In addition, the experimental results are impressive overall. I hope that the authors will address two concerns during the rebuttal period.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2092/Reviewer_ZiBp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2092/Reviewer_ZiBp"
        ]
    },
    {
        "id": "FMlcJh2_Gk",
        "original": null,
        "number": 3,
        "cdate": 1666788240449,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666788240449,
        "tmdate": 1666788240449,
        "tddate": null,
        "forum": "99RpBVpLiX",
        "replyto": "99RpBVpLiX",
        "invitation": "ICLR.cc/2023/Conference/Paper2092/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Deep learning models often exhibit consistent error patterns, where these errors often correspond to hard subpopulations in the data they are deployed on. This paper introduces a framework for automatic distillation and surfacing of a model\u2019s error patterns. In detail, this framework uses SVM to predict the error of the original model in the CLIP\u2019s embedding space, where the vector orthogonal to the decision boundary of SVM represents the direction of the failure mode of the original model. In addition, the authors also propose actionable interventions to remedy the failure mode.\n\nThe evaluation is done on hard subpopulations in image datasets such as CIFAR-10, ImageNet, and ChestX-ray14. Notably, the proposed method does not require direct\nhuman intervention or pre-annotated subgroups and is therefore a scalable approach.\n",
            "strength_and_weaknesses": "The proposed method is novel and opens potential for new line of research in identification of biases and difficult subpopulations. I personally find the submission to be clear and well-written. Overall, I am positive and would like to give a \"accept\".\nHowever, I have few more comments that I hope to help improve the paper. Several of them are around the modeling choices and some of them are to clarify my understanding of the practical usefulness of the proposed method.\n1.\tThe framework uses a linear support vector machine (SVM) to separate correct from incorrect examples and claims that the direction of the failure mode will be orthogonal to this decision boundary. My concern is whether the correct and incorrect examples are linearly separable. Can the authors provide data to support this claim? If it is not completely linearly separable, I suggest that the framework can be extended to use the simplest nonlinear classifiers.\n2.\tI find that the SVM will reduce the accuracy of the major subclasses (Table 1 in the Supplementary material). I suggest that the author discuss this phenomenon in the main text.\n3.\tI am concerned that the effectiveness of the proposed method depends on the data distribution of the validation set. My first request is for the authors to provide more experiments to verify the influence of long-tailed classes on the decision boundary of SVM. Second, I would like the authors to report the results with different proportions of dataset partitioning (e.g. 80% for training and 20% for validation).\n",
            "clarity,_quality,_novelty_and_reproducibility": "\nI find the proposed method to be novel and effective. \n\nThe paper is clear and well-written.",
            "summary_of_the_review": "I have a few comments around modeling designs but I think the comments are addressable.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2092/Reviewer_HQAk"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2092/Reviewer_HQAk"
        ]
    },
    {
        "id": "MyyYZ_K_4s",
        "original": null,
        "number": 4,
        "cdate": 1666796429582,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666796429582,
        "tmdate": 1666796429582,
        "tddate": null,
        "forum": "99RpBVpLiX",
        "replyto": "99RpBVpLiX",
        "invitation": "ICLR.cc/2023/Conference/Paper2092/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose an automated way to determine a model's error modes (hard subpopulations and spurious correlations). They do so by using linear classifiers (SVM) on a feature space (CLIP) such that these failure modes are a direction within the feature space (orthogonal to the hyperplane created by the SVM). Given the feature space used, diffusion models can allow for the generation of additional samples to address the failure modes of the model. The authors use the CelebA dataset (which has a spurious correlation between gender and age) and the CIFAR-10 dataset (which has underrepresented subtypes).",
            "strength_and_weaknesses": "Strengths.\n\n- The use of the SVM to create the boundary between the model's correct and incorrect outputs and having an image/caption style model's feature space provides a lot of capabilities to this approach. Captions can be provided to understand what the easiest versus hardest examples are, and the model allows hard and easy examples to be generated.\n- Excellent observation that the SVM does better than using the model confidences to determine hard/easy exemplars.\n\n\nWeakness\n- I worried that the paper was too CLIP limited; would the approach have worked as well with a different feature space representation.\n- In \"Targeted synthetic data augmentation\", the authors only retrained the last layer of the model but gave no reason as to why.",
            "clarity,_quality,_novelty_and_reproducibility": "Paper was well written, in particular the appendix provides the necessary detail to recreate the results. Excellent use of the new generation of text2image style models to help improve model performance.",
            "summary_of_the_review": "A thorough a well written paper showing how SVM and CLIP feature space can be used to automatically identify hard subpopulations and spurious correlations. Would like the two weaknesses to be clarified. The technique proposed could provide an additional tool for model understanding and post-hoc improvement.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2092/Reviewer_ZdLg"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2092/Reviewer_ZdLg"
        ]
    }
]