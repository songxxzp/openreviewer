[
    {
        "id": "d-jxaXZN7K",
        "original": null,
        "number": 1,
        "cdate": 1666446106857,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666446106857,
        "tmdate": 1667221174874,
        "tddate": null,
        "forum": "G4ywctru8UX",
        "replyto": "G4ywctru8UX",
        "invitation": "ICLR.cc/2023/Conference/Paper1034/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a training free algorithm for Neural Architecture Search (NAS). The proxy metric (TPC) used is the number of paths from the input to the output layer. To generalize it for very large networks, the network can be viewed as a graph and one could compute the outdegree of a node. This score is then used to rank all the architectures. TPC-Score was used a proxy instead of validation accuracy in  an evolutionary algorithm and neural architecture search was performed.  For image classification, they used ResNet search space where they constrained the number of model parameters to 1M. In addition to this, TPC-NAS was used to search for object detection architecture in the YOLOv4 search space. This metrics is very faster compared to other training-free proxies.",
            "strength_and_weaknesses": "**Strengths**\n1. It is almost instantaneous to compute the metric for a given architecture\n2. The experiments demonstrated that TPC-NAS is able to find well performing networks in ResNet search space to solve image classification and object detection.\n\n**Weakness**\n1. In Figure 3, the Kendall tau is computed on only 20 architectures. We need at least 100 architectures for the correlation to be significant.\n2. NASWOT and TE-NAS are computed on NasBench 101 and 201. So please demonstrate how effective your metric is on those 2 search spaces for at least 2 datasets. Also, please don't restrict the number of parameters\n3. As mentioned in Section 5.1, when the dataset is not taken into consideration while computing the proxy metric, then the architectures would be ranked the same on all the datasets. The authors suggest that TPC score could be used to eliminate bad candidate architectures early on. But for a good proxy metric, one must take into consideration the dataset characteristics. As mentioned in 2, please compute Kendall Tau for two datasets on the same search space and compare them against the other baselines. \n4. TPC Score only takes CONV layers into consideration. What about the impact of dropout, pool or skip connections? Initialization also plays a crucial role in the final performance of the network.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is written clearly and is novel. The authors provided the code. So it is reproducible.",
            "summary_of_the_review": "This paper devised a training-free NAS algorithm, where the metric is the number of paths from the input to the output layer. But its performance needs to be tested on NASBench-101 and 201 to be fair to other baselines. It is also important to understand if it adapts its score to a given dataset as they do not consider any dataset characteristics.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1034/Reviewer_F9pB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1034/Reviewer_F9pB"
        ]
    },
    {
        "id": "qrhMl3OhRGk",
        "original": null,
        "number": 2,
        "cdate": 1666680434762,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666680434762,
        "tmdate": 1666681220132,
        "tddate": null,
        "forum": "G4ywctru8UX",
        "replyto": "G4ywctru8UX",
        "invitation": "ICLR.cc/2023/Conference/Paper1034/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes the total path count (TPC) score as an efficient accuracy predictor for neural architecture search. Particularly, the TPC score is defined as the number of paths of the \u201dvanilla\u201d convolutional neural network, which is very simple to come by. In experiments, the proposed approach was evaluated on three vision tasks: image classification, object detection, and super-resolution.",
            "strength_and_weaknesses": "Strength \n\n- proposes the total path count (TPC) score as an efficient accuracy predictor for neural architecture search\n\n- outperforms the most relevant hand-crafted and NAS-discovered architectures on three applications\n\nWeaknesses\n\n- Clarity needs to be improved. Some important sections/functions are not well explained. For example, there is not a detailed explanation regarding the MUTATE function. It would be better to include an explanation to make the paper to be self-contained.\n\n- Experiments are lacking. There are no ablations on the hyperparameters, like Search Space S, hardware constraints K, maximal depth D, number of iterations M, population size N, and initial structure F0. The paper only compares the best results with the state-of-the-art approaches but does not explain the sensitivity to the hyperparameters. It is hard to justify the superior performance of the proposed approaches without giving the hyperparameters.\n",
            "clarity,_quality,_novelty_and_reproducibility": "An anonymous GitHub link is included in the paper for reproducibility.",
            "summary_of_the_review": "This paper proposes the total path count (TPC) score as an efficient accuracy predictor for neural architecture search and outperforms the most relevant hand-crafted and NAS-discovered architectures on three vision applications. But clarity needs to be improved and experiments are lacking.  ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1034/Reviewer_CdaL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1034/Reviewer_CdaL"
        ]
    },
    {
        "id": "idrTQaB3ZxO",
        "original": null,
        "number": 3,
        "cdate": 1667369116667,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667369116667,
        "tmdate": 1667369116667,
        "tddate": null,
        "forum": "G4ywctru8UX",
        "replyto": "G4ywctru8UX",
        "invitation": "ICLR.cc/2023/Conference/Paper1034/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The manuscript proposed an efficient neural architecture search (NAS) algorithm for computer vision tasks including 2D image classification, object detection, and super-resolution. The proposed algorithm introduces the total path count (TPC) score as an accuracy predictor. The TPC score is computed based on the shape of convolution kernels to indicate models\u2019 expressivity. And its computation can be efficiently achieved within few minutes. Moreover, the experimental results validate the proposed algorithm with several datasets of different computer vision tasks. All experiments use convolutional neural network (CNN) based search space.",
            "strength_and_weaknesses": "<Strength>\n\n\u2022\tThe paper is well-organized and well-written.\n\n\u2022\tThe experimental results supports the claims made in the manuscripts.\n\n\u2022\tThe submitted content is related to the application of fundamental tasks in computer vision, which is highly relevant to the ICLR audience.\n\n<Weakness>\n\n\u2022\tThe novelties of the proposed algorithm is limited. Computing the TPC score is similar to study the effective receptive field of CNN models. It is a fact that large receptive field helps models\u2019 expressivity because of long-range dependencies between image pixels.\n\n\u2022\tThe impact of the proposed approaches could be limited. Because it is applied to CNN models only and within a relative small search space.\n\n\u2022\tDiscussion or ablation studies are not sufficient (see below).\n\n<Comments>\n\n1.\tHow to extend the TPC score to the popular neural networks like various vision transformers or models with self-attention layers?\n\n2.\tDoes the training recipe matter for the NAS outcome? Does different training recipes or with different random seeds result in different Kendall rank correlation coefficients?\n\n3.\tThe manuscript claimed that the TPC score can be computed within a few microseconds. Please further clarify the device for such computation (e.g., what type of CPU or GPU)?\n\n4.\tDoes the TPC score correlate with the accuracy in a higher order? For instance, does large TPC score gap mean larger accuracy gap?\n\n5.\tWhat are the (approximated) Kendall rank correlation coefficients for object detection and super-resolution?\n\n6.\tIt is important to get a high ranking correlation for the model candidates with top performance because they matters more for final architecture selection. It would be better to compute the Kendall ranking coefficients for the models with top performance (e.g., top 5~10% accuracies).\n\n7.\tWhat are the typical cases for good models with low TPC scores? What are the reasons causing the low scores for the models?\n\n8.\tCan the TPC score be used for comparison of different CNN models (e.g., ResNet versus Inception network)?\n\n9.\tTypo: Page 4, \u201cRELU\u201d => \u201cReLU\u201d.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The manuscript is of moderate quality, with good clarity and limited novelties.",
            "summary_of_the_review": "My concerns about the manuscript are about its novelties and practical impacts. The novelties of the proposed algorithm is limited because the TPC score concept is very similar to the model\u2019s receptive field. And the proposed algorithm may not be practical as it is limited for CNN models only and applied within a small search space.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A.",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1034/Reviewer_3RDB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1034/Reviewer_3RDB"
        ]
    },
    {
        "id": "pb-5gcpXTKB",
        "original": null,
        "number": 4,
        "cdate": 1667405904649,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667405904649,
        "tmdate": 1667405904649,
        "tddate": null,
        "forum": "G4ywctru8UX",
        "replyto": "G4ywctru8UX",
        "invitation": "ICLR.cc/2023/Conference/Paper1034/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this work the Authors introduce the total path count (TPC) of a network as a zero-cost measure of network performance that can be used to rank CNN architectures very efficiently.\n\nThey further combine the TPC as a performance predictor with an evolutionary algorithm as a search strategy to introduce a new architecture search method (TPC-NAS). \n\nTPC-NAS is then used to find high-performing architectures with hardware constraints on image classification, object detection and super-resolution tasks. ",
            "strength_and_weaknesses": "This paper introduces the TPC as an extremely efficient architecture performance predictor that depends only on the architecture topology. This can significantly speed up NAS algorithms when combined with different black box search strategies.\n\nHowever, the\u00a0Kendall tau\u00a0analysis in section 3.4 is very limited, and the search space is not clearly described. Extending the experiments would be useful, in order to have a better assessment of how TPC performs in ranking architectures. One can for example sample architectures from CNN NAS search spaces such as NAS-Bench-201 whose architecture test accuracies can be queried as well.\u00a0\n\nFurthermore, in the experiments section it is not clearly stated whether the search spaces are the same for all methods in table.1. In general, in section 4, further experiments could be useful to clarify whether it is the TPC scoring method, the evolutionary search strategy, or the chosen search space which plays the most important role in achieving high performance\u00a0on different tasks.\u00a0\n\n(Also, the mutation operation in algorithm 2 is not defined, and in the main text there is no reference to the search space defined in the appendix.)",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is overall well written and easy to follow. But, some experiments need further clarifications, as described above. The TPC scoring method, and application to object detection and super-resolution seem to be the main contributions of this work. Code is also provided for reproducibility. ",
            "summary_of_the_review": "The efficient architecture performance predictor introduced in this paper is interesting and can in principle be very useful for neural architecture search if it is proven to be effective. However, experiments in section 3.4 are not extensive enough to support this fact. Moreover, some confusions need to be addressed in the experiments section. I would therefore rate this paper as marginally below acceptance threshold.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1034/Reviewer_3zBH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1034/Reviewer_3zBH"
        ]
    }
]