[
    {
        "id": "6fbRw4to0g",
        "original": null,
        "number": 1,
        "cdate": 1666654863546,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666654863546,
        "tmdate": 1669995552540,
        "tddate": null,
        "forum": "4-oNRO0Fqy",
        "replyto": "4-oNRO0Fqy",
        "invitation": "ICLR.cc/2023/Conference/Paper3350/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a user interface for analyzing differences between ML models (ostensibly public cloud models, but it could be anything).  While the idea of segmenting model input for the purpose of model understanding is interesting, this paper is basically describing a fairly primitive GUI for the (already published, Eyuboglu et al 2022) method that does the heavy lifting.  So most of the core novelty has already been described.\n\nQuite frankly, this paper comes across as a UI paper written by a ML person, but doesn\u2019t score well in either category.  I can\u2019t see its relevance to ICLR.  This paper might be a better fit for a visualization conference, but even there, the concepts behind these visualizations seem relatively standard, so it is hard for me to see what contribution is being made to the visualization literature.",
            "strength_and_weaknesses": "Strengths:\n+ Blackbox understanding of ML models is an interesting and growing problem\n+ The Domino method this builds on is interesting\n\nWeaknesses:\n- Very low novelty\n- No user studies to validate Mocha\u2019s effectiveness\n- No comparison with existing ML explanation tools\n- Insufficient comparison of design tradeoffs \n- Even ignoring all the problems with this paper, I can\u2019t believe that it serves a purpose in its current form.  Basically the granularity of the provided information just seems wrong.  The authors are able to cherry pick one useful example (black and white imagery classification got worse), but in general the slice labelings seem all over the place.  In practice, a real user of these APIs likely has labeled images they care about, and would generally prefer to measure the ML system\u2019s performance on their task directly.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity:  This paper is super clear, with good writing and illustrations.\n\nQuality:  The quality of the presentation is quite good.\n\nNovelty:  I think this work has minimal novelty.\n\nReproducibility:  If the code (and data!) is released as promised, it should be generally reproducible.",
            "summary_of_the_review": "I think the paper has low novelty and is a bad fit for ICLR.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3350/Reviewer_Q1WT"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3350/Reviewer_Q1WT"
        ]
    },
    {
        "id": "3AlOeyRvGsS",
        "original": null,
        "number": 2,
        "cdate": 1667139060807,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667139060807,
        "tmdate": 1667139060807,
        "tddate": null,
        "forum": "4-oNRO0Fqy",
        "replyto": "4-oNRO0Fqy",
        "invitation": "ICLR.cc/2023/Conference/Paper3350/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper provides a tool for understanding the performance changes between different updates of ML as service applications. The developed tool is interactive and helps the users discover meaningful coherent different data slices where the performance is changing on, called ChangeLists. The model is built on CLIP and Domino, and provides a web based interface that could be very helpful for users of MLaaS to figure out if updates should be adapted based on their specific application.  ",
            "strength_and_weaknesses": "Very well motivated and useful paper, with sound methodology, and could have impact in practice.",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is very well written and easy to follow. There are plans to release the code and without it is it hard to reproduce. ",
            "summary_of_the_review": "While I agree with the paper contribution being significant, I think this is more a demo paper and/or visualization paper. The novelty on the methodology side is limited and it is more a clever usage of prior methods/models (Domino/Clip). I am happy if the paper is accepted since it probably will be useful but I am not sure if it passes the novelty bar of ICLR. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3350/Reviewer_NHrB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3350/Reviewer_NHrB"
        ]
    },
    {
        "id": "3qNgInoilx",
        "original": null,
        "number": 3,
        "cdate": 1667476690228,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667476690228,
        "tmdate": 1667476690228,
        "tddate": null,
        "forum": "4-oNRO0Fqy",
        "replyto": "4-oNRO0Fqy",
        "invitation": "ICLR.cc/2023/Conference/Paper3350/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper tackles an interesting problem of explaining changes between two different deep models in terms of detailed, fine-grained changes in performance across different subsets of data, called slices. This is done by first identifying distinct subsets of data that correspond to some coherent concept, these subsets are then automatically annotated with natural language descriptions which the users can edit/modify. The differences between the two models in then described in terms of \"Changelists\" which is a collections of slices of data along with annotations and performance metrics on these slices. \n\n",
            "strength_and_weaknesses": "Strengths:\n\n1. A very interesting problem with practical implications.\n2. Well-written paper and easy to follow modulo some aspects which are mentioned in weaknesses.\n3. Experiments on different publicly available deep learning APIs show the usefulness of the proposed approach.\n\nWeaknesses:\n1. I think the description of attribute text isn't very clear. What are the instance level attributions a_i? Are these the generated descriptions from a generative model which were deemed closest in embedding space to the centroids (as described in Section 3.2.1)? The paper mentions that users can modify this attribution. Do we have a single text attribution for each slice or multiple? I think adding some examples of attributions more specifically where it is described \n\n2. It would help to write out the loss used in discovering the slices using EM instead of just referring to Domino (perhaps in the appendix). For instance this line is unclear \"Like Domino, we use a hyperparameter \u03b3 to balance the contribution of the embeddings and losses to the log-likelihood \u2013 higher \u03b3 trades-off coherence for explanatory power.\" What does explanatory power mean? what does coherence mean?\n\n3. Similarly in the last paragraph on page 7, \"For a slice S = \u03c8(X, Y ) with poor alignment with its attribution A, Mocha users can update the slice by training a new slicing function \u03c8 \u0303(X, Y ), using logistic regression on CLIP embeddings.\". It is not clear what does this precisely mean. CLIP embeddings encode image X to some latent space Z, how does Y play a role? does the logistic regression classifier take as input both Z and Y? I think these details are important in fully understanding the implementation in this paper.\n\n4. The estimation of Recall for attribution and slice alignment using importance sampling isn't very clear. The paper proposes to use a mixture distribution with one q_i per user generated text-description. My main confusion is this, does the user write multiple text annotations for each attribute or we have one annotation for an attribute? This goes back to my first point. Describing the attributes more clearly is necessary for better readability of the paper in my opinion. \n\n5. The formula for \\hat{Q} is not clear. The paper claims we do not have access to instance level attribute realizations for every image in the dataset. So, importance sampling is used to get n_Q samples and then manually annotate their attribute realizations. However, the formula seems to sum over all n samples in the dataset in the numerator. Is this a typo?",
            "clarity,_quality,_novelty_and_reproducibility": "I think the paper is in general well-written and solves a novel problem. I have some concerns with regards to the clarity of presentation which has been mentioned in the weaknesses section of this review. \n\nI do not have any reproducibility concerns contingent on the fact that my above concerns in the weaknesses section are adequately addressed. \n\n",
            "summary_of_the_review": "My final recommendation is a weak accept. I think the concerns regarding clarity should be addressed before acceptance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "The paper mentions ethical concerns which stems from the fact that pre-trained models are used which are known to exhibit social biases. However, this is not a concern of the method since this can be mitigated by using pertained models that learn better and fair representations.",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3350/Reviewer_LdES"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3350/Reviewer_LdES"
        ]
    },
    {
        "id": "Dl2yZHlNpuz",
        "original": null,
        "number": 4,
        "cdate": 1667496083352,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667496083352,
        "tmdate": 1667496083352,
        "tddate": null,
        "forum": "4-oNRO0Fqy",
        "replyto": "4-oNRO0Fqy",
        "invitation": "ICLR.cc/2023/Conference/Paper3350/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper provides an interactive framework called Mocha for an end-user to view and edit change lists.  This notion of change lists are also one of the key contributions of this paper to explain performance shift and shift inconsistency by analyzing changes in fine grained data slices. The paper leverages techniques primarily motivated from Domino (Eyuboglu et al. 2022) and discovers the slices using a mixture model. Attributions are inferred using importance sampling driven by CLIP followed by alignment specific sanity checks. The paper presents empirical results comparing production models from Microsoft and Google to view these change lists.",
            "strength_and_weaknesses": "**Strengths**\n\n 1) The paper addresses an important problem of trying to understand how model updates impact different data slices. In particular, the issue of global improvement in model performance at the risk of lowered performance in certain subgroups is very important to know when deploying production model changes.\n\n2) Paper knits all components together in an interactive framework and shows results using production models from Microsoft and Google.\n\n**Weakness**\n\n1) I believe one of the paper's biggest flaws is the lack of technical novelty. While I do acknowledge that the overall framework drives value, the individual components leverage existing prior art such as Domino (Eyuboglu et al. 2022), Mixture models and importance sampling procedures making incremental technical improvements. I am also not quite sure if this paper fits in within the core technical track of a conference like ICLR. It might be a very good fit for UI, demo or Industry track.\n\n2) I also do believe that some user studies are also important to assess how user friendly Mocha is. Overall the paper does present this as a framework which can potentially overwhelm the user due to its multiple technical intricacies.  Ideally, Mocha should be useful for data scientists and business intelligence teams also and not just be applicable to core AI scientists to drive real value. ",
            "clarity,_quality,_novelty_and_reproducibility": "Paper is written pretty well. Novelty as mentioned above is questionable.",
            "summary_of_the_review": "Overall, I find this paper to be a good read in terms of providing a framework to drive value for end users. My major concerns are on (a) technical novelty of individual components and (b) user effectiveness studies to assess how viable is it to use Mocha.  Also, I feel this paper should be more well placed rather than being considered in core technical track of ICLR as it might have good value as a demo or industry track paper at ICLR or other similar top tier conferences.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3350/Reviewer_C4kp"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3350/Reviewer_C4kp"
        ]
    }
]