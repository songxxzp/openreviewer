[
    {
        "id": "3gBkz4RA1s1",
        "original": null,
        "number": 1,
        "cdate": 1666534124474,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666534124474,
        "tmdate": 1666534124474,
        "tddate": null,
        "forum": "HVvqbDQdhW2",
        "replyto": "HVvqbDQdhW2",
        "invitation": "ICLR.cc/2023/Conference/Paper5446/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a dataflow analysis-guided graph learning approach namely DeepDFA for vulnerability detection. It encodes the node from control flow graph using an abstract dataflow embedding. Based on the vectorized node embedding, it further applies GGNN on the CFG for message passing. Then a graph representation is used to classify whether a function is vulnerable or not. By the experimental results, it confirms that DeepDFA is significantly faster than the baseline models. Furthermore, it also confirms that the designed embedding approach is also general to other vulnerability detection models. ",
            "strength_and_weaknesses": "Strength:\n\n- The related work is comprehensive, though there are some missing related works, it still cover current the most deep learning techniques for vulnerability detection. \n- The idea to compare data flow analysis to message passing in GNNs seems interesting. \n- This paper is easy to follow.\n\nWeaknesses:\n\n- This paper uses data flow for vulnerability dection. I agree that there are many vulnerability types caused by data dependencies, however how to deal with other vulnerabilites that are caused by other dependencies such as control dependencies?\n\n- Why choosing four properties such as API call, Data type, Constant and Operator? Are these properties enough for vulnerability detection? There appears to be insufficient evidence to justify this choice.\n\n- What is the novelty of model except the designed the abstract dataflow embedding? It seems that this paper just replace the embedding layer in GNNs to the abstract dataflow embedding for vulnerability detection. Furthermore, since the dataflow embedding size can be controlled by the hyper-parameter k, hence the model size and parameters will denifitely smaller than others. \n\n- Why choose GGNN for the model architecture? Can we use other GNN variants for the replacement.\n\n- I suggest authors to combine Table 2 (a) and (b) for better presentation.\n",
            "clarity,_quality,_novelty_and_reproducibility": "- Clarity: This paper is easy to follow.\n\n- Novelty: It seems that the main contribution is the proposed abstract dataflow embedding, which seems to be limited.\n\n- Reproducibility: The data and code is available for reproduction. \n\n- Quality: The idea seems interesting, but technical novelty for model is not enough.",
            "summary_of_the_review": "Although the idea to compare data flow analysis with GNNs is interesting, the technical novelty is not enough. Furthermore, the reason behind the embedding layer is also unclear. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5446/Reviewer_ePbc"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5446/Reviewer_ePbc"
        ]
    },
    {
        "id": "_UB01NPQQDk",
        "original": null,
        "number": 2,
        "cdate": 1666574284801,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666574284801,
        "tmdate": 1666574284801,
        "tddate": null,
        "forum": "HVvqbDQdhW2",
        "replyto": "HVvqbDQdhW2",
        "invitation": "ICLR.cc/2023/Conference/Paper5446/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes DeepDFA, an efficient graph neural network architecture based on the dataflow information of the program for vulnerable function detection. It develops the abstract dataflow embedding to represent the program. The key insight is that such representation enables the graph learning algorithm to behave similarly to the dataflow analysis process, a classical static analysis approach to detect vulnerabilities. Experimental results demonstrate that DeepDFA is fast in training and inference and achieves the best results when combined with an existing baseline.",
            "strength_and_weaknesses": "+ Design: analogies of the dataflow analysis algorithm and the message passing algorithm in graph neural networks are intuitive and novel.\n+ Results: the dataflow embedding improves the efficiency, precision, and generalizability of graph neural networks in vulnerability detection.\n\n- Unclear design choices of abstract dataflow embedding, in which the variable -- the key part in dataflow analysis - is not included.\n- Evaluation should show the vulnerability types and how dataflow analysis identifies them. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: the paper describes the core idea clearly. \n\nQuality: the quality of the writing can be improved, e.g., the description of the dataflow analysis can be made clearer. For example, there are also some discrepancies between the paper's description and the public algorithm, e.g., each node in CFG is usually a basic block, not a single statement. The description should be improved to walk through the algorithm in more detail. \n\nNovelty: the analogy of graph learning and dataflow analysis is novel, but the actual design based on this insight is not convincing (see summary of the review).\n\nReproducibility: the authors have provided experiment details to help reproduce the paper.",
            "summary_of_the_review": "I like the idea of this paper that incorporates the dataflow analysis as the inductive bias of neural networks for program analysis. However, I think the paper needs to address the following concerns.\n\nIt is unclear why the properties used to represent each node in the graph mismatch the information used in actual dataflow analysis. As described in Section 3.3, the authors used 4 properties of a node without including the variables in the program, but they are critical to dataflow analysis. Without incorporating variables, it is hard to argue that the graph learning algorithm is still learning dataflow analysis.\n\nSimilar to variable names, which the authors discard as they are program-specific, the 4 properties used to represent statement nodes are also domain-specific. API calls, type strings, constants, and operators might change across different programming languages, and their distribution might vary significantly across projects. How do these properties generalize to unseen ones? Are there experiments to ablate their effectiveness?\n\nWhat is the overhead of extracting the extra information of the program, i.e., abstract dataflow embedding, over using raw code tokens? It is helpful to show the tradeoff of increased data processing effort for improved training/inference efficiency.\n\nDataflow analysis algorithm assumes termination when reaching a fixed point. The authors also mentioned that the number of iterations depends on the graph size (d(G)+3). Why did the authors decide to fix such hyperparameters based on a validation set?\n\nWhat are the vulnerability types in the evaluated dataset -- is dataflow analysis indeed enough to analyze all the vulnerability types? If yes, as a baseline, the authors should report the performance of the classic dataflow analysis and argue why we need an alternative based on machine learning. If not, it is important to show in which case dataflow analysis fails. How does the model perform in these cases? What makes the model outperform the standard dataflow analysis (if this is true), if it simply learns the dataflow analysis?\n\nMinor:\n\nThe scale of the metrics described and used in the paper should be consistent. For example, the authors use 0.91 F1 scores in the introduction but use 96.4 F1 scores in the other places.\n\nThe authors of the citation \"Compilers: principles, techniques, & tools\" is incorrect.\n\nSection 2, I do not think that \"propagates the information along semantically important edges\" are realized in this paper. This paper proposes to propagate information on control flow graphs, but only control flows do not fully capture all the dependencies, e.g., data dependencies. I am not fully convinced that such a setup is \"significantly more efficient\" than transformers.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5446/Reviewer_EyDV"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5446/Reviewer_EyDV"
        ]
    },
    {
        "id": "dAOeP_YKHV9",
        "original": null,
        "number": 3,
        "cdate": 1666625529691,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666625529691,
        "tmdate": 1666626776171,
        "tddate": null,
        "forum": "HVvqbDQdhW2",
        "replyto": "HVvqbDQdhW2",
        "invitation": "ICLR.cc/2023/Conference/Paper5446/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this work, the authors present DeepDFA, a dataflow analysis-guided graph learning framework and embedding that use program semantic features for vulnerability detection. In experiment, they show DeepDFA ranked first in recall, first in generalizing over unseen projects, and second in F1 among all the state-of-the-art models they experimented with.",
            "strength_and_weaknesses": "Strength:\nThe paper is easy to follow in general.\nVulnerability detection using graph learning is an important problem.\n\nWeaknesses:\nThe authors explored to use graph learning for vulnerability detection, but the novelty is minor:\n(1)The analogy of dataflow analysis and graph learning is somewhat trivial especially when there are already several existing works, for example, \u201cProGraML: A Graph-based Program Representation for Data Flow Analysis and Compiler Optimizations. ICML 2021\u201d as this paper cited.\n\n(2)Moreover, the dataflow embedding in this paper, which only select API calls, data type, Constant, and Operator, seems not strong enough to represent dataflow. There is also other more important information, for example, tainted value or expressions, path constraint, and so on. Take the example in Figure 1, as the authors explained at the end of section 3.3, they show a null-pointer dereference vulnerability because the definition d1:str=NULL can reach the dereference at v4. How about when there is an if statement that checks whether str == NULL, if it does, program will terminate. Will DeepDFA also report a null-pointer dereference vulnerability since path constraints are omitted in the dataflow embedding? \n\n(3)The evaluation also should be improved, both in setting and description. \n\n(3.1) I wonder what level and what kinds of vulnerability DeepDFA is able to detect? \nIn evaluation, the authors did not compare with ProGraML, which is the most related to this work. Although ProGraML was evaluated on device mapping and algorithm classification, ProGraML is also able to do data flow tasks (referring to ProGraML\u2019s evaluation), such as Reachability analysis, Dominance analysis, liveness analysis, and so on. Since the two works are so related, it would be better to compare them in Reachability analysis, Dominance analysis, liveness analysis, and so on. If possible, also compare the ability of vulnerability detection by self-implementation based on ProGraML.\n \n \n(3.2) As I know, CodeBERT is a model for natural language code search and code documentation generation, how the authors apply CodeBERT for vulnerability detection, and what kinds of vulnerability can be detected? It would be better to give more details.\n \n \n(3.3) In the evaluation, the authors only show F1 score, precision, recall. What kinds of vulnerabilities are detected in the experiments? It would be better to show more details of the vulnerabilities.\n \n \n(3.4) I noticed there are some closely related works not included and discussed:\n\u201cLearning to Represent Programs with Graphs, ICLR2018\u201d\n\"Learning semantic program embeddings with graph interval neural network. OOPSLA 2020\u201d\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is easy to follow.\nNovelty: The authors explored to use graph learning for vulnerability detection, but the novelty is minor.\nReproducibility: The data and code is available for reproduction.\nQuality: The idea seems interesting, but novelty is not enough.",
            "summary_of_the_review": "The authors explored to use graph learning for vulnerability detection, but the novelty is minor:\n(1)The analogy of dataflow analysis and graph learning is somewhat trivial especially when there are existing works, for example\u201cProGraML: A Graph-based Program Representation for Data Flow Analysis and Compiler Optimizations. ICML 2021\u201d as this paper cited.\n(2)Moreover, the dataflow embedding in this paper, which only select API calls, data type, Constant, and Operator, seems not strong enough to represent dataflow. \n(3)The author shows experiment details, but can be improved\n\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5446/Reviewer_x4r7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5446/Reviewer_x4r7"
        ]
    },
    {
        "id": "uE1twn3DSxJ",
        "original": null,
        "number": 4,
        "cdate": 1666647124481,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666647124481,
        "tmdate": 1666647124481,
        "tddate": null,
        "forum": "HVvqbDQdhW2",
        "replyto": "HVvqbDQdhW2",
        "invitation": "ICLR.cc/2023/Conference/Paper5446/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes a GNN based approach for vulnerability detection. The control flow graph (CFG) of a program is augmented with dataflow information and graph learning is applied to predict vulnerability of the program. This work proposes an \u201cabstract dataflow embedding\u201d to represent important dataflow properties that are relevant to vulnerability detection and uses message-passing of the GNN model to mimic the dataflow analysis algorithm.  Evaluation of the proposed model on publicly available dataset shows improved performance compared to several state-of-the-art approaches.",
            "strength_and_weaknesses": "Strengh\n\nDataflow analysis has been used as a useful tool for vulnerability analysis. Augmenting dataflow analysis to improve performance of ML based vulnerability detection approaches seems reasonable.\n\nWeakness\n\n- The use of GNN to model CFG of programs for vulnerability detection has already been explored by previous works (as mentioned in the related work) . So, the novelty of this work is restricted to \u2018encode dataflow analysis in CFG\u2019 for graph learning. However, it is not clear how (or if) the proposed embedding is more effective than the already proposed embedding approach in PrograML. There is no comparative discussion/evaluation that demonstrates the superiority of the proposed approach.\n- It is not clear if the proposed approach detects vulnerabilities at the program/function/line level. Baseline methods seem to include detectors that focus on both function and line level.\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The overall end-to-end detection method could be described more clearly. More specifically, the granularity of detection and how to localize vulnerable code (if possible) in the proposed approach  is not clear from the description. Some clarifying questions on evaluations:\n- Evaluation results in Table 2(b) shows that although DeepDFA performs poorly, concatenating its output to LineVul\u2019s encoder output improves detection performance of LineVul. Is there any pattern  (e.g., type of vulnerability) which are missed by original LineVul, but detected by LineVul+DeepDFA?\n- How does the performance of LineVul+DeepDFA compare with concatenation of LineVul with other similar GNN based approaches (e.g., Devign)?\n- How to determine k? Effective k values could be different for different properties (e.g, api call vs data type).\n\n\nNovelty: DeepDFA proposes encoding of dataflow analysis in CFG for vulnerability detection. However, the novelty of this work is not well-demonstrated. Although not specifically applied to vulnerability detections, PrograML has already used a similar approach for program representations. \n\nReproducibility: Code, data, trained models, and relevant models used in the paper are shared. Thank you! ",
            "summary_of_the_review": "This work inspires the use of dataflow information in GNN based vulnerability detection. However, the proposed approach has reduced novelty. Also, the evaluation and description of the overall system lacks clarity.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper5446/Reviewer_FYuz"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper5446/Reviewer_FYuz"
        ]
    }
]