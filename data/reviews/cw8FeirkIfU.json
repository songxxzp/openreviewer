[
    {
        "id": "KjwMejP--v",
        "original": null,
        "number": 1,
        "cdate": 1666728782067,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666728782067,
        "tmdate": 1669146497604,
        "tddate": null,
        "forum": "cw8FeirkIfU",
        "replyto": "cw8FeirkIfU",
        "invitation": "ICLR.cc/2023/Conference/Paper3388/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the multi-armed bandit (MAB) problem under the constraint of *distributed* differential privacy (DP). The goal here is to match the optimal utility guarantees under *central* DP, whilst being able to achieve stronger privacy guarantees in the model where we don't have a central, trustworthy server for aggregation and analysis. This paper overcomes the following limitations of prior work in this distributed setting (albeit via *shuffle* DP): (1) it only provides approximate DP guarantees; (2) the cost of privacy is a factor of $\\sqrt{\\log(1/\\delta)}$ away from the optimal regret under pure DP in the central model; and (3) this works only for binary rewards or leads to high communication costs for real rewards.\n\nThere are two algorithms provided here: one for pure DP and one for Renyi DP (RDP). The four main challenges overcome and goals achieved here are: communication cost while achieving DP; achieving the best results so far under pure distributed DP; much better bounds under RDP, especially on real-world data; and overcoming the issue of privacy loss on finite computers due to floating point errors by using discrete noise distributions. Both theoretical and empirical results are provided.",
            "strength_and_weaknesses": "Strengths:\n1. The results for distributed DP provided here achieve the strongest privacy guarantees with utility matching that of the optimal, pure, central DP algorithm. The prior work in this distributed setting only offered approximate DP guarantees with utility worse by a multiplicative factor of $\\sqrt{\\log(1/\\delta)}$. The idea of using Polya noise is quite nice!\n2. The communication complexity of the above is also not too high -- $\\log(m)$ bits.\n3. The above could be extended to shuffle DP setting, as well.\n4. The RDP guarantee is much better in terms of the utility, and the algorithm does well empirically on real-world datasets, too.\n5. The above has asymptotically better utility than that of the prior work, has better guarantee than this paper's pure DP analogue for the setting where $\\delta > 1/T$, and has better guarantees under composition than that of the prior work.\n6. The experimental results indicate that these algorithms do almost as well as the central DP algorithm on both synthetic and real-world datasets.\n\nWeaknesses:\n1. The algorithmic framework is heavily inspired by those of the prior work of Balle et al' 2020 and Cheu et al' 2021. Even for the RDP algorithm, the idea of using Skellam noise is borrowed. So, I'm not sure how much the algorithmic novelty is here.\n2. As acknowledged by the authors (which I appreciate), the communication cost gets worse in the RDP setting with better privacy and utility demands. Is that a necessity? Some discussion of that could be useful!\n3. I have some complaints with the writing quality of this paper, which I will describe in the next section.",
            "clarity,_quality,_novelty_and_reproducibility": "Regarding the clarity and the writing, I have the following points.\n1. In the preliminaries for MAB, I would also want to describe the problem in the context of multiple users as in this paper. Doesn't really help if I have to look ahead in the paper for more context about this problem (even though this is quite well-known).\n2. In Section 3 where you define $l(b)$. I think it's a confusing notation because $l(b)$ just gives us a number of users at time batch $b$? We might also want to incorporate arm $a$ in there somewhere. Does this mean that in a time batch $b$, $l(b)$ users will pull arm $a$ in the time duration of batch $b$? I'm unsure about this notation, to be honest. It shouldn't be the case that I have to read the algorithm to make sense of this. But then, you define it finally in the algorithm as $2^b$. So, does it mean that $T \\geq K2^b$?\n3. At the end of page 4, you pretty much start stating the three points that you did earlier on page 2. I don't think that's really necessary.\n\nI like the quality of the work because the theoretical results produced are the best so far, and match the best possible utility. The empirical results look alright, too.\n\nThe novelty is what I'm concerned about, which I mention as Weakness 1 in the previous section. On one hand, it is nice to use existing and familiar techniques and analyses, but it does chip away from the significance sometimes, although I agree that it is a grey area to evaluate on.",
            "summary_of_the_review": "I think it's a decent paper, with potential improvements out there in the writing. Based on what I've said so far, I feel accepting it should be alright, but I would be taking the authors' response into account before sending my final recommendation.\n\nEdit: updated my score now.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3388/Reviewer_Z6zL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3388/Reviewer_Z6zL"
        ]
    },
    {
        "id": "kk0NRMYjGx4",
        "original": null,
        "number": 2,
        "cdate": 1666734375976,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666734375976,
        "tmdate": 1666734375976,
        "tddate": null,
        "forum": "cw8FeirkIfU",
        "replyto": "cw8FeirkIfU",
        "invitation": "ICLR.cc/2023/Conference/Paper3388/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work proves regret bounds for multi-arm bandit under distributed pure DP and RDP only using discrete noise. The theoretical results are verified by experiments.",
            "strength_and_weaknesses": "Strength\n- This work fills in the gap for distributed pure DP in previous works and the result is tight (matches the central DP lower bound)\n- The RDP upper bound is promising, and the result is relevant in practice as RDP is often used for tight privacy accounting. \n- The algorithm uses discrete noise which is more relevant in practice.\n- The theoretical bounds are verified by experiment results.\n\nWeakness\n- I was wondering if the distributed DP bounds can be obtained from LDP bound + privacy amplification by shuffling.\n- Lower bound is not provided for RDP.\n- Technically the work seems to mainly use existing techniques (discrete Laplace, Skellam noise, etc.). Perhaps the authors could better explain the technical novelties, e.g. why $(\\varepsilon, 0)$ bound could not be obtained in previous works and how it is obtained in this work\n\n\nMinor comments:\nSince the upper bound for distributed $(\\varepsilon, 0)-$DP matches that of central DP, row 4 in Table 1 could be changed to $\\Theta$ instead of $O$",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clearly written. The results are new, and the algorithmic techniques are practically relevant. ",
            "summary_of_the_review": "This work provides new regret bounds in MAB under distributed DP verified by experiments. The main drawback is that lower bound is missing for RDP, and technical novelty is unclear.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3388/Reviewer_PLdo"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3388/Reviewer_PLdo"
        ]
    },
    {
        "id": "IQtG_5E0N3",
        "original": null,
        "number": 3,
        "cdate": 1667182982775,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667182982775,
        "tmdate": 1668533015970,
        "tddate": null,
        "forum": "cw8FeirkIfU",
        "replyto": "cw8FeirkIfU",
        "invitation": "ICLR.cc/2023/Conference/Paper3388/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper considers the (stochastic) multiarmed bandits problems in the setting of distributed differential privacy, where each individual\u2019s reward function needs to be protected, and the central server running the bandits algorithm is not fully trusted to receive private information in the clear.  The setting studied in the paper does, however, allow for a secure intermediary, such as secure aggregation, or shuffling.\n\nThe main result of the paper is an algorithm with excess regret of $O(\\varepsilon^{-1} k \\log T)$, where $k$ is the number of arms, $T$ is the number of time steps, and $\\varepsilon$ is the privacy parameter. This is optimal for pure differential privacy even in the central model, and effectively removes a $\\sqrt{log 1/\\delta}$ factor from prior work. The prior work also offered somewhat weaker privacy guarantees.",
            "strength_and_weaknesses": "Getting a tight bound for a fundamental problem, in a distributed model of differential and yet matching the central model lower bound, is certainly nice. \n\nThe paper builds on ideas from prior works. The main algorithm is very similar but different from the VB-SDP-AE algorithm from the Tenebaum, Kaplan, Mansour, Stemmer [TMMS] paper. Part of the improvement over [TMMS] comes from using a better primitive for private binary summation, either by using a different secure intermediary primitive (secure aggregation) or by utilizing a more recent private summation protocol for the shuffle model, from a preprint of Cheu and Yan. Nevertheless, this is not enough to get the tight bound, and the additional tweak added to the TMMS algorithm seems to be essential.",
            "clarity,_quality,_novelty_and_reproducibility": "The initial submission did not clearly explain the innovation in this paper over prior work. The latest revision, however, significantly improves in this aspect.",
            "summary_of_the_review": "The paper has a nice result, which builds on prior work, but also adds new ideas.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3388/Reviewer_V7G1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3388/Reviewer_V7G1"
        ]
    }
]