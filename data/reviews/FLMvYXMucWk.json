[
    {
        "id": "IJG3Uxtx5Fn",
        "original": null,
        "number": 1,
        "cdate": 1666548315018,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666548315018,
        "tmdate": 1666548315018,
        "tddate": null,
        "forum": "FLMvYXMucWk",
        "replyto": "FLMvYXMucWk",
        "invitation": "ICLR.cc/2023/Conference/Paper539/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper studies the two-phase phenomena in training deep neural networks both empirically and theoretically. The work discovers and explains the reason for the feature collapse phenomenon in the first phase, i.e., the diversity of features over different samples keeps decreasing in the first phase, until samples of different categories share almost the same feature, which hurts the optimization of MLPs. It explains such a phenomenon in terms of the learning dynamics of MLPs. Additionally, the work theoretically analyzes the reason why four typical operations can alleviate the feature collapse.",
            "strength_and_weaknesses": "#Strength: the work is well presented and well written. It discovers an interesting phenomenon empirically with extensive experiments, and investigates it theoretically: the phenomenon that different neurons in a layer are optimized towards a common direction in the first phase\n\nIt provides explanations of why four typical operations can alleviate the feature collapse: \n\n#Weakness: The experiments are mostly done on MLP and VGG network architectures. More experiments should be done on more popular/modern architectures such as ResNet or even large Vision transformer networks.\n\nThe analysis is based upon gradient flow and quite strong assumptions.\nAlthough it explains the benefits of four typical operations from the new perspective, it is unclear for providing practical guidance for improving optimization design. The paper can be significantly improved by introducing new methods for improved training.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The presentation is quite clear. The work has some merits.\nThe code is provided.\n",
            "summary_of_the_review": "Overall, this work is well-written and well-presented.\nIt studies an interesting TFC phenomenon in deep learning training, with quite extensive experiments and theoretical justifications.\n\nIt is a bit unclear on the universality and practical guidance of TFC.\n",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper539/Reviewer_nGWd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper539/Reviewer_nGWd"
        ]
    },
    {
        "id": "PPlMMMdzp1",
        "original": null,
        "number": 2,
        "cdate": 1666604811957,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666604811957,
        "tmdate": 1670515404834,
        "tddate": null,
        "forum": "FLMvYXMucWk",
        "replyto": "FLMvYXMucWk",
        "invitation": "ICLR.cc/2023/Conference/Paper539/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors examine in depth the learning-sticking problem in early training of DNNs from the perspective of learning dynamics. \nThey offer a novel explanation for what often happens to network weights and inner activations during the problem - which they call \"the temporary feature collapse\" (TFC) phenomenon\nThey provide thorough theoretical (and empirical) analysis and justification of their idea.\n",
            "strength_and_weaknesses": "PLus\n- There are not many studies that look in depth on the early phase of DNNs training and that examine what exactly happens to the network \ninternal structure before the training error begins to decrease (and why this period is sometimes unexpectedly long).\nThe paper tries to fill in this gap.       \n- The paper shows a counter-intuitive (but possibly common) mechanism that causes a NN-model to get stuck in the early phase of training. \nThe idea presented is new and surprising to me. \n- The provided theoretical (and empirical) analysis in broad and thorough, with convincing results.\n\n\nMinus\n- Although the temporary feature collapse phenomenon is interesting, the impact of the findings on NN applications and future research may be rather limited.\n  The authors show that TFC can be easily avoided by commonly used techniques (clever weight initialization, momentum, l2 regularization, batch normalization) \n  which implies that TFC phenomenon rarely occurs in current applications.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\nAfter rebuttal:\n\nI have read the authors' comments, the new version of the paper and other reviews. I agree with most of the criticism regarding the original submission (e.g.,the need to test more NN-architectures, the need of real-world applications/impact, strong assumptions, and other theoretical analysis issues). On the other hand, I appreciate how the authors revised the paper to clarify these concerns. Most of the flaws are resolved in the final submission.\n\nI think the work is novel, interesting and solid enough to be accepted despite its remaining flaws (mainly the relatively limited practical impact). However, since my score seems too optimistic compared to other reviewers with similar opinions on the latest version, I lower my score to 6 for consensus (although it is hard for me to decide between 6 and 8).\n",
            "clarity,_quality,_novelty_and_reproducibility": "Novelty\n- Both the presented temporary feature collapse phenomenon and its explanation seem to be novel a provide a novel insight on the learning dynamics of early training phases.\nRelated work is cited and analyzed adequately.\n\nQuality\n- The claims are well-supported by the broad theoretical analysis and convincing experimental results. \nThe technical quality seems to be very good. However, I apologize for not being able to understand all the theory and proofs in depth and thus I don't feel capable to evaluate less obvious technical flaws if there are any. \n\nClarity\n- The presentation as a whole is clear and comprehensible, although there are less comprehensible technical proofs. ",
            "summary_of_the_review": "A solid contribution. It presents a new phenomenon in early DNNs training and shows its possible explanation. The claims are supported by thorough theoretical and empirical analyses.\nHowever, practical impact of the findings seems to be limited. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper539/Reviewer_4cUL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper539/Reviewer_4cUL"
        ]
    },
    {
        "id": "KM6-BRLi7cF",
        "original": null,
        "number": 3,
        "cdate": 1666788364491,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666788364491,
        "tmdate": 1669737790144,
        "tddate": null,
        "forum": "FLMvYXMucWk",
        "replyto": "FLMvYXMucWk",
        "invitation": "ICLR.cc/2023/Conference/Paper539/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This work finds that the MLP exhibits a fundamental yet counter-intuitive TFC phenomenon in the early stage of the training process. After that, the authors explain this phenomenon from the perspective of learning dynamics and explain why four types of operations can alleviate the TFC phenomenon. Extensive theories and experiments are conducted to support the arguments of this work. ",
            "strength_and_weaknesses": "Strength:\n\n(1)  The authors discover the common TFC phenomenon in early learning of the MLP.\n\n(2)  The authors explain this phenomenon from the perspective of learning dynamics. \n\n(3)  The authors explain why four types of operations, including normalization, momentum, initialization, and regularization, can alleviate the TFC phenomenon.\n\nWeaknesses:\n\nThis work explains the TFC phenomenon from the perspective of learning dynamics. I have some questions as follows. \n\n(1)  The authors argue that there exist two stages in the training process of DNNs, however, how to determine the percentage of two stages? If the first stage is short, what does this explanation tell us? And can you explain the second stage of the training process? \n\n(2)  It seems that all the explanations are based on DNNs, so is it suitable for CNNs or the recent transformer models? Furthermore, it is also more valuable if the authors point out what it will bring to real-world applications.\n",
            "clarity,_quality,_novelty_and_reproducibility": "This work has high quality and high clarity. This work has originality in explaining the TFC phenomenon of DNNs. The results should be reproducible because the authors provide codes in the supplementary material. ",
            "summary_of_the_review": "This work finds that in the early stage of the training process, the MLP exhibits a fundamental yet counter-intuitive TFC phenomenon and explains the reason why four typical operations can alleviate the TFC phenomenon. However, from my field, I cannot realize the value it can bring to the real world, and it seems that the theory analyses only focus on DNNs, which might not be suitable for CNNs or transformers. Could the authors give a further explanation because I am only partially in your field? Currently, I tend to vote marginally below the acceptance threshold but I am not an expert in the related field. I will hear more from other reviewers and the authors\u2019 responses.\n\n\n=== After rebuttal ===\n\nI have read the authors' responses and other reviewers' comments. The responses solve my concerns well. I am willing to raise my score.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper539/Reviewer_7KPL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper539/Reviewer_7KPL"
        ]
    },
    {
        "id": "1E9v87GqIZI",
        "original": null,
        "number": 4,
        "cdate": 1667157231777,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667157231777,
        "tmdate": 1669726913910,
        "tddate": null,
        "forum": "FLMvYXMucWk",
        "replyto": "FLMvYXMucWk",
        "invitation": "ICLR.cc/2023/Conference/Paper539/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper focuses on learning multi-layer perceptrons (MLPs), particularly the feature collapse phenomenon in the first phase, i.e., the diversity of features over different samples keeps decreasing in the first phase of training until samples of different categories share almost the same feature. The authors explain such a phenomenon in terms of the learning dynamics of MLPs.",
            "strength_and_weaknesses": "## Strength\n-  The feature collapse phenomenon in the first phase is very interesting. It could provide insights into understanding the learning dynamics of MLPs. This phenomenon complements the neural collapse phenomenon [A] observed at the end of the training stage. \n-  Partial analysis based on assumptions is provided to understand the feature collapse phenomenon.\n## Weakness\n- The feature collapse phenomenon happens only in certain cases. For example, this phenomenon disappears when batch normalization is used. This point was not clear until section 4.3. Given that batch normalization is a common practice in training deep neural networks, it should be clearly specified the training settings for observing the feature collapse phenomenon at the beginning (e.g., in both abstracts and introduction). \n- Section 4.1 provides two perspectives to analyze the feature collapse phenomenon. But there is no description of why these two perspectives are needed and how they could provide an explanation. For example,  perspective 1 focuses on the change of the weight vectors and observes the existence of the common optimization direction shared by different weight vectors. But recall that the feature collapse phenomenon refers to similar features across different inputs. It is not clear how perspective 1 can provide an explanation for the feature collapse phenomenon. \n- The analysis in section 4.2 is based on very strong assumptions. For example, Theorem 2 assumes that the features of different samples from the same category have been pushed in the same direction. This seems already assume the collapse phenomenon. \n- It is not clear how the analysis in section 4.2 deals with samples from different classes. Assumption 1 comes out of the blue, and there is no description for it. \n- Overall, I found it is not easy to follow section 4.2. The presentation of the analysis could be improved. \n- Section 4.3 shows that some techniques (like batch normalization) can alleviate the feature collapse phenomenon, while others (like L2 regularization) can strengthen this phenomenon. So should we alleviate or strengthen this phenomenon? How does this phenomenon affect performance? \n\n[A] Papyan, Han, Donoho. Prevalence of neural collapse during the terminal phase of deep learning training. Proceedings of the National Academy of Sciences, 2020.\n\n____________________ After rebuttal_______________\n\nI appreciate the authors' great efforts in addressing my comments. I have increased my rating, but I still have concerns about the analysis. Per the comment \"The key problem of explaining the TFC phenomenon is to prove that the significance of such a common direction is likely to be further enhanced, just like a \"self-enhanced system.\" Without the proof of the \"self-enhanced system,\" the assumed initial common direction does not significantly decrease the diversity of features, and cannot exhibit the TFC phenomenon.\", I am still not clear why the common gradient direction is not enough. Also, if it behaves like a \"self-enhanced system\", then the features will only become more collapsed, but why it disappears in the second phase? ",
            "clarity,_quality,_novelty_and_reproducibility": "The description of the feature collapse phenomenon is very clear and easy to follow. The results are also very interesting and could provide insights into understanding the learning dynamics of MLPs. However, this phenomenon is only observed in restricted cases, i.e., the vanilla training without batch normalization or other tricks. On the other hand, the result may provide new insight into the role of batch normalization and other techniques. The analysis is limited and based on strong assumptions. \n",
            "summary_of_the_review": "Based on the above comments, this paper studies an interesting phenomenon, the feature collapse phenomenon in the first stage of training. While this result is interesting and could provide insight into the training dynamics of MLP, this result is only observed under strict settings, the analysis seems to provide limited guidance on why this happens as it is based on strong assumptions and only considers the samples from the same classes, and it is not clear how this phenomenon affects the performance (since one can either alleviate or strengthen this phenomenon by some common techniques like batch normalization and weight decay). ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper539/Reviewer_4Wyv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper539/Reviewer_4Wyv"
        ]
    }
]