[
    {
        "id": "0FIVQTuqDG",
        "original": null,
        "number": 1,
        "cdate": 1666660424076,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666660424076,
        "tmdate": 1666660424076,
        "tddate": null,
        "forum": "BW9KtL-bott",
        "replyto": "BW9KtL-bott",
        "invitation": "ICLR.cc/2023/Conference/Paper4776/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors tackle personalized neural architecture search for federated learning, where data heterogeneity is alleviated by the architectural personalization. The authors propose a method named SPIDER that uses a supernet from which local models can be sampled while sharing the weights. The authors validate their method on several benchmarks against existing methods.\n",
            "strength_and_weaknesses": "**Strength**\n- The paper is easy to read.\n- They tackle the practical federated learning with architectural personalization.\n- The results are impressive.\n\n**Weaknesses**\n- The proposed algorithm trains two models at each client, both global supernet and local model, which may increase the computation and memory consumption of local resources. Although NAS is devised to optimize consumption of given resources, the proposed framework seems to be inefficient and even not practical in real-world scenarios. \n- In the same context, the overall communication and computation costs should be discussed and compared with the baseline models. But, I can only find the comparison of the searched model\u2019s performance and its size (parameters).\n- It is better to compare with more similar existing baseline models that uses supernet for sampling the local models, i.e. HeteroFL [Diao et al 21] or FedorAS [Dudziak et al 22], in terms of both efficiency (communication costs, etc) and performance.\n- More experiments should be conducted for detailed analysis, i.e. ablation study.\n\nDiao et al, HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients, ICLR 2021.\n\nDudziak et al, FedorAS: Federated Architecture Search under system heterogeneity\n",
            "clarity,_quality,_novelty_and_reproducibility": "There are some rooms for improving the quality, clarity, and originality of the proposed method. For example, detailed comparison with some existing methods that are utilizing the supernet for Federated NAS (i.e. HeteroFL, FedorAS, etc) and more analysis for the proposed method (i.e. ablation study)",
            "summary_of_the_review": "I enjoyed reading the paper, but several improvements seem to be required, as mentioned above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4776/Reviewer_fLM4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4776/Reviewer_fLM4"
        ]
    },
    {
        "id": "ThD4-aDAR6",
        "original": null,
        "number": 2,
        "cdate": 1666679589910,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666679589910,
        "tmdate": 1666679589910,
        "tddate": null,
        "forum": "BW9KtL-bott",
        "replyto": "BW9KtL-bott",
        "invitation": "ICLR.cc/2023/Conference/Paper4776/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper formulates a personalized neural architecture search framework for the federated learning, aiming at searching for the personalized neural architectures for each client under the federated learning scenarios. The topic and the proposed idea of this paper are novel, but the experimental analysis and the technical depth of this paper are not enough.",
            "strength_and_weaknesses": "S1. The topic studied in this paper, i.e., realizing both weight and architectural personalization in the federated learing (FL) scenarios, is important and novel in the field of FL. \nS2. This paper is well-written, the problem definition and algorithm description are clear and easy to follow.\nS3. In the experiments, the authors compare the proposed method with the personalized FL methods with a fixed model architecture, demonstrating the significance of realizing architectural personalization in the field of FL.\n\nW1. A kind of solution for the problem studied in this paper is to combine the existing personalized federated training method with the existing gradient-based neural architecture search (NAS). That is using the personalized federated training method to replace the non-personalized single-machine model training method applied in the existing gradient-based NAS method. In this way, both the architectures and the weights can be optimized in a personalized manner under the FL framework, realizing both weight and architectural personalization in the FL scenarios. \nAuthors should compare the above solution (using different NAS algorithms and federated training methods) with the proposed method in the experimental part, to demonstrate the superiority and the importance of the proposed method.\nW2. What\u2019s the difference between the solution mentioned in W1 with the proposed method in this paper? The solution mentioned in W1 is straightforward (it is just a simple combination of the existing works), and more appropriate solution should be designed to deal with the novel federated NAS problem. Does the novel federated NAS problem bring new challenges, requiring novel NAS solutions or federated training methods? Does the proposed method solve these challenges? Authors can discuss these contents in depth.\nW3. The experimental analysis is not enough. The performance curves, i.e., the federated performance of the proposed method and other federated NAS methods at different time steps, are not given and not analyzed in the experimental parts. These curves can reflect the search effect and the search efficiency of different algorithms under the FL framework, which is important for evaluating a federated NAS algorithm.\nW4. Why perturbation-based NAS is selected to realizing the NAS operations in the proposed method? Why not select the other gradient-based methods? The selection basis should be clarified in the next version. In addition, authors should add experiments to examine the differences of selecting perturbation-based NAS instead of other NAS method.",
            "clarity,_quality,_novelty_and_reproducibility": "The quality, clarity and originality of this paper is good.",
            "summary_of_the_review": "The topic is novel and important, the paper is well-written and the experiments demonstrate the significance of the proposed method. But some important baselines are missing in the experiments, the novelty of the proposed method should be discussed in depth, the experimental analysis are not enough, and the design of the proposed method are not clear. Suggest to further modify this paper for publication.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4776/Reviewer_pg98"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4776/Reviewer_pg98"
        ]
    },
    {
        "id": "kjH79HmrXqk",
        "original": null,
        "number": 3,
        "cdate": 1666820165461,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666820165461,
        "tmdate": 1666820165461,
        "tddate": null,
        "forum": "BW9KtL-bott",
        "replyto": "BW9KtL-bott",
        "invitation": "ICLR.cc/2023/Conference/Paper4776/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The submission proposed NAS algorithm for personalized Federated Learning. Specifically, it alternately optimizing one homogeneous global model and one local model that is the subnetwork of the global one. Basically, the idea is not novel and the solution is straightforward, limiting its contribution to the community. Moreover, the notations used are not well-presented, making the draft hard to follow. I thus do not champion the acceptance.",
            "strength_and_weaknesses": "\nStrong points:\nS1: the results seem promising.\n\nS2: the literature review is somehow thorough.\n\nWeakness:\n\nW1: the idea is not novel and the solution is straightforward. The submission claims in the related work section \u201cWhere all these models search for a unified global model, a key distinction of our work with these works is that we aim to search for a personalized model for each client.\u201d However, this is not true. Many existing work such as the following two are also providing NAS for different clients in FL.\n\n1). Personalized Neural Architecture Search for Federated Learning, Minh Hang et al. Neurips Workshop 2021.\n2). Personalized Federated Learning via Heterogeneous Modular Networks. Tianchun Wang, et al. ICDM 2022, 2022.\n\nActually, these two papers are using more elegant solution for PFL. The proposed solution adopts the mixture method of ideas of NAS and MAML. It needs to maintain two networks (one global and one local) that causes additional communication/storage burden in FL. The second term (regularization) term in formula (5) is very straightforward. \n\n\nW2: the notations used are not well-presented, making the draft hard to follow. The notations used are not formal. Typically, matrix, vectors, and scalars are using different fonts for easy reading. However, all the notations are using the same fonts. \n\nW3: There are too many typos and grammar errors indicating the low-quality of the draft. Even in the abstract, there are clear typos, e.g., \u201call the clientsin FL\u201d.\nMore examples, in the intro \u201cwe demonstrate accuracy gain of 10%, 6%, 4% over\u201d==>\u201dwe demonstrate an accuracy gain of 10%, 6%, 4% over \u201c\nIn the related work \u201c meeting clients efficiency budgets\u201d==> meeting clients\u2019 efficiency budgets\n\nW4: The experiments are far from complete. The authors only compared to very few PFL baselines. Many more related works are not compared. For example, the most relevant \u201cPersonalized Neural Architecture Search for Federated Learning, Minh Hang et al. Neurips Workshop 2021.\u201d Was not compared.\n\nW5: There is no theoretical analysis if the algorithm will converge or not.\n",
            "clarity,_quality,_novelty_and_reproducibility": "the notations used are not well-presented, making the draft hard to follow. The notations used are not formal. Typically, matrix, vectors, and scalars are using different fonts for easy reading. However, all the notations are using the same fonts. \n\nThere are too many typos and grammar errors indicating the low quality of the draft. Even in the abstract, there are clear typos, e.g., \u201call the clientsin FL\u201d.\nMore examples, in the intro \u201cwe demonstrate accuracy gain of 10%, 6%, 4% over\u201d==>\u201dwe demonstrate an accuracy gain of 10%, 6%, 4% over \u201c\nIn the related work \u201c meeting clients efficiency budgets\u201d==> meeting clients\u2019 efficiency budgets\n\nThere are no code release thus hard to validate the reproducibility.",
            "summary_of_the_review": "The submission proposed NAS algorithm for personalized Federated Learning. Specifically, it alternately optimizes one homogeneous global model and one local model which is the subnetwork of the global one. Basically, the idea is not novel and the solution is straightforward, limiting its contribution to the community. Moreover, the notations used are not well-presented, making the draft hard to follow. The experiments are also very short. Many baselines are not compared. I thus do not champion acceptance.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4776/Reviewer_AAmq"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4776/Reviewer_AAmq"
        ]
    },
    {
        "id": "diGtHwjXVYE",
        "original": null,
        "number": 4,
        "cdate": 1666936304836,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666936304836,
        "tmdate": 1666936304836,
        "tddate": null,
        "forum": "BW9KtL-bott",
        "replyto": "BW9KtL-bott",
        "invitation": "ICLR.cc/2023/Conference/Paper4776/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes SPIDER, an algorithmic framework that aims to search personalized neural architecture for federated learning. SPIDER alternatively optimizes a global model (called supernet) and a local model that is connected to global model and has its own architecture. Experimental results demonstrate that SPIDER outperforms other state-of-the-art personalization methods with much fewer times of hyperparameter tuning.",
            "strength_and_weaknesses": "Strength:\n- This paper proposes a novel method for federated neural architecture search \n- Empirical results against several existing baseline methods show some improvements of the proposed method\n\nWeakness: \n- There are some unclear parts on the proposed method: \n  - I am a bit confused on the definition of $a_k$, i.e. the architectural parameter for each client. Is this 0/1 variables whose elements are associated with operations in supernet? The authors may need to clarify that and revise some notations. \n  - Based on the above concern, how is $a_k$ updated in Algorithm 2? Specifically, in step 7, the authors evaluate the validation accuracy of $a_k^t$ with one operation removed. Nevertheless, note that only one operation is kept in each iteration, then how can we evaluate the validation accuracy of $a_k^t$ with more operation removed? This is very confusing and require some clarifications. \n- Some more discussions are needed for the proposed method:\n  - I am a bit uncertain on the differences between SPIDER and the following method: perform supernet training, then distill useful subnetworks from the trained supernet based on local data, while SPIDER distills subnetworks during training. The authors may add some discussions on this variant. \n  - Moreover, can algorithm 2 uses other NAS methods (e.g., [1])? Some discussions may also be needed to make the proposed method more complete. \n- Some recent baseline methods [2, 3] are missing in current version, which makes it hard to evaluate the actual performance of the proposed method. The authors may need to add some comparisons to them\n- Ablation studies are also largely missing in current version. It is unclear how each part of the proposed method contributes to its empirical performances. \n- Minor issue:\n  - It may be better to move some parts of the supplementary material to main text, e.g., architecture personalization gain, which seems critical for the whole paper\n  - The authors may check the citation format. Currently citations are mixed with the main text and creates some difficulties in reading\n  - Typos in abstract: line 6 \u201cclientsin -> clients in\u201d?\n\n[1] Single Path One-Shot Neural Architecture Search with Uniform Sampling. ECCV 2020\n\n[2] Personalized Federated Learning through Local Memorization. ICML 2022\n\n[3] Federated Learning with Partial Model Personalization. ICML 2022\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: this paper is mostly clear, though several parts require some clarifications. There are also some typos and formatting problems. \n\nQuality: the paper can still be further improved. Some more discussions are needed to make the proposed method complete, and the experiments also need some improvements to fully evaluate the proposed method. \n\nNovelty: the proposed method is novel and substantially different from existing methods in my opinion. \n\nReproducibility: this paper provides some information on its hyper-parameters, but does not provide its code, which may still create some difficulties repeating its experiments. \n",
            "summary_of_the_review": "While this paper proposes a novel method and empirical results show some improvements, the proposed method needs more clarifications and discussions. For the empirical results, some recent methods are missing in comparison, and ablation studies are also largely missing. Thus I choose reject as my initial score. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4776/Reviewer_p6Ea"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4776/Reviewer_p6Ea"
        ]
    }
]