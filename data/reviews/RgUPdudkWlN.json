[
    {
        "id": "OIc_-xnVn5v",
        "original": null,
        "number": 1,
        "cdate": 1666485757830,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666485757830,
        "tmdate": 1666485757830,
        "tddate": null,
        "forum": "RgUPdudkWlN",
        "replyto": "RgUPdudkWlN",
        "invitation": "ICLR.cc/2023/Conference/Paper1994/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper proposes a new data-augmentation strategy based on curriculum learning for long-tail problems. The key idea is to estimate the appropriate strength of data augmentation needed for each class during training. The proposed method was evaluated on widely used datasets and achieved favorable performance.",
            "strength_and_weaknesses": "## Strength\n1. The idea of changing the strength of data augmentation for each class during the training depending on their performance is reasonable and interesting. The idea is so simple that it can be easily integrated with other methods for long-tailed learning as shown in the paper.\n1. The proposed method is evaluated on popular datasets for long-tailed learning and shows consistently good performance.\n1. The analysis provided in section 4.3 helps readers understand the characteristics of the proposed method.\n1. The paper is mostly well written and easy to follow.\n\n## Weakness\n1. In my view, the important contributions of the paper are two-fold: (1) the paper presented a new way to estimate the performance of each class during training, and (2) the paper presented the idea of changing the strength of augmentation according to the performance of each class during training. I think the paper becomes stronger if it could provide more in-depth analysis on which part of the two are essential.\n    1. For (1) [A1] proposed to use validation data to estimate the difficulty of each class. Possibly the authors can use this method in the LoL process instead of the proposed one. This clarifies if it is the proposed LoL process that makes the overall performance better or an alternative method can also be used in the LoL process. \n    1. For (2), even though the authors compare the proposed method with other augmentation methods, it is not clear if the overall performance gain comes from the proposed curriculum, or the selected set of data augmentation and its strength presented in Appendix D. The last paragraph of Section 4 \u201cImpact of curriculum\u201d may be the one for this analysis, but I could not judge if the proposed curriculum is actually effective since there is no detailed explanation on other methods. For example, what is the \u201cvanilla algorithm\u201d? Which \u201chyperparameter optimization\u201d method is used? Please elaborate \u201cthe final augmentation strength of CUDA\u201d more. What happens if the kinds of augmentation and its strength is randomly sampled from the sets presented in Appendix D in each step? I am afraid that the performance gain presented in Table 1-3 actually come from just a richer set of data augmentation.\n1. It is not clear what \u201cthe augmentation policies\u201d in the 3rd line from the bottom of p8 means. Is it the augmentation policies of the existing methods or the proposed method? Even though the authors state that \u201dCUDA is computationally efficient\u201d in the last line, I doubt that it is not necessarily the case because the proposed method needs to run multiple inferences to calculate $V_{Correct}$.\n\n[A1] Sinha+, Class-Difficulty Based Methods for Long-Tailed Visual Recognition, IJCV 2022\n\nMinor points.\n1. I needed to read several times and make some guesses to understand what each graph in Figure 1 shows. I think the 6 graphs shown in the top row represent the accuracies of majority classes (class index 0-49) while the 6 graphs in the bottom row show those of minority classes (class index 50-99). I think it is better to add clearer and more detailed explanation in the caption or the figure itself.\n1. Figure 3: It is necessary to clearly indicate in the caption that the bottom row shows feature alignment gain, not feature alignment.\n1. It is good that the dynamics of the LoL score is shown in Figure 4, and it shows reasonable results. I wonder if it has actually correlate with the accuracy. The paper may become stronger if the analysis on the correlation between the estimated LoL score and validation or test accuracy is added.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "- The paper is mostly clear except the points I listed above.\n- The quality of the paper in terms of its writing, the technical soundness, and the support provided by the experiments is good. \n- Even though the idea of using different strength of data augmentation itself and the curriculum learning itself are well-known, I think the design presented in this paper to combine them to better handle long-tailed problems has good novelty.\n- Since the code is provided, I believe the results are reproducible though I have not tried to do so by myself. ",
            "summary_of_the_review": "I think the key idea of the paper is reasonable and the empirical evidence provided in the experiments are sufficient. Although the paper has some room for improvement, I think the paper has already enough contribution to the community.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1994/Reviewer_QwML"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1994/Reviewer_QwML"
        ]
    },
    {
        "id": "XISA4lss_I",
        "original": null,
        "number": 2,
        "cdate": 1666563861047,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666563861047,
        "tmdate": 1668869735365,
        "tddate": null,
        "forum": "RgUPdudkWlN",
        "replyto": "RgUPdudkWlN",
        "invitation": "ICLR.cc/2023/Conference/Paper1994/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper deals with class imbalance from the data augmentation perspective. It is based on and motivated by an analysis on the relationship between data augmentation degree and performance per class. ",
            "strength_and_weaknesses": "**Strengths**\n\n- Data augmentation is an interesting dimension to study class imbalance in general.\n\n- The proposed method is simple and reasonably effective in the sense that it exploits the empirical analysis.\n\n\n**Weaknesses**\n\n- The contribution of \"the first to suggest a class-wise augmentation method to find a proper augmentation strength for class imbalance problem\" is over claimed. As this is a special case of exiting dataset-specific data augmentation methods such as  (Cheung & Yeung, ICLR 2022).\n\n- In Introduction, the findings on the data augmentation and class performances are given without proper and concise explanation. This is fine only when they are intuitive and there is no need for explaining, but it seems not.\n\n- Figure 1 needs more interpretation in the caption. e.g. What is the metric for the grid charts\n\n- Method:\n> 1)  A few hyper-parameters are introduced, and how to tune them is not clear.\n> 2) What means by curriculum of DA? \n\n- Experiments: \n> 1) Given that this paper is about data augmentation, it is useful and necessary to compare with existing dataset-specific data augmentation search methods such as (Cheung & Yeung, ICLR 2022). This is missing now. \n> 2) The performance gain on larger datasets (ImageNet, iNaturelist 2018) in Table 2 is smaller. This seems that class-wise data augmentation will get less useful along the scale dimension. This is a key issue for experimental evaluation.\n> 3) Fig 5 (d): This shows that the most performance margin is from the use of curriculum. Given this, what is the performance for the case of w/o CUDA & w. Curriculum?  ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear and easy to understand with some parts in method and experiment for more clarity.\n\nThe novelty is sort of limited due to that dataset-specific data augmentation exists.\n\nThe reproducibility seems good since the method design is not complex.\n\nThe overall quality is limited at the current form, considering the weaknesses as listed above.\n\n\n\n",
            "summary_of_the_review": "A OKish work on class imbalanced learning with some limited evaluations and also likely limited scalability issue. \n\nSome clarity issues need to be addressed for the final judgement. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1994/Reviewer_nPVy"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1994/Reviewer_nPVy"
        ]
    },
    {
        "id": "eI4nqooE-o",
        "original": null,
        "number": 3,
        "cdate": 1666668404290,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666668404290,
        "tmdate": 1666668404290,
        "tddate": null,
        "forum": "RgUPdudkWlN",
        "replyto": "RgUPdudkWlN",
        "invitation": "ICLR.cc/2023/Conference/Paper1994/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper proposes to use a class-dependent augmentation strategy for tackling the class imbalance problem. The paper initially observes that by using a class-dependent augmentation where only the majority classes are augmented, the performance of the minority classes improves but that over the majority class regresses. Thus, the paper proposes to learn a curriculum for class-dependent augmentation strength, with the idea being that if the model is performing good over a certain class for an augmentation strength then the strength can be increases and reduced otherwise. They propose level-of-learning, which each class computes the augmentation strength to be used for that epoch. At each epoch, it is either incremented or decremented based on the model's performance over a subset of data for that class over all the augmentation strengths up to the current one.\n\nEmpirically the proposed method achieves a good boost on top of several different existing long-tail tackling approaches over different datasets. To show that their approach leads to a good balance between the majority and minorty classes, the authors plot the variance of weight L1-norm of linear classifier between each class and show that the variance is lower when using the proposed approach. The authors also compare against using a fixed augmentation strategy such as RandAugment and AUtoAugment and show that their method works better than using a fixed augmentation.",
            "strength_and_weaknesses": "Strengths - \n1. The paper is very well written and easy to flow along.\n2. The motivation in the paper about how doing augmentations for some classes affects the performance of non-augmented classes is really useful.\n3. Extensive experiments are conducted on top of existing baselines and over different datasets and the gains achieved show the usefulness of the approach.\n4. I really like the comparison against fixed augmentations such as AutoAugment and RandAugment. Such comparisons show the efficacy of the proposed class-dependent augmentation strategy.\n5. The comparison against doing a curriculum search using hyperparameter optimization algorithms is also neat and useful.\n\nWeakness - \n1. Since for computing the LoL the paper uses only a subset of the data from that class, I am curious to see the variance in the performance. However, none of the tables report the variance in the performance but only the mean result across 3 trials.\n\n2. The paragraph \"Dynamics of LoL score\" needs more emphasis. Specifically, it would be interesting to see some statistics of what are the LoL scores for the majority classes and the minority classes after the end of the training. While figure 4 has the plots, it is difficult to conclude something from there. Can authors include some statistics, such as the mean LoL score for the top k majority and minority classes respectively?\n\n3. How do the authors select which subset of data to use for LoL computation? Is it completely random? Can the authors also report what happens when the samples with the highest/lowest training loss and instead chosen?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is clear and easy to follow along with a good motivation behind the approach. The work seems novel to me.",
            "summary_of_the_review": "I really like the extensive experimentation and the different ablations done in the paper to show the efficacy of the approach. I am thus leaning towards accepting the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1994/Reviewer_URnx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1994/Reviewer_URnx"
        ]
    },
    {
        "id": "EzEKWx5113e",
        "original": null,
        "number": 4,
        "cdate": 1666703520410,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666703520410,
        "tmdate": 1669344369490,
        "tddate": null,
        "forum": "RgUPdudkWlN",
        "replyto": "RgUPdudkWlN",
        "invitation": "ICLR.cc/2023/Conference/Paper1994/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper found that augmentations in one class may be negative for itself but positive for other classes. Thus, they propose a novel data augmentation method, call CUDA for long-tailed recognition. This method can generate proper class-wise augmentation strength for long-tailed recognition. They first compute a level-of-learning score for each class and leverage the score to determine the augmentation. The authors conduct experiments on cifar-lt, imagenet-lt and inaturalist 2018. The comparisons with previous SOTA methods demonstrate the effectiveness of CUDA.",
            "strength_and_weaknesses": "Strength:\n \n1. \"Our key finding is that class-wise augmentation improves performance in the non-augmented classes while that for the augmented classes may not be significantly improved, and in some cases, performances may even decrease.\" The motivation and the findings in this paper are really interesting. \n\n2. The results are good and comprehensive in the experiments. \n\n3. The paper is well-presented and easy to follow. \n\nWeakness:\n\n1. One of the key ablations is missing. What are the results of uniformly assigning all data augmentations to all classes? This should be a baseline and presented in the tables. That is, the conventional operation\n\n2. Will the order of different augmentations have an effect on the final results?\n\n3. What is the effect of preset augmentation number K?\n",
            "clarity,_quality,_novelty_and_reproducibility": "The motivation of this paper is novel and interesting. \n\nIn this paper, 22 augmentations are considered. I am curious if the phenomenon that \"Our key finding is that class-wise augmentation improves performance in the non-augmented classes while that for the augmented classes may not be significantly improved, and in some cases, performances may even decrease.\" only exists in this setting. If we only consider several simple augmentations, for example, flip and resize, will the conclusion still satisfy? ",
            "summary_of_the_review": "The motivation, writing, and the results are good of this paper. However, there are some points which need further clarification.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1994/Reviewer_N4yQ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1994/Reviewer_N4yQ"
        ]
    },
    {
        "id": "ap216e0jy0",
        "original": null,
        "number": 5,
        "cdate": 1666720644150,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666720644150,
        "tmdate": 1668746881496,
        "tddate": null,
        "forum": "RgUPdudkWlN",
        "replyto": "RgUPdudkWlN",
        "invitation": "ICLR.cc/2023/Conference/Paper1994/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper proposes an auxiliary data augmentation technique that can be used on top of several long-tailed recognition methods. The main insight of the paper is that class-wise augmentation actually improves the performance of non-augmented classes. This is an important as well as counter-intuitive observation. The authors devise a data augmentation strategy that relies on the `strength' of augmentation, which is calculated using level-of-learning.\n",
            "strength_and_weaknesses": "Pros:\n1. The main observation of the paper- \"class-wise augmentation actually improves the performance of non-augmented classes\" is very crucial and important.\n2. The data augmentation strategy devised by the authors also seems clever and logical. However, there are a few things that are concerning (see concerns).\n\nConcerns:\n1. The way DA with strength parameter is devised is concerning because it assumes that the sequence of augmentation is permutation invariant and preserves the identity of the original sample. This need not be the case with many augmentations.\n2. From Fig. 5c it seems that the method is sensitive to threshold / accept rate \\gamma, in experiments also, the authors choose 2 different values of \\gamma (0.4 and 0.6). What procedure do the authors follow to decide this value? Is there any strategy one can follow to come up with this value?\n3. In Table 2, the improvement with CUDA looks very incremental. \n4. For such close values it is suggested that the authors report the scores in the form of mean \\pm std. dev to give a more clear view of how close the scores actually are.\n5. The authors show that the variance of L1-norm of a linear classifier decreases due to CUDA. In general, any data-augmentation strategy should decrease the variance because of an increase in the data samples.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Please see the comments in the previous section. ",
            "summary_of_the_review": "Overall, I feel the paper has a good amount of novelty and the observations made are crucial for the community. However, there are some concerns that need to be answered before going forward. Hence, at the moment I will keep my score as borderline reject. I would like to see other reviewers' scores and author rebuttals. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1994/Reviewer_Z6g5"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1994/Reviewer_Z6g5"
        ]
    }
]