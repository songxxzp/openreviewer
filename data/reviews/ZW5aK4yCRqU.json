[
    {
        "id": "vxSFzWieUj",
        "original": null,
        "number": 1,
        "cdate": 1665996305996,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665996305996,
        "tmdate": 1669793709735,
        "tddate": null,
        "forum": "ZW5aK4yCRqU",
        "replyto": "ZW5aK4yCRqU",
        "invitation": "ICLR.cc/2023/Conference/Paper1703/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors present a Convolutional Neural Network (CNN) architecture based on pointwise operations, global operations, and local operations, i.e., continuous convolutional kernels to handle the input with different lengths and resolutions. They show that this setting is data independent, which models long-range dependencies at every layer, with a fixed number of parameters. The experimental results show that the proposed Continuous Convolutional Neural Network (CCNN) performs well on the Long Range Arena dataset given sequence data. ",
            "strength_and_weaknesses": "# Strength:\n- The idea of \"a CNN architecture that can be used across input resolutions, lengths and dimensionalities (1D, 2D, 3D) showing its viability across several 1D, 2D and 3D tasks\" seems interesting, which may facilitate the cross-modal pre-training to further enhance the performance of large neural networks. \n- The experimental results seem encouraging that CCNN tends to outperform strong baselines on sequence data, e.g., the competitive results on the Long Range Arena dataset. \n\n# Weaknesses:\n- ### Major concerns:\n  - I politely disagree that \"Convolutional Neural Network (CNN) architectures must be tailored to specific tasks in order to consider the length, resolution, and dimensionality of the input data\" since the input data size can be inconsistent with the training dataset. Though CNN can not be directly applied to the 1D/3D input when pre-trained on 2D images, the descriptions of CNN as \"current CNN architectures are resolution-bounded and thus different resolutions require different CNNs\" and \"there is no trivial way to obtain equivalent kernel values on upsampled data, and hence, no way to apply a trained model directly\" seem inappropriate.\n  - The authors claim that \"our Continuous Convolutional Neural Network parameterizes kernel values as a continuous function $\\varphi$ over the input domain $R^d$, which decouples it from data characteristics\". It would be better to further discuss the \"data characteristics\" decoupled by the continuous function. Besides, it is true that a continuous kernel is compatible with arbitrary size/resolution/dimensionality, however, given the limited computing resources, a sampling operation is required during pre-processing (also pointed out by the authors in **Computational efficiency**). Is \"informed sampling\" against the motivation of a data-independent network?\n  - Though the authors elaborate on the \"data-independent\" architecture, I am not fully convinced that this setting should contribute to higher performance. Notice that the popular Transformer architecture still requires conventional convolution operations to extract features and then conducts multi-head self-attention. From my point of view, convolution operations that introduce inductive bias could be more suitable for images. Then, the authors may further discuss the motivation of this paper.  \n  - It would be better to report the real runtime speed instead of the model parameters to make a fair comparison with S4 [1].\n\n- ### Minor Comments:\n  - **Parameter scaling**: the description of \"CCNN formulation lacks in parameter scaling capabilities; increased parameter counts yield strongly\ndiminishing returns\" seems unclear.\n  - **Separable Continuous Convolutions**: How to determine the input channel number and the feature map size of the continuous \"spatial\" separable convolutional layer? It would be better to explain the meaning of $D$, $N_{in}$, and $N_{out}$.\n  - **Table 1**: As claimed in *Empirical results*, \"the CCNN is not restricted to grid data, e.g., 3D voxels, and can be used on point-clouds directly\", I expect promising results on ModelNet40. However, the $CCNN_{4,110}$ seems far from satisfactory.\n  - I am curious why the authors did not increase the weight decay $\\lambda$ given that \"we observed strong overfitting to the training set, which\nmay indicate the need for stronger regularization\"?\n  - **Normalized relative positions**: What if the largest unitary position is larger than $N$ at inference time?\n  - **Code repository and logging**: It seems that the code link is missing.\n  - **Section 3.1**: \"Pointwise operations are applied independently to each spatial element of the input signal\". However, each spatial element shares the same parameter for 1x1 convolutions.\n  - Please fix the \"Sec.??\" on page 4.\n  - I expect an ablation study on the effect of the S4 Block [1].\n \n# Reference:\n[1] Efficiently modeling long sequences with structured state spaces. ICLR2022\n",
            "clarity,_quality,_novelty_and_reproducibility": "I personally think the clarity and reproducibility of this paper are ok. However, the current manuscript has some overlaps with the existing works [2], which makes the real contribution of this paper very limited. A thorough discussion of the differences between CCNN and CKConv would help to make a fair judgment of this submission. \n\n# Reference:\n[2] CKConv: Continuous kernel convolution for sequential data. ICLR2022",
            "summary_of_the_review": "Overall, my major concern is the real novelty of this paper. Besides, considering that the empirical results on several datasets are relatively lower than the baseline results, the effectiveness of the proposed method remains unclear. The authors are encouraged to solve the weaknesses above.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1703/Reviewer_RGNG"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1703/Reviewer_RGNG"
        ]
    },
    {
        "id": "iVL9ewWCyIS",
        "original": null,
        "number": 2,
        "cdate": 1666611973358,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666611973358,
        "tmdate": 1666611973358,
        "tddate": null,
        "forum": "ZW5aK4yCRqU",
        "replyto": "ZW5aK4yCRqU",
        "invitation": "ICLR.cc/2023/Conference/Paper1703/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper presents Continuous Convolutional Neural Networks, which can process the input of arbitrary resolution, length, and dimensionality. Compared to conventional convolutional neural networks which adopts fixed-size kernels, the proposed continuous convolutional networks adopt dynamic and continuous kernels, which removes the dependencies of the input data. Based on the presented continuous convolution operation, this paper designs a deep continuous convolutional network and apply it to several tasks with different input shapes and resolutions. ",
            "strength_and_weaknesses": "### Strength\n1. This paper presents a data-independent operation, i.e., continuous convolution operator, which is adaptive to the shape, resolution, and dimension. The continuous convolution based on Continuous Kernels maps the spatial (relative) locations to the parameters.\n2. This paper builds a continuous convolutional networks based on the continuous kernel and depth-wise continuous convolutions, namely CCNN, and provides a series of optimization strategies, including the initialization, regularization, and etc.\n3. This paper adopts the same architecture on several tasks with different input resolutions or shapes, e.g., 2D images and 3D point clouds.\n4. Experimental results of this paper on varieties of benchmarks of various input shapes are good.\n\n### Weakness\n1. The novelty of this paper is limited. The proposed continuous convolution has been explored in the most relevant papers [1,2], which share the same motivation and similar approach with this submission. The authors SHOULD clearly state the contribution of this paper and the differences compared to others\u2019 works. The technical novelty of the proposed CCNN based on Continuous Kernels and FlexConv is limited for me.\n2. This paper lacks detailed illustration and description about the proposed architecture, which is the main contribution in my opinion since the continuous convolution can not be regarded as a novel contribution of this paper.\n3.  I don\u2019t agree that data-dependent architectures are terrible or limited by shapes, resolutions, or dimensions. Firstly, data-dependent architectures bring more inducive bias for specific tasks, which has better characteristics compared to the so-called universal architectures. Secondly, data-dependent or hand-crafted architectures can perform better on specific data/tasks in terms of both speed and accuracy, and most practical applications are driven by data-dependent architectures. Moreover, we now have massive versatile transformers and neural architecture search mechanisms, and I\u2019m concerned about the predominance of the proposed CCNN.\n4. This paper lacks the exact inference speed, training speed, or latency on the given devices, e.g., NVIDIA GPU. It matters for me.\n5. In Tab.1, the authors should provide more comparisons with the newer methods, e.g., vision transformers. I\u2019m glad to see that the proposed CCNN can perform better with less or comparable computation budget when compared to recent vision transformers.\n6. I\u2019m concerned about the transferring ability on 2D inputs, i.e., 2D images. For example, training the proposed CCNN and a normal CNN which have similar hierarchical architecture and parameters on ImageNet or other datasets and evaluate the performance on lower-resolution datasets. Providing fair comparisons and experimental evaluations will be more convincing in my opinion.\n\n[1] Remero et.al. CKConv: Continuous Kernel Convolution for Sequential Data. ICLR 2022.\n[2] Remero et.al. FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes. ICLR 2022.\n\n### Typos\nMissing reference in Sec. 3.3: \u201cwith 9 parameters (Sec. ??)\u201d.\n",
            "clarity,_quality,_novelty_and_reproducibility": "### Clarity\nThis paper should clearly state its technical contribution.\n### Quality\nThe writing quality is fair.\n\n### Novelty\nThe novelty is limited. The core idea of the proposed CCNN is the continuous kernel convolution, however, it has been explored and proposed by previous publications. The proposed CCNN adopts the continuous kernels to adapt for different shapes of input, which is below the threshold of technical novelty.\n\n### Reproducibility\nThe authors provide some implementation details of the experiments but it\u2019s still hard for reproducing the methods and experimental results.\n",
            "summary_of_the_review": "Considering the limited technical novelty and contribution of this paper, I think this paper is not qualified as a conference paper. This paper is highly coincident with previous works.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1703/Reviewer_jCEb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1703/Reviewer_jCEb"
        ]
    },
    {
        "id": "aCuoelPSOjK",
        "original": null,
        "number": 3,
        "cdate": 1666614259452,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666614259452,
        "tmdate": 1666614618882,
        "tddate": null,
        "forum": "ZW5aK4yCRqU",
        "replyto": "ZW5aK4yCRqU",
        "invitation": "ICLR.cc/2023/Conference/Paper1703/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper aims to make CNN suitable for data of arbitrary resolution, dimensionality and length without any structural changes. A Continuous CNN is proposed by introducing continuous convolutional kernels which is a data independent parameterization for convolutional weight. The proposed CCNN can work on on sequential (1D), visual (2D) and point-cloud (3D) tasks with the same architecture.",
            "strength_and_weaknesses": "Strength:\n- The motivation to construct a unified convolution neural network is interesting.\n- The Continuous CNN is a reasonable solution for general architecture.\n- Experimental results on a range of sequence, image and point-cloud datasets show the effectiveness of the proposed method.\n\nWeaknesses:\n- What about the computational complexity? I'm afraid it will be large since there is no downsampling.\n- The number of parameters will be large since the method introduces a kernel neural network.\n- To make neural network independently from the input length, or resolution, there are several other alternatives like deformable convolution [1] and graph convolution [2]. Why not using these methods? Please include discussion.\n- Just a suggestion and not necessary: could the proposed CCNN trained once on all the datasets in Table 1 and work well on all of them? Large-scale ImageNet performance?\n- Typos: \"??\" in footnote in page 4.\n- The writting of the paper should be improved: what are $*$ and $\\tilde{x}$ in Eq.(1).\n\n[1] Dai J, Qi H, Xiong Y, et al. Deformable convolutional networks[C]//Proceedings of the IEEE international conference on computer vision. 2017: 764-773.\n\n[2] Han K, Wang Y, Guo J, et al. Vision GNN: An Image is Worth Graph of Nodes[J]. arXiv preprint arXiv:2206.00272, 2022.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well organized. The proposed Continuous CNN is new to me. The implementation details are well provided but the code is not available.",
            "summary_of_the_review": "I like the idea to unify CNN architectures on various tasks.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1703/Reviewer_KStu"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1703/Reviewer_KStu"
        ]
    },
    {
        "id": "Bk3Fiaxuw1b",
        "original": null,
        "number": 4,
        "cdate": 1666767972496,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666767972496,
        "tmdate": 1666767972496,
        "tddate": null,
        "forum": "ZW5aK4yCRqU",
        "replyto": "ZW5aK4yCRqU",
        "invitation": "ICLR.cc/2023/Conference/Paper1703/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the authors proposed a unified CNN architecture that is tested on multiple datasets. The main idea is to learn a hyper-network to predict the discrete kernel given coordinates as input, which is instantiated based on an existing kernel-size differentiable convolution (FlexConv). Extensive experimental results are provided on multiple benchmark datastes covering inputs of different dimentionalities and modalities.",
            "strength_and_weaknesses": "Pros:\n1. The proposed idea is interesting.\n2. The empirical results are supporting.\n\nCons:\n1. The technical novelty is rather limited as the building blocks are mainly from exisiting work, e.g., FlexConv, although the reviewer does recognize the contribution of all the empirical results and discussions.\n2. One important aspect is missing: transformer is not only surprising as one architecture could be applied to different type of inputs. The more practical and important fact is that different inputs could indeed share most of the weights of the network [r1,r2]. \na. Therefore, it will be really more exciting if the authors also explores the setting where different types of inputs/tasks share the same set of network weights. \nb. Another interesting exploration is to interpret the network weights trained on different data: does model trained on different data in the same modality share certain weighs? do models trained on different types of data even also share certain patterns?\n\n[r1] All in one: Exploring unified video-language pre-training\n[r2] PolyViT: Co-training Vision Transformers on Images, Videos and Audio\n\n\n\nMinor:\n\"Sec. ??\" appears multiple times. For example, in Sec 3.3, in the second paragraph, \"Sec. ??\".",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is of OK quality and clarity. The originality of the method is limited as discussed above but the reported results and discussions could be of help for a sub-field in the community.",
            "summary_of_the_review": "Despite of limited novelty on the technical side and some missing exploration to further support the motivation of unifying the architecture among modalities, the reviewer still feels the current results and discussions could be possibly helpful for the community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper1703/Reviewer_Av5z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper1703/Reviewer_Av5z"
        ]
    }
]