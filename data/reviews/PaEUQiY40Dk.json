[
    {
        "id": "tBgMeh-ujU4",
        "original": null,
        "number": 1,
        "cdate": 1666616439966,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666616439966,
        "tmdate": 1666617400424,
        "tddate": null,
        "forum": "PaEUQiY40Dk",
        "replyto": "PaEUQiY40Dk",
        "invitation": "ICLR.cc/2023/Conference/Paper922/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper is overall a quite interesting paper. Based on an abstract teacher-student framework with simple network architecture, the authors explore how a masked reconstruction pre-training architecture performs feature learning and becomes beneficial for downstream tasks by modeling \"semantics\" as attribute vectors associated with different annotation labels. With the above analysis, the authors further conduct a MRP pre-training with ResNet and demonstrate more superior performance compared with supervised pre-training. \n\n",
            "strength_and_weaknesses": "- Strength:\n  - The authors provide a very detailed theoretical analysis based on the proposed teacher-student MRP framework.\n  - The idea of modeling \"semantics\" as several attribute vectors associated with classes is interesting.\n  - After theoretical analysis, the authors further conduct implementations to support their analysis.\n\n- Weakness:\n  - In the MRP architecture proposed in Sec. 3.2, are there any requirements of the teacher model parameters, like they should be the EMA of the parameters of the student model?\n  - The analysis heavily bases on the assumption that the \"semantics\" of the downstream dataset should be a subset of the pre-training dataset. Does it suggest that the downstream dataset should have similar distribution with the pre-training one, which is actually a very strong and unrealistic assumption? If not, what is the difference?\n  - The authors claim that the MRP pre-trained models would contain all the semantics of the downstream tasks, each at least corresponding to one kernel. Does it suggest to do transfer learning, if I can find the specific wining ticket of a given downstream task, pruning can actually replace fully fine-tuning?\n  - I wonder whether the MRP pre-trained models would be worse when the pre-training dataset does not contain all the semantics in the downstream datasets compared with supervised pre-training, since the latter replies on partial semantics matching while MRP might response to more semantics according to Fig. 3.\n- Could you further explain what the role of masking \\epsilon is, since it seems not to appear in your analysis in Sec. 4?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Check the weakness part for more details.",
            "summary_of_the_review": "This is overall an interesting paper solid theoretical analysis, which will provide good insights for future researches and algorithm development.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper922/Reviewer_TnqJ"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper922/Reviewer_TnqJ"
        ]
    },
    {
        "id": "Go2IL8Zz7g7",
        "original": null,
        "number": 2,
        "cdate": 1666649018964,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649018964,
        "tmdate": 1666649018964,
        "tddate": null,
        "forum": "PaEUQiY40Dk",
        "replyto": "PaEUQiY40Dk",
        "invitation": "ICLR.cc/2023/Conference/Paper922/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper provides a theoretical analysis that explains the benefit of MRP in SSL. Utilizing the multi-view data distribution and certain assumptions about the model architecture, the paper shows that the encoder trained with MRP can capture *all* the discriminative semantics of each semantic class in the pretraining dataset. This gives an advantage to the SSL+SL compared the SL only model since in SL training the model only captures *some* semantics due to lottery ticket hypothesis.",
            "strength_and_weaknesses": "Strength:\n\n1) The paper provides a strong theoretical analysis, supporting the benefit of MRP for SSL.\n\n2) It is really hard to pick a minimal set of assumptions about the data and model that are just sufficient to prove the advantage of MRP in SSL. I like how the paper mathematically defines multi/sing-view distributions and picks a simple network architecture and manages to prove the benefit of MRP over SL.\n\n\nWeaknesses:\n\n1) There are several limiting assumptions in the multi-view data distribution and network architectures that do not apply in practice. However, I understand that these restrictions are required for a sound theoretical analysis. \n\n2) The theoretical analysis in the paper does not result in a new practical approach, instead it supports the success of the existing methods in a limited setting.",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well written and the definitions, assumptions, and theorems are cleanly stated and make sense to the reader. Note that I did not read the proofs and can not speak of their correctness.",
            "summary_of_the_review": "Recent works have shown practically that supervised fine-tuning of the encoder learned via MRP remarkably surpasses the SL training from scratch but I am not aware of any theoretical work that supports the benefit of MRP. The paper provides new theoretical justification for the success of MRP in practice. Overall, the theoretical contributions of the paper are significant and novel.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper922/Reviewer_GkZ3"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper922/Reviewer_GkZ3"
        ]
    },
    {
        "id": "0luB9RKGXm",
        "original": null,
        "number": 3,
        "cdate": 1666669662717,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666669662717,
        "tmdate": 1666669662717,
        "tddate": null,
        "forum": "PaEUQiY40Dk",
        "replyto": "PaEUQiY40Dk",
        "invitation": "ICLR.cc/2023/Conference/Paper922/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors study the mask-reconstruction pretraining (MRP) approach and its ability to generalize well for downstream tasks. They show that under certain dataset and task assumptions, MRP can perform well for downstream classification tasks whereas supervised learning cannot. ",
            "strength_and_weaknesses": "Strengths\n- The problem is clearly an important one to study, and hasn't been adequately addressed by the existing literature. \n- The use of the multi-view data assumption from  (Allen-Zhu & Li, 2020) is clever. \n- The empirical results match the theoretical findings, from multi-view data assumption to test performance on downstream tasks. \n\nWeaknesses\n- The assumption that pre-training and downstream datasets follow the same distribution is in some ways limited. While the authors discuss how this framework is useful, it would be nice to see more analysis of \"transfer learning\", since this is much of the appeal of pre-training approaches. \n- Dataset assumptions are fairly strict, though the authors reason about how these assumptions are justified. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity\n\nThere are parts where the work is not clear and has typos. I've listed two glaring examples here, but I'm sure there are more throughout the text that should be re-checked. \n\nTop of page 8: \"in the pretraiing\"\nThe use of \"semantic\" as a singular noun is somewhat strange. I haven't seen this before and the authors should consider a different word choice. \n\nQuality and Novelty\n\nWhile some data assumptions come from a previous work, the problem setting is unique and the analysis is valuable.  ",
            "summary_of_the_review": "The theory is both correct, novel, and matches the empirical results of MRP, which is an important problem to study. While there are important results, the dataset assumptions cast some doubt on how generally applicable the results are. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper922/Reviewer_J85J"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper922/Reviewer_J85J"
        ]
    },
    {
        "id": "ITE90WNo9q",
        "original": null,
        "number": 4,
        "cdate": 1666854938343,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666854938343,
        "tmdate": 1666854938343,
        "tddate": null,
        "forum": "PaEUQiY40Dk",
        "replyto": "PaEUQiY40Dk",
        "invitation": "ICLR.cc/2023/Conference/Paper922/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper introduces a theoretical analysis to understand why mask reconstruction pre-training (MRP) works well in downstream tasks. It's found MRP can capture all discriminative semantics of each class in the pre-training dataset and thus utilize them to help downstream tasks. It provides solid proof, straightforward visualization and experiment result.",
            "strength_and_weaknesses": "Strengths:\n1. The problem of why MRP works so well and is much better than supervised learning is quite interesting and important for the community. This paper is a pioneer in studying how semantic features are learned under the above problem.\n2. The theoretical analysis covers both multi-view data and single-view data. It also covers both MAE-like methods, Teacher-Student MRP methods, and supervised learning methods. It also discusses different downstream tasks. \n\nWeaknesses:\n1. In this paper, it assumes the encoder in the student network is just a two-layer convolution + Smoothed ReLU network. I understand that this setting is easier to analyze. But in real-world applications, people usually use deeper models. And we know that some conclusions found in a simple model don't necessarily generalize to deeper models. So I wonder if it's possible to generalize the analysis to deeper models?\n2. I am a bit confused about the definition of whether one semantic is captured by the kernel. In 4.1, If I understand correctly, when the correlation score is increased to `1/polylog(k)`, it means matched. Why would the threshold be set as that?\n3. The experiments mainly cover visualization and accuracy. But those two proxies cannot indicate whether all discriminative semantics are captured in MAE/MRP. Is there any way we can quantitatively measure how many semantics in each class are captured by kernels?\n4. As you mentioned in section 4.2, Transformer is not discussed because of its correlated manipulations and highly nonlinear attention. Is that possible that we remove the nonlinear part and make it analyzable?\n5. Some typos such as `The pretraining dataset Z has` in Assumption1. ",
            "clarity,_quality,_novelty_and_reproducibility": "The paper writing is clear. The theoretical proof is novel and inspirational to the community.",
            "summary_of_the_review": "Overall, this paper targets an intriguing problem and provides solid proof. I'd lean to accept it.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper922/Reviewer_1jPb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper922/Reviewer_1jPb"
        ]
    }
]