[
    {
        "id": "9-ZRSlPk7Jy",
        "original": null,
        "number": 1,
        "cdate": 1666408777195,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666408777195,
        "tmdate": 1666408777195,
        "tddate": null,
        "forum": "vINj_Hv9szL",
        "replyto": "vINj_Hv9szL",
        "invitation": "ICLR.cc/2023/Conference/Paper2680/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper makes two contributions. First, it proposes a new benchmark for Inverse Constrained Reinforcement Learning (ICRL) for continuous control tasks that provides environments along with location constraints in those environments that an agent has to satisfy, as well as expert demonstrations obtained through PPO-Lag for each of these. The benchmark includes continuous control tasks in MuJoCo and separately a continuous driving control task. Second, the paper proposes a new method, Variational Inverse Constrained Reinforcement Learning (VICRL) which uses variational inference to infer a full posterior over possible constraints. The paper compares VICRL to previously proposed constraint inference methods and finds that VICRL slightly outperforms the alternatives.",
            "strength_and_weaknesses": "Strengths\n* Clarity of presentation. With the exception of some minor typos here and there, some of which I point out below, the paper is well written and clear. The benchmark is well motivated from the perspective of a key missing piece for comparing different approaches to ICRL, and the method description was straightforward to follow.\n\n* Potential for impact. The proposed benchmark seems like it would meaningfully fill a current gap to make reproducibility and comparisons across different methods for constraint inference easier. While I have some concerns that the benchmark as defined is too limited for meaningfully advancing the field as a whole, I believe in the general idea and think that if done well it could have a significant impact.\n\n* Baseline comparisons. The baselines compared to in this paper are up-to-date methods that highlight different approaches to learning and inferring constraints from demonstrations. This aids in the interpretation of the results for the proposed VICRL method.\n\n* Code looks reasonably straightforward to use with clear README which will be valuable for anyone interested in actually using the benchmark.\n\nWeaknesses\n* The VICRL method does not statistically outperform either of the presented state-of-the-art baselines across tasks (GACL or MECL). While it may perform comparably to prior techniques, there is no environment for which it statistically significantly outperforms baselines (based on Figures and Table B.2 of appendix). In order to then still show value of VICRL over the baselines, more information is needed as to where VICRL shines by having a posterior distribution over constraints. While what it learns appears to be interpretable based on the appendix, it is not obvious that the posterior distribution helps with this. So what exactly is the variational method providing in terms of interpretability, efficiency, or performance? If there is no clear answer to this, the paper might be better written as a benchmark only paper, with some extensions to the considered tasks.\n\n* Proposed benchmark is lacking constraint and environment representations that the community already thinks are critical.\n  * Grid-world representations not included, despite being mentioned by the authors in several places as a major focus of study for a subset of the RL community.\n  * Constraints specified mostly as location constraints do not cover the vast varieties of constraint types that matter for robotics and RL applications\n  * Many constraints that are interesting from a robotics standpoint include multiple variables, and sometimes multiple objects, and are often time-varying.\n  * For example, consider those that describe the dynamics inside common simulators like PyBullet or MuJoCo, we have constraints like fixed (two bodies move together as one), revolute (fixed axis of rotation around which an object can move), or sliding. In safety applications, constraints are very likely to be time-varying, such as avoiding coming into contact with any humans. \n  * None of these are represented by the current benchmark. This risks developing methods that are overly specific to static location-based constraints, which would not reflect what the community ultimately wants for downstream applications.\n\nNot a weakness per se, but I didn\u2019t understand how it could be possible that the constraint inference methods could out-perform PPO-Lag for the blocked ant environment. Could the authors elaborate on this?\n",
            "clarity,_quality,_novelty_and_reproducibility": "Most of my comments are above, but pointing out a few specific typos here to be fixed:\n\n* Figure 3 caption defined both above and below figure?\n* A few stray ICLR baselines instead of ICRL baselines :)\n* Figure 7 both columns labeled \u201cincomplete dataset\u201d when one should be about added noise I think.\n",
            "summary_of_the_review": "It is risky to write a paper that makes two contributions simultaneously. Doing so risks that neither component alone will be done sufficiently well to merit publication. Unfortunately I think that is the case with this paper. I personally think the introduction of the benchmark is likely to have a greater impact on the community than the VICRL technique, as the VICRL method does not statistically outperform either of the two state-of-the-art baselines for the presented tasks. However, as mentioned in the weaknesses section, the benchmark is not quite general enough to be used as a comprehensive assessment of agents\u2019 abilities to learn constraints from demonstrations. I therefore do not think the paper can be accepted as is, and would encourage the authors to expand the benchmark part of their paper to consider a greater range in the types of constraints that are investigated.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2680/Reviewer_4BCv"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2680/Reviewer_4BCv"
        ]
    },
    {
        "id": "iBA9WfXwCWX",
        "original": null,
        "number": 2,
        "cdate": 1666649662645,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666649662645,
        "tmdate": 1669264981457,
        "tddate": null,
        "forum": "vINj_Hv9szL",
        "replyto": "vINj_Hv9szL",
        "invitation": "ICLR.cc/2023/Conference/Paper2680/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper can be thought of as two (related) papers:\n\n1. A proposed benchmark for learning constraints from demonstrations in continuous (approximately deterministic) domains. Here constraint is taken to be an assertion that sum of unknown random variables (either in expectation or per episode) is less than a particular value. The goal of this family of problems is to identify the unknown constraints. This includes a series of domains with corresponding demonstrations, objectives, and constraints.\n\n2. An adaptation of maximum entropy based constraint inference that explicitly models distributions over the constraints. The adaptation is shown to perform well on the proposed benchmark making it a reasonable baseline for future comparisons.\n\n",
            "strength_and_weaknesses": "# Strength\n\n1. I agree with the paper that this (important) emerging sub-area is in need of common benchmarks.\n\n2. The domains and proposed constraints/demonstrations are certainly interest and cover both synthetic and \"real world\" scenarios.\n\n3. The proposed algorithm makes sense and builds on prior work in a pretty reasonable way.\n\n# Weakness\n\nAs I tried to highlight in the summary, this benchmark focuses on domains that are entirely deterministic (the synthetic ones) or approximately deterministic (the ones generated by human performance noise). Like with the development of maximum entropy inverse RL, it is worth distinguishing this from fundamentally stochastic domains, i.e., when causal entropy is not well approximated by \"non-causal\" entropy. Here I would argue that the gridworld domains that were directly disregarded offer a non-trivial test bed, e.g., for high-level planning in the presence of environment and multi-agent noise.\n\nIn particular, the proposed algorithm is really only suitable for (approximately) deterministic domains as is pointed out in Brian Ziebart's 2010 thesis. \n\n[Nitpick] Finally, I would argue that the proposed algorithm addresses a slightly different problem since it is privy to an implicit prior distribution over constraints?\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is reasonable well written and collected together several existing domains to construct the benchmark. The algorithm appears to be a straightforward adaptation of ideas from Scobee et al (as cited) to include a distribution on the constraints.",
            "summary_of_the_review": "I think the area of constraint learning is indeed in need of a set of benchmarks. I think this paper is a good step in that direction, although I would argue has a fairly biased focus on continuous deterministic domains that is not emphasized enough as a limitation / bias.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2680/Reviewer_sTb2"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2680/Reviewer_sTb2"
        ]
    },
    {
        "id": "yCT7R7i4us",
        "original": null,
        "number": 3,
        "cdate": 1666711918134,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666711918134,
        "tmdate": 1666711918134,
        "tddate": null,
        "forum": "vINj_Hv9szL",
        "replyto": "vINj_Hv9szL",
        "invitation": "ICLR.cc/2023/Conference/Paper2680/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The authors provide a new benchmark for constrained inverse reinforcement learning, including modified mujoco environments, as well as a self-driving-car inspired environment.  The authors additionally propose a Bayesian algorithm for solving problems in this class they call Variational Inverse Constrained Reinforcement Learning (VICRL).",
            "strength_and_weaknesses": "Strengths: The benchmark seems well motivated, and the experiments provided by the authors seem sufficient to establish the shape of the problem, but also to gesture at headroom for improvement.\n\nWeaknesses: It's unclear to me how long this will remain a relevant benchmark.  The MuJoCo suite is a bit dated now, and the community has tended to overfit to it as a reference simulator.  A benchmark like the one proposed by the authors, but with significantly more variability / range of difficulty seems like it would be strictly more useful, and possibly last longer as a concrete target for the community.  As it stands, I worry that this benchmark will be \"solved\" within approximately 6 months.",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity & Quality: The manuscript is quite clear and high quality.\n\nNovelty:  The bayesian approach by the authors is fairly novel, and the subfield targeted by this manuscript is clearly in need of some kind of rallying \"benchmark\".\n\nReproducibility: Code has not been shared, but it appears that it will be once deanonymization occurs.",
            "summary_of_the_review": "A solid submission, including a new algorithmic technique and a new benchmark.  I have some reservations about lasting impact, but these are not show-stopping reservations.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2680/Reviewer_cYaH"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2680/Reviewer_cYaH"
        ]
    }
]