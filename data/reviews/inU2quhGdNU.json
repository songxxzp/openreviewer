[
    {
        "id": "VUEgf8nnljX",
        "original": null,
        "number": 1,
        "cdate": 1666739428553,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666739428553,
        "tmdate": 1666739428553,
        "tddate": null,
        "forum": "inU2quhGdNU",
        "replyto": "inU2quhGdNU",
        "invitation": "ICLR.cc/2023/Conference/Paper2253/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper analyzes neural collapse (NC) phenomenon by decoupling it into two separate learning objectives: minimal intra-class variability and maximal inter-class separability, and proposes a Generalized NC applicable to broader applications. It then designs a quality as  hyperspherical uniformity gap (HUG) working as an alternative but meaningful loss as for CE and MSE. Theories and experiments on classification tasks show the effectiveness of the HUG loss.",
            "strength_and_weaknesses": "Strength:\n- The writing is good.\n\n- The decoupling and the generalization of NC is excited to me, especially the solid theoretical analysis along with the great numerical performance of the proposed HUG loss (though I didn't check the proofs).\n\nWeakness:\n- It mentions that HUG serves as an alternative loss function in place of CE and MSE, but HUG is only compared with CE loss in the experiments while MSE is missing. Moreover, the following two work closely related to MSE loss and the NC phenomenon are missing in the paper.\n\n    > Zhou, Jinxin, et al. \"On the Optimization Landscape of Neural Collapse under MSE Loss: Global Optimality with Unconstrained Features.\" arXiv preprint arXiv:2203.01238 (2022).\n\n    > Zhou, Jinxin, et al. \"Are All Losses Created Equal: A Neural Collapse Perspective.\" arXiv preprint arXiv:2210.02192 (2022).\n\n- The idea of GNC is great, but it is still under the assumption of a balanced dataset where each class has the same number of samples, which seems to be a bit conflict with the \"generalized\" claim. I think some comments and discussions are needed for this point.",
            "clarity,_quality,_novelty_and_reproducibility": "In my opinion, the work is of high-quality in that it provides sound theoretical foundations as well as convincing experimental results. Just some minor clarity issues:\n\n- In Theorem 3, what does $\\hat \\mu_C^C$ mean when $C\\to\\infty$? I am confused since the $C$'s appear in both the subscript and the superscript.\n- Also, $\\hat\\mu$ is not introduced until the line after Eq. (2), which is a projected vector on the unit-sphere. Is this the correct understanding? If it is, then this should be clarified in the paper.",
            "summary_of_the_review": "Based on the solidity of the work, as discussed above, I recommend for an acceptation.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2253/Reviewer_bush"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2253/Reviewer_bush"
        ]
    },
    {
        "id": "871jYdbVEL",
        "original": null,
        "number": 2,
        "cdate": 1666866756870,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666866756870,
        "tmdate": 1666866756870,
        "tddate": null,
        "forum": "inU2quhGdNU",
        "replyto": "inU2quhGdNU",
        "invitation": "ICLR.cc/2023/Conference/Paper2253/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The paper considers the asymptotic training dynamics when classification loss approaches zero.\nIt generalizes the neural collapse phenomenon to settings to models trained on large numbers of classes.\nFurther, it proposes loss functions that decouple inter-classes separability and intra-class variability.\nTheoretical properties of such loss functions are derived and empirically the loss functions are shown to be preferable over the cross entropy loss.\n",
            "strength_and_weaknesses": "**Strengths**\n- The paper addresses neural collapse in the setting when the number of classes is larger than the feature dimension, a much more difficult problem.\n- The empirical evaluation not only considers classification accuracy in a standard setting but considers additional aspects, such as long-tailed recognition or adversarial robustness.\n\n**Weaknesses**\n- Many of the presented theorems are essentially known.\n- Central to the paper is the design of loss functions that encourage inter-classes separability and intra-class variability. This is essentially the goal of contrastive learning. Relevant literature is neither mentioned nor discussed.\n- Actually, it is not proven that generalized neural collapse (GNC) occurs if the feature dimension is smaller than the number of classes.\n- The empirical evaluation misses relevant information.\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Already known theorems**.\n\nThe study of symmetric point configurations and energy minimizers on spheres is a classic problem and thus the paper can build upon a large body of existing results; some of these have already been used inside the machine learning community. In the current form of the paper, it is not clear, which results are considered new by the authors and which ones are considered established.\n\n- Theorem 1. This is a theorem about the energy-minimizing configurations of convex kernels. An identical version of this theorem can be found as Theorem 2.4.1 in the monograph Discrete Energy on Rectifiable Sets by Sergiy V. Borodachov [1].\n- Theorem 2. Admittedly, in the appendix it is clarified, that this can be concluded from Cohn & Kumar, 2007 [2]. A previous proof can be found in Theorem 3 of Yudin, 1993 [3].\n- Theorems 3. and 4. are well-known and can for example be found in [1] (also mentioned in the appendix).\n- Proposition 1. In the appendix it is clarified, that proposition 1 assumes *normalized* gaussian vectors. Then, this is an immediate consequence of the spherical symmetry of the gaussian distribution.\n- Propositions 2 and 3 are applications of the theorems to the specific loss functions. In this sense, they are new.\n- Proposition 4. This is a standard bound on the cross entropy loss which appears as an intermediate result in many papers about neural collapse for the cross entropy loss. Due to its simplicity, I don't think a reference is necessary, but calling it a proposition might be an overstatement.\n- Theorem 5. This is a corollary from theorem 3, obvious enough that no proof is included in the appendix.\n\n**Relation to contrastive learning**\n\nThe idea that inter-classes separability and intra-class variability is central to contrastive learning and has been applied there succesfully. This should definitely be discussed in the paper. In fact, the hyperspherical uniformity gap (HUG) proposed in this paper can be understood as a contrastive loss function. While recent works (e.g. [4,5]), typically utilize a loss function with a softmax function such that the attraction and repulsion forces are not obvious, older works (e.g. [6] minimize precisely, what the authors call hyperspherical energy (in [6] with $s=-2$). Particularly relevant to this paper are [7] which shows neural collapse for $c\\le d+1$ and [8] which studies the asymptotic behavior for $c\\to \\infty$, i.e. they imply a result analogous to Proposition 3 for contrastive learning.\n\n\n**The occurence of generalized neural collapse is not proven.**\n\nFirst, the paper is misleading, as suggests that prior works on neural collapse (NC) did not discuss the setting of $d< C-1$ and that therefore a generalization to GNC is required. This might be unintentional though. It is true, that theorems in prior works, typically require $d\\ge C-1$. But this should not be confused with that these works did not predict maximum inter-classes separability and minimum intra-class variability in general. The problem is that if $d< C-1$, there is no unique notion of maximum inter-classes separability and characterizing the loss minimizers is much more difficult. Particularly, different loss functions most likely have different minimizers. For example, [8] remark that\n>\" The assumption $c \\le d + 1$ [variable names changed] is crucial, as it is a necessary and sufficient condition for the existence of the regular simplex. [...] If it is violated, then the bounds derived in \u00a73 still hold, but are not tight. Studying the loss minimizing configurations in this regime is much harder. Even for the related and more studied Thomson problem of minimizing the potential energy of K equally charged particles on the 2-dimensional sphere, the minimizers are only known for K \u2208 {2, 3, 4, 5, 6, 12} (Borodachov et al., 2019).\"\n\nThus, I was very surprised and excited, that the authors defined GNC (2) via a minimum of Coulomb energy. While the minimizing configurations in this setting are equally not known, there is a large corpus of work dedicated to studying this setting. If it could be shown that a standard loss function like cross entropy would lead to minimal Coulomb energy, this would be very interesting and pave the way for future analysis. Regrettably, this is not shown. Instead, the authors analyze different loss functions. But even for these loss functions, only results for the well known settings $C\\le d+1$. $C=2d$ and $C\\to \\infty$ are presented, i.e. settings where the minimizers are universal in the sense that they apply to a wide range of loss functions.\nIn the setting $C> d+1$ I doubt that the different HUG variants satisfy property (2) of GNC, as even s-Riesz potentials can have different minimizers depending on the value of $s$.\nOverall, I wonder, *if the setting $C> d+1$ is studied only asymptotically, then why do we even need a generalized definition of neural collapse.*\n\nRegarding the empirical evidence on page 4.\nFigure 1 is misleading, as the 2-dim case is special because there GNC (2) is easily characterized by the angles between adjacent classes being constant and GNC(2) can be achieved. For higher dimensions, such an easy characterization impossible. \nEven if we would minimize the Coulomb energy for $d=3$, the experiment would be indecisive about whether GNC (2) is achieved or not. This is because there is a large number of local minima with approximately equal potential energy, cf. [1, Section 2.4]. Thus, GNC(2) cannot be proven with gradient based optimization, and, contrary to claimed in the paper the experiments do not \"verify the correctness of GNC(2)\".\n\n**Empirical evaluation**.\n\nImportant information is missing from the empirical evaluation.\n- It is claimed, that the performance gains of HUG over cross entropy are significant. Yet, there is no reported standard deviation.\n- How where the hyperparameters selected? Potentially, hyperparameters for HUG are tuned carefully but not for cross entropy.\n\n\n\nReferences\n[1] Discrete Energy on Rectifiable Sets, Sergiy V. Borodachov, Springer Monographs in Mathematics, 2019, https://link.springer.com/book/10.1007/978-0-387-84808-2  \n[2] Henry Cohn and Abhinav Kumar, Universally optimal distribution of points on spheres, 2007, https://www.ams.org/journals/jams/2007-20-01/S0894-0347-06-00546-7/  \n[3] The minimum of potential energy of a System of point charges, V. A. Yudin, 1993, https://doi.org/10.1515/dma.1993.3.1.75  \n[4] Chen et al., A Simple Framework for Contrastive Learning of Visual Representations, ICML 2020, https://proceedings.mlr.press/v119/chen20j.html  \n[5] Tian et al., What Makes for Good Views for Contrastive Learning?, NeurIPS 2020, https://proceedings.neurips.cc/paper/2020/hash/4c2e5eaae9152079b9e95845750bb9ab-Abstract.html  \n[6] Hadsell et al., Dimensionality Reduction by Learning an Invariant Mapping, CVPR 2006, https://ieeexplore.ieee.org/document/1640964  \n[7] Wang & Isola, Understanding contrastive representation learning through alignment and uniformity on the hypersphere. ICML 2020, https://dl.acm.org/doi/10.5555/3524938.3525859  \n[8] Graf et al., Dissecting Supervised Contrastive Learning, ICML 2021, https://proceedings.mlr.press/v139/graf21a.html  ",
            "summary_of_the_review": "The main weakness is the limited novelty of the paper and I recommend rejection.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2253/Reviewer_bWKx"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2253/Reviewer_bWKx"
        ]
    },
    {
        "id": "dmDRxo29PH",
        "original": null,
        "number": 3,
        "cdate": 1667083834951,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667083834951,
        "tmdate": 1668877374656,
        "tddate": null,
        "forum": "inU2quhGdNU",
        "replyto": "inU2quhGdNU",
        "invitation": "ICLR.cc/2023/Conference/Paper2253/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper proposes an interesting new Hyperspherical Uniformity Gap (HUG) objective that explicitly minimizes within-class variation while maximizing between-class variation. An especially interesting innovation is introducing---instead of canonical linear classifiers---a \"learnable proxy\" that is minimized directly with variation measures in the loss.",
            "strength_and_weaknesses": "**Strengths**\n The authors show theoretical derivations and discussions as well as numerical experiments supporting the use of HUG. The theorems and experiments, for the most part, are concise and easy to understand---supporting the authors' arguments. The appendix provides additional thought-provoking experiments and ablation studies.\n\n**Weaknesses**\nThis paper has notable weaknesses in its clarity and discussion of prior works.\n\nI describe potential improvements below:\n\n**Major Comments**\n* The authors do not provide any reproducible code. Might is be possible for the authors to give short, self-contained code that (at least) shows the implementation of MHE, MHS, and MGD?\n* Lu and Steinerberger [39] also discusses the connection of hypersphere uniformity with neural collapse in their Section 1.4. Moreover, they discuss this relative to a \"frame potential\" along the same lines as to the energy minimization discussed by the authors of this paper's theory. I realize the authors already briefly acknowledge [39], but is done only in one passing sentence. Given the similarities in these two works, might the authors add a slightly longer discussion/comparison of these two works?\n* The following ICML paper also examines neural collapse when the number of classes is larger than the ambient dimension:\n\n  Zhou, J., Li, X., Ding, T., You, C., Qu, Q. &amp; Zhu, Z.. (2022). On the Optimization Landscape of Neural Collapse under MSE Loss: Global Optimality with Unconstrained Features. Proceedings of the 39th International Conference on Machine Learning in *Proceedings of Machine Learning Research* 162:27179-27202. https://proceedings.mlr.press/v162/zhou22c.html.\n\n  Might the authors include additional discussions on how their GNC definition compares to the generalization of NC in the $d < C-1$ case given by Zhou et al. 2022?\n\n* Page 6-7: The implementations of MHE, MHS, and MGD all require the computation of *all pairwise distance norms* for the vectors passed to the associated HU(...) function. Computationally, this seems significantly slower than MSE or CE which do not require a quadratically-sized outer loop. Might the authors comment on this?\n\n*  On the same note: Might the authors discuss or include an experiment comparing the compute/CPU time required to train using HUG vs. using CE or MSE?\n\n**Minor Comments**\n* The authors discuss HUG extensively in pages 1-4, but HUG is not introduced until Page 5. As a result, for four entire pages, the reader is left to purely imagine what HUG (hypothetically) might be. This significantly weakens the authors' discussion. I strongly recommend introducing the formal definition of HUG earlier. \n* Page 2: Are Projection FDA and Data FDA instances of HUG with a particular choice of HU(...)? This is especially unclear at this point of this paper since HUG has not been introduced yet.\n* Page 2: It seems there is an even bigger problem with Projection FDA and DataFDA as objectives: They require explicitly calculating the Sb and Sw of (at best) the minibatch and (at worse) the entire dataset. This is very memory and computationally expensive. The inverse will also be expensive. MSE and CE training do not require these matrix quantities and would be much more efficient. Might the authors comment on this?\n* Page 5: \"Nontrivial to optimize the original HUG...\" At this point, the reader has not seen a concrete example of the HU(...) function yet. Thus, it is unclear why the original HUG is difficult to optimize. Even after seeing concrete examples in later papers, I am not sure which particular difficulties the authors are referring to.\n* Page 8-9: I feel like the experimental results on these pages are the most compelling part of the paper. Might it be possible for the authors to move it to earlier in the paper? (After maybe also introducing HUG and its concrete realizations earlier as well?)\n\n**Typos**\n* Figure 3 Caption: \"verifyng\"\n* Appendix A General Settings: \"gradient descend\"\n",
            "clarity,_quality,_novelty_and_reproducibility": "**Clarity**\nThe definitions and theoretical statements are clear. However, the exposition can be improved (HUG is not introduced until page 5), some discussions of prior works are missing, and some implementation details are unclear.\n\n**Novelty**\nThe HUG objective, the experiments, and their associated theoretical analysis are definitely novel ideas. However, similar ideas to those discussed by the authors *have* appeared in the literature (such as Lu and Steinerberger and Zhou et al. 2022).\n\n**Reproducibility**\n* There is no reproducible code provided with this paper.",
            "summary_of_the_review": "The HUG objective is an interesting, well-motivated idea. The claims and experiments of this paper are promising. However, the paper, as is, suffers from some clarity issues. For example, there is no reproducible code and the exposition can be improved. Additionally, two very related prior works are missing.\n\nI feel like the contributions of this paper are novel and worthy of publication. But the above-described issues make it only marginally so. \n\n* I am willing to raise my score of this paper if the authors sufficiently address the above-described issues during the revision/discussion period.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2253/Reviewer_k2o7"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2253/Reviewer_k2o7"
        ]
    },
    {
        "id": "VvLGKE0srM",
        "original": null,
        "number": 4,
        "cdate": 1667102020751,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667102020751,
        "tmdate": 1667102020751,
        "tddate": null,
        "forum": "inU2quhGdNU",
        "replyto": "inU2quhGdNU",
        "invitation": "ICLR.cc/2023/Conference/Paper2253/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "Inspired by the recently observed neural collapse (NC) phenomena in deep learning classifiers where the feature dimension is often large than the number of classes, this paper considers a more general format of neural collapse (GNC) to include the case where feature dimension $d$ is smaller than the number of class $C$. Then the authors decouple NC into two objectives: minimizing intra-class variability and maximizing inter-class separability on the hypersphere via the proposed hyperspherical uniformity. After decoupling these two objectives, the authors then propose a new objective, called hyperspherical uniform gap (HUG),  with three choices of measurement (MHE, MHS, and MGD) as examples. The proposed HUG-based loss shows some improvements in long-tailed recognition, continual learning, and adversarial robustness. ",
            "strength_and_weaknesses": "## Strength:\n- Overall, the paper is well-written and the results are clearly presented.\n- The authors slightly relax the definition of neural collapse to include the case where the feature dimension $d$ is smaller than the number of class $C$.\n- The paper proposes a new class of objective functions based on the hyperspherical uniform gap (HUG), which captures the difference between inter-class and intra-class hyperspherical uniformity. \n- The proposed loss improves upon CE in long-tailed recognition, continual learning, and adversarial robustness.\n\n## Weakness:\n- For the case the feature dimension $d$ is smaller than the number of class $C$, it seems that characterizing the geometry of maximally distant features on the unit sphere is still a challenging problem.  What is the minimum hyperspherical energy could be in this case? In other words, how could one tell if the features converge to GNC since the smallest hyperspherical energy is not zero?\n- It was also observed in [A] that when the feature dimension $d$ is smaller than the number of class $C$, the features are still well separated via CE loss, but not for MSE loss. But there is no analysis for CE loss. Under the setting of unconstrained features, could the new losses or CE be proved to converge to a solution of the generalized NC for that case (i.e., feature dimension $d$ is much smaller than the number of classes (C))?\n\n\n- I am curious whether normalization is necessary for the new objective, hyperspherical uniform gap. In other words, could the objective be extended to the case without normalization of the features?\n- Typo: Caption of figure 3 c: is it about inter-class separability?\n- Typo: Should -2<s<0 in Theorem 4?\n\n[A] Zhou et al., On the Optimization Landscape of Neural Collapse under MSE Loss: Global Optimality with Unconstrained Features, ICML 2022. \n",
            "clarity,_quality,_novelty_and_reproducibility": "- Overall, the paper is well organized and most parts are very clear. \n- Quality: this is well prepared as an academic work including theoretical proof and support experiments.\n- The paper provides a generalized neural collapse definition and new loss functions, which appear to be new. \n- In terms of reproducibility, the paper provides hyper-parameter settings for each experiment, but no code files or links are provided. ",
            "summary_of_the_review": "This paper introduces a more general NC definition and introduces a new objective (HUG) by decoupling the objectives into inter-class variability and inter-class separability. Some theoretical analyses are provided for both GNC and HUG. The proposed new loss functions can achieve better performance in long-tailed recognition, continual learning, and adversarial robustness. Overall, the results could be of interest to researchers working in these areas. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2253/Reviewer_S3We"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2253/Reviewer_S3We"
        ]
    }
]