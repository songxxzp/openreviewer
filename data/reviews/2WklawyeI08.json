[
    {
        "id": "J7L7Qo10bF",
        "original": null,
        "number": 1,
        "cdate": 1665875722119,
        "mdate": null,
        "ddate": null,
        "tcdate": 1665875722119,
        "tmdate": 1668803052010,
        "tddate": null,
        "forum": "2WklawyeI08",
        "replyto": "2WklawyeI08",
        "invitation": "ICLR.cc/2023/Conference/Paper2942/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The paper compares two forms of meta-learning, with inner-loop updates based either on modulated Hebbian plasticity, or on gradient descent over a network-generated synthetic loss function. \n\nVarious experiments show that both forms of episodic plasticity (Hebbian and gradient-based) improve performance over using fixed recurrent networks, as in RL^2/L2RL. Network-controlled modulation of plasticity is also shown to be important.\n\n",
            "strength_and_weaknesses": "Strengths:\n\n- The paper tackles an interesting problem (learning to learn without necessarily having access to a supervised or even a reward  signal during each episode, i.e. the inner loop is unsupervised).\n\n- The paper is interesting and may propose one novel method, i.e. network-generated gradient loss, though see below.\n\n- The experiments, such as they are, offer reasonable evidence that the proposed methods are useful over the studied tasks\n\n\nWeaknesses:\n\nMy main concern is about novelty. AFAICT the Hebbian portion of the method is identical to previous proposals that are cited in the paper. \n\nSimilarly, the gradient-based  method seems to be an example of meta-learning a loss function to perform gradient descent on in the inner loop. This approach is clearly not new, see e.g. https://arxiv.org/abs/1802.04821 , https://arxiv.org/abs/1906.05374 , https://arxiv.org/abs/2110.03909 and  the many references therein.  (Disclaimer: I am not affiliated with any of these authors)\n\nSurprisingly, no previous paper on this approach (meta-learning a loss function) seems to be cited in the paper, unless I missed it.\n\nThere *may* be some novelty in the proposed approach, because here the synthetic loss  is an output of the learner network itself (as opposed to a separate dedicated network). IIUC this means that the synthetic loss itself is subject to learning and tuning during the inner loop (as  in Baik et al. mentioned above, but in a much more flexible manner). This also gives rise to interesting loops in the learning process (though the precise working of the algorithm is a bit unclear, see below).\n\nIf this is correct, and if this is the claim to novelty of the paper, it should be stated explicitly.\n\nAdditional possible  problems:\n- The paper is somewhat unclear on certain points, which is important to better understand the proposed method. See below. \n- The experiments are interesting, but perhaps a bit limited?\n- Not really concerns, but suggestions for future work: the two approaches (Hebbian and gradient-based) seem fully compatible and it might be interesting to see what  happens when a network uses both together; the weight decay parameter, which is now just 1-eta, could include a separate learnable parameter as is Tyulmankov et al. and Rodriguez, Guo && Moraitis ICML 2022 (I am not affiliated with these authors).",
            "clarity,_quality,_novelty_and_reproducibility": "Two main points require clarification:\n\n- The description of the network operation is split over several section and somewhat  confusing. Most importantly, exactly which parameters are updated during the inner  vs. outer loop? This should be  specified explicitly.\n\n- The outer loop meta-optimization process should be described more explicitly, especially for the gradient-based case. E.g. do we compute full second-order gradient-of-gradients? Or is there some first-order approximation (like first-order MAML, or REPTL) ? \n\nFor novelty, see  above.\n",
            "summary_of_the_review": "== Update after reading the authors' response ==\n\nI thank the authors for their clarifications and I have updated my review and score towards acceptance.\n\n== Original review ==\n\nPlease cite more existing literature about the concept of meta-learned loss functions; explicitly state the novelty of the work; and clarify the working of the algorithm.\n\nI am willing to increase my score depending on the author's response to the above, especially regarding novelty.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2942/Reviewer_vDcd"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2942/Reviewer_vDcd"
        ]
    },
    {
        "id": "1u6-PVbvnO",
        "original": null,
        "number": 2,
        "cdate": 1666618423342,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666618423342,
        "tmdate": 1666621426510,
        "tddate": null,
        "forum": "2WklawyeI08",
        "replyto": "2WklawyeI08",
        "invitation": "ICLR.cc/2023/Conference/Paper2942/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The manuscript introduces a new way of learning task-specific unsupervised learning rule for RNNs in which the network computes not only its task output but also dynamically alters hyperparameters of its own learning process. The learning rule functional form is learned in a gradient-based outer loop based on task constraints provided via a validation set. The model is validated on a wide range of tasks and shows interesting few shot learning performance improvements relative to a static network.\n",
            "strength_and_weaknesses": "\n+ Strength: impressive performance\n+ S: analogies to biology as a motivation for the general approach\n- Weakness: the logic of the optimization procedure is not spelled out as clearly as it should be\n- W: alternative model comparison is restricted to variations of the same scheme, hard to evaluate the benefits of the approach more broadly w.r.t. alternative few shot learning approaches\n- W: conceptually unclear to me if the hebbian vs gradient based distinction is a technical choice or if one of the two versions is championed in the paper\n",
            "clarity,_quality,_novelty_and_reproducibility": "- the functional form of the internal loss was unclear (seems to aim to shrink the norm of the total output but it is unclear to me why that would be a generally useful task agnostic thing to do)\n- the timescales at which various bits change in the model are hard to parse at times; some visual for the inner/outer loop, which parameters they change and based on which loss would be very useful to. navigate the model complexity\n- the justification of the alternative models and the logic of their selection is critical for interpreting the results so it should be included in the main text\n- the exact details of the experiments w.r.t. to losses and how things were set up is insufficient",
            "summary_of_the_review": "Overall an intriguing idea and interesting results, but the presentation of the core methodology and its justification is too sparse and needs substantial improvement before publication.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2942/Reviewer_fkhw"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2942/Reviewer_fkhw"
        ]
    },
    {
        "id": "ZYUcbCnlP1G",
        "original": null,
        "number": 3,
        "cdate": 1666637701446,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666637701446,
        "tmdate": 1669069197152,
        "tddate": null,
        "forum": "2WklawyeI08",
        "replyto": "2WklawyeI08",
        "invitation": "ICLR.cc/2023/Conference/Paper2942/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "Inspired by the evolved role of plasticity in neural circuits, this paper proposes a meta-learning approach for training RNNs. The method consists of an inner loop with a learning rule that updates the parameters of an RNN, and an outer loop that learns a function for the update rule. ",
            "strength_and_weaknesses": "The proposed meta-learning approach is interesting especially from a neuroscience perspective (though not novel, e.g. Najarro and Risi, NeurIPS, 2020). However, I\u2019m not convinced that the proposed model has any advantages compared to the previously proposed methods. In particular, almost all the comparisons are between the proposed method and non-plastic RNNs which I found insufficient. \n\n$\\textbf{Questions}$:\n\n1- Almost all the comparisons are with what is called non-plastic RNNs in the paper. The motivation behind using non-plastic RNNs as the baseline model for comparisons is not explained in the paper. Specifically, the initialization of weights could place the untrained RNNs in a disadvantaged dynamical regime compared to the trained RNNs. It is hard to imagine a situation where non-plastic neural networks are considered as an alternative for how brains function, except in cases where, for example, the RNNs are initialized at the edge of chaos (criticality) which could give them specific advantages (better short-term memory, etc.) Can the authors elaborate more on the motivation behind comparing only with untrained RNNs? \n\n2- The update rules of the outer (meta-learning) rule are not shown in the paper. It was only mentioned that gradient descent was used for the outer loop, but the loss function and the target variables are not explained. Was the MSE loss shown in figures 2-3 used for the outer loop updates? Also, mentioned in section 3.2 \u201c [...] network parameters, including those that define the learning rules in the inner loop, are meta-trained with gradient descent.\u201d A list of parameters meta-trained with gradient descent would be helpful.\n\n3- Related to comment # 1, it would be interesting to see comparisons with RNNs trained in a supervised (or unsupervised) fashion (no meta-learning). The main advantages of the meta-learning approach in associative memory and few-shot learning would be more clear with those comparisons. \n\n4- One general comment: Although a key concept in the paper, the connection with meta-learning did not become clear until the end of the introduction (not even mentioned in the abstract). Concepts like \u201cself-determined target\u201d and \u201cneuromodulated plasticity\u201d are used a few times throughout the introduction before mentioning that the proposed method is a meta-learning algorithm. Because of that, It's difficult to follow the introduction and understand the main question of the paper. I suggest that the authors rephrase the introduction and highlight the connections with meta-learning at the very beginning. \n",
            "clarity,_quality,_novelty_and_reproducibility": "The proposed method requires more clarification for the meta-learning update rule. The proposed method is not very novel, and the quality of the paper is negatively affected by the lack of more thorough comparisons. ",
            "summary_of_the_review": "Although the proposed meta-learning algorithm is interesting (not novel), the comparisons with untrained (or non-plastic) RNNs is not sufficient for demonstrating the strengths of the proposed method. ",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2942/Reviewer_5CwK"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2942/Reviewer_5CwK"
        ]
    },
    {
        "id": "ai2fvGem8w",
        "original": null,
        "number": 4,
        "cdate": 1666657012190,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666657012190,
        "tmdate": 1666657012190,
        "tddate": null,
        "forum": "2WklawyeI08",
        "replyto": "2WklawyeI08",
        "invitation": "ICLR.cc/2023/Conference/Paper2942/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "In this paper, the Authors design and implement recurrent neural networks with two types of plasticity: classical Hebbian and gradient-based w.r.t. an internal loss function. The Authors then test their models on a set of memory/learning tasks including copying, cue-reward association, image classification, and regression. They find that the new gradient-based approach fares better on the regression task while the classical Hebbian approach is better in copying and image classification tasks. An ablation study is provided to assess the importance of the models\u2019 parameters.",
            "strength_and_weaknesses": "This is a thoroughly-designed and well-described study of plasticity in recurrent neural networks, which builds upon previous results by Jeff Clune, Ken Stanley, and colleagues, known to the ICLR community.\n\nThe paper introduces several interesting updates on top of the previous works. First, the \u201clearning rate of plasticity\u201d \\eta here is time-dependent, which supposedly allows the models to turn on the synaptic plasticity during one/few-shot learning, and to turn it off to retain the learned knowledge during testing. Second, in the gradient-based method, the Authors introduce internal loss. This loss relies on an extra output of the RNN, conditioned upon the RNN\u2019s weights trained in the outer loop, and is used to guide the network\u2019s plasticity in the inner loop. For both these updates, the Authors provide (in the Appendix) the ablation studies showing how different values of these parameters affect the models\u2019 performance.\n\nThe internal loss part seems especially interesting because it may link this work to a biological phenomenon of motivation. Previously. motivations in machine learning were set to reflect observable quantities such as curiosity; conversely, the internal cost functions here are defined by the model itself to reflect the important task-related quantities.\n\nAnother strength of this work lies in the comprehensive testing of the models which includes standard benchmarks and thorough ablation studies. It would be nice though to move more figures to the main text, if possible, as they show important results.\n\nSpeaking of weaknesses, the Hebbian-plasticity part of the work is highly similar to that in a series of works by Miconi et al, mentioned by the Authors (the similarity is also acknowledged by the Authors). The differences (which need to be clearly summarized somewhere in the text!) seem to be limited to 1) the time-dependent internal learning rate for synaptic plasticity, 2) not using Oja\u2019s rule, and 3) using a (more complex) image classification task instead of the Omniglot. Furthermore, the proposed gradient-based rule seems to be only efficient in the few-shot regression task among the used benchmarks. These two factors limit the contribution of this work to the field. I also found the biological insights a bit preliminary \u2013 though they do not constitute the main result of the work.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The text is well-written; the descriptions of the experiments contain sufficient information for reproducibility. The figures are good at conveying the results of the experiments (perhaps, they could be moved to the main text; also, little titles for individual panels within the figures may help parse them faster).",
            "summary_of_the_review": "This is a comprehensive study describing two mechanisms of synaptic plasticity in RNNs. The properties of the described models are thoroughly tested. In the future, some of the design choices made here (quite interesting!) may help build neuroscience-relevant models. The drawback is in high similarity to prior work (Hebb\u2019s rule part) and high similarity to Hebb\u2019s rule scores on benchmarks (gradient part).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2942/Reviewer_x3Sh"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2942/Reviewer_x3Sh"
        ]
    }
]