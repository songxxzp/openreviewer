[
    {
        "id": "rZRghfNKPHp",
        "original": null,
        "number": 1,
        "cdate": 1666569887868,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666569887868,
        "tmdate": 1666570135828,
        "tddate": null,
        "forum": "Gid_Z_oUV5q",
        "replyto": "Gid_Z_oUV5q",
        "invitation": "ICLR.cc/2023/Conference/Paper4804/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "In the paper, the authors propose SarNet, a method to tackle the hate speech detection task. The authors argue that previous methods tend to judge satirical speech as hate speech, resulting in false positives. Their main goal was to extract the degree of hate and sarcasm from a tweet to get a more realistic comprehension of any given tweet. They propose the pyramid network to extract the probabilities of hate and sarcasm.",
            "strength_and_weaknesses": "Strengths\n1. The author constructs a prisoner's dilemma via a Nash equalizer, treating sarcasm and hate as two prisoners, and finally uses the output of the dilemma to calculate the label of the final tweet.\n2. Improved performance compared to baseline methods and state-of-the-art.\n\nWeaknesses:\n1. The content of the article needs to be further refined.\n- Introduction mentions \"Our proposed SarNet model as shown in Figure 10 analyzes the contextual information of a sentence.\", but what Figure 10 expresses is \"Precision Score of SarNet vs state-of-the-art on Kaggle Dataset\", which does not fit the context. \n- There is an extra space in \"94.11 per cent\" and \"94.62 per cent\" in Sec 2.1.\n- The semantics of the two sentences in \"SarNet is proposed for true-hate detection which includes data pre-processing, and an explanation of our proposed two-fold deep learning based method.\" mentioned in Methodology are discontinuous.\n- The picture of Figure 1 is so blurry that I can't even make out the text in the blue box on the left.\n- In the experimental part, the authors did not analyze the experimental results.\n- There is no table or picture in the experimental part of the text, and the related work part is too long.",
            "clarity,_quality,_novelty_and_reproducibility": "In terms of clarity, the article needs to be further refined in both the logic part and the expression part.\nIn terms of novelty, SarNet is not the first method to tackle hate speech detection tasks.\nIn terms of reproducibility, looking at this article from METHODOLOGY, it is not difficult to reproduce this work.\nIn terms of quality, this paper proposes a two-fold deep learning-based model, which can achieve performance improvements, but the logic and expression of the article need to improve.",
            "summary_of_the_review": "This paper can achieve a certain performance improvement on hate speech detection task, but the logic and expression of the article have many areas worth improving.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4804/Reviewer_jETC"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4804/Reviewer_jETC"
        ]
    },
    {
        "id": "K0tsiy50XB",
        "original": null,
        "number": 2,
        "cdate": 1666686113212,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666686113212,
        "tmdate": 1666686332220,
        "tddate": null,
        "forum": "Gid_Z_oUV5q",
        "replyto": "Gid_Z_oUV5q",
        "invitation": "ICLR.cc/2023/Conference/Paper4804/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper presents two deep learning methods, SarNeis, that address the nuisance of hate speech detection in a given text or sentence and incorrectly flag a sarcastic tweet. First, the author employed ANN-BiLSTM, a pyramid network, to compute a sentence's hate and sarcastic probabilities. Secondly, the author used the nash equalizer from the game theory concept and prisoner's dilemma. In summary, SarNet integrates the ANN and LSTM network for calculating probabilities to Nash Equalizer, which plays games to identify the label of the sentence, using a quasi-ternary labeling process. The proposed method treats hate and sarcasm as two prisoners.",
            "strength_and_weaknesses": "Still, the ANN layers in the pyramid network pull aesthetic elements from the processed input tweet vectors. What would the model do with input texts that are often short primary samples with confusing words like idioms, onomatopoeias, homophones, phonemes, synonyms, acronyms, anaphora, and polysemy?\n\nANN can solve various problems, including virtually any problem reduceable to functions, yet, sharing is challenging after training an ANN; overfitting and convergence cannot be guaranteed. So, how will the SarNeis model handle these challenges? The addition of\nnash equilibrium to quantify probabilistic representations of the tweet as hate or sarcasm is excellent, but what type of stylometric features did ANN extract and improve with the BiLSTM layer? \n",
            "clarity,_quality,_novelty_and_reproducibility": "Generally, the manuscript starts off well with the sections on introduction and related work. In terms of quality, this paper presents a two-fold deep learning-based model, which can reach performance improvements, but the logic and expression of the article need to improve. In terms of clearness, the paper must be further refined in both logic and expression. Regarding reproducibility, glancing at this paper from a methodology perspective, it will be challenging to replicate this work. About novelty, SarNet is not the preferred method to tackle hate speech detection tasks.",
            "summary_of_the_review": "An interesting method is presented, focusing on using ANN-BiLSTM as a pyramid network to calculate a sentence's hate and sarcastic probabilities. The presented results show competitive performance with the SOTA method during training.  The paper is missing an error analysis section to investigate the registers of misclassified texts critically. Please provide examples of correctly/misclassified text with critical reflection.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No comments",
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4804/Reviewer_cP5A"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4804/Reviewer_cP5A"
        ]
    },
    {
        "id": "sLHnA8f08ey",
        "original": null,
        "number": 3,
        "cdate": 1666751930568,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666751930568,
        "tmdate": 1666751930568,
        "tddate": null,
        "forum": "Gid_Z_oUV5q",
        "replyto": "Gid_Z_oUV5q",
        "invitation": "ICLR.cc/2023/Conference/Paper4804/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper proposes a model for detecting true hate (vs. sarcasm) speech in texts, i.e., hate speech detection taking into account sarcasm.  The proposed model uses game theory (Prisoners\u2019 Dilemma) and Nash equilibrium. The experiments show that the proposed model outperforms baselines and state-of-the-art models. ",
            "strength_and_weaknesses": "strength:\n- sarcasm in hate speech seems important, and this paper tackles that problem.\n- the proposed model outperforms baselines and state-of-the-art models for hate speech detection\n\nweaknesses:\n- I am not familiar with game theory (Prisoners\u2019 Dilemma) and Nash equilibrium, etc. presented in this paper, and had difficulty to truly understand the proposed model.\n- Although the experiment results suggest that the detection performance of the proposed model is superior to other models, more analysis/discussion (especially regarding sarcasm) will be helpful to show whether the proposed model works in an intended way or not.\n- the study about the impact of different hyperparameter settings? Where can I find them? ",
            "clarity,_quality,_novelty_and_reproducibility": "- it seems novel and original. overall it was clear to describe what was done. ",
            "summary_of_the_review": "The paper tackles the problem of sarcasm in hate speech, and the proposed model outperforms other baselines and state-of-the-art. However, some analysis or discussion to show the efficacy of the model will be helpful.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4804/Reviewer_xKDB"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4804/Reviewer_xKDB"
        ]
    },
    {
        "id": "2a2Gfj8-gDV",
        "original": null,
        "number": 4,
        "cdate": 1667400437880,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667400437880,
        "tmdate": 1667400437880,
        "tddate": null,
        "forum": "Gid_Z_oUV5q",
        "replyto": "Gid_Z_oUV5q",
        "invitation": "ICLR.cc/2023/Conference/Paper4804/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "In this paper authors propose to use two separate networks, one that is trained to detect hate speech and  the other that is trained to detect sarcasm. The final sarcasm detection score is then a combination of the outputs of both networks. ",
            "strength_and_weaknesses": "Strengths:\n\n- Good idea to try to separate out hate from sarcasm via separate network. \n\nWeaknesses:\n\n- Paper is clearly not in a finalized state, it needs a thorough efforts in polishing. From Figures to how literature is compared in bullet point fashion, without trying to synthesize it. \n- Ideas also are too simple. Of course simple ideas can also work and those would definitely be valuable, but then authors need a bullet proof experiments. To really show that ideas work. \n- Experiments are basically non-existent. Authors should note that main paper needs to have the main story supported by the experiments, anything that is in appendices are not necessarily read at all. \n- But most important point is that of course we can always fit model to any dataset with even randomly assigned labels. How you can validate that your trained method really can detect sarcasm? ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity and quality of exposition is not up to the standard. ",
            "summary_of_the_review": "Quality is not up to the standard. ",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4804/Reviewer_ioZ4"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4804/Reviewer_ioZ4"
        ]
    }
]