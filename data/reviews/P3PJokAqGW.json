[
    {
        "id": "kERyrUUgvB",
        "original": null,
        "number": 1,
        "cdate": 1666379454875,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666379454875,
        "tmdate": 1666379454875,
        "tddate": null,
        "forum": "P3PJokAqGW",
        "replyto": "P3PJokAqGW",
        "invitation": "ICLR.cc/2023/Conference/Paper3163/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The aim of this paper is to learn probability distributions in high dimensions with dominance constraints. To this end, the authors are exploiting the Choquet order between probability distributions, and introduce the notion of Variational Dominance Criterion, a divergence measure that captures the relative spread of a distribution with respect to some baseline. Notably, the Choquet-Toland distance between two distributions can be simply expressed as a sum of symmetric variational dominance criteria. Based on these notions, the authors show that VDC suffers from the curse of dimensionality, but a VDC surrogate defined in terms of input convex max-out networks can be estimated from a polynomial number of samples, using a simple stochastic gradient descent scheme. The experimental results on portfolio optimization and image generation corroborate the merits of this approach.\n",
            "strength_and_weaknesses": "Overall, I found the paper well-written: while I am not an expert in stochastic orders, I could follow most of the parts.  From a theoretical viewpoint, the sample complexities about VDC and CT estimations (especially the lower bound) justify the use of ICMNs, for which the main properties are summarized in Theorems 3 and 6. The applications of this framework to multivariate portfolio selection and GAN training are relevant. Finally, the experiments on image generation look promising.\n\nI did not find real weaknesses, but the paper is very dense. I would suggest slightly revising the introduction in order to strengthen the motivation for using convex orders in high dimensions.  \n",
            "clarity,_quality,_novelty_and_reproducibility": "As indicated above, I found the paper quite clear. \n\nSmall typo in Page 3: $\\mathbb E_{x \\sim \\mu_-} x = \\mathbb E_{x \\sim \\mu_+} x$.\n",
            "summary_of_the_review": "In essence, it is a well-written paper about efficient learning of probability distributions under dominance constraints, with interesting applications and promising experimental results. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3163/Reviewer_6Q2H"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3163/Reviewer_6Q2H"
        ]
    },
    {
        "id": "eU1MJEu2Tx",
        "original": null,
        "number": 2,
        "cdate": 1666448162868,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666448162868,
        "tmdate": 1666448162868,
        "tddate": null,
        "forum": "P3PJokAqGW",
        "replyto": "P3PJokAqGW",
        "invitation": "ICLR.cc/2023/Conference/Paper3163/-/Official_Review",
        "content": {
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors study the order between probability measures. They introduce a \"Choquet-Toland\" type distance between probability measures, which is a drop-in replacement for IPMs. They formulate a min-max framework for computing with stochastic orders. They also use the input convex maxout networks to compute the proposed distance. They demonstrate the results from numerical experiments fin high-dimensional image generation. The numerics demonstrate the successfulness of this definition. Some related analyses have been also conducted. \n\n",
            "strength_and_weaknesses": "Strength: They define a new class of distance functions and order between probability densities. \n\n\nWeakness:\n\n1.  Some grammar mistakes: \n\"if F is the set of functions with Lipschitz\" should be \"if F is the set of functions with 1-Lipschitz continuity\" . \n\n2. The application of the new distance/order is not clear to me. ",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: The authors define a new class order between probability densities. I am not sure how this definition relates to machine learning applications. I suggest authors motivate more on the importance of their definitions. ",
            "summary_of_the_review": "The paper is overall well written with clear proofs and some numerical examples. However, I am not sure about its applications, and its importance in image generation.  Some analytical examples could be important for me to judge the novelty of their definitions. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3163/Reviewer_K4TL"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3163/Reviewer_K4TL"
        ]
    },
    {
        "id": "iGgZY9pPmm",
        "original": null,
        "number": 3,
        "cdate": 1666696685604,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666696685604,
        "tmdate": 1666696685604,
        "tddate": null,
        "forum": "P3PJokAqGW",
        "replyto": "P3PJokAqGW",
        "invitation": "ICLR.cc/2023/Conference/Paper3163/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors propose to use stochastic orders, more precisely, the Choquet order, instead of the commonly used integral probability metrics, to provide a differentiable measurement of the distance between distributions. Then this Choquet order can be applied to probability density estimation. By applying the proposed Choquet order in WGAN-GP, the approach provides slightly better FID than WGAN-GP.",
            "strength_and_weaknesses": "Strengths:\n\n1. The motivation is clear and the written is mostly clear. The structure of the paper is good and it is easy to follow.\n2. The derivation part is solid, even though I did not check the derivation in detail, from the current structure I can see that most of the derivation should be correct, and the derivation of the final surrogate function should be correct.\n\nWeakness:\n\n1. While the theoretic part of the paper is ok, the experimental part of the paper is kind of week. Only one experiment is done on real dataset, and the dataset is quite simple. The CIFAR10 dataset, provides images with low resolutions, and currently it would be hard to tell if the proposed approach can be applied to generate high quality images? \n\n2. While the synthetic experiments prove that the proposed approach works well for low dimensional data, how the proposed approach would perform on high dimensional data is still very unclear based on current experimental results.\n\n3. The proposed distance is used along with WGAN-GP in the experiments, can it work without WGAN-GP?",
            "clarity,_quality,_novelty_and_reproducibility": "The reproducibility and clarity is good. The novelty might be ok. But the quality of the experiments is quite limited.",
            "summary_of_the_review": "The theoretic part of the paper is ok. The proposed approach is kind of more complicated than WGAN, current experiments fail to show that it is worth to apply such complicated techniques (i.e. the benefits of such techniques is still not clear).",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3163/Reviewer_K5E1"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3163/Reviewer_K5E1"
        ]
    },
    {
        "id": "h-89Ktzip2",
        "original": null,
        "number": 4,
        "cdate": 1666735947165,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666735947165,
        "tmdate": 1666735947165,
        "tddate": null,
        "forum": "P3PJokAqGW",
        "replyto": "P3PJokAqGW",
        "invitation": "ICLR.cc/2023/Conference/Paper3163/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "This paper revisits standard Optimal Transport concepts through the lens of convex orders. In particular, the authors introduce the Variational Dominance Criterion (VDC, equation 1), which possesses some interesting properties due to the asymmetry of the space ${\\cal A}$ with respect to which the supremum is taken. The VDC is then thoroughly studied: statistical rates for the VDC estimation are given (Thm 2), an approximation based on maxout networks is proposed, that has parametric rate (Thm 3), a pseudo distance, the CT distance is then introduced and studied as well. Experiments are presented to show the relevance of the metrics introduced.",
            "strength_and_weaknesses": "**Strengths**\n- the paper is globally clear and well written\n- the topic addressed is of high interest to the ICLR community\n- the contributions are important and well supported. In particular the surrogate VDC is very interesting. I also like that the approximation error due to the VDC surrogate is discussed at the end of Section 5\n- the interest of the approach is proven empirically. Exhibiting a practical example where the dominance is needed is nice\n\n**Weaknesses**\n- from my understanding, the asymmetry of the proposed criterion is one of its main novelty and interest. Then, I feel it might be discussed more into details why the CT distance, that breaks this good feature, is interesting. In particular, how is better than standard IPMs?\n- there is a notation clash between the cone $K$ and the constant in the theorems\n- last line of first paragraph of Section 2: \"for any $f \\in \\mathcal{F}$\" is missing\n- Thm 1: the equation numbering is weird, the push forward notation is not defined",
            "clarity,_quality,_novelty_and_reproducibility": "Very good\n\n",
            "summary_of_the_review": "Overall I like the paper and think it should be accepted.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper3163/Reviewer_QEba"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper3163/Reviewer_QEba"
        ]
    }
]