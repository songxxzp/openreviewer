[
    {
        "id": "m0gp00mnz17",
        "original": null,
        "number": 1,
        "cdate": 1666593365445,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666593365445,
        "tmdate": 1666593365445,
        "tddate": null,
        "forum": "YCMKCwN4PQw",
        "replyto": "YCMKCwN4PQw",
        "invitation": "ICLR.cc/2023/Conference/Paper2119/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper argues that current Graph Neural Networks (GNNs) suffer from high time cost when trained on massive data, and class-imbalance issue. The authors then propose GraphDec to address the problems by pruning both GNN and the training data.",
            "strength_and_weaknesses": "## Strength\n(+) The authors provide plentiful empirical results to show the effectiveness of GraphDec.\n\n## Weakness\n(-) Motivation is unclear. \n- Does the imbalance class problem really exist when massive training data is available? \n- Why do the authors choose self-supervised graph contrastive learning? If the model is learned in a self-supervised fashion, does it suffer from class-imbalance?\n\n(-) Key theoretical results seem to be irrelevant with GNNs, graph contrastive learning. Furthermore, I can not see the connections between the proposed methods and the theorem. \n\n(-) Moreover, class-imbalance issue seems not to be considered in method design, making the readers confusing about the improvements in experiments. \n\n(-) The main method seems not to consider any characteristics of graphs and GNNs, but a bag of tricks when applying Data Diet to graph contrastive learning.\n\n(-) The main method also introduces additional computation and memory overheads, which makes readers confusing about its advantages compared to existing graph contrastive learning, sparsity and class-imbalanced learning methods. Besides, the authors did not provide any efficiency checks such as complexity or the running time cost in experiments.\n\n(-) The authors did not compare other pruning methods and the state-of-the-art graph contrastive learning methods. The node classification experiments did not include graph contrastive learning methods either.\n\n(-) There are too many hyperparameters are introduced, but the authors did not test the sensitivity to these hyperparameters.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The problem seems to be new and interesting, but the writing and the organization of the paper is hard for readers to get the idea that the authors try to convey. There are unclarified points, concepts and typos. Here are some examples:\n\n- In Theorem 1, what\u2019s $L^i_{train}$? \n- In Theorem 1, why the validation loss in involved?\n- In Theorem 1, what\u2019s $\\sigma_T$?\n- In Theorem 1, what\u2019s the point to upper bound a minimum number?\n- Eq. 4: the input is $x^{(t)}$?\n- In Eq. 4-5, what\u2019s $\\theta_{pruned}$? Is it irrelevant with $t$?\n",
            "summary_of_the_review": "I vote for a reject. As pointed out in Weakness, the motivation of the paper is unclear, the proposed methods along with the theory seems to be irrelevant to the problems (the massiveness and class-imbalance in graphs) that the authors try to address, making the main methodology is full of tricks and the paper too technical.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None.",
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2119/Reviewer_ta4g"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2119/Reviewer_ta4g"
        ]
    },
    {
        "id": "gvQofgv_NzA",
        "original": null,
        "number": 2,
        "cdate": 1666632841887,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666632841887,
        "tmdate": 1666632841887,
        "tddate": null,
        "forum": "YCMKCwN4PQw",
        "replyto": "YCMKCwN4PQw",
        "invitation": "ICLR.cc/2023/Conference/Paper2119/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "This paper addresses the class-imbalance problem in graph learning. The authors propose Graph Decantation (GraphDec) framework for learning balanced graph representation in a self-supervised manner. The key procedure of GraphDec is to select some informative samples from unbalanced node data or graph data during training based on the gradient norm. The idea is interesting and novel, and the method is generally applicable to either node-level or graph-level class-imbalance situations.",
            "strength_and_weaknesses": "Strength:\n1. The idea of unifying dynamic informative subset selection and subnetwork selection during training is a first exploration and compelling. In addition, as a rebalancing method in this paper, data and model co-pruning do not require additional learnable weights or human-crafts hyperparameters. It can be used as a plug-and-play tool for other GNN models.\n\n2. The model design is well-driven by an intriguing hypothesis. It theoretically examines the extent to which a subset of the training data can approximate the learning efficiency of the entire dataset. Based on the hypothesis, the methods and experiments also demonstrate the rebalanced subset's gradients can effectively approximate the entire imbalanced dataset. \n\n3. The authors suggest Graph Decantation (GraphDec) as a solution to the difficulties posed by training on huge class-imbalanced graph data. Utilizing the self-pruned contrastive framework's sensitivity on informative samples to gradually refine a more balanced subset is an innovative approach. Consequently, this subset can reduce learning computation and train the model contributing more balanced predictions for classifying graph data.\n\n4. The experiments are sufficient and the improvement of GraphDec is significant. Particularly, the experiments studying the \"Evolution of Sparse Subset by Scoring All Samples\" are interesting, which supports the paper's motivation and inspires readers.\n\n\nWeakness:\n1. Does the idea of dynamically mining informative samples be applicable to some supervised frameworks? It will be nice to discuss the effect of applying the self-supervised learning (SSL) framework since the motivation for using SSL needs to be strengthened. Also, I think the problem of imbalance classification on the graph is very general among supervised and self-supervised settings. It is better to analyze the generality of GraphDec.\n\n2. When I see the GraphDec sorting neural weights and data samples for pruning, I am expecting the exact computation consumption of this model-data joint optimization can be clearly shown. I am not sure whether the method can actually trim down the computational cost.",
            "clarity,_quality,_novelty_and_reproducibility": "Core resources (e.g., code, data) are available. The submission contains sufficient details (e.g., proofs, experimental setups) to be useful and clear to other researchers. The overall method is novel and ingenious.\n",
            "summary_of_the_review": "This is a technically sound paper with novel ideas on dynamic graph learning model and data sparsity, and its impact on the community is not restricted to the graph area. I believe that the experimental evaluation results are encouraging and sufficient. I would like to accept this novel and solid work. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2119/Reviewer_9iT6"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2119/Reviewer_9iT6"
        ]
    },
    {
        "id": "MKlf3E-baSw",
        "original": null,
        "number": 3,
        "cdate": 1666685176086,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666685176086,
        "tmdate": 1666685176086,
        "tddate": null,
        "forum": "YCMKCwN4PQw",
        "replyto": "YCMKCwN4PQw",
        "invitation": "ICLR.cc/2023/Conference/Paper2119/-/Official_Review",
        "content": {
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "summary_of_the_paper": "The paper aims to solve both graph data imbalance and unnecessary model-level computation burden in a unified framework. Specifically, the authors first examine the challenges from theoretical and empirical perspectives. Then, the authors propose GraphDec, a novel data-model dynamic sparsity framework to address the challenges. Extensive experiments on multiple benchmark datasets demonstrate that GraphDec outperforms state-of-the-art methods.",
            "strength_and_weaknesses": "+This work is solid and insightful. The proposed framework investigates a new perspective in which sparsification can be utilized in both graph datasets and graph neural networks, which possess many advantages for real-world applications. For example, this work can be leveraged to detect important data points and conserve computational time.\n\n+The authors conduct comprehensive ablation studies to evaluate each model components, which clearly show the contributions of every module and the impact of rebalancing strategies.\nThe introduced components such as dynamically downsampling important subsets, and pruning contrastive model are empirically proven to contribute distinct positive impacts to the full framework. Despite employing a subset of the data, the proposed method achieves similar or better performance compared to the methods that utilize the entire dataset. \n\n+ The overall structure is based on an intriguing hypothesis with proof. The authors provide a hypothesis to explain why downsample a subset can estimate the entire graph dataset; they infer that the subset with the gradient closest to the gradient of the entire dataset is the most important. They then apply this inspiration to develop GraphDec. In addition, the inspiration provided by this hypothesis is also relevant for tasks in other domains (e.g., computer vision, natural language processing).\n\nWeakness/questions:\n-What is the purpose of training the contrastive learning system? Does this method exclude other learning schemes and supervised loss? The paper can be improved by highlighting the unique effect, such as a concise summary of the motivation and empirical ablation experiments.\n\n-Certain technical descriptions lack clarity for readers unfamiliar with coresets. In the experiment section, for instance, the word \"prune\" is sometimes used in a rather ambiguous manner. In the previous method section, it refers to the network, whereas in the experiment section, prune appears to be the \"sampling\" step of the dataset. The authors should provide additional information to explain the definitions of prune and sample on data and model or clarify that the terms are used in different sentences.\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and the methodology is well-motivated. The designed model is novel and solid. The availability of code and data facilitates reproducibility.",
            "summary_of_the_review": "The paper address two significant challenges of imbalanced graph learning by designing a novel and effective model. The technical contribution is solid. The empirical explanations are interesting, and the experimental results are remarkable. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper2119/Reviewer_ZWS9"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper2119/Reviewer_ZWS9"
        ]
    }
]