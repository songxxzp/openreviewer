[
    {
        "id": "1FHeTlhIIX",
        "original": null,
        "number": 1,
        "cdate": 1666307125744,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666307125744,
        "tmdate": 1666497347015,
        "tddate": null,
        "forum": "woOQ5Hb1oOF",
        "replyto": "woOQ5Hb1oOF",
        "invitation": "ICLR.cc/2023/Conference/Paper4754/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This work attempts to apply diffusion models to synthesize EEG data as data augmentation. Specifically, the work uses the continuous-time diffusion framework with progressive distillation as their methodology. The synthesized data is validated based on training on the VEPESS dataset and the BCIC4D2a dataset, where a set of model validation tasks are performed including (1) quality evaluation on the generated class-conditioned data, (2) quality evaluation on the generated subject-conditioned data, and (3) how the generated data could help classification performance.",
            "strength_and_weaknesses": "Strength\n\n1. The paper presented a set of interesting application tasks/experiments on EEG datasets.\n2. Many tasks are considered, including class-conditioned generation, subject-conditioned generation, and classification. \n\nWeaknesses\n1. Major concern 1: the method lacks novelty\n- The presented work is a simple application of existing diffusion model + progressive distillation on EEG datasets. No novel method is presented.\n\n2. Major concern 2: experimental evaluation\n- There exists only one benchmark model throughout the paper. The authors give their reason as \u201cWe chose only the RWGAN (Panwar et al. (2020)) as a baseline model because other deep learning models in the literature were either incompletely documented, designed only for single-channel EEG generation, or did not work based on the given information in the published work.\u201d However, I found it hardly a valid reason for not implementing enough benchmarks. (1) If the model isn\u2019t completely documented, one should try to implement it based on customized design and model choice that is fairly selected. (2) One could always try to implement classic models such as naive VAE or GAN based on the presented setting. (3) \u201cThe model does not work\u201d also is an unvalidatable claim as it is unclear if it is reviewer\u2019s coding issue or if it is the models\u2019 issue.\n- Due to the lack of benchmarking models, both Table 1 and Table 2 are not really informative and do not tell if the model perform good enough. First of all, for many scores the test-set score is better than the model\u2019s performance, which only give a controversial conclusion because it either indicates that (1) the dataset is distributed in a certain diverse way and the model does not overfit (which indicates in certain case the lower the score the better), (2) the model does not perform well enough to mimic the training set structure. That is why most existing works under this setting would just train many models on the whole dataset and compare different models\u2019 performance.\n- The augmentation experiments is not complete. There are no benchmarking models. One thing that can be done is to use the generated data as augmentation and compare it with traditional augmentation (e.g. noise). Also one could benchmark the generated data from this model to the generated images from other models (the GAN that is implemented beforehand).\n- Overall, there isn\u2019t sufficient quantitative evaluation as well.\n\n3. The writing isn\u2019t clear.\n- There are many grammar errors and wording issues throughout.\n\n4. Related works are not summarized and compared properly.\n",
            "clarity,_quality,_novelty_and_reproducibility": "The clarity has a large room for improvement.\nThe quality and the novelty are both not sufficient.\n",
            "summary_of_the_review": "I suggest rejection. The paper lacks methodology novelty, and the evaluation procedure lacks benchmarking and quantitative evaluations.",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4754/Reviewer_UL6z"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4754/Reviewer_UL6z"
        ]
    },
    {
        "id": "KQD6jWcKQN",
        "original": null,
        "number": 2,
        "cdate": 1666609488854,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666609488854,
        "tmdate": 1666609488854,
        "tddate": null,
        "forum": "woOQ5Hb1oOF",
        "replyto": "woOQ5Hb1oOF",
        "invitation": "ICLR.cc/2023/Conference/Paper4754/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "The work shows a way of generating brain signals that can be useful in augmentation tasks. The current work shows that DPM-based brain signal generation is a very feasible task and can be used to create datasets that help improve deep learning models in classification tasks.\n",
            "strength_and_weaknesses": "*Strength \n\n-This work explored the application of the diffusion probabilistic model in EEG analysis.\n\n-A large number of experiments were carried out on the manuscript.\n\n*Weaknesses\n\n- Technological innovation is limited. It is just a simple application of diffusion probabilistic model in specific fields.\n\n-Although some evaluation indicators are effective. But I am worried about the value of practical application. As the authors mentioned, the classification performance on EEGNet cannot be improved.\n\n-The details of the model are too simple. For example, what is Swish in the model diagram.\n",
            "clarity,_quality,_novelty_and_reproducibility": "-The range of chromaticity bars in Figure 2 and Figure 5 is different. So some visual comparisons seem unfair.\n\n-Why are some EEG-GANs not compared as baseline methods?\n\nPlease see the other specific comments in Strength And Weaknesses.",
            "summary_of_the_review": "This is a typical application study. The diffusion probabilistic is simply applied to EEG. Some details still need to be clarified by the authors.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4754/Reviewer_fUSb"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4754/Reviewer_fUSb"
        ]
    },
    {
        "id": "Nj8kGm2Mtns",
        "original": null,
        "number": 3,
        "cdate": 1666818095319,
        "mdate": null,
        "ddate": null,
        "tcdate": 1666818095319,
        "tmdate": 1666818819705,
        "tddate": null,
        "forum": "woOQ5Hb1oOF",
        "replyto": "woOQ5Hb1oOF",
        "invitation": "ICLR.cc/2023/Conference/Paper4754/-/Official_Review",
        "content": {
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "summary_of_the_paper": "This paper applies recent generative model, diffusion probabilistic model (DPM), to generate synthetic electroencephalography (EEG) data with utility demonstrated in two BCI applications (event-related potentials and motor imagery) using publicly available BCI datasets.",
            "strength_and_weaknesses": " \nStrengths: \n\n- Authors present qualitative and quantitative results on the generated EEG signals, generating user-specific data, the impact of data augmentation on the downstream task (EEG signal classification) and progressive distillation to improve inference time. \n\n- Results presented from two BCI applications (event related potential, motor imagery).\n\nWeaknesses: \n\n-    The results that are most relevant to data augmentation (section 5.4) do not really support the authors claims. \"These observations\nimply that although EEGWave was able to learn the main characteristics of the real signals, it could not produce signals that are diverse enough to regularize EEGNet.\" \n\n- Figure and table captions need to be more informative to better interpret presented results. Are they subject-specific or presented in aggregate? Within-subject performance is more relevant in BCI applications as trends may sometimes be linked to EEG signal quality (signal-to-noise ratio). If presenting results in aggregate, an analysis comparing within-subject performance across all conditions needs to be included. \n\n-    Since the authors contrasts DPM with RWGAN, classification results (not just assessment of the generated EEG signals) with synthetic data generated with GAN need to be included given that DPMs are slower (inference time also needs to be included for comparison). This is relevant in assessing the trade-off. Signal fidelity may not necessarily be as relevant if it has minimal/no impact on the performance of the classification task (the model only learns the most relevant features to distinguish between classes).\n\n\n",
            "clarity,_quality,_novelty_and_reproducibility": "Clarity: Overall, the paper is generally readable, well-organised and the relevant authors (DPM, distillation) cited. However, several sections, particularly methods and results are confusing. Figure captions should be more informative, axes labeled, legends and acronyms need to be defined in the tables/figure captions. \n\nQuality: The most relevant set of results to support the authors claims on data augmentation, section 5.4, is the weakest section of the paper. Statistical analyses are needed to evaluate the significance of the results. \n\nNovelty: The authors apply recent methods in the literature (DPM, progressive distillation) to EEG signal generation. Authors claim this is the first application of DPM to EEG data.\n\nReproducibility: Additional details need to be described to better reproduce the findings. ",
            "summary_of_the_review": "Recommendation is based mainly on the weaknesses outlined above. \n\nOther comments\n-\t\u201cFinding publicly available brain signal datasets that meet all requirements is a challenge.\u201d\n         o\tWhat do authors mean by \u201call requirements\u201d?\n\n-\t\u201cHowever, the spatial resolution of the technology is quite poor due to its heavy dependence on the number of electrodes used for signal recording and non-invasiveness.\u201d \n         o\tAuthors should expand on relevance of this to the proposed work. \n\n-\t\u201cThe size and quality of publicly available data sets are limited, also often insufficient and imbalanced.\u201d\n         o\tThere are several publicly available BCI datasets. Authors should provide evidence (references, characteristics of publicly available datasets, etc.) to support this claim.\n         o\tThe traditional approach to training machine learning models for BCI use is to rely on user-specific data. How are publicly available datasets relevant/useful within this training paradigm?\n\n-\t\u201cWe chose only the RWGAN (Panwar et al. (2020)) as a baseline model because other deep learning models in the literature were either incompletely documented, designed only for single-channel EEG generation, or did not work based on the given information in the published work.\u201d\n          o\tAuthors should reference the other models that were considered. \n          o    What do authors mean by \u201cdid not work\u201d? Needs to be more specific.\n\n-\tDiederik P Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. On density estimation with diffusion models.\n         o\tUpdate title of paper in reference\n\n-\tMore informative caption for Figure 1.\n\n-\tWhat are EEGWave, EEGWave 1x, EEGWave 1024 step, EEGWave 1 step? Figure 1 caption needs to be more description/informative.\n\n-\t\u201cWe give both qualitative and quantitative results\u201d\n         o\tDistinguish between the qualitative and quantitative results listed, and include a brief description of each measure.\n\n- The value of the subject-specific result section (section 5.3), especially to the classification task is not clear. One limitation is that the model is restricted to the subjects in the training dataset (subject labels are one-hot encoded), so needs to be retrained each time a new subject is added. Based on section 5.4, data from several subjects are combined to create the training/validation sets. \n\n-\tAre results presented in the figures/tables from one subject? Mean aggregate over all subjects? This needs to be specified in the captions. Preferably, subject-specific results are desirable, especially with relatively few subjects (18 and 9). Waveforms can be illustrated with data from a few subjects. If presented in aggregate, what are the number of subjects and the standard deviation for the measures presented in the table? What does bold mean in each table?\n\n-\tWhat do labels 0, 1, 2, 3 in Figures 6 and 7 mean. Label y-axes in Figures 8 and 9. What is \"Base\" in figures 8 and 9?\n\n-\t\u201cAlthough the mixed training gave slightly better accuracy on the validation subset during training, it did not improve the accuracy of the test set. On the contrary, with the pre-training approach, the model converged faster and achieved better accuracy on the test.\u201d\n      o    Reference the relevant figures in the text. Are these aggregate results?\n\n-\t\u201cThe number of training iterations in steps 2 and 1 is doubled, following the work of _.\u201d\n\n-\t\u201cWe believe the current work shows that DPM-based brain signal generation is a very feasible task and can be used to create datasets that help improve deep learning models in classification tasks.\u201d\n\n-   \u201cThe metrics commonly used in image synthesis tasks often give contrary results in brain signal generation.\u201d\n       o  Can authors explain what this means, especially \"contrary results\"? How is this relevant in interpreting results. What measures do the authors propose that are more relevant to brain signal generation?\n",
            "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4754/Reviewer_e92U"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4754/Reviewer_e92U"
        ]
    },
    {
        "id": "QzxG0d9T-l",
        "original": null,
        "number": 4,
        "cdate": 1667102048138,
        "mdate": null,
        "ddate": null,
        "tcdate": 1667102048138,
        "tmdate": 1667102048138,
        "tddate": null,
        "forum": "woOQ5Hb1oOF",
        "replyto": "woOQ5Hb1oOF",
        "invitation": "ICLR.cc/2023/Conference/Paper4754/-/Official_Review",
        "content": {
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "summary_of_the_paper": "The authors proposed the use of diffusion probabilistic models (DPMs) to generate EEG data in order to increase the size of datasets for training brain-computer interface classifiers. The qualitative and quantitative characteristics of the generated dataset were compared to the RWGAN model. The DPM model turned out to be comparable with RWGAN. The dataset of evoked potentials and the task of separating imaginary movements were taken as initial datasets. The authors note that DPM is able to generate EEG recordings that preserve the individual characteristics of subjects. The possibility of increasing the performance of EEGNet on the BCI4D2a dataset (classification of imaginary movements) was considered by expanding the dataset with generated data and by pretraining the dataset on these data. The second approach showed better results.",
            "strength_and_weaknesses": "# Strengths\n\n-   The authors have shown that diffusion probabilistic models (DPMs) are promising for generating brain data.\n-   The problem to be solved is sufficiently substantiated in the introduction.\n-   Two different datasets with different tasks are considered\n\n# Weaknesses\n\n-   It is not clear how the data was divided into train and test sets in section 5.2\n-   a more detailed analysis of the specificity of subjects is missing (Section 5.3):\n    \n    1.  it would be good to supplement with a comparison\n    \n    of the specificity of subjects with other methods,\n    \n    1.  It is interesting to see the class of problems where such a property of the method is an advantage, and in which it is a limitation. Does this mean that this method cannot generate new subject data?\n-   In section 5.4, the conclusion that pretraining on the generated data gives a gain is not obvious from the form of the matrix. Perhaps a general statistic would help.\n\nDDIM - no decryption of the abbreviation One-hot - typo The number of training iterations in steps 2 and 1 is doubled, following the work of . - link missing",
            "clarity,_quality,_novelty_and_reproducibility": "Clear, but not terribly original demonstration that diffusion models have a potential for EEG signal generation.",
            "summary_of_the_review": "A paper applying diffusion models to the task of EEG data generation. Although the idea is interesting and the results are potentially promising, as mostly an application, the paper lacks in rigorous evaluation and empirical demonstration.",
            "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold"
        },
        "signatures": [
            "ICLR.cc/2023/Conference/Paper4754/Reviewer_bBMm"
        ],
        "readers": [
            "everyone"
        ],
        "nonreaders": [],
        "writers": [
            "ICLR.cc/2023/Conference",
            "ICLR.cc/2023/Conference/Paper4754/Reviewer_bBMm"
        ]
    }
]